{
  "task_id": "17_3",
  "conversation_id": "17",
  "turn_id": 3,
  "domain": "cloud",
  "input": "Major. menor update.",
  "gold_answer": " To determine the type of update that is available, compare your current worker node versions to the latest worker node fix pack version in the Red Hat OpenShift version change log. Major updates are indicated by the first digit in the version label (4.x.x), minor updates are indicated by the second digit (x.7.x).  A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.             ",
  "enrichments": {
    "Question Type": [
      "Keyword",
      "Summarization"
    ],
    "Multi-Turn": [
      "Clarification"
    ],
    "Answerability": [
      "ANSWERABLE"
    ]
  },
  "retrieved_contexts": [
    {
      "document_id": "ibmcld_06160-11142-12906",
      "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.",
      "url": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready",
      "score": 50.470383,
      "feedback": {
        "relevant": {
          "868c6e58-57c1-48ee-8c67-832dbedcac18": {
            "value": "no",
            "timestamp": 1724166608
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "|user|: What are the steps to be taken to gather the relevant worker node data?\n|assistant|:    There are general steps to gather the relevant worker node data: First,  Check the conditions of your worker nodes and cluster before you gather data. This includes checking the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.Secondly if all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.  Before opening a support ticket, it is recommended to review the information and follow any troubleshooting steps in Debugging worker nodes, Worker node states, and Troubleshooting worker nodes in Critical or NotReady state. To gather worker node data, you can use the command 'kubectl top node' (for Kubernetes clusters) or 'oc top node' (for OpenShift clusters), which will display the CPU and memory usage of each node and once you have gathered this information, include it in your support ticket when you open one.                        \n|user|: How can i update a classic worker node?\n|assistant|: An update is available for your worker nodes in a classic infrastructure cluster. As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version. For Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.You can update the master Kubernetes version with the ibmcloud ks cluster master updatecommand. Remember that your worker nodes can be only up to two versions behind the master version (n-2). The worker node IP address remains the same after the update operation.\n|user|: Major. menor update."
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_10596-11475-13230",
      "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%",
      "url": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready",
      "score": 50.23218,
      "feedback": {
        "relevant": {
          "868c6e58-57c1-48ee-8c67-832dbedcac18": {
            "value": "no",
            "timestamp": 1724676697
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "|user|: What are the steps to be taken to gather the relevant worker node data?\n|assistant|:    There are general steps to gather the relevant worker node data: First,  Check the conditions of your worker nodes and cluster before you gather data. This includes checking the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.Secondly if all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.  Before opening a support ticket, it is recommended to review the information and follow any troubleshooting steps in Debugging worker nodes, Worker node states, and Troubleshooting worker nodes in Critical or NotReady state. To gather worker node data, you can use the command 'kubectl top node' (for Kubernetes clusters) or 'oc top node' (for OpenShift clusters), which will display the CPU and memory usage of each node and once you have gathered this information, include it in your support ticket when you open one.                        \n|user|: How can i update a classic worker node?\n|assistant|: An update is available for your worker nodes in a classic infrastructure cluster. As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version. For Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.You can update the master Kubernetes version with the ibmcloud ks cluster master updatecommand. Remember that your worker nodes can be only up to two versions behind the master version (n-2). The worker node IP address remains the same after the update operation.\n|user|: Major. menor update."
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_10394-7-1848",
      "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.",
      "url": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic",
      "score": 49.73401,
      "feedback": {
        "relevant": {
          "868c6e58-57c1-48ee-8c67-832dbedcac18": {
            "value": "no",
            "timestamp": 1724168625
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "|user|: What are the steps to be taken to gather the relevant worker node data?\n|assistant|:    There are general steps to gather the relevant worker node data: First,  Check the conditions of your worker nodes and cluster before you gather data. This includes checking the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.Secondly if all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.  Before opening a support ticket, it is recommended to review the information and follow any troubleshooting steps in Debugging worker nodes, Worker node states, and Troubleshooting worker nodes in Critical or NotReady state. To gather worker node data, you can use the command 'kubectl top node' (for Kubernetes clusters) or 'oc top node' (for OpenShift clusters), which will display the CPU and memory usage of each node and once you have gathered this information, include it in your support ticket when you open one.                        \n|user|: How can i update a classic worker node?\n|assistant|: An update is available for your worker nodes in a classic infrastructure cluster. As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version. For Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.You can update the master Kubernetes version with the ibmcloud ks cluster master updatecommand. Remember that your worker nodes can be only up to two versions behind the master version (n-2). The worker node IP address remains the same after the update operation.\n|user|: Major. menor update."
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_10642-7855-9754",
      "text": "\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.",
      "url": "https://cloud.ibm.com/docs/openshift?topic=openshift-update",
      "score": 15.150766,
      "feedback": {
        "relevant": {
          "868c6e58-57c1-48ee-8c67-832dbedcac18": {
            "value": "yes",
            "timestamp": 1724166681
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "What means a Major. minor update?"
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_10642-6354-8294",
      "text": "\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.",
      "url": "https://cloud.ibm.com/docs/openshift?topic=openshift-update",
      "score": 12.376706,
      "feedback": {
        "relevant": {
          "868c6e58-57c1-48ee-8c67-832dbedcac18": {
            "value": "yes",
            "timestamp": 1724166709
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "What means a Major. minor update?"
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_11770-14487-16386",
      "text": "\n[Assign the newly attached hosts to your Satellite resource](https://cloud.ibm.com/docs/satellite?topic=satellite-assigning-hostshost-assign-manual). These hosts automatically receive the update when you assign them.\n4. After the new hosts are successfully assigned to your Satellite resource, [remove and delete the old hosts that you previously noted](https://cloud.ibm.com/docs/satellite?topic=satellite-host-remove).\n\n\n\n\n\n\n\n Updating worker node hosts in the Red Hat OpenShift on IBM Cloud console \n\nYou can update worker node hosts by using the Red Hat OpenShift on IBM Cloud console.\n\n\n\n1. Log in to the IBM Cloud console and click OpenShift > Clusters.\n2. Click the cluster where the hosts that you want to update are assigned and navigate to the Worker nodes page.\n3. Select each host that you want to update. After you select the hosts, an Update option appears.\n4. Click Update. In the dialog box that appears, click Update again. A message appears that the update started successfully.\n5. Wait while the hosts update. The update process for each host is complete when the Status of the host returns to Normal and the new version is listed in the Version column.\n\n\n\n\n\n\n\n Determining if the worker node version update is a major, minor, or patch update \n\nThe process to update a worker node is the same for all types of updates. However, you can find information on whether the update is a major, minor, or patch update.\n\nTo determine the type of update that is available, compare your current worker node versions to the latest worker node fix pack version in the [Red Hat OpenShift version change log](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions). Major updates are indicated by the first digit in the version label (4.x.x), minor updates are indicated by the second digit (x.7.x) and patch updates are indicated by the trailing digits (x.x.23_1528_openshift).",
      "url": "https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers",
      "score": 12.378856,
      "feedback": {
        "relevant": {
          "868c6e58-57c1-48ee-8c67-832dbedcac18": {
            "value": "yes",
            "timestamp": 1724166736
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "What means a Major. minor update?"
                }
              }
            }
          }
        }
      }
    }
  ],
  "timestamp": 1724166019
}