{
  "task_id": "26_3",
  "conversation_id": "26",
  "turn_id": 3,
  "domain": "cloud",
  "input": "how can I improve query",
  "gold_answer": "You can use the tools that are built into Discovery to make improvements. If you want more control over how queries are handled, you must use the query API. Cataloging improves your query performance, especially for text-based data formats where the schema inference requires a full scan of the data before the actual query execution. Adding a custom stop words list can improve the relevance of results for natural language queries. You can also improve the quality of search results by expanding the meaning of the queries that are submitted by customers.",
  "enrichments": {
    "Question Type": [
      "How-To"
    ],
    "Multi-Turn": [
      "Follow-up"
    ],
    "Answerability": [
      "ANSWERABLE"
    ]
  },
  "retrieved_contexts": [
    {
      "document_id": "ibmcld_07045-7-2118",
      "text": "\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.",
      "url": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-improvements",
      "score": 13.19539,
      "feedback": {
        "relevant": {
          "dc79eb51-e320-43c1-841c-3b1baa66d0aa": {
            "value": "yes",
            "timestamp": 1724209870
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "improve query"
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_13498-1605-3435",
      "text": "\nThus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.\n\nCommon table expressions are defined by using the reserved keyword WITH followed by one or more named queries. Each common table expression that is specified can also be referenced by name in the FROM clause of subsequent common table expressions.\n\nCreating a common table expression avoids the overhead of creating and dropping an intermediate result object on Cloud Object Storage that is needed only for a certain query.\n\nMoreover, a common table expression is beneficial when the same result table must be shared in a fullselect.\n\n\n\n\n\n Examples \n\nThe common table expression examples use values clauses to define tables inline. For more information about the values clause, see [valuesClause](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencevaluesClause).\n\n-- find the department with the highest total pay\nWITH dtotal AS (\nSELECT\ncol1 AS deptno,\nSUM(col3+col4) AS totalpay\nFROM VALUES -- deptno, empid, salary, bonus\n(1, 1, 1000, 0), (1, 2, 2000, 500), (1, 3, 3000, 0),\n(2, 4, 5000, 200), (2, 5, 6000, 0), (2, 6, 4000, 0),\n(3, 7, 2000, 500), (3, 8, 2000, 500), (3, 9, 8000, 0)\nGROUP BY col1\n)\nSELECT deptno\nFROM dtotal\nWHERE totalpay = (SELECT MAX(totalpay) FROM dtotal)",
      "url": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference",
      "score": 11.480839,
      "feedback": {
        "relevant": {
          "dc79eb51-e320-43c1-841c-3b1baa66d0aa": {
            "value": "yes",
            "timestamp": 1724209872
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "improve query"
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_07163-1627-3707",
      "text": "\nSee [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https://cloud.ibm.com/docs/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\nThe components needed to train a Discovery instance include the following:\n\n\n\n* Training data. This is the set of queries and examples the service uses to refine query results.\n* Query. A natural-language query that applies to the training-data set. Each query has one or more associated examples, as described in the following bullet point. Each query must be unique within the training-data set.\n* Example. This is a document indexed in a Discovery collection that acts as an exemplar, good or bad, for the associated query. When you add an example to a training-data query, you include a relevance label that indicates the relevance (or \"goodness\" versus \"badness\") of the document as it applies to the specified query.\n\nExamples are identified by the indexed document ID. As noted, every example must include a label that indicates the \"goodness\" or \"badness\" of the document as it pertains to the query.\n\nExamples can optionally specify a cross-reference query. The cross-reference query needs to return only the example document and must be independent of the unique Watson Discovery document ID. Cross-reference queries are not currently used automatically but can be used to repair training data in the event that new IDs are assigned to documents during an ingestion event.\n\n\n\n\n\n Training data requirements",
      "url": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api",
      "score": 11.536515,
      "feedback": {
        "relevant": {
          "dc79eb51-e320-43c1-841c-3b1baa66d0aa": {
            "value": "yes",
            "timestamp": 1724209873
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "improve query"
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_13075-7-2200",
      "text": "\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).",
      "url": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-tooling",
      "score": 11.319935,
      "feedback": {
        "relevant": {
          "dc79eb51-e320-43c1-841c-3b1baa66d0aa": {
            "value": "yes",
            "timestamp": 1724209875
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "improve query"
                }
              }
            }
          }
        }
      }
    },
    {
      "document_id": "ibmcld_07108-7-1958",
      "text": "\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":",
      "url": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-settings",
      "score": 11.390717,
      "feedback": {
        "relevant": {
          "dc79eb51-e320-43c1-841c-3b1baa66d0aa": {
            "value": "yes",
            "timestamp": 1724209877
          }
        }
      },
      "query": {
        "query": {
          "bool": {
            "must": {
              "text_expansion": {
                "ml.tokens": {
                  "model_id": ".elser_model_1",
                  "model_text": "improve query"
                }
              }
            }
          }
        }
      }
    }
  ],
  "timestamp": 1724209769
}