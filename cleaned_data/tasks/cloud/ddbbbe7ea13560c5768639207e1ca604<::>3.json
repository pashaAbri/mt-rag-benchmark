{
  "task_id": "ddbbbe7ea13560c5768639207e1ca604<::>3",
  "conversation_id": "38",
  "turn_id": 3,
  "domain": "cloud",
  "user": {
    "speaker": "user",
    "text": "data volume",
    "timestamp": 1724763580,
    "enrichments": {
      "Question Type": [
        "Keyword",
        "Non-Question",
        "Summarization"
      ],
      "Multi-Turn": [
        "Follow-up"
      ],
      "Answerability": [
        "ANSWERABLE"
      ]
    }
  },
  "agent": {
    "speaker": "agent",
    "text": "There are certain guidelines for the volume of data when adding documents for annotation to train a machine learning model. It is recommended to provide a set of documents that have a total size of about 300,000 words. The number of words can be adjusted based on the complexity of the type system. Each document should be limited to a page or two of content, preferably fewer than 2,000 words and closer to 1,000 words per document.  A goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.  The set of documents for training must contain at least 10 annotated documents.",
    "timestamp": 1724763584,
    "contexts": [
      {
        "document_id": "ibmcld_16487-7-2224",
        "text": "\nAdding documents for annotation \n\nTo train a machine learning model, you must add documents that contain subject matter knowledge, such as journal articles or other industry-specific texts, to your workspace.\n\n\n\n About this task \n\nThis section describes how to add documents for annotation only. To define rules for the rule-based model, you add or upload documents from which you can draw patterns to define as rules. See [Adding documents for defining rules](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_anno_add) for more information.\n\n\n\n\n\n Documents \n\nTo train a machine learning model, you need to collect documents that are representative of your domain content and of high value to your application.\n\nTry to ensure that your training documents are truly representative of content that is of interest to your domain; that is, they contain many relevant mentions that can be annotated. To choose the best documents, follow these guidelines:\n\n\n\n* Strive to provide a set of documents that have a total size of about 300,000 words. Provide more words for a complex type system, and fewer for a simpler one.\n* Limit each document to a page or two of content (fewer than 2,000 words, and closer to 1,000 words per document is best). In the early stages of model development, keeping each document down to a few paragraphs is also a good practice. A human annotator can mark mentions and relations in a long document, but attempts to mark coreferences across multiple pages might prove unwieldy.\n* Ensure that the data in the documents is distributed across all possible entity types, subtypes, and roles, and the relationships between them. A goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.\n* Again, documents should represent the breadth of the subject matter that the application will cover, but in the case of skewed frequency-of-occurrence of entity types and relation types, try to get at least 50 exemplars of each type, more for entity types that have mentions which tend to be phrases.\n* The set that you create for training must contain at least 10 annotated documents.",
        "url": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation",
        "score": 18.297113,
        "feedback": {
          "relevant": {
            "f6ce971c-68d2-4c26-b1c0-477dd28a5181": {
              "value": "yes",
              "timestamp": 1724763831
            }
          }
        },
        "query": {
          "query": {
            "bool": {
              "must": {
                "text_expansion": {
                  "ml.tokens": {
                    "model_id": ".elser_model_1",
                    "model_text": "documents size  for annotaion"
                  }
                }
              }
            }
          }
        }
      },
      {
        "document_id": "ibmcld_16483-9110-10998",
        "text": "\n<br><br> * CSV file in UTF-8 format<br> * Text in UTF-8 format<br> * HTML<br> * PDF files (scanned and password-protected files are not supported)<br> * Microsoft Word DOC or DOCX files (password-protected files are not supported)<br> * ZIP file that contains documents downloaded from another workspace<br> * ZIP file that contains documents in UIMA CAS XMI format<br><br><br> ZIP archive file of documents <br><br> * 40,000 characters per document<br> * 10,000 documents per workspace<br> * 1,000 document sets (including annotation sets) per workspace<br> * 5 MB per file and 200 MB per upload (TXT, PDF, DOC, DOCX, and HTML files)<br><br><br> \n Pre-annotation Use a dictionary or IBM Watson\u00ae Natural Language Understanding pre-annotator to provide a starting point for human annotation. <br> <br>You cannot re-annotate a corpus from IBM Watson Explorer. Raw documents. <br> <br>Note: Do not pre-annotate documents that a human annotator has already annotated, or you will lose the work done by the human annotator. Partly-annotated documents None \n Document annotation Manage human annotation. Annotate entities, relations, and coreference chains to create ground truth Annotation task Ground truth <br><br> * 256 active anntation tasks per workspace<br><br><br> \n Training and refinement Train a supervised machine learning model to extract domain-specific information from unstructured text. Evaluate and improve a supervised machine learning model. You cannot create a semi-supervised or unsupervised machine learning model. You cannot do extensive feature engineering. Not applicable Machine learning model <br><br> * 1 machine learning model per workspace<br> * 10 model versions per workspace<br> * Maximum number of workspaces is determined by your deployment.<br> * The maximum number of training actions you can perform per month is determined by your deployment.<br><br><br>",
        "url": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-create-project",
        "score": 18.251581,
        "feedback": {
          "relevant": {
            "f6ce971c-68d2-4c26-b1c0-477dd28a5181": {
              "value": "yes",
              "timestamp": 1724763828
            },
            "7ee1aecf-492d-4847-a436-3db915c57d2e": {
              "value": "no",
              "timestamp": 1726508092
            }
          }
        },
        "query": {
          "query": {
            "bool": {
              "must": {
                "text_expansion": {
                  "ml.tokens": {
                    "model_id": ".elser_model_1",
                    "model_text": "documents size  for annotaion"
                  }
                }
              }
            }
          }
        }
      },
      {
        "document_id": "ibmcld_16423-7-2234",
        "text": "\nAdding documents for annotation \n\nTo train a machine learning model, you must add documents that contain subject matter knowledge, such as journal articles or other industry-specific texts, to your workspace.\n\n\n\n About this task \n\nThis section describes how to add documents for annotation only. To define rules for the rule-based model, you add or upload documents from which you can draw patterns to define as rules. See [Adding documents for defining rules](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_anno_add) for more information.\n\n\n\n\n\n Documents \n\nTo train a machine learning model, you need to collect documents that are representative of your domain content and of high value to your application.\n\nTry to ensure that your training documents are truly representative of content that is of interest to your domain; that is, they contain many relevant mentions that can be annotated. To choose the best documents, follow these guidelines:\n\n\n\n* Strive to provide a set of documents that have a total size of about 300,000 words. Provide more words for a complex type system, and fewer for a simpler one.\n* Limit each document to a page or two of content (fewer than 2,000 words, and closer to 1,000 words per document is best). In the early stages of model development, keeping each document down to a few paragraphs is also a good practice. A human annotator can mark mentions and relations in a long document, but attempts to mark coreferences across multiple pages might prove unwieldy.\n* Ensure that the data in the documents is distributed across all possible entity types, subtypes, and roles, and the relationships between them. A goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.\n* Again, documents should represent the breadth of the subject matter that the application will cover, but in the case of skewed frequency-of-occurrence of entity types and relation types, try to get at least 50 exemplars of each type, more for entity types that have mentions which tend to be phrases.\n* The set that you create for training must contain at least 10 annotated documents.",
        "url": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation",
        "score": 18.100645,
        "feedback": {
          "relevant": {
            "f6ce971c-68d2-4c26-b1c0-477dd28a5181": {
              "value": "yes",
              "timestamp": 1724763825
            }
          }
        },
        "query": {
          "query": {
            "bool": {
              "must": {
                "text_expansion": {
                  "ml.tokens": {
                    "model_id": ".elser_model_1",
                    "model_text": "documents size  for annotaion"
                  }
                }
              }
            }
          }
        }
      }
    ],
    "original_text": "Based on the provided document, there are certain guidelines for the volume of data when adding documents for annotation to train a machine learning model. It is recommended to provide a set of documents that have a total size of about 300,000 words. The number of words can be adjusted based on the complexity of the type system. Each document should be limited to a page or two of content, preferably fewer than 2,000 words and closer to 1,000 words per document. During the early stages of model development, it is advisable to keep each document down to a few paragraphs. Additionally, the data in the documents should be distributed across all possible entity types, subtypes, and roles, and their relationships. A goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection. The set of documents for training must contain at least 10 annotated documents."
  }
}