model_name: "mixtral_8x22b_instruct"
provider: "together_ai"
api_model_id: "mistralai/Mixtral-8x22B-Instruct-v0.1"
api_endpoint: "https://api.together.xyz/v1/chat/completions"
max_tokens: 200
temperature: 0.0
top_p: 1.0
do_sample: false
# Note: Mixture of Experts architecture, 32K context length

