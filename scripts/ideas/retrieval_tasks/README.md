# Extractive Query Rewriting - Scripts

This directory contains implementations of extractive query rewriting approaches for the MT-RAG benchmark.

## Directory Structure

- `pure_extractive/` - MMR-based term selection
- `hybrid_extractive/` - MMR + Templates + Entity Recognition
- `generate_all_extractive_datasets.sh` - Generate all datasets at once

## Quick Start

### 1. Download the Embedding Model (First Time Only)

```bash
cd scripts/ideas/retrieval_tasks
python download_model.py
```

This downloads the BGE model (~400MB) to `.models/bge-base-en-v1.5` for offline use.

### 2. Generate All Datasets

To generate datasets for all domains and both methods:

```bash
cd scripts/ideas/retrieval_tasks
./generate_all_extractive_datasets.sh
```

This will:
1. Check/download the model if needed
2. Generate rewrites for all domains
3. Create:
   - Analysis results in `{method}/results/`
   - MT-RAG formatted datasets in `{method}/datasets/`

### Individual Method Usage

#### Pure Extractive

```bash
python pure_extractive/pure_extractive_rewrite.py <domain>
```

Example:
```bash
python pure_extractive/pure_extractive_rewrite.py clapnq
```

Generates rewrites using MMR-based term selection.

**Outputs:**
- Analysis: `pure_extractive/results/{domain}_rewrites.jsonl`
- MT-RAG format: `pure_extractive/datasets/{domain}_pure_extractive.jsonl`

#### Hybrid Extractive

```bash
python hybrid_extractive/hybrid_extractive_rewrite.py <domain>
```

Example:
```bash
python hybrid_extractive/hybrid_extractive_rewrite.py cloud
```

Generates rewrites using MMR + templates + NER.

**Outputs:**
- Analysis: `hybrid_extractive/results/{domain}_rewrites.jsonl`
- MT-RAG format: `hybrid_extractive/datasets/{domain}_hybrid_extractive.jsonl`

## Domains

- `clapnq` - Wikipedia Q&A (208 queries)
- `cloud` - Technical Documentation (188 queries)
- `fiqa` - Financial Q&A (180 queries)
- `govt` - Government/Policy (201 queries)

## Dependencies

```bash
pip install sentence-transformers spacy scikit-learn nltk
python -m spacy download en_core_web_sm
```

**Note**: Both methods use `BAAI/bge-base-en-v1.5` embeddings, which will be downloaded automatically on first run (~400MB).

## Output Directory Structure

After running the generation scripts, you'll have:

```
scripts/ideas/retrieval_tasks/
â”œâ”€â”€ pure_extractive/
â”‚   â”œâ”€â”€ pure_extractive_rewrite.py
â”‚   â”œâ”€â”€ datasets/                         (MT-RAG format for retrieval)
â”‚   â”‚   â”œâ”€â”€ clapnq_pure_extractive.jsonl (208 queries)
â”‚   â”‚   â”œâ”€â”€ cloud_pure_extractive.jsonl  (188 queries)
â”‚   â”‚   â”œâ”€â”€ fiqa_pure_extractive.jsonl   (180 queries)
â”‚   â”‚   â””â”€â”€ govt_pure_extractive.jsonl   (201 queries)
â”‚   â””â”€â”€ results/                          (Analysis format)
â”‚       â”œâ”€â”€ clapnq_rewrites.jsonl
â”‚       â”œâ”€â”€ cloud_rewrites.jsonl
â”‚       â”œâ”€â”€ fiqa_rewrites.jsonl
â”‚       â””â”€â”€ govt_rewrites.jsonl
â”‚
â””â”€â”€ hybrid_extractive/
    â”œâ”€â”€ hybrid_extractive_rewrite.py
    â”œâ”€â”€ datasets/                         (MT-RAG format for retrieval)
    â”‚   â”œâ”€â”€ clapnq_hybrid_extractive.jsonl
    â”‚   â”œâ”€â”€ cloud_hybrid_extractive.jsonl
    â”‚   â”œâ”€â”€ fiqa_hybrid_extractive.jsonl
    â”‚   â””â”€â”€ govt_hybrid_extractive.jsonl
    â””â”€â”€ results/                          (Analysis format)
        â”œâ”€â”€ clapnq_rewrites.jsonl
        â”œâ”€â”€ cloud_rewrites.jsonl
        â”œâ”€â”€ fiqa_rewrites.jsonl
        â””â”€â”€ govt_rewrites.jsonl
```

## Output Formats

### Analysis Format (results/)

Detailed analysis with original and rewritten queries:

```json
{
  "id": "query_id",
  "original": "original query text",
  "rewritten": "rewritten query text",
  "history_length": 3
}
```

### MT-RAG Format (datasets/)

Standard format for retrieval evaluation:

```json
{
  "_id": "query_id",
  "text": "|user|: rewritten query text"
}
```

This format matches the existing MT-RAG retrieval tasks and can be used directly with retrieval systems.

## Results

**ğŸ“Š See [FULL_RESULTS_COMPARISON.md](FULL_RESULTS_COMPARISON.md) for complete evaluation results**

### Quick Summary (NDCG@10)

| Domain | Lastturn | Human | Pure | Hybrid | Best |
|--------|----------|-------|------|--------|------|
| clapnq | 0.269 | **0.301** | 0.290 | 0.284 | Human |
| cloud | **0.252** | 0.248 | 0.239 | 0.241 | Lastturn |
| fiqa | 0.136 | **0.186** | 0.152 | 0.155 | Human |
| govt | 0.319 | **0.354** | 0.339 | 0.336 | Human |

**Key Findings:**
- âœ… Pure and Hybrid perform nearly identically
- âœ… Beat lastturn in 3/4 domains (+5-14%)
- âš ï¸ Still ~7.5% behind human rewrites
- âŒ All rewriting hurts technical (cloud) domain

**Recommendation:** Use **Pure Extractive** for simplicity with same performance as Hybrid.

## Documentation

See `knowledgebase/ideas/retrieval_tasks/` for detailed documentation:
- `extractive_implementation_analysis.md` - Data analysis and approach rationale
- `pure_extractive_rewrite.md` - Pure extractive implementation details
- `hybrid_extractive_rewrite.md` - Hybrid extractive implementation details

