{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":0.0327868852,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":0.0322580645,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_10852-44214-45420","score":0.0317460317,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_13429-166159-168045","score":0.03125,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_10852-43319-44485","score":0.0307692308,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":0.0303030303,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-2884-4620","score":0.0298507463,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":0.0294117647,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12330-7-2140","score":0.0289855072,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_02772-1628-3402","score":0.0285714286,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-1426-3052","score":0.0327868852,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":0.0322580645,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-15747-17355","score":0.0312576313,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-7-1743","score":0.0312576313,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":0.03125,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":0.0303030303,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":0.0298507463,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-44214-45420","score":0.0294117647,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":0.0289855072,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_15790-1791-3014","score":0.0142857143,"text":"\n* For more information on deleting a subnet, see [Deleting VPC resources by using the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-console), [Deleting VPC resources by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-cli), or [Deleting VPC resources by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-api).\n\n\n\n* floating-ip\n\n\n\n* For more information on creating a floating IP, see [Using the IBM Cloud console to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console), [Using the REST APIs to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-rest-apis), or [Using the CLI to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-clicreate-a-subnet-cli).\n* For more information on deleting a floating IP, see [Deleting VPC resources by using the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-console), [Deleting VPC resources by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-cli), or [Deleting VPC resources by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-api).\n\n\n\n* network-acl","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quota-troubleshooting"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4981892575,"ndcg_cut_10":0.6394562303}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02718-1684-3722","score":0.0163934426,"text":"\n[Writing] There's a couple benefits to using a feature flag service. Number one is you can have essentially managed place for your features, or excuse me your feature flags. [Writing] Number two is you can turn these on and off without modifying your properties in your future, in your apps or web pages. [Writing] And number three is you get audit and usage data. It's harder to get the audit and usage data by using JSON files.\n\nOkay, so now let's go back to our example we've got our open banner feature and now let's wrap it with some feature flag code.\n\nAnd so here's an example, kind of pseudo code, that you can use if store open is enabled.\n\n[Writing] if (storeopen is Enabled()){ Then we're going to show open banner [Writing] show Open Banner();}\n\nso this pseudocode represents our feature code and the flag that potentially could encompass it.\n\nNow let's actually put this in production and [Draw] make it show showcase to some users.\n\nSo now that we've got our feature in production it's not usable to any users right now this is an idea typically displayed with feature flags called dark launch. Dark launch is when a feature is in production but not visible to any or all users or any or some users, excuse me.\n\nNow we want to introduce the idea of [Writing] segments.\n\nSo we've already said that we only want a certain number of people to view this, people who are nearby our new shop. This will be our segment A, and a segment is simply users or groups of users that have attributes tied to them.\n\nSo this first one might have [Writing] current location, and [Writing] zip code.\n\nAttributes, this allows users who are either currently in the location or have already stipulated that they live nearby to view this feature, but before we do that we want to test the feature out on our own employees. [Writing] So we would have segment Bof our testers because we want them to be our employees the attribute might be [Writing] email ID.\n\nNow we can effectively test our feature in production by {Draw] flipping this toggle on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_10817-1342-3184","score":0.0163934426,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02569-4530-5596","score":0.0161290323,"text":"\nIt is expected for message values to duplicate information from code, target, and custom extensions to the error model.\n\nImportantly, message values are still meant for developers and for this reason SHOULD NOT be localized or written for use in a user interface. Fields mentioned within a message SHOULD be mentioned by exact field name (e.g., first_name, not \"first name\").\n\nConsider the example above of an error code with value invalid_color. A poor message would be:\n\n\"The color provided for paint was invalid.\"\n\nUnlike the code, a message MAY prescribe a specific solution, thereby adding value. A better message would be:\n\n\"The color for paint must be red or blue.\"\n\nAs demonstrated in the above examples, message values SHOULD use the back-tick character to enclose field names, parameter names, header names, and specific values.\n\n\n\n\n\n\n\n Robustness tradeoffs \n\nThe robustness principle section has been moved to a [new page](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-robustness), and the previous guidance has been substantially repudiated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-errors"},{"document_id":"ibmcld_04518-1426-3052","score":0.0161290323,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02538-4432-6174","score":0.0158730159,"text":"\nservicekey = \"<service_key>\"\nurl = \"<API_ENDPOINT>\"\n}\n\nWhere\n\n\n\n\n\n Option 2. Referencing credentials from a Terraform tfvars file \n\nYou can store sensitive information, such as credentials, in a local terraform.tfvars file and reference these credentials in your provider block.\n\nDo not commit the terraform.tfvars into a public source repository. This file is meant to be stored in your local machine only.\n\n\n\n1. Create a terraform.tfvars file on your local machine and add the input parameters that are required for your resource or data source.\n\nservicekey = \"<Service Key>\"\nurl = \"<API_ENDPOINT>\"\n2. Create a provider.tf file and use Terraform interpolation syntax to reference the variables from the terraform.tfvars.\n\nvariable \"servicekey\" {}\nvariable \"url\" {}\n\nprovider \"logdna\" {\nservicekey = var.servicekey\nurl = var.url\n}\n\n\n\n\n\n\n\n\n\n Step 3. Initialize the Terraform CLI. \n\nNext, initialize the Terraform CLI. Run the following command:\n\n.\/terraform init\n\nYou should see the following message: Terraform has been successfully initialized!.\n\n\n\n\n\n Step 4. Create a Terraform configuration file \n\nNext, create a Terraform configuration file that is named main.tf. In this file, you add the configuration to manage a category by using HashiCorp Configuration Language (HCL). For more information, see the [Terraform documentation](https:\/\/www.terraform.io\/docs\/language\/index.html).\n\nThe following code shows a sample configuration file to manage a category to group views.\n\nresource \"logdna_category\" \"custom_category\" {\ntype = \"views\"\nname = \"My Category\"\n}\n\nThe following code shows a sample configuration file to manage a category to group boards.\n\nresource \"logdna_category\" \"custom_category\" {\ntype = \"boards\"\nname = \"My Category\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-terraform-categories"},{"document_id":"ibmcld_10852-44214-45420","score":0.0158730159,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_09447-4414-6156","score":0.015625,"text":"\nservicekey = \"<service_key>\"\nurl = \"<API_ENDPOINT>\"\n}\n\nWhere\n\n\n\n\n\n Option 2. Referencing credentials from a Terraform tfvars file \n\nYou can store sensitive information, such as credentials, in a local terraform.tfvars file and reference these credentials in your provider block.\n\nDo not commit the terraform.tfvars into a public source repository. This file is meant to be stored in your local machine only.\n\n\n\n1. Create a terraform.tfvars file on your local machine and add the input parameters that are required for your resource or data source.\n\nservicekey = \"<Service Key>\"\nurl = \"<API_ENDPOINT>\"\n2. Create a provider.tf file and use Terraform interpolation syntax to reference the variables from the terraform.tfvars.\n\nvariable \"servicekey\" {}\nvariable \"url\" {}\n\nprovider \"logdna\" {\nservicekey = var.servicekey\nurl = var.url\n}\n\n\n\n\n\n\n\n\n\n Step 3. Initialize the Terraform CLI. \n\nNext, initialize the Terraform CLI. Run the following command:\n\n.\/terraform init\n\nYou should see the following message: Terraform has been successfully initialized!.\n\n\n\n\n\n Step 4. Create a Terraform configuration file \n\nNext, create a Terraform configuration file that is named main.tf. In this file, you add the configuration to manage a category by using HashiCorp Configuration Language (HCL). For more information, see the [Terraform documentation](https:\/\/www.terraform.io\/docs\/language\/index.html).\n\nThe following code shows a sample configuration file to manage a category to group views.\n\nresource \"logdna_category\" \"custom_category\" {\ntype = \"views\"\nname = \"My Category\"\n}\n\nThe following code shows a sample configuration file to manage a category to group boards.\n\nresource \"logdna_category\" \"custom_category\" {\ntype = \"boards\"\nname = \"My Category\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-terraform-categories"},{"document_id":"ibmcld_10852-43319-44485","score":0.015625,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02542-4477-6135","score":0.0153846154,"text":"\nservicekey = \"<service_key>\"\nurl = \"<API_ENDPOINT>\"\n}\n\nWhere\n\n\n\n\n\n Option 2. Referencing credentials from a Terraform tfvars file \n\nYou can store sensitive information, such as credentials, in a local terraform.tfvars file and reference these credentials in your provider block.\n\nDo not commit the terraform.tfvars into a public source repository. This file is meant to be stored in your local machine only.\n\n\n\n1. Create a terraform.tfvars file on your local machine and add the input parameters that are required for your resource or data source.\n\nservicekey = \"<Service Key>\"\nurl = \"<API_ENDPOINT>\"\n2. Create a provider.tf file and use Terraform interpolation syntax to reference the variables from the terraform.tfvars.\n\nvariable \"servicekey\" {}\nvariable \"url\" {}\n\nprovider \"logdna\" {\nservicekey = var.servicekey\nurl = var.url\n}\n\n\n\n\n\n\n\n\n\n Step 3. Initialize the Terraform CLI. \n\nNext, initialize the Terraform CLI. Run the following command:\n\n.\/terraform init\n\nYou should see the following message: Terraform has been successfully initialized!.\n\n\n\n\n\n Step 4. Create a Terraform configuration file \n\nNext, create a Terraform configuration file that is named main.tf. In this file, you add the configuration to create the streaming configuration by using HashiCorp Configuration Language (HCL). For more information, see the [Terraform documentation](https:\/\/www.terraform.io\/docs\/language\/index.html).\n\nThe following code shows a sample configuration file to stream data to Event Streams.\n\nresource \"logdna_stream_config\" \"config\" {\nuser = var.stream_user\npassword = var.stream_password\ntopic = \"example\"\nbrokers = [\n\"broker-1.kafka_brokers_sasl URL:9093\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-terraform-streaming"},{"document_id":"ibmcld_04518-7-1743","score":0.0153846154,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10116-7136-9295","score":0.0163934426,"text":"\nThe OCP licenses are also part of the worker node plan and listed as a sub-item of the worker nodes in your IBM Cloud bill.\n\n\n\n\n\n Deprecated: Old OCP licenses for existing worker nodes before 9 November 2020 or deprecated bare metal flavors \n\na Red Hat OpenShift license is billed for every four virtual cores (or two physical cores) of the worker node flavor. You are charged for the entire license for each month that you have worker nodes in a deployed state. The monthly charge applies to both virtual and physical worker nodes. For example, if you create the cluster on 15 August and delete the cluster on 14 September, you are still charged for the OCP licenses for two monthly periods: August and September.\n\n\n\n* If you delete your worker node before the end of the month, your monthly license is available for other worker nodes in the same cluster. If the other worker nodes are not the same CPU size, you need additional licenses.\n* If you delete the cluster before the end of the month, you are still charged the entire monthly price for the Red Hat OpenShift license.\n\n\n\nWhen you estimate the cost of a new cluster or worker node, the OCP licenses are included as a separate line item. The OCP licenses are also listed as separate plans in your IBM Cloud bill.\n\n\n\n\n\n How can I migrate from the old to new OCP licenses? \n\nYou can follow the same procedure to [update flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemachine_type) by adding new worker pools and removing the old worker pools. If you use bare metal, make sure that you use the latest series 4 flavors. Many existing bare metal flavors don't support the new OCP licenses.\n\nYou can check the new rates in the pricing estimate when you create a cluster or worker pool in the console. The OCP licenses are no longer a separate line item in the estimate, but instead are in the cost of the worker nodes.\n\n\n\n\n\n\n\n OCP licenses from Cloud Pak entitlements \n\nWhen you purchase products such as IBM Cloud Paks, your purchase might include OCP licenses. When you create a cluster or worker pool, you can choose to apply your entitlement to cover the cost of the OCP licenses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10817-2884-4620","score":0.0163934426,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_14546-6172-8106","score":0.0161290323,"text":"\nMetric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges. You can view the charges on the IBM Cloud billing and usage view along with the usage and charges from all other IBM Cloud services.\n\nIn the IBM Cloud Usage view, locate the VMware Solutions service type. Locate the Organization plan to find the Veeam and Zerto usage across all virtual data centers in that organization. The virtual data center usage is located in a separate plan for either VMware Shared on-demand or VMware Shared Reserved.\n\nVeeam\n\nZerto\n\n\n\nTable 5. Licenses and fees for Veeam\n\n Metric Frequency Description \n\n MAX_VEEAM_LICENSES Monthly Veeam license charge for every VM under backup. The monthly charge is for the highest number of VMs under backup at any time period in the month. \n TOTAL_VEEAM_BLOCK_STORAGE_GB_HOURS Hourly Charge per GB of block storage used for all backups. \n TOTAL_VEEAM_OBJECT_STORAGE_GB_HOURS Hourly Charge per GB of object storage used for all backups. \n\n\n\nNo additional Veeam or Zerto usage charges for VMware Shared are incurred.\n\nFor the Veeam service, initially, all backups go to the block storage that is closest to their VM workloads. Backups that are a part of an inactive backup chain are immediately moved to Cloud Object Storage. The restore speed for these inactive backups might be impacted.\n\nYou can change how fast the inactive backup chains are moved to Cloud Object Storage by opening an IBM Cloud for VMware Solutions service ticket.\n\n\n\n\n\n Related links \n\n\n\n* [VMware Shared overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_02665-1570-3896","score":0.0161290323,"text":"\nStandard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n\n\n\n\n What are the charges to use App Configuration? \n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service. For example, an entity might be an instance of an app that runs on a mobile device, a microservice that runs on the cloud, or a component of infrastructure that runs that microservice. For any entity to interact with App Configuration, it must provide a unique entity ID. This task is most easily accomplished by programming your app or microservice to send the Entity ID by using the App Configuration SDK.\n\nAPI Call - An API call is the invocation of the App Configuration through a programmable interface.\n\nExactly what constitutes an API call varies depending on the entity type (for example, a microservice or a mobile app). For server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_13612-0-945","score":0.0158730159,"text":"\n\n\n\n\n\n\n  Charge Metrics and Order consideration \n\n\n\n  Release Notes \n\n\n\n\n\n  Abstract \n\nBefore submitting an order, the following should be considered to ensure the order is 'right sized' and will meet the requirements of the client.\n\nImportant: Customers must purchase (or own) App Points for TRIRIGA Application Suite (TAS) prior to (or in conjunction with) ordering the IBM Managed Service. The managed service provides IBM Cloud based hosting, product installation, operation, maintenance and support for TAS.\n\nInformation should be gathered about the potential usage of the suite, including which applications will be required, how many users on each application and the primary usage of the applications.\n\nThere are three (3) TAS-MS part numbers:\n\nD02QTZX - Capacity\n\nD02QUZX - Data\n\nD02QWZX - VPC (Virtual Processor Core)\n\nFor additional information, please contact:\n\nPedro Echeverria [pedech@br.ibm.com](mailto:pedech@br.ibm.com)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-charge-metrics"},{"document_id":"ibmcld_10817-7-1802","score":0.0158730159,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_08588-1691-3649","score":0.015625,"text":"\nBefore you create a key ring for your Hyper Protect Crypto Services instance, keep in mind the following considerations:\n\n\n\n* Every Hyper Protect Crypto Services instance comes with a default key ring.\n\nEach newly created Hyper Protect Crypto Services instance comes with a generated key ring with an ID of default. All keys that are not associated with a specified key ring exist within the default key ring.\n* Key rings can hold root keys and standard keys, but not EP11 keys.\n\nKey rings can contain both root and standard keys. There is no limit on how many keys can exist within a key ring. Key rings don't apply to Enterprise PKCS #11 (EP11) keys.\n* A key only can belong to one key ring at a time.\n\nA key can belong to only one key ring. Key ring assignment happens upon key creation. If a key ring ID is not passed in upon creation, the key will belong to the default key ring. You can update the key ring after the key creation.\n* You can create up to five keystores in a service instance for free, including key rings and EP11 keystores. The maximum number of key rings for a service instance is 50.\n\nEach additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For more information about pricing, see [the pricing sample](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs).\n\n\n\n\n\n Creating key rings \n\nBefore you can group keys into a key ring, you need to create a key ring first. You can use either the console or the key management service API to create a key ring.\n\nYou can create up to five keystores in a service instance for free, including key rings and EP11 keystores. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month.\n\n\n\n Creating key rings with the console \n\nCreate a key ring with the console by completing the following steps:\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-managing-key-rings"},{"document_id":"ibmcld_10817-7707-9426","score":0.015625,"text":"\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate\nlet session = NSURLSession(configuration: NSURLSessionConfiguration.defaultSessionConfiguration(), delegate: NetworkUtilsDelegate(), delegateQueue:NSOperationQueue.mainQueue())\n\/\/ set the SDK to use this urlSession instead of the default shared one\nwhisk.urlSession = session\n\n\n\n Support for qualified names with mobile SDK \n\nAll actions and triggers have a fully qualified name that is made up of a namespace, a package, and an action or trigger name. The SDK can accept these elements as parameters when you are invoking an action or Firing a trigger. The SDK also provides a function that accepts a fully qualified name that looks like \/mynamespace\/mypackage\/nameOfActionOrTrigger. The qualified name string supports unnamed default values for namespaces and packages that all Cloud Functions users have, so the following parsing rules apply:\n\n\n\n* qName = \"foo\" results in namespace = default, package = default, action\/trrigger = \"foo\"\n* qName = \"mypackage\/foo\" results in namespace = default, package = mypackage, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/foo\" results in namespace = mynamespace, package = default, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/mypackage\/foo\" results in namespace = mynamespace, package = mypackage, action\/trigger = \"foo\"\n\n\n\nAll other combinations issue a WhiskError.QualifiedName error.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_03704-10459-12479","score":0.0153846154,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_12330-7-2140","score":0.0153846154,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1390561795}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10863-7246-8495","score":0.0299107143,"text":"\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n\/\/ This last throw is absolutely important to make the top-most promise, which we initially returned at the\n\/\/ top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n\/\/ even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_12880-0-1003","score":0.0163934426,"text":"\n\n\n\n\n\n\n  Why can't I view any usage or rewards details in Partner Center? \n\nIf you can't view usage and rewards details in an account that you've been added to, you might not have the correct IAM access.\n\n  What\u2019s happening \n\nWhen you're working in an IBM Cloud\u00ae account that you've been added to, you can't view or access details about usage or rewards in Partner Center. Specifically, the chart on the Usage and offers page doesn't display any data. And, the following error message is displayed in the Your rewards section.\n\n> Oops! Your incentives details are currently unavailable.\n\n  Why it\u2019s happening \n\nBy default, only account owners can view usage and rewards details. For users of an account to view this information, specific IAM access is required: [viewer role on the Billing service](https:\/\/cloud.ibm.com\/docs\/sell?topic=account-account-servicespc-buildgrow-account-management).\n\n  How to fix it \n\nContact your account owner and request viewer access to usage and rewards details.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-ts-view-usage"},{"document_id":"ibmcld_10863-4041-5570","score":0.0163934426,"text":"\nresolve({ cloudant_result: 'SUCCESS' });\n}, 5000);\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"cloudant_result\": \"SUCCESS\"\n}\n\nLogs:\n[\n\"2020-04-21T01:53:36.739565Z stdout: fake db access done. Resolving Promise...\"\n]\n\n\n\n\n\nYour db-access action is ready!\n\n\n\n\n\n Step 3: Create the ow-sdk-action actionow-sdk-action action \n\nThe ow-sdk-action action is a Node.js program that calls the other two actions: cos-access and db-access. When invoked, the ow-sdk-action action code acts as a custom sequence, first calling cos-access, then db-access, and finally cos-access again. The results of each action are stored in a variable that is called chained_action_results, which is then returned at the end. When the action is invoked, follow the code comments to see what is happening.\n\n\n\n1. From the Actions page, create a third action called ow-sdk-action.\n\n\n\n1. Name your action ow-sdk-action.\n2. Select the action-tutorial package.\n3. Select Node.js 10 for the runtime.\n4. Click Create.\n5. Paste in the following code example:\n\n\/\n* main() will be run when you invoke this action\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_13498-93516-95314","score":0.0161290323,"text":"\n-A All number types Unary negative operator. The type of the result is the same as the type of A. \n +A All number types Unary positive operator. The type of the result is the same as the type of A. \n A All number types Bitwise NOT operator. The type of the result is the same as the type of A. \n\n\n\n\n\n\n\n Arithmetic operators \n\n\n\nTable 51. Arithmetic operators.\n\n Operator Operand types Description \n\n A + B All number types Returns the result of adding A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A - B All number types Returns the result of subtracting B from A. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A * B All number types Returns the result of multiplying A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. If the operation causes an overflow, cast at least one of the operators to a type that is higher in the type hierarchy. \n A \/ B All number types Returns the result of dividing A by B. The type of the result is DOUBLE. \n A % B All number types Returns the remainder after dividing A by B. For example, 13.7 % 3 returns 1.7. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A DIV B Integer types Returns the integer part of the result of dividing A by B. For example, 13.7 DIV 3 returns the integer 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_02680-6103-7532","score":0.0161290323,"text":"\nval result = feature.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval feature: Feature? = appConfiguration.getFeature(\"yaml-feature\")\nfeature.getFeatureDataType(); \/\/ STRING\nfeature.getFeatureDataFormat(); \/\/ YAML\nfeature.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check Table 1)\n\n\n\n\n\n Property \n\nval property: Property? = appConfiguration.getProperty(\"json-property\")\nproperty.getPropertyDataType(); \/\/ STRING\nproperty.getPropertyDataFormat(); \/\/ JSON\n\n\/\/ Example below (traversing the returned JSONObject)\nif (property != null) {\nval result = property.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval property: Property? = appConfiguration.getProperty(\"yaml-property\")\nproperty.getPropertyDataType(); \/\/ STRING\nproperty.getPropertyDataFormat(); \/\/ YAML\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_10863-6347-7636","score":0.0158730159,"text":"\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_13429-163247-165127","score":0.0158730159,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_07098-12237-14153","score":0.015625,"text":"\nFilter search results are not returned in order of relevance.When you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter, the filter parameter runs first, and then any aggregation, query, or natural_language_query parameters run in parallel.With a simple query, especially on a small data set, the filter and query parameters often return the exact same (or similar) results. If the filter and query calls return similar results, and you don't need the responses to be returned in order of relevance, use the filter parameter. Filter calls are faster and are cached. Caching means that the next time you make the same call, you get a much quicker response, particularly in a big data set.<-- <\/section \"id=\"section-filter\" \"> --><-- <section \"id=\"section-query-parameters-structure\" \"> --> Structure parameters Structure parameters define the content and organization of the documents in the returned JSON. Structure parameters don't affect which documents are part of the entire results set.<-- <\/section \"id=\"section-query-parameters-structure\" \"> --><-- <section \"id=\"section-return\" \"> --> return A comma-separated list of the portion of the document hierarchy to return. Any of the document hierarchies are valid values. If this parameter is an empty list, then all fields are returned.<-- <\/section \"id=\"section-return\" \"> --><-- <section \"id=\"section-count\" \"> --> count The number of documents that you want to return in the response. The default is 10. The maximum for the count and offset values together in any one query is 10000.<-- <\/section \"id=\"section-count\" \"> --><-- <section \"id=\"section-offset\" \"> --> offset Index value of the position of the search result where the set of results to return begins. For example, if the total number of results that are returned is 10, and the offset is 8, it returns the last two results. The default is 0.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_13498-94895-96764","score":0.0153846154,"text":"\nA % B All number types Returns the remainder after dividing A by B. For example, 13.7 % 3 returns 1.7. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A DIV B Integer types Returns the integer part of the result of dividing A by B. For example, 13.7 DIV 3 returns the integer 4. \n A & B All number types Returns the result of bitwise AND of A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. \n `A B` All number types \n A ^ B All number types Returns the result of bitwise XOR of A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. \n\n\n\n\n\n\n\n String operator \n\n\n\nTable 52. String operator.\n\n Operator Operand types Description \n\n `A B` \n\n\n\n\n\n\n\n Comparison operators \n\n\n\nTable 53. Comparison operators.\n\n Operator Operand types Description \n\n A = B All primitive types Returns TRUE if A is equal to B, FALSE otherwise. \n A == B All primitive types Synonym for the equal (=) operator. \n A <> B All primitive types Returns NULL if A or B is NULL, TRUE if A is not equal to B, FALSE otherwise. \n A != B All primitive types Synonym for the not equal (<>) operator. \n A < B All primitive types Returns NULL if A or B is NULL, TRUE if A is less than B, FALSE otherwise. \n A <= B All primitive types Returns NULL if A or B is NULL, TRUE if A is less than or equal to B, FALSE otherwise. \n A !> B All primitive types Returns NULL if A or B is NULL, TRUE if A is not greater than B, FALSE otherwise. \n A > B All primitive types Returns NULL if A or B is NULL, TRUE if A is greater than B, FALSE otherwise. \n A >= B All primitive types Returns NULL if A or B is NULL, TRUE if A is greater than or equal to B, FALSE otherwise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_02679-8312-9928","score":0.0153846154,"text":"\nThe SDK uses the attribute values to determine whether the specified entity satisfies the targeting rules, and returns the appropriate feature flag value.\n\n\n\n\n\n\n\n Get single property \n\nconst property = appConfigClient.getProperty('property_id'); \/\/ property can be null incase of an invalid property id\n\nif (property != null) {\nconsole.log(Property Name ${property.getPropertyName()} );\nconsole.log(Property Id ${property.getPropertyId()} );\nconsole.log(Property Type ${property.getPropertyDataType()} );\n}\n\n\n\n\n\n Get all properties \n\nconst properties = appConfigClient.getProperties();\nconst property = properties['property_id'];\n\nif (property != null) {\nconsole.log(Property Name ${property.getPropertyName()} );\nconsole.log(Property Id ${property.getPropertyId()} );\nconsole.log(Property Type ${property.getPropertyDataType()} );\n}\n\n\n\n\n\n Evaluate a property \n\nYou can use the property.getCurrentValue(entityId, entityAttributes) method to evaluate the value of the property. This method returns a JSON object containing evaluated value and evaluation details.\n\nconst entityId = '<entityId>';\nconst entityAttributes = {\ncity: 'Bangalore',\ncountry: 'India',\n};\n\nconst result = property.getCurrentValue(entityId, entityAttributes);\nconsole.log(result.value); \/\/ Evaluated value of the property. The type of evaluated value will match the type of property (Boolean, String, Numeric).\nconsole.log(result.details); \/\/ a JSON object containing detailed information of the evaluation. See below\n\n\/\/ the result.details will have the following\nconsole.log(result.details.valueType); \/\/ a string value. Example: DEFAULT_VALUE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07549-19143-21543","score":0.0163934426,"text":"\nThe information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).The requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.Corresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.<-- <\/section \"id=\"section-en-notice-non-source\" \"> --><-- <section \"id=\"section-en-notice-add-term\" \"> --> 7. Additional Terms \"Additional permissions\" are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.When you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_10817-6582-8092","score":0.0163934426,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07549-17189-19772","score":0.0161290323,"text":"\nIf the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d. A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.A \"User Product\" is either (1) a \"consumer product\", which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, \"normally used\" refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\"Installation Information\" for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_10817-7-1802","score":0.0161290323,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13863-0-797","score":0.0158730159,"text":"\n\n\n\n\n\n\n  Working with Network Interface Card routing \n\nWhen working with a VSI that has multiple network interface cards (NICs), pay close attention to its networking settings to avoid connectivity problems. These problems may be due to how the routing works in the VSI and its security group. The default route points to the first NIC. In that case, pinging the address of the first NIC may work, however pinging the address of the second NIC may fail. Your security group may block response traffic that is not associated with inbound traffic.\n\nAs per your needs, you may need to change your default route to configure where to route traffic from all source addresses. Or, you may need to add a route to your routing table to configure where to send traffic from specific source addresses.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-tg-nic"},{"document_id":"ibmcld_10817-2884-4620","score":0.0158730159,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07863-0-2804","score":0.015625,"text":"\n\n\n\n\n\n\n  SA-5 - Information System Documentation \n\n\n\n  Control requirements \n\nThe organization:\n\nSA-5 (a)\n:   Obtains administrator documentation for the information system, system component, or information system service that describes:\n\n\n\n1.  Secure configuration, installation, and operation of the system, component, or service;\n2.  Effective use and maintenance of security functions\/mechanisms; and\n3.  Known vulnerabilities regarding configuration and use of administrative (i.e., privileged) functions;\n\n\n\nSA-5 (b)\n:   Obtains user documentation for the information system, system component, or information system service that describes:\n\n\n\n1.  User-accessible security functions\/mechanisms and how to effectively use those security functions\/mechanisms;\n2.  Methods for user interaction, which enables individuals to use the system, component, or service in a more secure manner; and\n3.  User responsibilities in maintaining the security of the system, component, or service;\n\n\n\nSA-5 (c)\n:   Documents attempts to obtain information system, system component, or information system service documentation when such documentation is either unavailable or nonexistent and takes [Assignment: organization-defined actions] in response;\n\nSA-5 (d)\n:   Protects documentation as required, in accordance with the risk management strategy; and\n\nSA-5 (e)\n:   Distributes documentation to [Assignment: organization-defined personnel or roles].\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control helps organizational personnel understand the implementation and operation of security controls associated with information systems, system components, and information system services. Organizations consider establishing specific measures to determine the quality\/completeness of the content provided. The inability to obtain needed documentation may occur, for example, due to the age of the information system\/component or lack of support from developers and contractors. In those situations, organizations may need to recreate selected documentation if such documentation is essential to the effective implementation or operation of security controls. The level of protection provided for selected information system, component, or service documentation is commensurate with the security category or classification of the system. For example, documentation associated with a key DoD weapons system or command and control system would typically require a higher level of protection than a routine administrative system. Documentation that addresses information system vulnerabilities may also require an increased level of protection. Secure operation of the information system, includes, for example, initially starting the system and resuming secure system operation after any lapse in system operation.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-5"},{"document_id":"ibmcld_10852-45155-46272","score":0.015625,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_05125-1346-2681","score":0.0153846154,"text":"\nThe official s3fs documentation suggests using libcurl4-gnutls-dev instead of libcurl4-openssl-dev. Either work, but the OpenSSL version may result in better performance.\n\nFor macOS, you will need to build s3fs from source:\n\nEnsure you have the following packages installed (all are available via [Homebrew](https:\/\/brew.sh)):\n\n\n\n* macfuse\n* automake\n* gcc\n* curl\n* libxml2\n* pkg-config\n* openssl\n\n\n\nAnd as noted in the output of the openssl install, you'll need to set these environment variables:\n\nexport LDFLAGS=\"-L\/usr\/local\/opt\/openssl@3\/lib\"\nexport CPPFLAGS=\"-I\/usr\/local\/opt\/openssl@3\/include\"\nexport PKG_CONFIG_PATH=\"\/usr\/local\/opt\/openssl@3\/lib\/pkgconfig\"\n\nBe aware that [macFUSE is closed-source software](https:\/\/osxfuse.github.io) containing a kernel extension, and may require a license for commercial use.\n\nFirst clone the Github repository:\n\ngit clone https:\/\/github.com\/s3fs-fuse\/s3fs-fuse.git\u00a0\n\nThen build s3fs:\n\ncd s3fs-fuse\n.\/autogen.sh\n.\/configure\nmake\n\nAnd install the binary:\n\nsudo make install\n\n\n\n\n\n Configuration \n\nStore your credentials in a file containing either <access_key>:<secret_key> or :<api_key>. This file needs to have limited access so run:\n\nchmod 0600 <credentials_file>\n\n\n\nNow you can mount a bucket using:\n\ns3fs <bucket> <mountpoint> -o url=http{s}:\/\/<endpoint> \u2013o passwd_file=<credentials_file>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-s3fs"},{"document_id":"ibmcld_10817-1342-3184","score":0.0153846154,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11192-0-1195","score":0.0327868852,"text":"\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/planning-analytics?topic=planning-analytics-exploring-scorecards"},{"document_id":"ibmcld_09615-10623-12269","score":0.0322580645,"text":"\n\"containers-kubernetes\"\n]\n},\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-4729-6393","score":0.0317460317,"text":"\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-2350-4116","score":0.03125,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-8271-10037","score":0.0307692308,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09628-1427-3147","score":0.0303030303,"text":"\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:\n\noperand\n: Operand is the name of the property in the target that is used to filter data. The following operands are supported: location, service_name, service_instance, resource_type, and resource. The value is extracted from the target CRN.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route_rules_definitions"},{"document_id":"ibmcld_09623-1182-2897","score":0.0298507463,"text":"\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Configure the route \n\nRun the following command to exclude all metrics received by IBM Cloud Metrics Routing from the us-south region.\n\nibmcloud metrics-router route create --name drop-route --rules '[{\"action\": \"drop\", \"inclusion_filters\":{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}]}]'\n\nWhere inclusion_filters specifies the filters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09623-4-1600","score":0.0294117647,"text":"\n* CLI\n\n\n\n\n\n\n\n Excluding metrics by using the drop action \n\nYou can configure IBM Cloud\u00ae Metrics Routing to exclude (drop) metrics based on a configured rule. Dropped metrics are not sent on to a target.\n\n\n\n Prereqs \n\n\n\n1. [Install the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli).\n2. [Install the IBM Cloud Metrics Routing CLI](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli-config).\n3. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing routes.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-iam)\n4. Log in to IBM Cloud. Run the following command: [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_login).\n\n\n\n\n\n\n\n Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location, service_name, service_instance, resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09625-1179-2989","score":0.0289855072,"text":"\nStep 2: Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Step 3: Configure the route","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-from-1-location"},{"document_id":"ibmcld_04612-2600-4714","score":0.0285714286,"text":"\nThe CPU utilization can be affected by the total workload of the hosting hardware and other factors.\n* Responsetime is the average amount of time that the app takes to respond to a request. Responsetime is specified in ms (milliseconds).\n* Throughput is the total number of the requests that are processed in a time period. Throughput is specified in rps (requests per second).\n* Custom_metric is your own custom metric. The Custom_metric name can be any alphanumeric value. Autoscaling is triggered when the corresponding metric is emitted to the App Autoscaler. For more information, see the [custom metric usage guide](https:\/\/github.com\/cloudfoundry\/app-autoscaler\/tree\/develop\/docsauto-scale-your-application-with-custom-metrics).\n\n\n\nIn addition to specifying the metric type, specify an operator, threshold, breach duration, adjustment, and cooldown period values.\n\nWhen the threshold is continuously breached during the breach duration period, and beyond the cooldown period, the App AutoScaler triggers the defined autoscaling action. The number or percentage of app instances is adjusted.\n\n\n\n* The operator can be >=, >, <=, or <.\n* The threshold must be a numeric value.\n* The breach duration is defined in seconds. The default value is 120 seconds.\n* The adjustment value specifies how the number of app instances change in each scaling action. You can specify an absolute number or a percentage of instances to add or remove.\n* The cooldown period specifies the time to wait before the taking the next autoscaling action. A cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04334-286223-287431","score":0.031778058,"text":"\n<-- <\/section \"id=\"section-delete-alert-policy-examples\" \"> --><-- <\/section \"id=\"section-delete-alert-policy\" \"> --><-- <\/section \"id=\"section-alert-policy\" \"> --><-- <section \"id=\"section-alert-webhook\" \"> --> Alert Webhook <-- <section \"id=\"section-list-alert-webhooks\" \"> --> ibmcloud cis alert-webhooks List all alert webhooks. ibmcloud cis alert-webhooks -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-list-alert-webhooks\" \"> --> Command options -i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-list-alert-webhooks\" \"> --><-- <section \"id=\"section-list-alert-webhooks-examples\" \"> --> Examples List all webhooks for instance cis-demo ibmcloud cis alert-webhooks -i \"cis-demo\"\n<-- <\/section \"id=\"section-list-alert-webhooks-examples\" \"> --><-- <\/section \"id=\"section-list-alert-webhooks\" \"> --><-- <section \"id=\"section-show-alert-webhook\" \"> --> ibmcloud cis alert-webhook Show the details of a given webhook. ibmcloud cis alert-webhook WEBHOOK_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-272370-273682","score":0.0312805474,"text":"\n<-- <section \"id=\"section-opt-certificate-alert\" \"> --> Command options --type: The type of the certificate.--name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-certificate-alert\" \"> --><-- <section \"id=\"section-certificate-alert-examples\" \"> --> Examples Create a certificate alert for instance cis-demo. ibmcloud cis alert-policy certificate-alert-create --type universal --name test1 --emails test1@cn.ibm.com --enabled true -i \"cis-demo\"\n<-- <\/section \"id=\"section-certificate-alert-examples\" \"> --><-- <\/section \"id=\"section-certificate-alert\" \"> --><-- <section \"id=\"section-create-glb-healthcheck-alert\" \"> --> ibmcloud cis alert-policy glb-healthcheck-alert-create Create an alert policy for changes in health status for global load balancer, pools, and origins.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-287106-288268","score":0.030798389,"text":"\n<-- <\/section \"id=\"section-list-alert-webhooks-examples\" \"> --><-- <\/section \"id=\"section-list-alert-webhooks\" \"> --><-- <section \"id=\"section-show-alert-webhook\" \"> --> ibmcloud cis alert-webhook Show the details of a given webhook. ibmcloud cis alert-webhook WEBHOOK_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-show-alert-webhook-options\" \"> --> Command options WEBHOOK_ID: The ID of alert webhook. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-show-alert-webhook-options\" \"> --><-- <section \"id=\"section-show-alert-webhook-examples\" \"> --> Examples Show the details of alert webhook b2633e68-9a64-4519-b361-a64a67c8db8e. ibmcloud cis alert-webhook b2633e68-9a64-4519-b361-a64a67c8db8e -i \"cis-demo\"\n<-- <\/section \"id=\"section-show-alert-webhook-examples\" \"> --><-- <\/section \"id=\"section-show-alert-webhook\" \"> --><-- <section \"id=\"section-create-alert-webhook\" \"> --> ibmcloud cis alert-webhook-create Create an alert webhook for a given instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-265349-266540","score":0.0303308824,"text":"\n<-- <\/section \"id=\"section-list-alert-policies-examples\" \"> --><-- <\/section \"id=\"section-list-alert-policies\" \"> --><-- <section \"id=\"section-show-alert-policy\" \"> --> ibmcloud cis alert-policy get (Show) Show the details of a given policy. ibmcloud cis alert-policy get POLICY_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-show-alert-policy-options\" \"> --> Command options POLICY_ID: The ID of alert policy. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-show-alert-policy-options\" \"> --><-- <section \"id=\"section-show-alert-policy-examples\" \"> --> Examples Show the details of alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy get a2633e68-1a64-2512-a321-b64a17c7db7a -i \"cis-demo\"\n<-- <\/section \"id=\"section-show-alert-policy-examples\" \"> --><-- <\/section \"id=\"section-show-alert-policy\" \"> --><-- <section \"id=\"section-create-ddos-attack-l7-alert\" \"> --> ibmcloud cis alert-policy ddos-attack-l7-alert-create Create an alert policy for DDoS attack l7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-282023-283354","score":0.029877369,"text":"\nRequired.--name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-update-certificate-alert\" \"> --><-- <section \"id=\"section-update-certificate-alert-examples\" \"> --> Examples Update a certificate alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy certificate-alert-update a2633e68-1a64-2512-a321-b64a17c7db7a --name test1 --emails test1@cn.ibm.com --webhooks b2633e68-9a64-4519-b361-a64a67c8db8e --enabled true -i \"cis-demo\"\n<-- <\/section \"id=\"section-update-certificate-alert-examples\" \"> --><-- <\/section \"id=\"section-update-certificate-alert\" \"> --><-- <section \"id=\"section-update-glb-healthcheck-alert\" \"> --> ibmcloud cis alert-policy glb-healthcheck-alert-update Update an alert policy for changes in health status for global load balancer, pools, and origins.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-266269-267601","score":0.0294372294,"text":"\n<-- <\/section \"id=\"section-show-alert-policy-examples\" \"> --><-- <\/section \"id=\"section-show-alert-policy\" \"> --><-- <section \"id=\"section-create-ddos-attack-l7-alert\" \"> --> ibmcloud cis alert-policy ddos-attack-l7-alert-create Create an alert policy for DDoS attack l7. ibmcloud cis alert-policy ddos-attack-l7-alert-create --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) --description DESCRIPTION] -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-create-ddos-attack-l7-alert\" \"> --> Command options --name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-create-ddos-attack-l7-alert\" \"> --><-- <section \"id=\"section-create-ddos-attack-l7-alert-examples\" \"> --> Examples Create a ddos attack alert policy for instance cis-demo.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04027-6430-8358","score":0.0163934426,"text":"\nGive this new panel a title, Disk space used %.\n3. Select fs.used.percent from the Metrics drop-down list.\n4. In the Segment by drop down list, select kubernetes.deployment.label.name and click Save.\n5. Hover your mouse over the data in the generated graph and a pop-up window is displayed that shows the average disk space percentage used by each peer container.\n\n\n\nAt this point you have configured panels to display the percentage of CPU used by each peer container, the percentage of memory used by each peer container, and the percentage of disk space used by each peer container. You can drag the panels up and down on the dashboard, and delete any panels that are not interesting to you.\n\nZoom\n\n![peer dashboard in monitoring](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/peerdashboard.png)\n\nFigure 1. Peer dashboard in IBM Cloud Monitoring\n\n\n\n\n\n Create dashboards for the CA and ordering nodes \n\nWhen you are satisfied with your peer dashboard, you can simply replicate it, using the Copy Dashboard menu item on the Options menu. Give the dashboard a new name, for example Blockchain Operations - CAs or Blockchain Operations - Ordering nodes. Then, edit the scope of the new dashboard to be either container.name contains ca or container.name contains orderer respectively.\n\n\n\n\n\n\n\n Step four: Configure alerts to monitor resource usage \n\nNow that you have configured monitoring of your peer, CA, and ordering nodes, the final important step is to configure alerts in IBM Cloud Monitoring so that a notification is triggered when a specified condition is met. You can trigger an alert notification via email, slack, PagerDuty, Webhooks, OpsGenie, and VictorOps channels. First configure the notification channel and then define the alert triggers.\n\n\n\n1. Configure your preferred notification channel by clicking on your user icon followed by Settings.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-monitoring"},{"document_id":"ibmcld_06407-7-1993","score":0.0161290323,"text":"\nRelease notes for IBM Cloud\u00ae Databases for EnterpriseDB \n\nUse these release notes to learn about the latest updates to IBM Cloud\u00ae Databases for EnterpriseDB that are grouped by date or build number.\n\n\n\n 23 May 2023 \n\nSetting up disk alerts for disk utilization tutorial\n: In this tutorial, you use the IBM Cloud API and the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) to set up an alert that emails you whenever the disk utilization of your database exceeds 90%. This specific example creates an alert on a Databases for Elasticsearch deployment, but it is applicable to all the databases in the IBM Cloud Databases catalog. For more information, see [Setting up disk alerts for disk utilization](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-disk-util-alert-tutorial).\n\n\n\n\n\n 19 October 2022 \n\nDeploying and Connecting a Cloud Databases Instance Tutorial\n: This tutorial guides you through the process of deploying a Cloud Databases instance and connecting it to a web front end by creating a webpage that allows visitors to input a word and its definition. These values are then stored in a database running on Cloud Databases. You install the database infrastructure by using Terraform and your web application uses the popular Express framework. The application can then be run locally, or by using Docker. For more information, see [Deploying and Connecting a Cloud Databases Instance](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-create-instance-tutorial).\n\n\n\n\n\n 11 October 2022 \n\nProtecting IBM Cloud\u00ae Databases for EnterpriseDB resources with context-based restrictions\n: Context-based restrictions (CBR) give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Cloud Databases resources can be controlled with CBR and identity and access management (IAM) policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-enterprisedb-relnotes"},{"document_id":"ibmcld_06716-7-1951","score":0.0158730159,"text":"\nRelease notes for IBM Cloud\u00ae Databases for Redis \n\nUse these release notes to learn about the latest updates to IBM Cloud\u00ae Databases for Redis that are grouped by date or build number.\n\n\n\n 23 May 2023 \n\nSetting up disk alerts for disk utilization tutorial\n: In this tutorial, you use the IBM Cloud API and the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) to set up an alert that emails you whenever the disk utilization of your database exceeds 90%. This specific example creates an alert on a Databases for Elasticsearch deployment, but it is applicable to all the databases in the IBM Cloud Databases catalog. For more information, see [Setting up disk alerts for disk utilization](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-disk-util-alert-tutorial).\n\n\n\n\n\n 19 October 2022 \n\nDeploying and Connecting a Cloud Databases Instance Tutorial\n: This tutorial guides you through the process of deploying a Cloud Databases instance and connecting it to a web front end by creating a webpage that allows visitors to input a word and its definition. These values are then stored in a database running on Cloud Databases. You install the database infrastructure by using Terraform and your web application uses the popular Express framework. The application can then be run locally, or by using Docker. For more information, see [Deploying and Connecting a Cloud Databases Instance](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=cloud-databases-create-instance-tutorial).\n\n\n\n\n\n 11 October 2022 \n\nProtecting IBM Cloud\u00ae Databases for Redis resources with context-based restrictions\n: Context-based restrictions (CBR) give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Cloud Databases resources can be controlled with CBR and identity and access management (IAM) policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-redis-relnotes"},{"document_id":"ibmcld_06445-7-1950","score":0.015625,"text":"\nRelease notes for IBM Cloud\u00ae Databases for etcd \n\nUse these release notes to learn about the latest updates to IBM Cloud\u00ae Databases for etcd that are grouped by date or build number.\n\n\n\n 23 May 2023 \n\nSetting up disk alerts for disk utilization tutorial\n: In this tutorial, you use the IBM Cloud API and the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) to set up an alert that emails you whenever the disk utilization of your database exceeds 90%. This specific example creates an alert on a Databases for Elasticsearch deployment, but it is applicable to all the databases in the IBM Cloud Databases catalog. For more information, see [Setting up disk alerts for disk utilization](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=messages-for-etcd_full-disk-util-alert-tutorial).\n\n\n\n\n\n 19 October 2022 \n\nDeploying and Connecting a Cloud Databases Instance Tutorial\n: This tutorial guides you through the process of deploying a Cloud Databases instance and connecting it to a web front end by creating a webpage that allows visitors to input a word and its definition. These values are then stored in a database running on Cloud Databases. You install the database infrastructure by using Terraform and your web application uses the popular Express framework. The application can then be run locally, or by using Docker. For more information, see [Deploying and Connecting a Cloud Databases Instance](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=cloud-databases-create-instance-tutorial).\n\n\n\n\n\n 11 October 2022 \n\nProtecting IBM Cloud\u00ae Databases for etcd resources with context-based restrictions\n: Context-based restrictions (CBR) give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Cloud Databases resources can be controlled with CBR and identity and access management (IAM) policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-etcd-relnotes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-4-2165","score":0.0327868852,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":0.0322580645,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":0.0317460317,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":0.03125,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_16002-11336-13014","score":0.0153846154,"text":"\ncheck the VPN connection status to be changed to up\nterraform state show ibm_is_vpn_gateway_connection.is_vpn_gateway_connection\n\n\n\nFor more information, see the [Terraform registry](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_vpn_gateway_connection).\n\n\n\n\n\n\n\n Upgrading a VPN from a custom IKE or IPsec policy \n\nComplete the following procedure to upgrade a VPN from a custom IKE or IPsec policy.\n\n\n\n Before you begin \n\nOn 20 September 2022, VPN for VPC IKE and IPsec weak ciphers were deprecated. To upgrade a VPN connection that was created using a custom IKE or IPsec policy that contains weak ciphers, complete the following steps.\n\nYou will experience a network outage during the upgrade. The duration of the outage depends on the time that it takes to update the weak ciphers and to reestablish the VPN connection. It is recommended that you plan a maintenance window for this upgrade.\n\nBefore you begin, it is a good idea to first configure your on-prem VPN gateway peer to contain both the weak and secure ciphers for Phase 1 and Phase 2 negotiation. Then, change the IBM VPN gateway to remove the use of the weak ciphers by following these steps. Afterward, remove the weak ciphers from the on-prem VPN gateway. This step might also reduce the outage time.\n\n\n\n\n\n Upgrading a VPN from a custom IKE policy in the UI \n\nTo upgrade the IKE policy by using the UI, follow these steps:\n\n\n\n1. From the VPNs for VPC page, select Site-to-site gateways > IKE policies.\n2. Select the IKE policy configured in the VPN connection that you want to upgrade.\n3. Highlight the row of the IKE policy in the table, then click Edit from the Actions menu !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-upgrading-weak-ciphers"},{"document_id":"ibmcld_16359-9997-12076","score":0.0153846154,"text":"\nSet the Enable disambiguation switch to Off.\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to disable clarification. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Excluding an action from clarifying questions \n\nYou can also prevent a single action from being used in a clarifying question. The effect of this choice depends on the confidence score for the action that you exclude.\n\nIf the action has the highest confidence score for a customer's question, no clarifying question is asked, and the action is triggered.\n\nIf the action doesn't have the highest confidence score, the action is excluded from the list of choices in the clarifying question.\n\nFor more information about confidence scores, see [Confidence scoring](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-confidence-scoring).\n\nTo exclude an action from clarification:\n\n\n\n1. From the action editor, click the Action settings icon ![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. In Action Settings, toggle the Ask clarifying question switch to Off.\n\n\n\n\n\n\n\n\n\n Coordinating how multiple actions start \n\nAs you work on your assistant, it's a good idea to coordinate customer phrase examples across multiple actions. It's important to distinguish how each action is triggered. When a user enters a question or request, the phrase is evaluated across all the Customer starts with examples in every action. If two actions have similar phrase examples, then the wrong action might get triggered by your user's question.\n\n\n\n Confidence scoring \n\nBehind the scenes, Watson Assistant determines a confidence score for each phrase. The score is absolute, meaning that a confidence score is assigned based on a predetermined scale, and not relative to other customer phrases. This approach adds flexibility in case multiple questions or requests are detected in a single user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_13673-4007-5957","score":0.0151515152,"text":"\nThe <break> element inserts a pause into the spoken text. It has the following optional attributes:\n\n\n\n* strength specifies the length of the pause in terms of varying strength values:\n\n\n\n* none suppresses a break that might otherwise be produced during processing.\n* x-weak, weak, medium, strong, or x-strong insert increasingly stronger breaks.\n\n\n\n* time specifies the length of the pause in terms of seconds or milliseconds. Valid value formats are {integer}s for seconds or {integer}ms for milliseconds.\n\n\n\nBreak size <break strength=\"none\"\/> no pause\nBreak size <break strength=\"x-weak\"\/> x-weak pause\nBreak size <break strength=\"weak\"\/> weak pause\nBreak size <break strength=\"medium\"\/> medium pause\nBreak size <break strength=\"strong\"\/> strong pause\nBreak size <break strength=\"x-strong\"\/> x-strong pause\nBreak size <break time=\"1s\"\/> one-second pause\nBreak size <break time=\"1500ms\"\/> 1500-millisecond pause\n\n\n\n\n\n The <desc> element \n\nThe <desc> element can occur only within an <audio> element. Because the <audio> element is not supported, neither is the <desc> element.\n\n\n\n\n\n The <emphasis> element \n\nThe <emphasis> element is supported for use only with the expressive neural voices.\n\nWith the expressive neural voices, you can use the <emphasis> element to emphasize or de-emphasize one or more words of the input text. The element supports an optional level attribute that accepts one of the following values:\n\n\n\n* none - Prevents the service from emphasizing text that might otherwise be emphasized.\n* moderate - Provides a noticeable amount of emphasis to the text. This level is the default if you omit the level attribute.\n* strong - Provides a more significant amount of emphasis to the text than the moderate level provides.\n* reduced - De-emphasizes the text by tending to reduce its significance in the audio. This level is the opposite of stressing the text.\n\n\n\nThe following example applies the moderate level to the word give:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-elements"},{"document_id":"ibmcld_16312-7-1935","score":0.0151515152,"text":"\nGlossary \n\n\n\nGlossary\n\n Term Definition \n\n Action Actions represent the tasks or questions that your assistant can help customers with. Each action has a beginning and an end, making up a conversation between the assistant and a customer. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview). \n Ask clarifying question A feature that enables the assistant to ask customers to clarify (disambiguate) their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question). \n Assistant Container for your actions, channels, and integrations. You add actions and at least one channel to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview). \n Change conversation topic A feature that gives the user the power to direct the conversation. It allows digressions and prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-change-topic). \n Channel The location where your assistant interacts with your users, for example, over the phone, on a website, or in Slack. At least one channel is required for every assistant. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant). \n Completion Measures how often within a given time period users reach the end step of an action. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-action-completioncomplete-reasons). \n Content The conversation logic and words that are used to respond to your customer. Content is required for every assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-glossary"},{"document_id":"ibmcld_14951-9338-11113","score":0.0149253731,"text":"\nTo ensure your clients will work reliably in the future, check that the new instance_groups_supported property on the [load balancer](https:\/\/cloud.ibm.com\/apidocs\/vpcget-load-balancer) is true before specifying that load balancer or one of its pools.\n\n\n\n\n\n\n\n 13 June 2023 \n\n\n\n For all version dates \n\nVPC routing table authorizations. You can use the new VPC routing table authorizations to allow users to administer VPC routing tables but not allow them to administer the broader VPC. The VPC API methods that operate on routing tables have been updated to check for these new authorizations, instead of the broader VPC authorizations. The VPC Administrator, Editor, Operator, and Viewer IAM access roles have been updated so that users with those roles will function as before. However, custom roles that require access to routing tables must be updated. For more information, see [IAM actions for VPC routing tables](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-iam-actions-vpc-routing-tables).\n\n\n\n\n\n\n\n 23 May 2023 \n\n\n\n For all version dates \n\nRemoval of weak VPN for VPC ciphers. Effective 18 May 2023, the following VPN IKE and IPsec ciphers are removed:\n\n\n\n* Authentication algorithms md5 and sha1\n* Encryption algorithm triple_des\n* Diffie\u2013Hellman groups 2 and 5\n\n\n\nAs a result, you will no longer be able to create an IKE\/IPsec policy or VPN connection that includes a weak cipher, but you can still [upgrade weak cipher suites](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-upgrading-weak-ciphers&interface=ui) on an existing policy or connection. For more information, see [Upgrading weak cipher suites on a VPN gateway](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-upgrading-weak-ciphers&interface=api).\n\n\n\n\n\n\n\n 2 May 2023 \n\n\n\n For all version dates \n\nExporting custom images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-api-change-log"},{"document_id":"ibmcld_16242-7-2224","score":0.0149253731,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01178-16125-18417","score":0.0312576313,"text":"\nKafka quotas use sampling to determine how long clients should be paused before they can send or receive more data. For unpredictable workloads, or configurations that result in quota decisions being made using only a few samples, you might observe the percentage quota used metric going above 100%.\n\n\n\n Authentication failures \n\nIncrementing count of the number of authentication failures\n\n\n\nTable 7. Authentication failures metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_authentication_failure_total \n Metric Type counter \n Value Type none \n Segment By Service instance, Service instance name \n\n\n\nIdeally zero. A nonzero value on this indicates that clients attempt to connect by using invalid credentials. Ensure that all clients are using valid credentials.\n\n\n\n\n\n Consume message conversion time \n\nIndicates that the accumulated time spent performing message conversion from clients that are consuming by using older protocol versions.\n\n\n\nTable 8. Consume message conversion time metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_consume_conversions_time_quantile \n Metric Type gauge \n Value Type second \n Segment By Service instance, Quantile, Service instance name \n\n\n\nIdeally zero, as nonzero indicates that clients are experiencing more latency because of using an older protocol level. Those clients are down-level and must be upgraded. Ensure that all clients are at the latest levels.\n\n\n\n\n\n Estimated connected clients percentage \n\nThe percentage of maximum number of connected clients.\n\n\n\nTable 9. Estimated connected clients percentage metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_recommended_max_connected_clients_percent \n Metric Type gauge \n Value Type percent \n Segment By Service instance, Service instance name \n\n\n\nThis is for information to help you monitor trends in your usage. See [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose) to determine what the recommended limits are for your plan and cluster.\n\n\n\n\n\n Connected clients software name and version \n\nThe number of connected clients with a particular client software name and version.\n\n\n\nTable 10. Connected clients software name and version metric metadata\n\n Metadata Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-metrics"},{"document_id":"ibmcld_02871-1651-3098","score":0.0163934426,"text":"\nTest the deployed assistant and make refinements.\n7. After you build an effective assistant, take a snapshot of the dialog skill and save it as a version.\n\nSaving a version when you reach a development milestone gives you something you can go back to if subsequent changes you make to the skill decrease its effectiveness. See [Creating skill versions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions).\n8. Deploy the version of the assistant into a test environment, and test it.\n9. Monitor the chat transcript logs for your test assistant to determine if you need to make improvements to your training data or dialog.\n10. When you are happy with the performance of your assistant, deploy the best version of the assistant into a production environment.\n11. Monitor the logs from conversations that users have with the deployed assistant.\n\n\n\nThe process of monitoring the conversations that your assistant has with your customers is your responsibility. Devise ways to analyze these chat transcripts so you can find out where the assistant is misunderstanding users or where its training data needs to be improved. For example, you might need to augment the training data if many customers ask for help with something that your assistant does not know anything about, or you might have two intents that are not distinct enough from one another if your assistant regularly picks the wrong dialog branches for certain topics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dev-process"},{"document_id":"ibmcld_16314-2927-4978","score":0.0163934426,"text":"\nAdd a step or edit an existing step to transfer the conversation to a live agent.\n\nTransferring the conversation to a live agent ends the action. If there are situations where you want the conversation to continue within the assistant rather than being transferred, use step conditions as needed.\n2. In the And then field at the end of the step, select Connect to agent.\n3. In the Settings window, you can customize messages the assistant displays as part of the transfer:\n\n![Connect to agent settings](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-agent-settings.png)\n\n\n\n* Response if agents are online: The message the assistant sends to the customer when the conversation is being transferred to an agent. The default message is Let's send you to an available agent.\n* Response if agents are offline: The message the assistant sends to the customer when no agents are currently available to take over the conversation. The default message is There are no agents available at this time. When one becomes available, we'll connect you.\n* Message to agent: An optional message the assistant sends to the live agent when transferring the conversation.\n* Route to a specific queue: An optional selection to route customers to a specific integration, which can be helpful if you have more than one set up.\n\n\n\n4. Click Apply.\n\n\n\nIf you want to edit the transfer settings later, click Edit settings in the And then field.\n\n\n\n\n\n Fallback escalations \n\nExamples of fallback escalations include:\n\n\n\n* The customer repeatedly asks a question or makes a request that the assistant cannot match to any defined action.\n* The customer repeatedly gives an invalid answer to a question.\n* The customer explicitly asks to speak to a human.\n\n\n\nFallback escalations use the Fallback action, which is a built-in system action that is automatically triggered in any of these fallback scenarios. By default, the Fallback action handles these error conditions by initiating a transfer to a live agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent"},{"document_id":"ibmcld_16250-12497-14080","score":0.0161290323,"text":"\nAt that point, the system can respond by updating the relevant failover metadata to route traffic to the service instance in the other region. Once a failover happens, you can decide to continue using the new region as the active instance, or if you want to resume using the initial region once it has stabilized.\n\nFor an active\/active topology, some form of a load balancing can be used, where two or more service instances in unique regions always receive a percentage of traffic. Additional logic would need to be established to determine when to pull a region out of rotation. This monitoring logic could use a [circuit break pattern](https:\/\/martinfowler.com\/bliki\/CircuitBreaker.html) similar to the active\/passive configuration or rely on a separate dedicated monitoring framework that determines region health. Also similar to active\/passive, determining when to insert a region back in rotation would need to be considered as well.\n\n\n\n\n\n Failover for v2 stateful API \n\nFailover for the v2 stateful API is similar to stateless, with these details to consider:\n\n\n\n* The state of a given conversation is persisted by Watson Assistant in a database that is tied to a particular region. As such, a failover for the stateful v2 \/message may more disruptive.\n* For an active\/passive topology, you should assume that all in-progress conversations are ended.\n* For an active\/active topology, given the region-locked persistence constraints of the v2 stateful \/message architecture, all turns (\/message API calls) of a given conversation (session) should occur within the same region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16259-1485-3642","score":0.0161290323,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_03312-12659-14672","score":0.0158730159,"text":"\nNote that IAM is a global service, but the custom resources (assistants and skills) used by Watson Assistant access control means each region, which has specific resources, requires specific policies.\n\nFor an active\/passive topology, some form of a [circuit break pattern](https:\/\/martinfowler.com\/bliki\/CircuitBreaker.html) can be used. A single service instance in a given region is used exclusively unless errors are detected. At that point, the system can respond by updating the relevant failover metadata to route traffic to the service instance in the other region. Once a failover happens, you can decide to continue using the new region as the active instance, or if you want to resume using the initial region once it has stabilized.\n\nFor an active\/active topology, some form of a load balancing can be used, where two or more service instances in unique regions always receive a percentage of traffic. Additional logic would need to be established to determine when to pull a region out of rotation. This monitoring logic could use a [circuit break pattern](https:\/\/martinfowler.com\/bliki\/CircuitBreaker.html) similar to the active\/passive configuration or rely on a separate dedicated monitoring framework that determines region health. Also similar to active\/passive, determining when to insert a region back in rotation would need to be considered as well.\n\n\n\n\n\n Failover for v2 stateful API \n\nFailover for the v2 stateful API is similar to stateless, with these details to consider:\n\n\n\n* The state of a given conversation is persisted by Watson Assistant in a database that is tied to a particular region. As such, a failover for the stateful v2 \/message may more disruptive.\n* For an active\/passive topology, you should assume that all in-progress conversations are ended.\n* For an active\/active topology, given the region-locked persistence constraints of the v2 stateful \/message architecture, all turns (\/message API calls) of a given conversation (session) should occur within the same region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_10852-50127-51451","score":0.015625,"text":"\n* [Implementing feeds with polling](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_polling)\n* [Implementing feeds by using connections](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_connections)\n\n\n\n[IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-alerts-notifyalerts-notify)\n\n\n\n Watson packages \n\n[Watson Assistant](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantpkg_watson_assistant)\n\n\n\n* [Creating a Watson Assistant service instance](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantservice_instance_conversation)\n* [Installing the Watson Assistant package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantinstall_conversation)\n\n\n\n* [Installing from the Cloud Functions CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantconversation_cli)\n* [Installing from the Cloud Functions console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantconversation_ui)\n\n\n\n* [Using the Watson Assistant package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantusage_conversation)\n\n\n\n[Natural Language Classifier](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_natlang_classifierpkg_natlang_classifier)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_16250-1908-4265","score":0.015625,"text":"\nHowever, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_02898-0-1202","score":0.0153846154,"text":"\n\n\n\n\n\n\n  Planning the dialog \n\nLearn how to approach building a dialog.\n\n\n\n*  Plan out the design of the dialog that you want to build before you add a single dialog node. Sketch it out on paper, if necessary.\n*  Whenever possible, base your design decisions on data from real-world evidence and behaviors. Do not add nodes to handle a situation that someone thinks might occur.\n*  Avoid copying business processes as-is. They are rarely conversational.\n*  If people already use a process, examine how they approach it. People typically optimize the process from a conversational perspective.\n*  Decide on the tone, personality, and positioning of your assistant. Consistently reflect these choices in the dialog you create.\n*  Never misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it.\n*  Not everything has to be a conversation. Sometimes a web form works better.\n\n\n\nPrevious topic:[Dialog overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build)\n\nNext topic:[Building a conversational flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan"},{"document_id":"ibmcld_02844-1555-3643","score":0.0151515152,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16262-7-2107","score":0.0300904977,"text":"\nAccessing context data in dialog \n\nThe context is an object that contains variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation. The context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each user who interacts with the assistant. For user-based plans, this ID is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n\nThere are two types of context:\n\n\n\n* Global context: context variables that are shared by all skills that are used by an assistant, including internal system variables that are used to manage conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_16306-8539-10329","score":0.0163934426,"text":"\nIf no utterance is received before the timeout occurs, the phone integration sends a message to the assistant that includes the post_response_timeout_occurred property set to true. \n cdr_custom_data Object A JSON object containing key\/value pairs to be stored in the CDR record for the call. Each time this object is sent, its contents are merged with data sent previously during the call. \n turn_settings.timeout_count Integer The time (in milliseconds) to wait for Watson Assistant to finish processing each conversation turn. \n\n\n\n\n\n\n\n Example request JSON \n\n\"voice_telephony\" : {\n\"post_response_timeout_count\":10000,\n\"final_utterance_timeout_count\":30000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\" : {\n\"custom_data_1\": \"data 1\",\n\"custom_data_2\": \"data 2\"\n}\n}\n\n\n\n\n\n\n\n text_messaging \n\nIncluded only if the SMS with Twilio integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the text_messaging object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation. \n private.user_phone_number String The phone number from which the customer's SMS message originated. \n\n\n\n\n\n\n\n Example JSON \n\n\"text_messaging\": {\n\"private\":{\n\"user_phone_number\":\"+18595553456\"\n},\n\"assistant_phone_number\":\"+18885556789\"\n}\n\n\n\n\n\n\n\n whatsapp \n\nIncluded only if the WhatsApp integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the whatsapp object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_03363-4-2165","score":0.0163934426,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16261-12076-14011","score":0.0161290323,"text":"\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input\/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16314-1398-3402","score":0.0161290323,"text":"\n* [Salesforce](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-salesforce)\n* [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n* [Zendesk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk)\n\n\n\nThere are two basic scenarios when your assistant might need to transfer a conversation to a live agent:\n\n\n\n* Planned escalation refers to any anticipated situations in which you know you always want to hand off the conversation to a live agent.\n* Fallback escalation is an unexpected situation in which the customer is unable to get help from the assistant.\n\n\n\nWhen the assistant initiates a transfer, the agent receives a notification within the agent dashboard, and has access to the history of the customer's chat with the assistant.\n\n\n\n Planned escalations \n\nExamples of planned escalations might include the following:\n\n\n\n* The customer asks for a service that cannot be completed without the assistance of a live agent\n* The customer needs help with a sensitive subject that requires a human touch, such as asking about bereavement benefits or resolving a complaint\n\n\n\nTo set up a planned escalation, you build an action that can recognize a specific situation that requires a live agent. An example would be an action that is triggered by customer input I want to pay my bill (you might want to let live agents handle payments).\n\nWithin any action, you can create a step that initiates a transfer to a live agent:\n\n\n\n1. Add a step or edit an existing step to transfer the conversation to a live agent.\n\nTransferring the conversation to a live agent ends the action. If there are situations where you want the conversation to continue within the assistant rather than being transferred, use step conditions as needed.\n2. In the And then field at the end of the step, select Connect to agent.\n3. In the Settings window, you can customize messages the assistant displays as part of the transfer:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent"},{"document_id":"ibmcld_16322-7-2220","score":0.0158730159,"text":"\nPhone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-context"},{"document_id":"ibmcld_03112-4-2069","score":0.0158730159,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Accessing context data in dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Accessing context data \n\nThe context is an object containing variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation; the context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each end user who interacts with the assistant. For user-based plans, this ID is used for billing purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_03367-2935-4844","score":0.015625,"text":"\nprivate.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF). \n speech_to_text_result object The final response from the Speech to Text service in JSON format, including the transcript and confidence score for the top hypothesis and any alternatives. The format matches exactly the format that is received from the Speech to Text service. (For more information, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-textrecognize).) \n\n\n\n\n\n Example \n\n{\n\"input\": {\n\"text\": \"agent \",\n\"integrations\": {\n\"voice_telephony\": {\n\"speech_to_text_result\": {\n\"result_index\": 0,\n\"stopTimestamp\": \"2021-09-29T17:43:31.036Z\",\n\"transaction_ids\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_16250-1908-4265","score":0.015625,"text":"\nHowever, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03367-1712-3458","score":0.0153846154,"text":"\nIf this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"Hello\"\n}\n]\n},\n\"context\": {\n\"integrations\": {\n\"voice_telephony\": {\n\"post_response_timeout_count\": 10000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05479-871-1495","score":0.0163934426,"text":"\n{\"level\":\"info\",\"ts\":1625217529.370393,\"logger\":\"git\",\"msg\":\"ssh\",\"path\":\"\/usr\/bin\/ssh\",\"version\":\"OpenSSH_8.0p1, OpenSSL 1.1.1g FIPS 21 Apr 2020\"}\n{\"level\":\"info\",\"ts\":1625217529.3847454,\"logger\":\"git\",\"msg\":\"git\",\"path\":\"\/usr\/bin\/git\",\"version\":\"git version 2.27.0\"}\n{\"level\":\"info\",\"ts\":1625217529.3940003,\"logger\":\"git\",\"msg\":\"git-lfs\",\"path\":\"\/usr\/bin\/git-lfs\",\"version\":\"git-lfs\/2.11.0 (GitHub; linux amd64; go 1.14.4)\"}\n{\"level\":\"debug\",\"ts\":1625217529.3940916,\"logger\":\"git\",\"msg\":\"\/usr\/bin\/git clone --quiet --no-tags --branch main --depth 1 --single-branch -- https:\/\/github.com\/IBM\/CodeEngineX \/workspace\/source\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-build-gitsource-stepfail"},{"document_id":"ibmcld_05891-234382-236109","score":0.0163934426,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_12430-2025-3161","score":0.0161290323,"text":"\nmsg: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud\/kv\/data\/mykvsecret:key1 token={{ vault_token }} url={{ hostname_vault }}') }}\"\n\n- name: Lookup User Credentials secret with token - full\nvars:\nsecret_id: \"dc1d3b5a-176f-aea4-8124-7073f53dcf82\"\nansible.builtin.debug:\nmsg: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud\/username_password\/secrets\/{{ secret_id }} token={{ vault_token }} url={{ hostname_vault }}') }}\"\n\n- name: Parsing username_password\nvars:\nsecret_id: \"dc1d3b5a-176f-aea4-8124-7073f53dcf82\"\nsecret_data: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud\/username_password\/secrets\/{{ secret_id }}:secret_data token={{ vault_token }} url={{ hostname_vault }}') | to_json }} \"\nansible.builtin.debug:\nmsg: \"user is {{ secret_data.username }} and password is {{ secret_data.password }}\"\n\nwhen: login.status == 200\nShow more\n\nA successful request returns the following response.\n\nTASK [Lookup KV secret with token] \nok: [localhost] => {\n\"msg\": \"secret1\"\n}\n\nTASK [Lookup User Credentials secret with token - full] \nok: [localhost] => {\n\"msg\": {\n\"created_by\": \"xxxxxxxxxxxxx\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-integration-ansible"},{"document_id":"ibmcld_04489-234834-236561","score":0.0161290323,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05367-2825-4556","score":0.0158730159,"text":"\nAfter you create and run your Function, you can also update your Function by using any of the preceding ways, independent of how you created or previously updated your Function.\n\n\n\n\n\n Requests and responses \n\nFunctions are invoked with the HTTP protocol. When you invoke your Function, you can specify the custom request parameters, custom request body and headers, as well as the HTTP method. The request parameters are made available to the Function code as input parameters. The Function code can set the response body, response headers, and response code, which are returned to the caller from the Functions endpoint.\n\n\n\n Example 1: Generating an HTML response from a Function \n\nThe following example illustrates how to generate an HTML response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name) {\nmsg = Hello, ${params.name}!\n} else {\nmsg = Hello, FaaS on CodeEngine!\n}\nreturn {\nheaders: { 'Content-Type': 'text\/html; charset=utf-8' },\nbody: <html><body><h3>${msg}<\/h3><\/body><\/html>\n}\n}\n\nmodule.exports.main = main;\n\n\n\n\n\n Example 2: Setting a response code and response header \n\nYour Function can set a specific response code and header flags. The following example illustrates how you can set a response code and response header to add a redirect to a different URL.\n\nfunction main(params) {\nreturn {\nheaders: { location: 'https:\/\/cloud.ibm.com\/docs\/codeengine' },\nstatusCode: 302\n}\n}\n\n\n\n\n\n Example 3: Generating a plain text response from a Function \n\nThe following example illustrates how to generate a plain text response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name !== \"\") {\nmsg = Hello, ${params.name}!\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-work"},{"document_id":"ibmcld_05891-230244-232067","score":0.0158730159,"text":"\nAcceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_11852-5893-6717","score":0.015625,"text":"\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.133Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_ID value from SATELLITE_CONNECTOR_ID environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.138Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A01\",\"msg\":\"Load SATELLITE_CONNECTOR_IAM_APIKEY value from file \/agent-env-files\/apikey.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.140Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_TAGS value from SATELLITE_CONNECTOR_TAGS environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.141Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_REGION value from SATELLITE_CONNECTOR_REGION environment variable.\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-run-agent-locally"},{"document_id":"ibmcld_04489-230696-232519","score":0.015625,"text":"\nAcceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_11852-7002-7827","score":0.0153846154,"text":"\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.392Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"tunneldns\",\"msgid\":\"D04\",\"msg\":\"DoTunnelDNSLookup DNS resolve c-01-ws.us-south.link.satellite.cloud.ibm.com to 169.61.31.178\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.560Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"utilities\",\"msg\":\"MakeLinkAPICall GET \/v1\/connectors\/U2F0ZWxsaXRlQ29ubmVjdG9yOiJjaThzdWd1ZDFwZ2RrZmUxa3UxZyI status code 200\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.563Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT03\",\"msg\":\"Got configuration\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.565Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT04-wss:\/\/c-01-ws.us-south.link.satellite.cloud.ibm.com\/ws\",\"msg\":\"Connecting to wss:\/\/c-01-ws.us-south.link.satellite.cloud.ibm.com\/ws\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-run-agent-locally"},{"document_id":"ibmcld_05832-21399-23084","score":0.0153846154,"text":"\nIf not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option. \n <kubernetes_namespace> Optional: The Kubernetes namespace that you want to forward logs from. This option applies only when you are using log type container. \n <container_name> Optional: The name of the container from which you want to filter logs. \n <logging_level> Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. To display your messages in JSON, append the --output json option to the command. \n <message> Optional: Filters out logs that contain a specified message that is written as a regular expression. \n <filter_ID> Optional: The ID of the log filter. \n --show-matching-configs Optional: Show the logging configurations that each filter applies to. \n --all Optional: Delete all your log forwarding filters. \n\n\n\n\n\n1. Create a logging filter.\n\nibmcloud ks logging filter create --cluster <cluster_name_or_ID> --type <log_type> --logging-configs <configs> --namespace <kubernetes_namespace> --container <container_name> --level <logging_level> --regex-message <message>\n2. View the log filter that you created.\n\nibmcloud ks logging filter get --cluster <cluster_name_or_ID> --id <filter_ID> --show-matching-configs\n3. Update the log filter that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00580-37889-39953","score":0.0327868852,"text":"\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_16666-10416-12326","score":0.0322580645,"text":"\n* Add the metadata catalogs to manage your table schemas.\n* Select the query engine to work with your data.\n\n\n\nComplete the following steps:\n\n\n\n1. In the Bucket configuration page, select Provision new IBM-managed bucket.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select a catalog.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the Presto engine and smallest starter (1 coordinator node 1 worker node memory optimized).\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nAlthough you can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to, this would change the consumption rate of your promo code. When you add items in the Infrastructure manager, you can see the resource unit consumption per hour.\n\nThe promotion credits consumption begins immediately after you configure and the support services are created for your metadata. Ensure that you pause the Presto engine when it is not used. This helps in optimizing the usage credit.\n\n\n\n\n\n Step 6: Ingesting data \n\nThe data files are ingested into watsonx.data using CLI. For the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_07436-1437-3014","score":0.0317460317,"text":"\nYou tried to perform a domain name resolution multiple times for a given name using a custom resolver, but none of the attempts worked.\n\n\n\n* You received an NXDOMAIN error across multiple domain name resolution attempts.\n* The error persists for many minutes, but less than an hour.\n* The first attempt at DNS resolution takes the longest, typically. Most attempts for the same query after the first one take less time to resolve.\n\n\n\n Why it\u2019s happening \n\nFor example, an application in your VPC had attempted a domain name resolution to your custom resolver. Your custom resolver responded with an NXODMAIN response from an upstream DNS resolver and had cached that response. Then for subsequent queries, your custom resolver responded with that cached response. Because resolving from cache is faster, subsequent DNS queries that were resolved through the custom resolver's cache took less time. The TTL has a 30-minute maximum for the negative cache for the custom resolver, which is currently not a configuration parameter.\n\n How to fix it \n\nAvoid caching a negative DNS response in the resolver for that query before the period in which applications expect to intentionally make queries and get good responses. For example:\n\n\n\n* Add the DNS resource record that is associated with the queried name before the applications make that first DNS query.\n* Add the DNS resource record that is associated with the queried name, then wait until the negative cache entry on the custom resolver expires. Resume DNS queries, and maintain access to resource records for that DNS name.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-troubleshoot-nxdomain"},{"document_id":"ibmcld_00436-0-941","score":0.03125,"text":"\n\n\n\n\n\n\n  Updating CDN configuration details \n\nAfter your CDN is running, you can update CDN configuration details. Follow these steps.\n\n\n\n1.  On the CDN page, select your CDN, which takes you to the Overview page.\n2.  Select the Settings tab. Your CDN configuration details are displayed.\n\nYou only see SSL Certificate if your CDN was configured with HTTPS.\n\nFor Server, the following fields can be changed:\n\n\n\n*  Host header\n*  Origin server address\n*  HTTP\/HTTPS Port\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\nFor Object Storage, the following fields can be changed:\n\n\n\n*  Host header\n*  Endpoint\n*  Bucket name\n*  HTTPS Port\n*  Allowed file extensions\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\n3.  Update the Origin or Other Options details if needed, then click the Save button in the lower right corner to update your CDN configuration details.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-updating-cdn-configuration-details"},{"document_id":"ibmcld_07436-7-1996","score":0.0307692308,"text":"\nWhy did I get an NXDOMAIN error on name resolution? \n\nYou tried to perform a domain name resolution, but it didn't work. Your response can vary depending on whether the domain name resolution is the first query attempt, or across multiple query attempts.\n\n\n\n NXDOMAIN error on the first query \n\n What\u2019s happening \n\nYou tried to perform a domain name resolution for the first time, but you receive an NXDOMAIN error.\n\n Why it\u2019s happening \n\nNXDDOMAIN errors happen when a request to resolve a domain is sent to the DNS and the request can't be resolved to an IP address. An NXDOMAIN error message means that the domain does not exist.\n\n How to fix it \n\n\n\n* Verify DNS Services is configured correctly and that access to 161.26.0.7 and 161.26.0.8 is available from within the virtual server instance by using the following dig command: $ dig @161.26.0.7 yourzone.com.\n* Verify the server that you are sending the request from is configured to use one of these DNS resolvers: 161.26.0.7 or 161.26.0.8.\n* Verify the server that you are sending the request from is part of a VPC that has been added as a permitted network to the DNS zone.\n* Verify the FQDN for which name resolution is attempted has a resource record in the DNS zone.\n* Verify that the DNS request is using the correct resource record type in the query.\n\n\n\n\n\n\n\n NXDOMAIN error across multiple query attempts for the same name with custom resolver \n\n What\u2019s happening \n\nYou tried to perform a domain name resolution multiple times for a given name using a custom resolver, but none of the attempts worked.\n\n\n\n* You received an NXDOMAIN error across multiple domain name resolution attempts.\n* The error persists for many minutes, but less than an hour.\n* The first attempt at DNS resolution takes the longest, typically. Most attempts for the same query after the first one take less time to resolve.\n\n\n\n Why it\u2019s happening \n\nFor example, an application in your VPC had attempted a domain name resolution to your custom resolver.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-troubleshoot-nxdomain"},{"document_id":"ibmcld_15712-17534-19586","score":0.0303030303,"text":"\nBy default, the dashboard begins with the name \"blank dashboard\". You can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs. You might want to do this if you need raw data points or want to consume your metrics from a command-line interface rather than using the IBM Cloud Monitoring dashboard.\n\nAfter creating your monitoring instance, you must collect the following two pieces of information.\n\n\n\n* The Monitor API token\n* The endpoint of your IBM Cloud Monitoring instance\n\n\n\nTo collect this information and work with your monitoring instance using metric query API, follow these steps:\n\n\n\n1. Access the [Monitoring home page](https:\/\/cloud.ibm.com\/observe\/monitoring), and click Open Dashboard next to the instance you want to work with. After the dashboard displays, select your Account Profile icon on the left sidebar, then select Settings. Your account settings display.\n2. Your Monitor API token is an alphanumeric string that is located in the Monitor API Token field. Click the Copy button to the right of the key to transfer it to your clipboard.\n\nDo not share this API token. Anyone who has this API token has full access to your metrics.\n3. To get the endpoint of your IBM Cloud Monitoring instance, navigate to your main dashboard in your browser. Then, select the URL to the dashboard, which appears similar to:\n\nhttps:\/\/us-south.monitoring.cloud.ibm.com\/\/default-dashboard\/ibm_is_load_balancer?last=3600\n\nThe first part of the URL (in this case, us-south.monitoring.cloud.ibm.com) is your endpoint. Make note of it.\n4. After you have both the API token and the endpoint, you can format your POST request. The following POST request is an example, with all the parameters that you can modify. These parameters are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-monitoring-metrics-alb"},{"document_id":"ibmcld_15746-9884-11961","score":0.0298507463,"text":"\nYou can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs. You might want to do this if you need raw data points or want to consume your metrics from a command-line interface rather than using the dashboard.\n\nAfter creating your IBM Cloud Monitoring instance, you must collect the following two pieces of information.\n\n\n\n* The Monitor API token\n* The endpoint of your IBM Cloud Monitoring instance\n\n\n\nTo collect this information and start working with your monitoring instance using metric query API, follow these steps:\n\n\n\n1. Access the [Monitoring home page](https:\/\/cloud.ibm.com\/observe\/monitoring), and click Open Dashboard next to the instance you want to work with. After the IBM Cloud Monitoring dashboard displays, select your Account Profile icon on the left sidebar, then select Settings. Your account settings display.\n2. Your Monitor API token is an alphanumeric string that is located in the Monitor API Token field. Click the Copy button to the right of the key to transfer it to your clipboard.\n\nDo not share this API token. Anyone who has this API token has full access to your metrics.\n3. To get the endpoint of your IBM Cloud Monitoring instance, navigate to your main dashboard in your browser. Then, select the URL to the dashboard, which appears similar to:\n\nhttps:\/\/us-south.monitoring.cloud.ibm.com\/\/default-dashboard\/ibm_is_load_balancer?last=3600\n\nThe first part of the URL (in this case, us-south.monitoring.cloud.ibm.com) is your endpoint. Make note of it.\n4. After you have both the API token and the endpoint, you can format your POST request. The following POST request is an example, with all the parameters that you can modify. These parameters are:\n\n\n\n* The Monitor API token.\n* The endpoint of your monitoring instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb_monitoring-metrics"},{"document_id":"ibmcld_13480-7-2163","score":0.0294117647,"text":"\nGetting started with the catalog \n\nEach instance of IBM Cloud\u00ae Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud\u00ae Object Storage. Catalog syntax is compatible with Hive metastore syntax. See how to [work with the catalog](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogusage) and refer to the [Catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterHiveCatalog) section of the SQL reference.\n\n\n\n Benefits \n\nYou can explore, change, or discover structured data on [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/getting-started.htmlgetting-started-console) with Data Engine by using SQL syntax. To query data on Object Storage without a table in the catalog, you need to specify the data location (the corresponding Object Storage URI) and the data format in your SELECT statement. During query execution, data and schema are dynamically discovered as part of the SQL compilation process. This process, called inference, derives column names, data types, the list of partitions, and individual objects on Object Storage that together make up the table data.\n\nInferring all this information and doing it repetitively with every query imposes latency to your queries. The inference process can take up a significant amount of time, especially for text formats (for example, CSV and JSON), or when thousands of objects exist in different table partitions. In some cases, the inference process even accounts for the largest part of the overall query execution time. So, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13483-3955-6052","score":0.0289855072,"text":"\nAn INTO clause is implicitly added by the driver based on the Cloud Object Storage location that is given with the targetcosurl connection property.\n\nResults in the targetcosurl location are never deleted by the driver. Use [expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) to clean up your results on the IBM Cloud automatically.\n\n\n\n\n\n Basic limitations \n\nThe following limitations are implied by the use of Data Engine, which is not a full-featured database:\n\n\n\n* The driver is based on an asynchronous REST API and does not maintain persistent connections to the backend.\n* Data Engine is not designed for interactive performance on small data. Even tiny queries usually take several seconds to run.\n* Query results are returned through results in Cloud Object Storage. A SELECT query creates a full copy of the selected table (or Cloud Object Storage) in the targetcosurl location.\n* Streaming of query results cannot start until the execution fully completed and results were written to Cloud Object Storage.\n* Data Engine works on read-only data in Cloud Object Storage, so the following functions that are related to data updates is not supported:\n\n\n\n* Transactions are not supported. commit() and rollback() are no-ops.\n* Result sets that can be updated are not supported.\n\n\n\n* SQL statements cannot be canceled.\n\n\n\n\n\n\n\n Driver-specific limitations \n\nSee the following technical limitations of the driver:\n\n\n\n* Only primitive SQL types are supported in the result. Types like STRUCT, ARRAY, LOB, or ROWID cannot be retrieved from the result.\n* When you access the result, use the getter method, matching the result column type, for example, getInt() to retrieve an INTEGER column. Some implicit conversions are supported, for example, accessing an INTEGER column with getLong(), but not all conversions are implemented.\n* All result sets are FORWARD_ONLY and can be iterated with the ResultSet.next() method only. Determining the cursor position and explicitly moving the cursor is not supported.\n* Prepared statements are not supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-jdbc"},{"document_id":"ibmcld_15263-5634-7460","score":0.0285714286,"text":"\nibmcloud is instance-delete $vsi\n\nThe status of the instance changes to deleting immediately, but it still appears in a list query result. The deletion of an instance can take up to 30 minutes.\n\nYou can request other subnet resources to be deleted in parallel while you wait for the instance to be deleted. However, the subnet cannot be deleted until the instance and all other resources in the subnet no longer appear in the list query results.\n\nIf a secondary network interface exists in the subnet you are trying to delete, you must delete the instance. A network interface cannot be deleted from the instance without deleting the instance.\n\n\n\n\n\n Delete the subnet \n\nAfter all the resources inside the subnet were deleted, which means that they are not returned in a list query result, run the following command to delete the subnet:\n\nibmcloud is subnet-delete $subnet\n\nThe status of the subnet changes to deleting immediately, but it might take a few minutes until the subnet is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Step 3: Delete all public gateways in the VPC, if any \n\nTo list all public gateways in your account, run the following command:\n\nibmcloud is public-gateways\n\nFor each public gateway in the VPC you want to delete, run the following command to delete the public gateway, where $gateway is the public gateway ID.\n\nibmcloud is public-gateway-delete $gateway\n\n\n\n\n\n Step 4: Delete the VPC \n\nAfter all subnets and public gateways in the VPC are deleted, run the following command to delete the VPC, where $vpc is the ID of the VPC you are deleting.\n\nibmcloud is vpc-delete $vpc\n\nThe status of the VPC changes to deleting immediately, but it might take a few minutes until the VPC is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Deleting a VPC by using the REST APIs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-vpc-resources"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-101780-103603","score":0.0327868852,"text":"\nFor more information, see [catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.\n\nThe column and partition definitions are optional. If they are not provided, the table schema and partitioning is detected from the structure of the data at the indicated location. If you explicitly provide these definitions, ensure that they match the objects that are stored in Object Storage. See [data types](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencedataType) for details on the supported column types.\n\n-- create a definition for the table customer\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nlocation cos:\/\/us-geo\/sql\/customers.csv\nShow more\n\nBefore you can use a newly created partitioned table, you must call ALTER TABLE tablename RECOVER PARTITIONS. Otherwise, querying the table returns an empty result.\n\n-- create a definition for the table customers_partitioned\nCREATE TABLE customers_partitioned (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (COUNTRY)\nlocation cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\n-- attach table partitions by scanning the location of the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_09994-7-1823","score":0.0322580645,"text":"\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_00512-12262-14029","score":0.0317460317,"text":"\nFor the queries described previously, you need two indexes:\n\n\n\n1. A global index-mapping device ID to infrastructure ID\n2. A partitioned index-mapping device ID to reading\n\n\n\n\n\n Creating a global view index \n\nA view index is the most efficient way to do the simple device ID to infrastructure ID mapping. To define it, upload a design document with options.partitioned set to false as this index is global. While in a real map function you'd want to be more defensive around field existence, this document would look something like this:\n\n{\n\"options\": {\n\"partitioned\": false\n},\n\"views\": {\n\"by-device\": {\n\"map\": \"function(doc) { emit(doc.deviceID, doc.infrastructureID) }\"\n}\n}\n}\n\nAssuming the previous document in .\/view.json, this document is uploaded to the database by using the following command:\n\ncurl -X PUT \"$SERVICE_URL\/readings\/_design\/infrastructure-mapping\" -H 'Content-Type: application\/json' --data @view.json\n\nFor more language examples that show creating a global view, see the [Storing the view definition](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreducestoring-the-view-definition) guide, or [the Create or modify a design document section in API Docs](https:\/\/cloud.ibm.com\/apidocs\/cloudantputdesigndocument).\n\n\n\n\n\n Creating a partitioned IBM Cloudant Query index \n\nTo return the readings for a specific device from a partition, you can use an IBM Cloudant Query index. For this document, use POST to _index with an index definition that includes the partitioned field set to true.\n\nFor Query index definitions, the partitioned field isn't nested inside an options object.\n\nFor these queries, you need two partitioned indexes:\n\n\n\n1. By timestamp\n2. By device ID and timestamp\n\n\n\n\n\n Uploading partitioned index by timestamp","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_02628-4002-5694","score":0.03125,"text":"\nWith your query parameters defined in the previous step, you are ready to define the response object, which is returned when you invoke the weather API. Scroll to the Definitions panel.\n\n\n\n1. Add a new definition.\n2. Name the new definition Current.\n3. Set the Type of Object.\n4. Add new properties for the Current definition as shown in Table 1.\n\n\n\nTable 1. Properties for the Current definition\n\n Name Type \n\n zip string \n temperature integer \n humidity integer \n city string \n state string \n\n\n\n\n\n![definition-current-1.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/definition-current-1.png)\n\n\n\n5. Save your API.\n\n\n\n12. In the previous step, you defined the response object. Next you'll need to ensure the response object is associated with the get \/current path. In the navigation, scroll back up to the Paths panel. a. Open the GET \/current operation, and scroll to the Responses section. b. Change the schema of the 200OK response from \"object\" to \"Current\". c. Save your API.\n13. The GET \/current path and operation get the current weather data. Now you'll need to create a similar path and operation to get today's weather data. Similar to how you created the \/current path in step 11, create a new path: \/today.\n14. Add a Parameter to the GET \/today operation.\n\n\n\n* Parameter Name: zipcode\n* Located in: Query\n* Required: Yes\n* Type: string\n\n\n\n15. Create a new definition: Today.\n16. Add new properties for the Today definition as shown in Table 2.\n\n\n\nTable 2. Properties for the Today definition\n\n Name Type \n\n zip string \n hi integer \n lowe integer \n nighthumidity integer \n dayhumidity integer \n city string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-tut_add_openapi_rest_tk"},{"document_id":"ibmcld_13480-1642-3813","score":0.0307692308,"text":"\nSo, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names. Hence, SQL authors are able to compose queries without having to know the exact location and format of data on Object Storage. If the data location changes, only the table in the catalog must be updated, but the table name remains unchanged. Updates of the physical data structure are simplified and the robustness of SQL statements and applications is increased.\n\n\n\n\n\n Usage \n\nYou manage the database catalog in Data Engine with Database Definition Language (DDL) statements that you submit just like any other SQL query statement. The catalog is stored independently of Object Storage: No data is written to Object Storage when you create or change table definitions, and no data is deleted from Object Storage when you drop a table definition. To call the catalog management statements, you need the Manager user role assigned.\n\nTo register a new table in the catalog, use the CREATE TABLE statement, as in the following example:\n\nCREATE TABLE employees\nUSING PARQUET\nLOCATION cos:\/\/us-geo\/sql\/employees.parquet\n\nThe statement automatically detects the schema of the data at the location that is indicated. See the [SQL reference](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecreateTable) for options that can be set on the table.\n\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogpartitioned).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_00539-1510-2962","score":0.0300768883,"text":"\nFor the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byName\",\n\"type\": \"json\"\n}\n\nFor more information, see [Creating an Index](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-querycreating-an-index).\n\n\n\n\n\n Can I sort my search results with IBM Cloudant Query? \n\nYes! The _find JSON syntax allows for a sort parameter to be provided listing the attribute or attributes to sort by. In this case, we are sorting by date:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00522-2652-4218","score":0.0300768883,"text":"\nOpen the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard1.png)\n\nFigure 1. Window for running queries\n\n\n\nIBM Cloudant matches the documents that meet your criteria and it seems to do it quickly, but there's a catch. IBM Cloudant isn't using an index to service this query, meaning that the database has to scan every document in the database to get your answer. This scan is fine for small data sets. But if you're running a production application where the data set is expanding all the time, you definitely don't want to rely on unindexed queries.\n\n\n\n\n\n Creating an index \n\nTo create an index, we can tell IBM Cloudant to create an index on the publisher and year fields that we are using in our query.\n\n\n\n1. From the IBM Cloudant Dashboard, select the books database.\n2. Select the Design Documents tab.\n3. Select New Indexes from the Design Documents menu.\n4. Copy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_02628-2920-4398","score":0.0294117647,"text":"\n![toolkit-add-new-api.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/toolkit-add-new-api.png)\n6. Click Create API to complete the wizard.\n7. After your API is created, the Design tab is selected.\n8. Scroll to the Host panel. Enter $(catalog.host) as the value if the field is not automatically completed.\n9. Scroll to the Security tab and delete the \"clientIDHeader (API Key)\" that was auto-generated.\n(We'll visit security with API Keys in the next tutorial.)\n10. In the Paths panel, create a path by clicking +. a. Name the new path \"\/current\".\nb. In the same Paths panel, select the GET \/current section.\nc. In the GET \/current section, add a Parameter. As you noticed while exploring the sample app, the weather service requires zipcode as a parameter.\n\n\n\n* Name: zipcode\n* Located in: Query\n* Required: Yes\n* Type: string\n![path-current-1.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/path-current-1.png) d. Save your API.\n\n\n\n11. With your query parameters defined in the previous step, you are ready to define the response object, which is returned when you invoke the weather API. Scroll to the Definitions panel.\n\n\n\n1. Add a new definition.\n2. Name the new definition Current.\n3. Set the Type of Object.\n4. Add new properties for the Current definition as shown in Table 1.\n\n\n\nTable 1. Properties for the Current definition","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-tut_add_openapi_rest_tk"},{"document_id":"ibmcld_13498-114407-116260","score":0.0287784679,"text":"\n-- set the index location for the table CUSTOMERS_PARTITIONED\nALTER TABLE CUSTOMERS_PARTITIONED DROP METAINDEX LOCATION\n\n\n\n\n\n\n\n IndexAsset \n\n\n\n metaindexAsset \n\nThe indexAsset is either based on a table or Cloud Object Storage location.\n\nThe metaindexAssetLocation is a subset of the [externalTableSpec](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec).\n\nThe metaindexAssetHiveTable refers to a Hive table.\n\n\n\n\n\n\n\n\n\n Miscellaneous definitions \n\n\n\n COSURI \n\nA Cloud Object Storage Uniform Resource Identifier (COS URI) is a string of characters that uniquely identifies an object on Cloud Object Storage. By definition URIs are case-insensitive.\n\nThe syntax of a Cloud Object Storage URI is thoroughly described in section [Table unique resource identifier](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewunique).\n\n\n\n\n\n CRN_URI \n\nA database table CRN is a unique identifier that consists of the CRN of a database service instance and a specific table name that instance. The user must have access to this service instance and its credentials.\n\nThe syntax of a table CRN is thoroughly described in section [Table unique resource identifier](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewunique).\n\n\n\n\n\n DB2_TABLE_URI \n\nA Db2 table URI is a string of characters that uniquely identifies a table in an IBM\u00ae Db2\u00ae on Cloud and IBM\u00ae Db2\u00ae Warehouse on Cloud instance. The instance must be enabled for IAM and the IBMid if the user must be added as a database user.\n\nThe syntax of a Db2 Table URI is thoroughly described in section [Table unique resource identifier](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewunique).\n\n\n\n\n\n Identifier \n\nAn identifier is a name that uniquely identifies an entity. The two types of identifiers are unquoted identifiers and back quoted identifiers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_00580-42802-44973","score":0.0144927536,"text":"\nThis practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.\n\nComplete the index definition with the JSON:\n\nClick Create Index when you're done.\n\nClicking the button sends a POST request to the _index endpoint (other API calls are available to update and delete existing indexes).\n\nIndexes are built asynchronously by IBM Cloudant in the background. For large databases, it can take IBM Cloudant some time to construct the index for the first time. The index cannot use the database until that initial build is ready.\n\nWe can repeat our query for books in the 20th century. This time we specify the index name with the use_index field. The answer returns - this time powered by our index. You might not notice a speed improvement for a small database, but the benefit is definitely felt as your data size and query volume grows. Indexing helps your queries remain performant as your application scales.\n\nWhen you tell IBM Cloudant to create a secondary index, it starts a background task that looks at all the documents in turn and creates a new data structure on disk: the index. The index is a balanced tree which pairs the keys (the attribute or attributes that you need indexed) with the document _id they came from.\n\nThe index can be used to efficiently lookup known keys and ranges of keys without having to rescan the entire database.\n\nAnother trick that you can employ at index time is the partial filter. You can optionally supply a partial filter in your index definition. This IBM Cloudant Query selector is executed at index time to decide which documents' data makes it to the index and which are ignored.\n\nIn this example, a selector is employed that allows only dates that fall on a weekend to make it to the index. Smaller indexes are faster and more efficient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13075-7-2200","score":0.0327868852,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07163-7-1995","score":0.0322580645,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07175-7-2035","score":0.0317460317,"text":"\nViewing metrics and improving query results with the Performance dashboard \n\nThe Performance dashboard in the Discovery tooling can be used to view query metrics, as well as improve query results, including query relevance.\n\nYou can access the Performance dashboard by clicking the View data metrics icon. The dashboard is not available in Premium or Dedicated environments.\n\nThere are two options to improve natural language query results:\n\n\n\n* [Fix queries with no results by adding more data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardaddmore)\n* [Bring relevant results to the top by training your data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardtraindata)\n\n\n\nYou can view the data metrics in the [query overview](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardoverview).\n\n\n\n Fix queries with no results by adding more data \n\nIn this section of the dashboard, you can review queries that returned zero results and add more data so that the query returns results in the future. Click the View all and add data button to get started.\n\n\n\n\n\n Bring relevant results to the top by training your data \n\nIn this section, you can train your collections to improve the relevance of natural language query results. Click the View all and perform relevancy training button to get started. Then see [Adding queries and rating the relevancy of results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingresults) for instructions.\n\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_13075-1823-3835","score":0.03125,"text":"\nFor more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07175-1564-2340","score":0.0307692308,"text":"\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned\n* A graph that displays these results over time, so that you can track how adding more data and relevancy training are improving performance\n\n\n\nThese results are gathered using the Events and Feedback API. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_07214-71282-73334","score":0.0303030303,"text":"\n: [Resolved](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notesdiscovery-30june2017)\n\nImproved tooling error log : The Tooling error log is no longer limited to a maximum of eight (8) pages of results. The error log still displays the document ID if the document name is not available.\n\nUpdate to configuration names : Configuration names are limited to 50 characters and must consist of the characters [a-zA-Z0-9-_].\n\nImproved availability of 'passages' parameter : The passages parameter previously available only through the API is now available through the Tooling as well as the API.\n\n\n\n\n\n 25 April 2017 \n\nNew training data functionality : Use training data to improve the accuracy of your query results. When you provide a Discovery instance with training data, the service uses advanced Watson algorithms to determine the most relevant results. As you add more training data, the service instance becomes more accurate and sophisticated in the results it returns. See [Improving the relevance of your query results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) and the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data) for information.\n\nNew beta support for 'natural_language_query' parameter : The API now supports the natural_language_query parameter as a beta release. This parameter enables you to specify a query in natural language instead of in the Discovery service's query language. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\n\n\n\n\n 14 April 2017 \n\nNew enhancements to query API : Enhancements are now available for the query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query). See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nNew support for 'passages' parameter in the query API : The query API now supports the passages parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_13075-5007-7084","score":0.0298507463,"text":"\nTo return to the main Build queries screen at any time, click Build queries on the upper left. To return to the Manage data screen, click the name of the collection on the upper right.\n\nIf you would like to delete all of the training data in your collection at one time, you must do so via the API. See [Delete all training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data) for more information. For more information about training via the API, see [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api).\n\n\n\n\n\n Testing and iterating on the relevancy of results \n\nAfter you complete rating results and Watson applies the training, test to see if your query results improved. To do so, run test queries that are related, but not identical to, your training queries. Check to see if the results of your test queries improved.\n\nIf you would like to further improve results after testing, you could:\n\n\n\n* Add more documents to your collection.\n* Add more training queries.\n* Rate more results, making sure to use both the Relevant and Not relevant ratings.\n\n\n\nFor additional training guidance, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Confidence scores \n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language.\n\nThe confidence score is returned for both trained and untrained private collections (with the exception of filter-only queries of untrained collections). In addition, Discovery returns a document_retrieval_strategy field that indicates the source of the confidence score:\n\n\n\n* untrained\n* relevancy_training, or\n* continuous_relevancy_training\n\n\n\nThe document_retrieval_strategy can be used along with the confidence score to determine how the results provided should be used. In cases where load is high, the document_retrieval_strategy returned might be untrained, even if the collection is trained.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07214-57536-59639","score":0.0294117647,"text":"\nImproved query and add functions at top level : id, score, and highlight at the top level (You can continue to add documents to your collection using document IDs with the add a document function. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-a-document) for details. : _ prefixed field names at the top level (as a result, when querying for a document by ID, you can query for id instead of _id.) : and , in the field name : + and - prefixed field names : \"\" empty values for a field name : If your JSON documents include these characters in the field names, or id, score, and highlight at the top level, you need to remove them before adding the documents to your collection, or those fields are empty. You can create a custom configuration and normalize your JSON before adding documents to your collection to avoid this issue. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-configuration) for details. In addition, documents that include the punctuation characters ?, :, or in the file name cause errors during ingestion. Before ingesting them, rename any documents that include these characters.\n\nImproved 'natural_language_query' retrieval methods : The retrieval methods for natural_language_query are updated to improve the relevance of results by matching words with related semantics. This update only affects collections that did not undergo relevance training. If you are using natural_language_query and did not conduct relevance training, you might see improvement in the order of results returned.\n\nImproved query builder navigation : Changes to the query builder to make it easier to toggle between the Discovery Query Language and Natural Language query options, as well as among query, filter, and aggregation.\n\n\n\n\n\n 25 August 2017 \n\nImproved 'passages' array : The passages array now includes field, start_offset, and end _offset. field is the name of the field the passage was extracted from. start_offset is the starting character of the passage text within the field. end_offset is the ending character of the passage text within the field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07120-21369-22998","score":0.0289855072,"text":"\nFor more information about splitting documents, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\n\n\n\n\n Step 8: Test the project again \n\nLet's find out whether we improved the search function by adding a user-trained SDU model for the document. To do so, let's retest the project.\n\n\n\n1. From the navigation panel, click Improve and customize to open the Improve and customize page.\n2. First, to make sure that we didn't degrade the quality of the search, let's ask one of the questions that returned a good response when we tested earlier.\n\nIn the Search field, enter What is the purpose of Rule 15c3-5?\n\nZoom\n\n![Shows a query that is being entered into the Improve and customize page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-retest-query.png)\n\nFigure 25. Query added to the Improve and customize page\n\nMultiple responses are returned this time. The following response contains the exact answer to the question without any extraneous text:\n\nIn November 2011, the SEC implemented the final provision of Rule 15c3-5 curbing unfiltered market access. The provision mandated that brokers verify their clients\u2019 order flow for compliance with credit and capital thresholds before routing to market centers.\n\nZoom\n\n![Shows that multiple responses are returned for the query.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-rule-response.png)\n\nFigure 26. Multiple responses are returned for the query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_07242-2547-4328","score":0.0285714286,"text":"\n\"document_id\": \"bdcd6a9cc1438a3faa8c925f6a8d9429\"\n}\n]\n},\n\"event_type\": \"query\",\n\"session_token\": \"1_LKczxWGEWx5TJAi1_Qs35yOoa7\",\n\"created_timestamp\": \"2018-09-12T05:20:07.469Z\"\n}\nShow more\n\nWith query logs you can investigate the type of results returned to your end users and investigate ways to improve result quality using the approaches available in Discovery. For example:\n\n\n\n* relevancy training, see [Improving result relevance with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) and [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling)\n* [query operators](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators)\n* [query expansion](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion)\n* custom configurations, see the [Configuration reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref)\n\n\n\n\n\n\n\n Creating event logs \n\nEvent logs are used to track the interactions of users within your application. This can help you understand how well your application is performing, as well as identify areas that you might need to focus on to improve results. Discovery provides an API that can be embedded in your application to track events. Calling this API with the appropriate information when a user performs an action sends a signal back to Discovery, which can then be viewed in the logs.\n\nEvents can help gather information on computing metrics (like clickthrough rate) to measure how effective the application is at helping end users find relevant information, or can be used to help seed training by reviewing the queries and clicks to start to build ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.2,"recall_5":0.2,"recall_10":0.2,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.3391602053,"ndcg_cut_10":0.3391602053}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07115-5269-7471","score":0.0327868852,"text":"\nYour documents might not have a text field if you uploaded a CSV file that doesn't have a column named text, or uploaded a JSON file that doesn't have an object named text, or if you used the Smart Document Understanding tool to define fields with other names in which the bulk of the content of your documents now are stored.\n\nWhen you train a project from the API, results are taken from all of the root-level fields and they are all considered to have equal significance. Unlike Discovery Query Language queries, with natural language queries you cannot specify which fields from the document you care about or how much significance to give to each one. When you teach Discovery with examples, the service figures out for you how much weight to give to each field.\n\nDiscovery builds a model that assigns different weights to term, bigram, and skip-gram matches for each of the root-level fields and balances them against matches from all of the other document fields. With enough examples, Discovery can return better answers because it knows where the best answers are typically stored.\n\nRelevancy training cannot be used to give more weight to nested fields. Nested fields are grouped and assigned one overall score. No matter how much you train, Discovery never gives a nested field more weight than it gives to a root-level field. For more information about nested fields, see the [FAQ](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-faqsfaq-nested-fields).\n\n\n\n\n\n Training a project \n\nThe training data that is used to train the relevancy model includes these parts:\n\n\n\n* A natural language query that is representative of a query that your users might submit\n* Results of the query which are returned by the service\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"},{"document_id":"ibmcld_07395-1443-2217","score":0.0322580645,"text":"\nThe specific IDs of affected VPCs.\n2. The IDs of the DNS Services private resource records (if any).\n3. The IDs of zones that have affected private resource records (if any).\n4. The DNS queries made. If possible, give the details on DNS queries related to the issue, including DNS message ID and timestamp for each.\n5. Information about the source of the DNS query (for example, the ID of the VPC from which the query originated).\n6. If it affects a custom resolver, then include the custom resolver ID.\n7. If it affects a GLB health check, then include the GLB health check ID and the IDs of affected GLBs.\n8. If it is an issue with a forwarding rule, then include the forwarding rule ID.\n9. If it is an issue with a secondary zone, then include the secondary zone rule ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-gettinghelp"},{"document_id":"ibmcld_13508-0-1227","score":0.0317460317,"text":"\n\n\n\n\n\n\n  Video tutorials \n\nThe following videos help you to get provisioned and use IBM Cloud\u00ae Data Engine. The videos show you how to run queries, use the REST API, and how to connect to IBM Cloud\u00ae Object Storage through the command line.\n\n\n\n  Get started \n\nThe first video shows you how to provision IBM Cloud\u00ae Object Storage and IBM Cloud\u00ae Data Engine to get you started.\n\n\n\n\n\n  Run queries \n\nThe second video helps you to run a basic query from the console.\n\n\n\n\n\n  Use sample queries, Notebooks, and REST API \n\nThe following video gives a broader introduction to the service, introduces some of the sample queries in the UI, shows the use of real-life data, Notebooks, and REST API.\n\n\n\n\n\n  Use the REST API \n\nThe following video shows you how to use the REST API.\n\n\n\n\n\n  Use the command line \n\nThe next video shows you how to manage data files in an Object Storage instance through the command line.\n\n\n\n\n\n  Run IBM Cloud\u00ae Data Engine end-to-end with the REST API \n\nThe following video in this series shows you how to run Data Engine end-to-end with the REST API.\n\n\n\n\n\n  In-depth overview \n\nFinally, the last video is an in-depth overview of IBM Cloud\u00ae Data Engine, offering an extensive introduction to the service.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-video"},{"document_id":"ibmcld_07098-4987-7173","score":0.03125,"text":"\nUp to 60 passages are sent to the answer-finding service. How these 60 passages are chosen differs based on the passages.per_document parameter value.\n\n\n\n* If passages.per_document is false, the top 60 passages from all of the documents that are returned by search are chosen based on their passage scores only.\n* If passages.per_document is true, the returned documents are ranked first, and then the top 60 passages from these top documents are chosen.\n\nFor example, if you set the query to return 100 documents (count=100) and ask for 2 passages from each document (passages.max_per_document=2), then 2 passages are chosen from each of the 30 top-ranked documents (2 x 30 = 60 passages) only. No passages are chosen from the remaining 70 documents.\n\n\n\nIf your goal is to get the best 10 short answers, a good approach is to give the answer-finding feature various passages from more documents than just the top 10. To do so, set passages.per_document to true, and then request 20 documents and up to 3 passages from each document with the answer-finding feature enabled. The answer-finding feature searches for answers in up to 20*3 = 60 passages.\n\nAnswer finding does not use the transformed query string that is generated by query analysis. Instead, it uses a copy of the user's original input that is stored at query time to find the best short answer. If the answer-finding module is confident that it found an answer in one of the passages, the answer confidence score is combined with the document and passage scores to produce a final ranking, which can promote a document or passage that might otherwise be missed.\n\n\n\n\n\n Answer-finding API details \n\nThe answer-finding API adds the following parameters to the passage section of the query API:\n\n\n\n* find_answers is optional and defaults to false. If it is set to true (and the natural_language_query parameter is set to a query string), the answer-finding feature is enabled.\n* max_answers_per_passage is optional and defaults to 1. In this case, the answer-finding feature finds the number of answers that are specified at most from any one passage.\n\n\n\nA section is also added to the return value within each passage object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_02748-1631-3376","score":0.0307692308,"text":"\nEmail The primary email address that is attached to the user. \n First name and surname Your user's first name and surname as they provided during the sign-up process. \n Last Login The timestamp of the last time that the user logged in to your application. Note: If you added your user through the dashboard, the login is blank until the user themselves signs in to your app. When sign-in occurs, they also become an App ID user. \n ID The ID that is assigned to the user by App ID. In the UI, it isn't shown but you can copy the value and paste it in a text editor to see the value. \n Predefined attributes Predefined attributes are things that are known about a user based on SCIM. \n Custom attributes Custom attributes are additional information that is added to their profile or that is learned about the user's as they interact with your application. \n Summary All the attributes are compiled to form one profile that gives you a complete overview of your Cloud Directory user. For more information, see [user profiles](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles). \n\n\n\n\n\n\n\n\n\n Viewing user information with the API \n\nYou can use the App ID API to view details about your app users.\n\n\n\n1. Obtain your tenant ID from your instance of the service.\n2. Search your App ID users with an identifying query, such as an email address, to find the user ID.\n\ncurl -X GET \"https:\/\/<region>.appid.cloud.ibm.com\/management\/v4\/<tenantID>\/cloud_directory\/Users?query=<identifyingSearchQuery>\" -H \"accept: application\/json\" -H \"authorization: Bearer <token>\"\n\nExample:\n\ncurl -X GET https:\/\/us-south.appid.cloud.ibm.com\/management\/v4\/e19a2778-3262-4986-8875-8khjafsdkhjsdafkjh\/cloud_directory\/Users?query=user@domain.com\n-H \"accept: application\/json\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-users"},{"document_id":"ibmcld_02477-6892-7897","score":0.0303030303,"text":"\nFor more information, see [Service keys by using the API](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-service_keysservice_keys_api).\n* Replace <GROUP_ID> with the groupId returned from [listing configured groups](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-groups-manage-apigroup-list-api).\n* Replace <NAME> with the name you want to give to the group.\n* Replace <SCOPE> with a query specified as a JSON array. See [Defining service groups](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-group_data_accessgroups_data_access_groups) for example access scope search queries.\n\n\n\ncurl --request PATCH --url https:\/\/api.eu-gb.logging.cloud.ibm.com\/v1\/config\/groups\/xxxxxxxxxxxx -H \"content-type: application\/json\" -H \"servicekey: <SERVICE_KEY>\" -d '{\"name\": \"My log group2\",\"accessScopes\": [\"reasonCode:200\"] }'\n\nThe response will be similar to the following:\n\n{\"name\":\"My log group2\",\"groupId\":\"xxxxxxxxxxxx\",\"accessScopes\":[\"reasonCode:200\"]}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-groups-manage-api"},{"document_id":"ibmcld_00580-34804-36790","score":0.0298507463,"text":"\nYou can see from the first line that standard JavaScript objects can be used in your code and sent to IBM Cloudant with no conversion, as they turn into JSON natively in JavaScript.\n\nWriting a document is simply a matter of calling db.insert, which maps to a PUT\/POST API call or to _bulk_docs.\n\nTo summarize, the official libraries for IBM Cloudant are Java\u2122, Python, and Nodejs. They are thin wrappers around the IBM Cloudant HTTP API - so it's worth understanding the underlying API to understand all the parameters.\n\nThe libraries handle two things for you, which is useful:\n\nAuthentication\n: Exchanging your keys for tokens, whether it be legacy authentication or IAM.\n\nRetry logic\n: The libraries can be configured to retry API calls that exceeded your provisioned capacity. If configured this way, they pause and reattempt the API call multiple times with exponential back-off.\n\nRetrying such API calls is sensible if you have a temporary and unexpected elevation in traffic. If you are routinely exceeding your provisioned capacity, no amount of retrying gets the database work done - you need more capacity!\n\nThat's the end of this part. The next part is called Querying.\n\n\n\n\n\n\n\n Querying video \n\nLearn the different ways to query data in IBM Cloudant.\n\n\n\n* Querying video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 10 - Querying.\n\nSo far we performed CRUD (create, retrieve, update, and delete) operations from the command line, the dashboard, and from code. These operations use the document's _id:\n\n\n\n* Fetch document by _id.\n* Update document whose _id = 'x'.\n* Delete document whose _id = 'x'.\n* Get documents in the _id range 'a' to 'z'.\n\n\n\nThese operations are the building blocks of a database, but they get you only so far. What if you need to return a subset of documents that match on fields within the document? A person's birth date?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_13493-2289-4276","score":0.0294117647,"text":"\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.\n* You must have at least 'Writer' access to the corresponding Object Storage bucket.\n\n\n\nIn the Details tab of the selected job, you can set any location that you specified in the INTO clause as your default location.\n3. Click Run.\n\nWhen the query completes, a preview of the query result is displayed in the query result tab of the UI. The preview function is only available for CSV and JSON result formats. You can run up to five queries simultaneously with a Standard plan instance of Data Engine.\n\n\n\n\n\n Sample queries \n\nWhat does a typical query look like? The following sample queries give you an idea to get you started:\n\n\n\n Example of a table exploration query \n\nThe following query selects all columns of a table and limits the result to 50 rows. Use it to explore a particular table.\n\nSELECT \nFROM cos:\/\/us-geo\/sql\/customers.csv STORED AS CSV\nORDER BY CustomerID\nLIMIT 50\n\n\n\n\n\n Example of an exact target path specification \n\nThe following query writes an SQL result into an exact result path. Normally, Data Engine always appends jobid=<jobid> to the provided target path to ensure a unique result location with each query execution. However, in the following sample query, this suffix is eliminated by adding JOBPREFIX NONE to the path in the INTO clause.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_07096-7-1899","score":0.0289855072,"text":"\nQuery operators \n\nYou can use operators when you write queries to submit to Discovery by using the Query API.\n\nThe types of operators that are supported differ by query type:\n\n\n\n* [Natural language queries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsnlq-operator)\n* [Discovery Query Language (DQL) queries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsdql-operators)\n\n\n\n\n\n Natural Language Query (NLQ) operator \n\nThe natural_language_query parameter accepts a string value.\n\n\n\n \"\" (Phrase query) \n\nUse quotation marks to emphasize a single word or phrase in the query that is most important to match. For example, the following request boosts documents that contain the term \u201cnomination\u201d in them.\n\n{\n\"natural_language_query\":\"What is the process for \"nomination\" of bonds?\"\n}\n\nSpecifying a quoted phrase does not prevent documents without the phrase from being returned. It merely gives more weight to documents with the phrase than those without it. For example, the query results might also contain documents that mention \u201cbonds\u201d or \u201cprocess\u201d and do not contain the word \u201cnomination\u201d.\n\nThe following request boosts the phrase \u201cchange in monetary policy\u201d and also matches \u201cchange\u201d or \u201cmonetary\u201d or \u201cpolicy\u201d.\n\n{\n\"natural_language_query\":\"\"change in monetary policy\"\"\n}\n\nSingle quotation marks (') are not supported. You cannot use wildcards (*) in phrase queries.\n\n\n\n\n\n\n\n Discovery Query Language (DQL) operators \n\nOperators are the separators between different parts of a query.\n\n\n\n . (JSON delimiter) \n\nThis delimiter separates the levels of hierarchy in the JSON schema\n\nFor example, the following query argument identifies the section of the enriched_text object that contains entities and the text recognized as an entity.\n\nenriched_text.entities.text\n\nThe JSON representation of this section looks as follows:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"},{"document_id":"ibmcld_05152-7-1585","score":0.0285714286,"text":"\nUsing SQL Query \n\nIBM Cloud\u00ae Data Engine is a fully-managed service that lets you run SQL queries (that is, SELECT statements) to analyze, transform, or clean up rectangular data using the full ANSI SQL standard.\n\nWhen you use the console to interact with your instance of IBM Cloud Object Storage, there are instances of IBM Cloud SQL Query automatically recognised in the new \"Integrations\" panel. You can also create new instances of IBM Cloud Data Engine directly from the \"Integrations\" panel in your browser. See Figure 1, showing the option to integrate services like Data Engine next to your credentials and buckets.\n\nZoom\n\n![Integrations in COS](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/integrate-from-cos.jpg)\n\nFigure 1. Integrate SQL Query from COS instance\n\nSelect the card detailing the options and offering for IBM Cloud Data Engine. This is shown in Figure 2.\n\nZoom\n\n![Integrate SQL Query](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/integrate-with-sql.jpg)\n\nFigure 2. Select the SQL Query card to integrate\n\nFigure 3 shows the panel that opens when the card is selected. This panel give you control over the location and costs regarding your new instance of IBM Cloud Data Engine. Select the region appropriate for your buckets and the plan suitable for your projects. If you want more information you can use the documentation to [get started](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-sql-query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1175161048}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16551-0-1579","score":0.0327868852,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_01241-13660-15370","score":0.0322580645,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule that you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [here](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > File Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete to delete the snapshot. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-13788-15540","score":0.0314980159,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [Replicating Data](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > Block Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete. Click the confirmation box that warns about possible data loss, then click Delete. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations (oldest first).\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_00241-15158-16579","score":0.0303308824,"text":"\nslcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host to ensure the host is not connecting to the volume during the restore for any reason.\n\n\n\n* [Unmounting Block Storage for Classic volumes on Linux\u00ae server](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-mountingLinuxunmountingLin)\n* [Unmounting Block Storage for Classic volumes on Microsoft\u00ae server](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-mountingWindowsunmountingWin)\n\n\n\n2. Go to the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/login). From the menu, select Classic Infrastructure![Classic icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/classic.svg).\n3. Click Storage, Block Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_01225-7204-8862","score":0.0287784679,"text":"\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Resizing storage with Terraform \n\nYou can increase your storage capacity by using the ibm_storage_file resource, and specifying a different number in the capacity argument. The following example increases the capacity of an Endurance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_endurance\" {\ntype = \"Endurance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 0.25\n}\n\nThe following example increases the capacity of a Performance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_performance\" {\ntype = \"Performance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 100\n}\n\nFor more information about the arguments and attributes, see [ibm_storage_file](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/storage_file).\n\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Expanding Storage over 12 TB \n\nIf you need to increase your Storage volume capacity beyond 12 TB, you can request to be added to the allowlist by submitting a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add). When the request is approved by the Offering Manager, you're going to be notified through the case process. You're also going to see the option to increase your storage up to 24 TB in the console.\n\nThe number of operations that can be performed on the storage is limited. This limit is 180k IOPS. So if you want to provision a volume with 10 IOPS, your maximum volume size is 18 TB. If you want to provision the maximum size of 24 TB, then the maximum rate of reads and writes to the volume is 4 IOPS per GB.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacity"},{"document_id":"ibmcld_04693-5720-7686","score":0.0158730159,"text":"\nFor example, you might scale from 256 - 1256 MB by changing the memory quota on the app details page. However, because the disk quota remained the same, you didn't get more disk space.\n\n Why it\u2019s happening \n\nThe default disk quota that is allocated for an app is 1 GB. If you need more disk space, you must manually specify the disk quota.\n\n How to fix it \n\nUse one of the following methods to specify your disk quota. The maximum disk quota that you can specify is 2 GB. If 2 GB is still not enough, try an external service such as [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n\n\n\n* In the manifest.yml file, add the following item:\n\ndisk_quota: <disk_quota>\n* Use the -k option with the ibmcloud cf push command when you push your app to IBM Cloud:\n\nibmcloud cf push appname -p app_path -k <disk_quota>\n\n\n\n\n\n\n\n Org's services limit is exceeded \n\nIf you are a Lite account user, you might be unable to create an app in IBM Cloud if you exceeded your organization's services limit.\n\n What\u2019s happening \n\nWhen you try to create an app in IBM Cloud, the following error message is displayed:\n\nBXNUI2032E: The <service_instances> resource wasn't created. While Cloud Foundry was being contacted to create the resource, an error occurred. Cloud Foundry message: \"You have exceeded your organization's services limit.\"\n\n Why it\u2019s happening \n\nThis error occurs when you exceed the limit on the number of service instances that you can have for your account.\n\n How to fix it \n\nDelete any services instances that aren't needed, or remove the limit on the number of service instances that you can have.\n\n\n\n* To delete a services instance, you can use the IBM Cloud console or the command line interface.\n\nTo use the IBM Cloud console to delete a service instance, complete the following steps: 1. In the resource list, click the Actions menu for the service that you want to delete. 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-ts-cf-apps"},{"document_id":"ibmcld_16452-7020-8905","score":0.0153846154,"text":"\nFor help using the ground truth editor, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Experimental services and features: What does experimental mean? \n\nIBM releases experimental services and features for you to try out. These services might be unstable, change frequently in ways that are not compatible with earlier versions, and might be discontinued with short notice. These services and features are not recommended for use in production environments.\n\nFor more information about experimental services, see the [IBM Cloud documentation ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/cloud.ibm.com\/docs\/get-support\/servicessupport.htmls-services-exporcont). For the full details of experimental services, see the latest version of the [IBM Cloud Service Description ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm?OpenDocument).\n\n\n\n\n\n Storage space issues \n\n\n\n Symptoms \n\nYou might see a message about having exceeded the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n* Upload documents or dictionaries\n* Deploy a model or version a model\n* Run a pre-annotator on documents\n\n\n\n\n\n\n\n Causes \n\nThe storage limit has been met or would be exceeded if the action were to proceed.\n\n\n\n\n\n Resolving the problem \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n* Delete snapshot versions of any models that you do not expect to need to revert to.\n* Delete any models that you do not need.\n* If your models are too important to delete, consider increasing the amount of storage in your deployment.\n\n\n\n\n\n\n\n\n\n Contacting IBM Support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-troubleshooting"},{"document_id":"ibmcld_01241-14983-16623","score":0.0153846154,"text":"\nslcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host.\n\nFor more information about mounting and unmounting storage, see [connecting your new storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mountingLinux).\n2. Go to the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/login). From the menu, select Classic Infrastructure![Classic icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/classic.svg).\n3. Click Storage, File Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to the snapshot to be used and click Restore.\n\nCompleting the restore results in the loss of the data that was created or modified after the snapshot was taken. This data loss occurs because your storage volume returns to the same state that it was in of the time of the snapshot.\n6. Click Yes to start the restore.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_05149-4519-6367","score":0.0151515152,"text":"\nIf not, follow the [getting started tutorial](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) to obtain the prerequisites and become familiar with the console.\n\n\n\n Set a list of authorized IP addresses using a legacy firewall \n\n\n\n1. Start by selecting Storage to view your resource list.\n2. Next, select the service instance with your bucket from within the Storage menu. This takes you to the Object Storage Console.\n3. Choose the bucket that you want to limit access to authorized IP addresses.\n4. Select Access policies from the navigation menu.\n5. Select the Authorized IPs tab.\n6. Click Add IP addresses, then choose Add.\n7. Specify a list of IP addresses in [CIDR notation](https:\/\/en.wikipedia.org\/wiki\/Classless_Inter-Domain_Routing), for example 192.168.0.0\/16, fe80:021b::0\/64. Addresses can follow either IPv4 or IPv6 standards.\n8. Click Add.\n9. The firewall will not be enforced until the address is saved in the console. Click Save all to enforce the firewall.\n10. Note that all objects in this bucket are only accessible from those IP addresses.\n\n\n\n\n\n\n\n Remove any IP address restrictions using a legacy firewall \n\n\n\n1. From the Authorized IPs tab, check the boxes next to any IP addresses or ranges to remove from the authorized list.\n2. Select Delete, and then confirm the dialog box by clicking Delete again.\n3. The updated list won't be enforced until the changes are saved in the console. Click Save all to enforce the new rules.\n4. Now all objects in this bucket are only accessible from these IP addresses!\n\n\n\nIf there are no authorized IP addresses listed this means that normal IAM policies will apply to the bucket, with no restrictions on the user's IP address, unless there are context-based restrictions in place.\n\n\n\n\n\n Set a legacy firewall through an API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall"},{"document_id":"ibmcld_01270-4-1929","score":0.0151515152,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Ordering File Storage for Classic \n\nYou can provision File Storage for Classic and fine-tune to meet your capacity and IOPS needs. Get the most out of your storage with two options for specifying performance.\n\n\n\n* You can choose from Endurance IOPs tiers that feature pre-defined performance levels to fit workloads that don't have well-defined performance requirements.\n* You can fine-tune your storage to meet specific performance requirements by specifying the total number of IOPS with Performance.\n\n\n\n\n\n Ordering File Storage for Classic in the UI \n\n\n\n1. Log in to the [IBM Cloud\u00ae catalog](https:\/\/cloud.ibm.com\/catalog) and click Storage. Then, select File Storage for Classic. Click Create.\n2. Select your deployment location (region, location, zone).\n\n\n\n* Ensure that the new Storage is added in the same location as the compute host or hosts that you have.\n\n\n\n3. Billing. If you selected a data center with improved capabilities (marked with an asterisk), you can choose between Monthly or Hourly Billing.\n\n\n\n* With hourly billing, the number of hours that the file volume existed on the account is calculated at the time the volume is deleted or at the end of the billing cycle. Which ever comes first. Hourly billing is a good choice for storage that is used for a few days or less than a full month.\n* With monthly billing, the calculation for the price is pro-rated from the date of creation to the end of the billing cycle and billed immediately. If a file volume is deleted before the end of the billing cycle, the difference is not refunded. Monthly billing is a good choice for storage that is used in production workloads that use data that needs to be stored and accessed for long periods of time (month or longer).\n\n\n\n4. Enter your storage size in the Size field.\n5. Select the size of the Snapshot space from the list.\n\nThis space is in addition to your usable space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-orderingFileStorage"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14654-7-1943","score":0.0327868852,"text":"\nPlanning for vCenter Server instances \n\nPlan your instance based on the IBM Cloud\u00ae data center location, your workload capacity requirements, and add-on services requirements. Review the following requirements before you order your VMware vCenter Server\u00ae instance.\n\n\n\n* New deployments of vCenter Server instances with VMware vSphere\u00ae 6.5 or 6.7 are not supported.\n* New deployments of vCenter Server multizone instances are not supported.\n* New deployments of vCenter Server with NSX-V instances are not supported.\n\n\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vCenter Server deployment has strict requirements on the physical infrastructure. Therefore, you can deploy instances only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vCenter Server deployment.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for vCenter Server instances\n\n Geography Data center Pod Server options for NSX-T<br><br>[1] Server options for NSX-V<br><br>[2] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake<br><br>[3] \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_planning"},{"document_id":"ibmcld_14823-7-1880","score":0.0322580645,"text":"\nPlanning for VMware vSphere \n\nReview the following requirements before you order a VMware vSphere\u00ae instance. Plan your VMware vSphere based on the IBM Cloud\u00ae data center location and your workload capacity requirements.\n\nYou are responsible for setting up the environment, installing, and configuring various VMware\u00ae components after the VMware ESXi\u2122 servers are deployed. The following examples are VMware components: VMware vCenter Server\u00ae, VMware NSX\u00ae, and VMware vSAN\u2122.\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vSphere deployment has strict requirements on the physical infrastructure. Therefore, you can deploy clusters only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vSphere deployment.\n\nCascade Lake bare metal servers are available in\n\nmultizone regionIBM Cloud data centers. For more information, see [Multizone region (MZR) overview](https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-multi-zone-region-mzr-overview).\n\nIf you select a vSAN component, the location list is filtered by SSD (Solid-State Disk) availability.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for VMware vSphere instances\n\n Geography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"},{"document_id":"ibmcld_14823-1485-2621","score":0.0317460317,"text":"\nGeography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD04 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD05 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK02 01-02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK04 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK05 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n\n\n\n\n\n\n\n Related links \n\n\n\n* [Ordering VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-req)\n* [Adding ESXi servers to VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_addingservers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"},{"document_id":"ibmcld_13162-12751-14416","score":0.03125,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-11690-13171","score":0.0307692308,"text":"\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16729-11586-13439","score":0.0303030303,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_03538-14399-15690","score":0.0298507463,"text":"\nYour account settings would look like:\n\nibmcloud atracker setting get\nOK\nIBM Cloud Activity Tracker settings\nMetadata region primary: us-east\nDefault targets: []\nPermitted target regions: [us-east]\nPrivate api endpoint only: false\nAPI version: 2\n\nYour target would look like:\n\nibmcloud atracker target ls\nListing IBM Cloud Activity Tracker targets for all regions...\nOK\nName ID Region Type Service to Service Enabled CreatedAt UpdatedAt\ntarget-logdna <LOGDNA TARGET ID 1> us-east logdna - 2022-05-16T17:16:05.234Z 2022-05-16T17:16:05.234Z\n\n\n\n\n\n Data Lake scenario \n\nYou can choose any of the following options to send auditing events to a data lake:\n\n\n\n* Configure your account to route auditing events to Activity Tracker Event Routing hosted event search instances. Stream the events to Event Streams, and then, send them to a data lake. You can filter the data to be streamed to the data lake.\n\nSimplify the Activity Tracker Event Routing hosted event search configuration so only 1 instance needs to be configured to feed auditing events to Event Streams.\n* Configure Activity Tracker Event Routing in your account to route auditing events directly to an IBM Cloud Object Storage data lake.\n\nUse this option for Financial Services Cloud workloads where end-to-end compliance is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-scenarios&interface=cli"},{"document_id":"ibmcld_03537-14329-15620","score":0.0294117647,"text":"\nYour account settings would look like:\n\nibmcloud atracker setting get\nOK\nIBM Cloud Activity Tracker settings\nMetadata region primary: us-east\nDefault targets: []\nPermitted target regions: [us-east]\nPrivate api endpoint only: false\nAPI version: 2\n\nYour target would look like:\n\nibmcloud atracker target ls\nListing IBM Cloud Activity Tracker targets for all regions...\nOK\nName ID Region Type Service to Service Enabled CreatedAt UpdatedAt\ntarget-logdna <LOGDNA TARGET ID 1> us-east logdna - 2022-05-16T17:16:05.234Z 2022-05-16T17:16:05.234Z\n\n\n\n\n\n Data Lake scenario \n\nYou can choose any of the following options to send auditing events to a data lake:\n\n\n\n* Configure your account to route auditing events to Activity Tracker Event Routing hosted event search instances. Stream the events to Event Streams, and then, send them to a data lake. You can filter the data to be streamed to the data lake.\n\nSimplify the Activity Tracker Event Routing hosted event search configuration so only 1 instance needs to be configured to feed auditing events to Event Streams.\n* Configure Activity Tracker Event Routing in your account to route auditing events directly to an IBM Cloud Object Storage data lake.\n\nUse this option for Financial Services Cloud workloads where end-to-end compliance is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-scenarios"},{"document_id":"ibmcld_13466-0-409","score":0.0289855072,"text":"\n\n\n\n\n\n\n  Data transport automation to Db2 on Cloud \n\nIBM Cloud\u00ae Data Engine supports automating the transport and transformation of data from IBM Cloud\u00ae Object Storage to IBM\u00ae Db2\u00ae on Cloud. Read how you can [automate serverless data pipelines for your data warehouse or data lakes](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/automate-serverless-data-pipelines-for-your-data-warehouse-or-data-lakes).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-db2"},{"document_id":"ibmcld_16728-5097-7108","score":0.0285714286,"text":"\n[solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Bring Your Own IP Address](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16627-0-1141","score":0.0327868852,"text":"\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-exp_objects"},{"document_id":"ibmcld_16640-7-2035","score":0.0322580645,"text":"\nKnown issues (Limitations) \n\nThe following limitations and known issues, apply to IBM\u00ae watsonx.data.\n\n\n\n Issue: Unable to view created schema \n\nWhen a user with the User role and the Create access (the user only has the Create access) is added to an external database, they cannot see the schemas that they created. Though the user can create schemas, they cannot view them. Following is the system response:\n\npresto:default> show schemas;\nSchema\n--------\n(0 rows)\n\nWorkaround: Provide select privilege for the schema the user created.\n\n\n\n\n\n Issue: Access denied message occurs when querying an external database \n\nWhen a user with the User role and Create access (the user only has Create access), is added to an external database, they cannot run the select query from the table they have created. Though the user can connect to the Presto engine and create tables and schemas, they cannot query from the table. The system displays an Access Denied message.\n\nQuery 20230608_132213_00042_wpmk2 failed: Access Denied: Cannot select from columns [id] in table or view tab_appiduser_01\n\nWorkaround: Provide select privilege for the table the user created.\n\n\n\n\n\n Issue: Schema created under different catalog \n\nSchemas are available across Iceberg and Hive catalogs. When a schema is created under Iceberg catalog, it is listed under Hive catalog and vice versa.\n\n\n\n\n\n Issue: Presto does not support deletion of Iceberg tables \n\n\n\n\n\n Issue: DROP SCHEMA in Db2 \n\nIn Db2, the schema can be dropped only if it is empty. Initiating DROP SCHEMA statement against a non-empty schema may result in Db2 SQL Error SQLCODE=-478 and SQLSTATE=42893.\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Db2 \n\nDb2 connector partially supports CREATE VIEW statement. The Presto supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Netezza \n\nNetezza connector partially supports CREATE VIEW statement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-known_issues"},{"document_id":"ibmcld_16567-9760-11240","score":0.0317460317,"text":"\n--source-table-def-file ([VirtualizeTableSourceTableDefFile](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugincli-virtualize-table-parameter-source-table-def-item-example-schema))\n: Required.\n\n--sources ([]string)\n: The name of data source. Required.\n\n--virtualized-table-name (string)\n: The name of the table that will be virtualized. Required.\n\n--virtualized-schema (string)\n: The schema of the table that will be virtualized. Required.\n\n--virtualized-table-def-file ([VirtualizeTableVirtualTableDefFile](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugincli-virtualize-table-parameter-virtual-table-def-item-example-schema))\n: Required.\n\n--is-included-columns (string)\n: The columns that are included in the source table.\n\n--replace (bool)\n: Determines whether to replace columns in the virtualized table.\n\n\n\n\n\n Examples \n\nVirtualize table\n\nibmcloud watson-query virtualized-table-create --source-table-name table1 --source-table-def-file source_tabel_def.json --virtualized-schema DV_IBMID_270001PD8Q --sources CONN1:TABLE1 --virtualized-table-name TABLE1 --virtualized-table-def-file virtualized_table_def.json. The json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_04326-9759-11237","score":0.03125,"text":"\n--source-table-def-file ([VirtualizeTableSourceTableDefFile](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-namecli-virtualize-table-parameter-source-table-def-item-example-schema))\n: Required.\n\n--sources ([]string)\n: The name of data source. Required.\n\n--virtualized-table-name (string)\n: The name of the table that will be virtualized. Required.\n\n--virtualized-schema (string)\n: The schema of the table that will be virtualized. Required.\n\n--virtualized-table-def-file ([VirtualizeTableVirtualTableDefFile](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-namecli-virtualize-table-parameter-virtual-table-def-item-example-schema))\n: Required.\n\n--is-included-columns (string)\n: The columns that are included in the source table.\n\n--replace (bool)\n: Determines whether to replace columns in the virtualized table.\n\n\n\n\n\n Examples \n\nVirtualize table\n\nibmcloud watson-query virtualized-table-create --source-table-name table1 --source-table-def-file source_tabel_def.json --virtualized-schema DV_IBMID_270001PD8Q --sources CONN1:TABLE1 --virtualized-table-name TABLE1 --virtualized-table-def-file virtualized_table_def.json. The json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_04326-4587-6220","score":0.0307692308,"text":"\nManage user access to virtualized table.\n\n\n\n ibmcloud watson-query virtualized-table-user-grant \n\nGrant a user access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --user USER\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required. The minimum length is 1 character.\n\n--table-schema (string)\n: The schema of the virtualized table. Required. The minimum length is 1 character.\n\n--user (string)\n: The identifier of the authorization, if grant access to all users, the value is PUBLIC, othervise the value is the watson query username. Required. The minimum length is 1 character.\n\n\n\n\n\n Examples \n\nGrant a user access to a specific virtualized table\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-user-revoke \n\nRevoke user access to the virtualized table.\n\nibmcloud watson-query virtualized-table-user-revoke --user USER --table-name TABLE-NAME --table-schema TABLE-SCHEMA\n\n\n\n Command options \n\n--user (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n--table-name (string)\n: The virtualized table's name. Required.\n\n--table-schema (string)\n: The virtualized table's schema name. Required.\n\n\n\n\n\n Examples \n\nRevoke user access to the virtualized table\n\nibmcloud watson-query virtualized-table-user-revoke --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n\n\n Roles","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16567-4588-6221","score":0.0303030303,"text":"\nManage user access to virtualized table.\n\n\n\n ibmcloud watson-query virtualized-table-user-grant \n\nGrant a user access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --user USER\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required. The minimum length is 1 character.\n\n--table-schema (string)\n: The schema of the virtualized table. Required. The minimum length is 1 character.\n\n--user (string)\n: The identifier of the authorization, if grant access to all users, the value is PUBLIC, othervise the value is the watson query username. Required. The minimum length is 1 character.\n\n\n\n\n\n Examples \n\nGrant a user access to a specific virtualized table\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-user-revoke \n\nRevoke user access to the virtualized table.\n\nibmcloud watson-query virtualized-table-user-revoke --user USER --table-name TABLE-NAME --table-schema TABLE-SCHEMA\n\n\n\n Command options \n\n--user (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n--table-name (string)\n: The virtualized table's name. Required.\n\n--table-schema (string)\n: The virtualized table's schema name. Required.\n\n\n\n\n\n Examples \n\nRevoke user access to the virtualized table\n\nibmcloud watson-query virtualized-table-user-revoke --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n\n\n Roles","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_16582-4627-6260","score":0.0298507463,"text":"\nManage user access to virtualized table.\n\n\n\n ibmcloud watson-query virtualized-table-user-grant \n\nGrant a user access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --user USER\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required. The minimum length is 1 character.\n\n--table-schema (string)\n: The schema of the virtualized table. Required. The minimum length is 1 character.\n\n--user (string)\n: The identifier of the authorization, if grant access to all users, the value is PUBLIC, othervise the value is the watson query username. Required. The minimum length is 1 character.\n\n\n\n\n\n Examples \n\nGrant a user access to a specific virtualized table\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-user-revoke \n\nRevoke user access to the virtualized table.\n\nibmcloud watson-query virtualized-table-user-revoke --user USER --table-name TABLE-NAME --table-schema TABLE-SCHEMA\n\n\n\n Command options \n\n--user (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n--table-name (string)\n: The virtualized table's name. Required.\n\n--table-schema (string)\n: The virtualized table's schema name. Required.\n\n\n\n\n\n Examples \n\nRevoke user access to the virtualized table\n\nibmcloud watson-query virtualized-table-user-revoke --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n\n\n Roles","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_16664-1011-1647","score":0.0294117647,"text":"\nHudi X X X \u2713 -- X X X X X \u2713 X X X X X X X X \n\n\n\n\n\n Limitations \n\n\n\n1. For CREATE TABLE, MySQL connector supports only CREATE TABLE AS.\n2. For ALTER TABLE, MongoDB connector supports only table rename.\n3. Db2 connector partially supports ALTER TABLE, CREATE VIEW, and DROP SCHEMA.\n4. Netezza connector partially supports ALTER TABLE and CREATE VIEW.\n5. MySQL, PostgreSQL, MongoDB, Db2, and Netezza connectors support DROP TABLE only when enabled in catalog.\n6. The CREATE SCHEMA, CREATE TABLE, DROP SCHEMA, DROP TABLE, DELETE, DROP VIEW, ALTER TABLE, and ALTER SCHEMA are not available for database based catalogs in the Data Manager UI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-supported_sql_statements"},{"document_id":"ibmcld_04326-5931-7596","score":0.0289855072,"text":"\nRequired.\n\n--table-schema (string)\n: The virtualized table's schema name. Required.\n\n\n\n\n\n Examples \n\nRevoke user access to the virtualized table\n\nibmcloud watson-query virtualized-table-user-revoke --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n\n\n Roles \n\nManage service roles for users and virtualized tables.\n\n\n\n ibmcloud watson-query virtualized-table-role-grant \n\nGrant a user role access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-role-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --role ROLE\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required. The minimum length is 1 character.\n\n--table-schema (string)\n: The schema of the virtualized table. Required. The minimum length is 1 character.\n\n--role (string)\n: The identifier of the authorization, if grant access to all users, the value is PUBLIC, othervise the value is the watson query username. Required. The minimum length is 1 character.\n\n\n\n\n\n Examples \n\nGrants a user role access to a specific virtualized table\n\nibmcloud watson-query virtualized-table-role-grant --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --role DV_ENGINEER\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-role-revoke \n\nRevoke roles access to a virtualized table.\n\nibmcloud watson-query virtualized-table-role-revoke --role ROLE --table-name TABLE-NAME --table-schema TABLE-SCHEMA\n\n\n\n Command options \n\n--role (string)\n: The watson query role type. Values can be DV_ADMIN, DV_ENGINEER, DV_STEWARD, or DV_WORKER, which correspond to MANAGER, ENGINEER, STEWARD, and USER roles in the user interface. Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16567-5932-7597","score":0.0285714286,"text":"\nRequired.\n\n--table-schema (string)\n: The virtualized table's schema name. Required.\n\n\n\n\n\n Examples \n\nRevoke user access to the virtualized table\n\nibmcloud watson-query virtualized-table-user-revoke --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --user user1@ibm.com\n\n\n\n\n\n\n\n\n\n Roles \n\nManage service roles for users and virtualized tables.\n\n\n\n ibmcloud watson-query virtualized-table-role-grant \n\nGrant a user role access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-role-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --role ROLE\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required. The minimum length is 1 character.\n\n--table-schema (string)\n: The schema of the virtualized table. Required. The minimum length is 1 character.\n\n--role (string)\n: The identifier of the authorization, if grant access to all users, the value is PUBLIC, othervise the value is the watson query username. Required. The minimum length is 1 character.\n\n\n\n\n\n Examples \n\nGrants a user role access to a specific virtualized table\n\nibmcloud watson-query virtualized-table-role-grant --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --role DV_ENGINEER\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-role-revoke \n\nRevoke roles access to a virtualized table.\n\nibmcloud watson-query virtualized-table-role-revoke --role ROLE --table-name TABLE-NAME --table-schema TABLE-SCHEMA\n\n\n\n Command options \n\n--role (string)\n: The watson query role type. Values can be DV_ADMIN, DV_ENGINEER, DV_STEWARD, or DV_WORKER, which correspond to MANAGER, ENGINEER, STEWARD, and USER roles in the user interface. Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00640-1128-2229","score":0.0327868852,"text":"\nCloudant service = Cloudant.newInstance();\n\nAllDocsQuery query1 = new AllDocsQuery.Builder()\n.keys(Arrays.asList(\"small-appliances:1000042\",\n\"small-appliances:1000043\"))\n.build();\n\nAllDocsQuery query2 = new AllDocsQuery.Builder()\n.limit(3)\n.skip(2)\n.build();\n\nPostAllDocsQueriesOptions queriesOptions =\nnew PostAllDocsQueriesOptions.Builder()\n.queries(Arrays.asList(query1, query2))\n.db(\"products\")\n.build();\n\nAllDocsQueriesResult response =\nservice.postAllDocsQueries(queriesOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nfrom ibmcloudant.cloudant_v1 import AllDocsQuery, CloudantV1\n\nservice = CloudantV1.new_instance()\n\nall_docs_query1 = AllDocsQuery(\nkeys=['small-appliances:1000042', 'small-appliances:1000043']\n)\n\nall_docs_query2 = AllDocsQuery(\nlimit=3,\nskip=2\n)\n\nresponse = service.post_all_docs_queries(\ndb='products',\nqueries=[all_docs_query1, all_docs_query2]\n).get_result()\n\nprint(response)\n\nallDocsQueries := []cloudantv1.AllDocsQuery{\n{\nKeys: []string{\n\"small-appliances:1000042\",\n\"small-appliances:1000043\",\n},\n},\n{\nLimit: core.Int64Ptr(3),\nSkip: core.Int64Ptr(2),\n},\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"},{"document_id":"ibmcld_04339-2716-4263","score":0.0322580645,"text":"\n\"query\" : 50,\n\"read\" : 1000,\n\"write\" : 500\n}\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\ncurrent.throughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.\n\n\n\n\n\n\n\n ibmcloud cloudant capacity-update \n\nSets the target provisioned throughput capacity for an IBM Cloudant instance. When target capacity is changed, the current capacity asynchronously changes to meet the target capacity.\n\nibmcloud cloudant capacity-update --blocks BLOCKS\n\n\n\n Command options \n\n--blocks (int64)\n: A number of blocks of throughput units. A block consists of 100 reads\/sec, 50 writes\/sec, and 5 global queries\/sec of provisioned throughput capacity. Required.\n\nThe minimum value is 0.\n\n\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant capacity-update --blocks 10\n\n\n\n\n\n Example default output \n\nExample CapacityThroughputInformation response.\n\nblocks\t10\nquery\t50\nread\t1000\nwrite\t500\n\n\n\n\n\n Example full output \n\nExample CapacityThroughputInformation response.\n\n{\n\"current\" : {\n\"throughput\" : {\n\"blocks\" : 5,\n\"query\" : 25,\n\"read\" : 500,\n\"write\" : 250\n}\n},\n\"target\" : {\n\"throughput\" : {\n\"blocks\" : 10,\n\"query\" : 50,\n\"read\" : 1000,\n\"write\" : 500\n}\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\ntarget.throughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.\n\n\n\n\n\n\n\n\n\n Monitoring \n\nCommands for Monitoring resource.\n\n\n\n ibmcloud cloudant events-config","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cloudant-cli"},{"document_id":"ibmcld_00579-2977-4822","score":0.0317460317,"text":"\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes. This practice is costly in terms of performance, as every lookup is a full scan of the database rather than an indexed lookup. If your data is small, this full-scan lookup doesn\u2019t matter, but as the data set grows, performance becomes a problem for you, and for the cluster as a whole. It is likely that we will limit this facility soon. The IBM Cloudant Dashboard provides a method for creating indexes in an easy way.\n\nCreating indexes and crafting IBM Cloudant Queries that take advantage of them requires some flair. To identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data.\n\nFor more information, see [IBM Cloudant Query docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query).\n\n\n\n\n\n In IBM Cloudant Search (or IBM Cloudant Query indexes of type text), limit the number of fields \n\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_04339-5327-6381","score":0.03125,"text":"\nRequired.\n\nAllowable list items are: management, data. The minimum length is 1 item.\n\n\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant events-config-update --types management,data\n\n\n\n\n\n Example output \n\nExample Ok response.\n\n{\n\"ok\" : true\n}\n\n\n\n\n\n\n\n ibmcloud cloudant throughput \n\nView the current consumption of provisioned throughput capacity for an IBM Cloudant instance. The current consumption shows the quantities of reads, writes, and global queries conducted against the instance for a given second.\n\nibmcloud cloudant throughput\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant throughput\n\n\n\n\n\n Example default output \n\nExample CurrentThroughputInformation response.\n\nquery\t13\nread\t133\nwrite\t42\n\n\n\n\n\n Example full output \n\nExample CurrentThroughputInformation response.\n\n{\n\"throughput\" : {\n\"query\" : 13,\n\"read\" : 133,\n\"write\" : 42\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\nthroughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cloudant-cli"},{"document_id":"ibmcld_00472-13535-15011","score":0.0307692308,"text":"\nSee the following example that uses the command line to test the standard analyzer:\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_search_analyze\" -H \"Content-Type: application\/json\"\n-d '{\"analyzer\":\"standard\", \"text\":\"ablanks@renovations.com\"}'\n\nSee the following result of testing the standard analyzer:\n\n{\n\"tokens\": [\n\"ablanks\",\n\"renovations.com\"\n]\n}\n\n\n\n\n\n\n\n Queries \n\nAfter you create a search index, you can query it.\n\n\n\n* Run a partition query by using the following request:\n\nGET \/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_search\/$INDEX_NAME\n* Run a global query by using the following request:\n\nGET \/$DATABASE\/_design\/$DDOC\/_search\/$INDEX_NAME\n\n\n\nSpecify your search by using the query parameter.\n\nSee the following example that uses HTTP to query a partitioned index:\n\nGET \/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_search\/$INDEX_NAME?include_docs=true&query=\":\"&limit=1 HTTP\/1.1\nContent-Type: application\/json\nHost: $ACCOUNT.cloudant.com\n\nSee the following example that uses the command line to query a partitioned index:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_search\/$INDEX_NAME?include_docs=true&query=\":\"&limit=1\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionSearchOptions;\nimport com.ibm.cloud.cloudant.v1.model.SearchResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostPartitionSearchOptions searchOptions =","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_00522-3956-5681","score":0.0303030303,"text":"\nCopy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard2.png)\n\nFigure 2. Window for creating indexes\n\n\n\nThe fields array contains a list of fields that we want IBM Cloudant to index.\n\nIf we repeat our query, it is faster and remains quick even as the database size reaches millions of documents.\n\nIndexing instructs IBM Cloudant to create a secondary data structure that allows it to find the slice of data you need much faster than looking over every document in turn. IBM Cloudant Query is best for fixed queries based on the same fields in the same order.\n\nFor more information, see the following details in IBM Cloudant documentation:\n\n\n\n* [Optimizing IBM Cloudant Queries](https:\/\/blog.cloudant.com\/2020\/04\/24\/Optimising-Cloudant-Queries.html)\n* [IBM Cloudant Query documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n\n\n\nThis index is useful for queries that involve both the publisher and the year, but if we introduce another field or make the query more complex (for example, by using the $or operator), then the index doesn't get used. We are back to a full database scan.\n\nFor a general-purpose search facility, we need IBM Cloudant Search, which is described in the next section.\n\n\n\n\n\n\n\n Step 3. Creating a search engine - IBM Cloudant Search \n\nIBM Cloudant Search is based on Apache Lucene and has its own query language that allows rich queries to be constructed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_00640-7-1376","score":0.0298507463,"text":"\nSending multiple queries to a database \n\nNow, the following instructions describe how to send multiple queries to a database by using _all_docs and _view endpoints.\n\n\n\n Sending multiple queries to a database by using _all_docs \n\nTo send multiple queries to a specific database, send a POST request to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/_all_docs\/queries.\n\nSee the following example that uses HTTP to send multiple queries to a database:\n\nPOST \/$DATABASE\/_all_docs\/queries HTTP\/1.1\n\nSee the following example to multi-query the list of all documents in a database:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X POST \"$SERVICE_URL\/products\/_all_docs\/queries\" -H \"Content-Type: application\/json\" --data '{\n\"queries\": [\n{\n\"keys\":\n\"small-appliances:1000042\",\n\"small-appliances:1000043\"\n]\n},\n{\n\"limit\": 3,\n\"skip\": 2\n}\n]\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQuery;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQueriesResult;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsQueriesOptions;\n\nimport java.util.Arrays;\n\nCloudant service = Cloudant.newInstance();\n\nAllDocsQuery query1 = new AllDocsQuery.Builder()\n.keys(Arrays.asList(\"small-appliances:1000042\",\n\"small-appliances:1000043\"))\n.build();\n\nAllDocsQuery query2 = new AllDocsQuery.Builder()\n.limit(3)\n.skip(2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"},{"document_id":"ibmcld_00539-7-1755","score":0.0294117647,"text":"\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00491-1283-3050","score":0.0289855072,"text":"\n(Optional) [Create an acurl alias](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"},{"document_id":"ibmcld_00539-4998-6652","score":0.0285714286,"text":"\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...\n\"execution_stats\": {\n\"total_keys_examined\": 0,\n\"total_docs_examined\": 1000000,\n\"total_quorum_docs_examined\": 0,\n\"results_returned\": 2,\n\"execution_time_ms\": 4400.699\n}\n}\n\nThe ratio between total_docs_examined and results_returned is key here: a high value indicates that too many documents are being scanned per document that is returned.\n\nFor more information, see [Blog post on Optimizing IBM Cloudant Queries](https:\/\/blog.cloudant.com\/2020\/04\/24\/Optimising-Cloudant-Queries.html).\n\n\n\n\n\n Which IBM Cloudant Query operators defeat the use of an index? \n\nAny of the [combination operators](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryoperators) other than $and can make a query do a full database scan without the help of a secondary index. For example, if an $or operator is used, then no secondary index can be used to assist the query. If in doubt, use the [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2406672991}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06926-3212-5298","score":0.0327868852,"text":"\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.\n* IBM Cloud customers can extend or migrate the reach of their network significantly, due to addition of new sites or applications throughout the IBM network.\n* Tenant-specific routing tables narrow the aperture for IP address overlap, without the risk of overlap with other tenants' subnets or other parts of the network that are not applicable.\n\n\n\nCompared to the older ACL model, there are a few minor tradeoffs to take into account:\n\n\n\n* Converting to a customer VRF requires a maintenance window, which causes a brief disruption of backbone traffic flows.\n* Remote access by using the managed VPN services (SSL, IPsec) is limited to just SSL VPN into a data center; however, the shared ACL over the backbone allows global access from any entry point from either service.\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_03180-11118-12801","score":0.0322580645,"text":"\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_03162-10976-13038","score":0.0317460317,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_16258-7-1952","score":0.03125,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":0.0307692308,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_02844-1555-3643","score":0.0303030303,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_16338-2788-4628","score":0.0298507463,"text":"\n* [Confidence scores](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-confidence)\n* [Step locator](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-step-locator)\n* [Follow along](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-follow-along)\n\n\n\n\n\n Start and end of an action \n\nThe assistant marks the spots in the conversation when a customer enters an input that fits within an action. The assistant also marks when an action completes, and how it completes.\n\nCompletion options include ending:\n\n\n\n* With an end step\n* Without an end step\n* With a human agent escalation\n* With a search to a knowledge base\n\n\n\n\n\n\n\n Action confidence score \n\nEvery input that you enter that can start a new topic shows a confidence score icon. Hover over this icon to see a list of actions with different confidence scores.\n\nThese scores represent the assistant\u2019s confidence that the sentence or phrase that you entered can be solved by the steps that are built into a specific action.\n\nZoom\n\n![Debug mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/rn-debug-confidence.png)\n\nDebug mode\n\nThe top score in green represents the action with the highest confidence and the one the assistant used.\n\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_16338-4145-6019","score":0.0294117647,"text":"\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.\n\nClick the icon, and the editor shows the corresponding step in the background.\n\nZoom\n\n![Step locator](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/review-step-locator.png)\n\nStep locator\n\n\n\n\n\n Follow along \n\nFollow along connects what you are seeing in Preview with what you built in the action. As you interact with your assistant, the debug mode automatically opens each step in the background. That means you can fix an error as soon as you see it, because the editor is already open to the corresponding step.\n\n\n\n\n\n\n\n Variable values in Preview \n\nAs you test your conversation in Preview, you can check that each variable is set correctly. Click Variable values to see the values stored in each variable during the conversation. The Variable values pane has two tabs, one for action variables and one for session variables. If you are using dialog, you can see session variables for both actions and dialog on the Session variables tab.\n\nZoom\n\n![Variable values](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/variable-values-preview.png)\n\nVariable values\n\nTo learn more about variables, see [Managing information during the conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-info).\n\n\n\n\n\n Extension inspector in Preview","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_06926-4859-5591","score":0.0289855072,"text":"\nDuring conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)\n* [VPC conversion instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure&interface=uihow-you-can-initiate-the-conversion)\n* [IBM Cloud service endpoints conversion instructions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpoint)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_10143-7-2020","score":0.0285714286,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cluster_access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-1324-3123","score":0.0327868852,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":0.0322580645,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_02844-1555-3643","score":0.03125,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_03043-1537-3553","score":0.0303099885,"text":"\nTo train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor in the tool to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/basic-impl.png)\n\n\n\nTo enable your dialog skill to handle more nuanced questions, define entities and reference them from your dialog.\n\n\n\n* [Entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities); An entity represents a term or object that is relevant to your intents and that provides a specific context for an intent. For example, an entity might represent a city where the user wants to find a business location, or the amount of a bill payment. In the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_16259-1485-3642","score":0.0289915966,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_03162-10976-13038","score":0.0158730159,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_16370-7-1926","score":0.0158730159,"text":"\nTutorial: Customizing the greeting action based on the current page \n\nThis tutorial shows how you can dynamically customize the greeting action that is triggered by the web chat based on the page the user is currently viewing.\n\nFor a complete, working version of the example described in this tutorial, see [Select greeting action for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/select-greeting-action).\n\nIf you do not have the home screen enabled, the default behavior when the web chat opens is to send an empty message to the assistant to start the conversation. This empty message triggers the Greet customer action, which typically sends a welcome message.\n\nRather than starting the conversation with a generic greeting, you might want your users to see a prompt that is specific to the page they are already viewing. For example, if a user has already navigated to a page about credit cards and then opens the web chat, you might want to start the conversation with a message that is specific to credit cards.\n\nAlthough this example shows how to adapt the text based on the current page, you can use the same basic approach to adapt the text based on any client condition (such as the time of day or the user's geographical location).\n\nTo change the greeting action based on the current page the user is viewing, follow these steps:\n\n\n\n1. Determine what page the user is currently viewing. Depending on the design of your application, there are various ways to do this, but one simple mechanism is to check the value of a URL query parameter (in this example, page):\n\nconst page = new URLSearchParams(window.location.search).get('page');\n2. Create a handler for the [pre:send](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventspresend) event, which is fired before a message is sent to the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-custom-action-for-page"},{"document_id":"ibmcld_03180-11118-12801","score":0.0153846154,"text":"\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_07068-2140-4064","score":0.0151515152,"text":"\nList fields across collections [GET \/v1\/environments\/{environment_id}\/fields](https:\/\/cloud.ibm.com\/apidocs\/discoverylistfields) [GET \/v2\/projects\/{project_id}\/fields](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistfields) \n\n\n\n\n\n\n\n Configurations \n\nThe v2 API does not have an endpoint that is dedicated to configurations. Instead, configuration settings for projects, collections, and queries are specified directly in the API for those objects. Not all of the configuration parameters that are available in v1 are available or applicable in v2.\n\nIn the [v1 configuration API](https:\/\/cloud.ibm.com\/apidocs\/discoverycreateconfiguration), the JSON object that is used to specify a configuration object contains several parameters that are either available in different formats from other v2 endpoints or are not available in v2. The following table describes how to find related parameters in v2.\n\nYou cannot customize the conversion of documents during the ingestion process in v2 as you can in v1.\n\n\n\nConfiguration setting details\n\n v1 configuration parameter v2 API \n\n \"conversions.html\": { ... } Not available \n \"conversions.image_text_recognition\": { ... } Not available from the API. However, you can enable optical character recognition (OCR) for a collection from the product user interface to extract text from images. OCR has other benefits, too. For example, if a page in a document can't be processed, OCR converts the page into an image and scans it to ensure that the document is uploaded successfully. \n \"conversions.json_normalizations\": { ... } Moved to the [Collections API](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistcollections). \n \"conversions.pdf\": { ... } Not available. If you used special parameters to extract text from images in PDFs, enable optical character recognition (OCR) from the product user interface for the collection that contains the PDFs instead. \n \"conversions.segment\": { ...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_03036-5624-7724","score":0.0151515152,"text":"\n[Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09560-7265-8618","score":0.0327868852,"text":"\nPATCH \/v5\/ibm\/deployments\/:deployment_id\/groups\/:group_id\nRead deployment group\n---\nDELETE \/v5\/ibm\/deployments\/:deployment_id\/management\/database_connections\nKill all database connections\n---\nPATCH \/v5\/ibm\/deployments\/:deployment_id\/configuration\nUpdate deployment configuration\n---\nGET \/v5\/ibm\/deployments\/:deployment_id\/configuration\/schema\nRead deployment configuration schema\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\nCreate a user based on user type\n---\nPATCH \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\nUpdate a DeploymentUser\n---\nDELETE \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\nRemove a user based on user type\n---\nGET \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\/connections\/:endpoint_type\nRead deployment user connections\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\/connections\/:endpoint_type\nCreate deployment user connections\n---\nGET \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\nRead Allowlisted IP Addresses\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\nCreate an Allowlisted IP Addresses\n---\nDELETE \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\/:ip_address_id\nRemove an Allowlisted IP Addresses\n---\nPUT \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\nBulk allowlist IP addresses\n---","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-iam"},{"document_id":"ibmcld_01077-3119-4885","score":0.0322580645,"text":"\n<service_id>.user-password.update A user's password was updated. A \"-failure\" flag is included in the message if the attempt to update a user's password failed. \n <service_id>.user.create A user was created. A \"-failure\" flag is included in the message if the attempt to create a user failed. \n <service_id>.user.delete A user was deleted. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.table.delete A table was deleted. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.token.create A token was created. A \"-failure\" flag is included in the message if the attempt to create a user failed. \n <service_id>.token.delete A token was deleted. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.privilege.update A privilege was granted. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.privilege.revoke A privilege was revoked. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.database-connection.list Lists active database connections. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.database-connection.stop Terminates a database connection. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.lock.enable Locks a user account indefinitely. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.lock.disable Unlocks a user account. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n <service_id>.policy.list Lists available policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-auditing-events-for-db2-warehouse-on-cloud"},{"document_id":"ibmcld_09560-5213-6558","score":0.0317460317,"text":"\nGET \/v5\/ibm\/deployments\/:deployment_id\/configuration\/schema\nRead deployment configuration schema\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\nCreate a user based on user type\n---\nDELETE \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\nRemove a user based on user type\n---\nGET \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\/connections\/:endpoint_type\nRead deployment user connections\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/users\/:user_type\/:user_id\/connections\/:endpoint_type\nCreate deployment user connections\n---\nGET \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\nRead Allowlisted IP Addresses\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\nCreate an Allowlisted IP Addresses\n---\nDELETE \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\/:ip_address_id\nRemove an Allowlisted IP Addresses\n---\nPUT \/v5\/ibm\/deployments\/:deployment_id\/allowlists\/ip_addresses\nBulk allowlist IP addresses\n---\nPOST \/v5\/ibm\/deployments\/:deployment_id\/elasticsearch\/file_syncs\nCreate elasticsearch file sync\nShow more\n\n\n\n\n\n Administrator \n\nThe allowed actions for the Administrator role.\n\nGET \/v5\/ibm\/deployables\nRead Deployables\n---\nGET \/v5\/ibm\/regions\nRead Discover available regions\n---\nGET \/v5\/ibm\/tasks\/:task_id\nRead a Task\n---\nGET \/v5\/ibm\/backups\/:backup_id\nRead a Backup\n---","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-iam"},{"document_id":"ibmcld_09537-4412-6182","score":0.03125,"text":"\nAction Name Legacy Action name Description \n\n <service_id>.deployment-backup.create <service_id>.backup-ondemand.create An on-demand backup of your deployment was created. If the backup failed, a \"-failure\" flag is included in the message. \n <service_id>.deployment-backup-scheduled.create <service_id>.backup-scheduled.create A scheduled backup of your deployment was created. If the backup failed, a \"-failure\" flag is included in the message. \n <service_id>.deployment-user.update <service_id>.user-password.update A user's password was updated. A \"-failure\" flag is included in the message if the attempt to update a user's password failed. \n <service_id>.deployment-user.create <service_id>.user.create A user was created. A \"-failure\" flag is included in the message if the attempt to create a user failed. \n <service_id>.deployment-user.delete <service_id>.user.delete A user was deleted. A \"-failure\" flag is included in the message if the attempt to delete a user failed. \n No Longer Sent (see below for more information) <service_id>.backup.restore A restore from backup was created. If the attempted restore failed, a \"-failure\" flag is included in the message. \n <service_id>.deployment-group.update <service_id>.resources.scale A scaling operation was performed. If the scaling operation failed, a \"-failure\" flag is included in the message. \n <service_id>.deployment-allowlist-ip-addresses.update <service_id>.whitelisted-ips-list.update The allowlist was modified. A \"-failure\" flag is included in the message if the attempt to modify the allowlist failed. \n <service_id>.deployment.update <service_id>.serviceendpoints.update A change was made to the service endpoints configuration. If the operation failed, a \"-failure\" flag is included in the message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-activity-tracker"},{"document_id":"ibmcld_02599-1644-3412","score":0.0307692308,"text":"\napiconnect.user_registry_testConnection.create Test a User Registry connection \n apiconnect.user_registry_search.create Search for users in the user registry \n apiconnect.user_create.create Create a User object \n apiconnect.user_clear.delete Clear the User objects \n apiconnect.user_update.update Update the User object by name or ID \n apiconnect.user_del.delete Delete the User object by name or ID \n apiconnect.user_requestPasswordReset.create Send reset password link \n apiconnect.user_resetPassword.create Reset password \n apiconnect.user_searchAdmin.create Search for users in the admin realm \n apiconnect.user_searchProvider.create Search for users in the provider realm \n apiconnect.oauth2_token.create Generate a token \n apiconnect.oauth2_redirect_post.create Authorization provider redirect endpoint \n apiconnect.api_key_create.create Create a API Key object \n apiconnect.api_key_del.delete Delete the API Key object by name or ID \n apiconnect.org_setting_singletonUpdate.update Update the Organization Setting object \n apiconnect.notification_template_updateProviderSubcollectionOrgScope.update Update the Notification Template object by name or ID \n apiconnect.notification_template_updateCatalogSubcollectionOrgScope.update Update the Notification Template object by name or ID \n apiconnect.notification_template_updateSpaceSubcollectionOrgScope.update Update the Notification Template object by name or ID \n apiconnect.notification_template_updateConsumerSubcollectionOrgScope.update Update the Notification Template object by name or ID \n apiconnect.org_update.update Update the Organization object by name or ID \n apiconnect.org_del.delete Delete the Organization object by name or ID \n apiconnect.org_transferOwner.create Transfer owner to an associate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-at_events"},{"document_id":"ibmcld_08423-6549-8265","score":0.0303030303,"text":"\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the SO user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, SO user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the SO user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 2. Create service IDs and API keys for the normal user \n\nTo create a service ID for the normal user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the normal user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Normal user and description for the normal user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Normal user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Normal user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the normal user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"},{"document_id":"ibmcld_14780-7-2222","score":0.0298507463,"text":"\nvCenter identity and access management \n\nInside IBM Cloud\u00ae for VMware\u00ae Regulated Workloads, multiple levels of access are available. The automation uses a set of user IDs to perform operations such as adding hosts, clusters, or storage to your VMware instance.\n\n\n\n vCenter and Platform Services Controller user IDs \n\nThe following user IDs are used to add an identity source, which is embedded by default, into vCenter.\n\n\n\nTable 1. vCenter and Platform Services Controller user IDs\n\n User User ID Method Description \n\n Privileged user root SSH Used for VMware configuration such as setting up VMware High Availability and creating distributed switches. Used post deployment to pair primary and secondary vCenter Server instances. \n Privileged user customerroot SSH Created for customer use only. \n IBM automation automation@root_domain <br>(Active Directory user) HTTPS Used post deployment to add and remove hosts and clusters and to deploy and configure virtual machines (VMs) for add-on services. \n Privileged user cloudadmin@root_domain <br>(Active Directory user) HTTPS Created for customer use only. \n\n\n\nHTTPS is used for vCenter setup and configuration, and for VMware operations such as adding hosts, clusters, or storage for vCenter management of resources.\n\n\n\n vCenter access \n\nPrivileged users are granted cloudadmin access to vCenter Server through the vCetner roles.\n\n\n\n\n\n\n\n NSX Manager user IDs \n\n\n\nTable 2. NSX Manager user IDs\n\n User User ID Description \n\n IBM automation ibm_automation <br>(NSX-T\u2122 principal identity user) Used post deployment to manage NSX VTEP IP addresses and to manage host and cluster configuration when hosts and clusters are added or removed. Also used to manage ESG configuration for add-on services that require public network access for licensing, activation, or usage reporting. \n Privileged user admin Created for customer use only. \n\n\n\n\n\n\n\n ESXi host user IDs \n\n\n\nTable 3. ESXi host user IDs\n\n User User ID Description \n\n Privileged user ic4vroot Used post deployment to add more NFS storage, configure routes for that storage, and to run all server validation code. \n Privileged user root Created for customer use only. \n\n\n\n\n\n\n\n Active Directory user IDs \n\n\n\nTable 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-iam-vsphere"},{"document_id":"ibmcld_02734-3347-4762","score":0.0294117647,"text":"\nThe user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.\n5. The user might choose to sign in to access more features of your app.\n6. Your application notifies App ID that the user wants to interact with your app as an identified user.\n7. App ID returns the login widget to your app.\n8. The user selects their preferred identity provider and provides their credentials.\n9. Your application informs App ID that the user selected an identity provider.\n10. App ID authenticates the call with the identity provider.\n11. The identity provider confirms whether the login was successful.\n12. App ID uses the anonymous token to find the anonymous profile and attaches the user's identity to it.\n13. After App ID creates the new tokens, the service invalidates the user's anonymous token.\n14. App ID returns the new access and identity tokens. The new tokens contain the public information that is shared by the identity provider and the attributes of the user's formerly anonymous profile.\n15. The user is granted access to your app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_08423-7919-9687","score":0.0289855072,"text":"\n3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Anonymous user and description for the anonymous user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Anonymous user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Anonymous user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the anonymous user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\nFor more information about creating services IDs, see [Creating and working with service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids). For detailed instructions on creating service ID API keys, see [Managing service ID API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceidapikeys).\n\n\n\n\n\n\n\n Step 3: Assign IAM roles to the service IDs \n\nYou can grant access to service IDs within a Hyper Protect Crypto Services service instance by using the IBM Cloud console.\n\n\n\n 1. Assign the custom roles to the SO user service ID \n\nTo assign the custom roles that are defined in [Step 1](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-accessstep1-create-custom-roles) to the SO user service ID, follow these steps:\n\nTo assign access to the keystores for the SO user, follow these steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"},{"document_id":"ibmcld_12574-4662-6837","score":0.0285714286,"text":"\nIf a user leaves your company, you can delete the user's corporate identity in your directory, which revokes access to IBM Cloud.\n\n\n\n\n\n Functional IDs \n\nFunctional IDs are most commonly used when an application or service needs a digital identity and access to IAM-enabled resources or classic infrastructure resources. Some services require a functional ID when you create service instances, for example the Kubernetes Service.\n\nA functional ID is a type of user ID that exists in your Identity Provider's (IdP) user directory, but it's not tied to a specific user. To create a functional ID, you must create a new user in the user directory and invite them to your IBM Cloud account.\n\nThe functional ID is used to create service instances, like Kubernetes Service clusters. This way, instances aren't linked to a specific person that might leave the company, which would leave the instance without an owner. Generally, functional IDs can do more in IBM Cloud than a service ID. For example, functional IDs, like user IDs, can be granted access to services and applications through access policies.\n\nIBM Cloud API keys for users can be created and associated with a functional ID. If a service requires a user API key for interacting with other services or applications, use the functional ID API key. By using the API key that is associated with the functional ID, you can provide only the access that is needed for that service.\n\nIf you're using a functional ID as the account owner, instead consider [Setting an alternative account owner](https:\/\/cloud.ibm.com\/docs\/account?topic=account-classic-infra-owner&interface=ui). This is available only for classic infrastructure accounts.\n\n\n\n\n\n\n\n Service IDs \n\nService IDs are another type of identity that is used in an account. Service IDs are used to provide a separate identity for services and applications. Service IDs are best used when an application or service needs a digital identity and needs access to only IAM-enabled resources. You can create a service ID to be used by an application that needs access to your IBM Cloud services so that individual user credentials don't need to be used.\n\n\n\n Service ID API keys","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-identity-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07765-0-1628","score":0.0327868852,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_07787-0-1608","score":0.0322580645,"text":"\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"},{"document_id":"ibmcld_02746-7-1681","score":0.0317460317,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_00708-54925-56282","score":0.03125,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-54925-56282","score":0.0307692308,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-54906-56263","score":0.0303030303,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_00708-32460-34303","score":0.0298507463,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-32460-34303","score":0.0294117647,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-32441-34284","score":0.0289855072,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_03638-1509-3624","score":0.0285714286,"text":"\nYou can record these details for both an individual device and for all devices associated with your account:\n\n\n\n* View individual device IPs from the Device List.\n* View individual device root passwords in the Snapshot View for the device.\n* View multiple device IPs by using the Download CSV option from the Device List. Then, select Download CSV from the Settings cog to download a full list of devices and details in spreadsheet format.\n\n\n\n4. Update the credentials for operating systems and other software. All of the software that was loaded onto your device during the provisioning process was assigned temporary credentials. You can view and manage these credentials on the Passwords tab of each device in the IBM Cloud\u00ae console. Use these temporary credentials to access your software for the first time. Then, change the password to your software by following strong password practices. Create a password that consists of a combination of letters, numbers, and symbols. Optionally, you can store password updates on the Passwords tab for each device. However, when you store passwords, any person with access to the account and appropriate permissions can view the passwords that are stored on the Passwords screen.\n5. Access your server on the private network. You can use the IBM Cloud infrastructure private network to interact with your devices through remote desktop (RDP) by using SSH and KVM over IP. You can use the VPN Access tool for private network connection to either the closest SSL VPN endpoint or to the endpoint of your choice. VPN access is also required to interact with several services. To access the private network, edit the user\u2019s VPN access from the User List. To access the User List, click Account > Users > User list. Use the [Virtual Private Network](https:\/\/www.ibm.com\/cloud\/vpn-access) page to connect to one of the various VPN options.\n6. After you have your infrastructure and environments up and running, you are ready to set up your monitoring service. IBM Cloud Monitoring gives you insight into the performance and health of your applications, services, and platforms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-set-up"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03354-4-1897","score":0.0327868852,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_01178-22864-25119","score":0.0322580645,"text":"\nSegment By Service instance, Service instance name \n\n\n\n\n\n\n\n Number of under in-sync replica partitions \n\nThe number of partitions with fewer than two in-sync replicas.\n\n\n\nTable 18. Number of under in-sync replica partitions metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_under_minisr_partitions \n Metric Type gauge \n Value Type none \n Segment By Service instance \n\n\n\nIdeally this value should be zero. A nonzero value might highlight a temporary issue with the cluster.\n\n\n\n\n\n Produce message conversion time \n\nIndicates that the accumulated time spent performing message conversion from clients that are producing by using older protocol versions.\n\n\n\nTable 19. Produce message conversion time metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_produce_conversions_time_quantile \n Metric Type gauge \n Value Type second \n Segment By Service instance, Quantile, Service instance name \n\n\n\nIdeally zero. A consistent growth in this indicates that some clients are down-level and should be upgraded. Ensure that all clients are at the latest levels.\n\n\n\n\n\n Rebalancing consumer groups \n\nThe number of rebalancing consumer groups in an Event Streams instance.\n\n\n\nTable 20. Rebalancing consumer groups metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_rebalancing_consumergroups \n Metric Type gauge \n Value Type none \n Segment By Service instance, Service instance name \n\n\n\nWhile it is expected that this figure is occasionally >0 (as broker restarts happen frequently,) sustained high levels suggest that consumers might be restarting frequently and leaving or rejoining the consumer groups. Check you client logs.\n\n\n\n\n\n Reserved disk space percentage \n\nThe percentage of reserved disk space that is required for all allocated partitions if fully used.\n\n\n\nTable 21. Reserved disk space percentage metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_reserved_disk_space_percent \n Metric Type gauge \n Value Type percent \n Segment By Service instance, Service instance name \n\n\n\nShows the percentage of disk space that would be used if your topics were filled to the extent of their configured retention size.\n\n\n\n\n\n Schema greatest version percentage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-metrics"},{"document_id":"ibmcld_09994-4281-6432","score":0.0317460317,"text":"\nBETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2> Includes all the rows that were valid at any time between TIMESTAMP EXPRESSION 1 and TIMESTAMP EXPRESSION 2 (inclusive), whose insert timestamp is less than or equal to TIMESTAMP EXPRESSION 2 and whose delete timestamp is NULL or is greater than TIMESTAMP EXPRESSION 1. If TIMESTAMP EXPRESSION 1 or TIMESTAMP EXPRESSION 2 is less than the table\u2019s retention start timestamp, an error is returned. If TIMESTAMP EXPRESSION 1 is greater than TIMESTAMP EXPRESSION 2, the query produces no rows. \n\n\n\n\n\n\n\n\n\n Timestamps in time travel queries \n\n\n\n Retention time interval and retention time period \n\nA table\u2019s retention time interval defines the number of days past their delete timestamps that historical (deleted) rows are available for time travel queries. At any given time, the retention time period ends at the current timestamp (date and time) and extends back the given number of days. This is a sliding time window that advances as the current system time advances.\n\n\n\n\n\n Retention lower bound \n\nFor the most part, a table\u2019s retention lower bound is the date and time when the table was defined to be a temporal table. This could have been when you ran the CREATE TABLE command, or the last time you altered the table\u2019s DATA_VERSION_RETENTION_TIME from zero to non-zero.\n\n\n\n\n\n Retention start timestamp \n\nAt the time of defining a table to be temporal (when the retention lower bound is defined), there are no historical rows available over the retention time period. To capture the notion of how far back historical rows are actually available (visible to time travel queries), a table\u2019s retention start timestamp is defined. The retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date\/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_09956-7-2100","score":0.03125,"text":"\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/docs\/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_15164-5536-7411","score":0.0307692308,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"},{"document_id":"ibmcld_15161-5539-7414","score":0.0303030303,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15162-5539-7414","score":0.0298507463,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"},{"document_id":"ibmcld_15163-5557-7432","score":0.0294117647,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"},{"document_id":"ibmcld_09956-1678-3537","score":0.0289855072,"text":"\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table\n* _v_schema\n* _v_database\n\n\n\n\n\n\n\n\n\n Viewing the retention time interval with the web console \n\n\n\n Viewing the default retention time interval for the system with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Go to Databases. The retention time interval for the system is displayed in the Retention time interval section at the top of the page.\n\n\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. View the retention time interval:\n\n\n\n* For a table:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to view the retention interval is located.\n3. Ensure that you are in the DB Objects > Tables tab.\n4. Identify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_15160-5628-7463","score":0.0285714286,"text":"\nLocal time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled. You can also specify the maximum number of fast restore snapshots that you want to retain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":0.0327868852,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":0.0322580645,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":0.0317460317,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-35313-36062","score":0.03125,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":0.0307692308,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-1603-3385","score":0.0303030303,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-2946-5057","score":0.0298507463,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04111-34153-35639","score":0.0294117647,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_16286-1338-3308","score":0.0289855072,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_04170-7-2189","score":0.0285714286,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04170-7-2189","score":0.0320184426,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-3403-5572","score":0.0320020481,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-5067-6335","score":0.0315136476,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":0.0163934426,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":0.0158730159,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04168-6066-7283","score":0.015625,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04334-39121-41053","score":0.0153846154,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04113-1734-4014","score":0.0151515152,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04146-2946-5057","score":0.0151515152,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04172-7-2047","score":0.0149253731,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":0.0327868852,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":0.0322580645,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":0.0317460317,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04168-6066-7283","score":0.03125,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04172-7-2047","score":0.0307692308,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04118-5438-6061","score":0.0303030303,"text":"\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_04175-0-1274","score":0.0298507463,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-7-2225","score":0.0294117647,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-1738-2974","score":0.0289855072,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-35313-36062","score":0.0285714286,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04175-0-1274","score":0.0327868852,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_16505-4167-5227","score":0.0320020481,"text":"\nSee [Adjudication](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruthwks_haperform). \n Train the model Create the machine learning model. See [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-mlwks_madocsets). \n Evaluate the model Evaluate the accuracy of the model. See [Evaluating annotations added by the model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-mlwks_matest). Depending on model accuracy, this step might result in the need to repeat earlier steps again and again until optimal accuracy is achieved. See [Analyzing machine learning model performance](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml) for ideas about what to update based on common performance issues. \n Publish the model Export the model. See [Using the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator"},{"document_id":"ibmcld_16451-3317-5174","score":0.0305361305,"text":"\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16442-4240-5350","score":0.0303308824,"text":"\nSee [Adjudication](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruthwks_haperform). \n Train the model Create the machine learning model. See [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-mlwks_madocsets). \n Evaluate the model Evaluate the accuracy of the model. See [Evaluating annotations added by the model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-mlwks_matest). Depending on model accuracy, this step might result in the need to repeat earlier steps again and again until optimal accuracy is achieved. See [Analyzing machine learning model performance](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml) for ideas about what to update based on common performance issues. \n Publish the model Export the model. See [Using the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-ml).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator"},{"document_id":"ibmcld_16524-3358-5215","score":0.0300768883,"text":"\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_05455-2559-3773","score":0.0161290323,"text":"\nRay [Ray](https:\/\/www.ray.io\/) is an open technology that enables data scientists and application developers to run their code in a distributed fashion. It also provides a lean and easy interface for distributed programming with many different libraries, best suited to perform machine learning and other intensive compute tasks. See [Ray on IBM Cloud Code Engine: Boost Your Serverless Compute](https:\/\/www.ibm.com\/cloud\/blog\/ray-on-ibm-cloud-code-engine). \n Iter8 [Iter8](https:\/\/iter8.tools) is the release engineering tool for Kubernetes that enables SLO validation, A\/B testing, and progressive rollouts for Kubernetes applications. You can use Iter8 to validate your Code Engine applications. See [Validating your application code and latency with Iter8](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-slovalidationtut). \n Guard [Guard](https:\/\/pkg.go.dev\/knative.dev\/security-guardsection-readme) is a workload runtime-security solution, well-equipped to protect Serverless Services. Code Engine users may use Guard as a security layer to protect Code Engine applications. See [Securing your application with Guard](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started-with-guard).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-supported-integrations"},{"document_id":"ibmcld_16524-7-2263","score":0.0158730159,"text":"\nTraining the machine learning model \n\nIn IBM Watson\u00ae Knowledge Studio , the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\n> Restriction: Only three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nSee [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_16451-7-2278","score":0.015625,"text":"\nTraining the machine learning model \n\nIn IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak for Data, the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\nOnly three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nFor more information about which ratios to apply, see [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_13129-7-1929","score":0.0153846154,"text":"\nBuild, deploy, test and monitor a predictive machine learning model \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nIn this tutorial, the Iris flower data set is used for creating a machine learning model to classify species of flowers.\n\nIn the terminology of machine learning, classification is considered an instance of supervised learning, i.e. learning where a training set of correctly identified observations is available.\n\nWatson Studio provides you with the environment and tools to solve your business problems by collaboratively working with data. You can choose the tools you need to analyze and visualize data, to cleanse and shape data, to ingest streaming data, or to create and train machine learning models.\n\n\n\n Objectives \n\n\n\n* Import data to a project.\n* Build a machine learning model.\n* Deploy the model and try out the API.\n* Test a machine learning model.\n* Monitor the deployed model\n* Retrain your model.\n\n\n\nZoom\n\n![Architecture Diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution22-build-machine-learning-model\/architecture_diagram.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The admin uploads a CSV file from a local machine.\n2. The uploaded CSV file is stored in IBM Cloud Object Storage service as a dataset.\n3. The dataset is then used to build and deploy a machine learning model. The deployed model is exposed as an API (scoring-endpoint).\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_07067-22055-24017","score":0.0149253731,"text":"\n: You cannot deploy models directly to Discovery v2 service instances from Knowledge Studio. Instead, you must export the machine learning models from Knowledge Studio, and then import them into Discovery. The model must have been exported from Knowledge Studio after 16 July 2020. If you have a model that was exported before that date, you must reexport the model from Knowledge Studio. Only paid Knowledge Studio plans support exporting models.\n\nFor more information, see one of the following topics:\n\n\n\n* IBM Cloud Pak\u00ae for Data: [Exporting a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-mlexporting-a-machine-learning-model)\n* IBM Cloud: [Deploying a machine learning model to Watson Discovery](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlwks_madiscovery)\n\n\n\nFor information about how to import a model to Discovery v2, see [Importing Machine Learning models](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-ml).\n\n\n\n\n\n Update your application to use the v2 API \n\nThe Watson Developer SDKs support both Discovery v1 and v2.\n\nThese instructions assume that your application is using the latest version of the v1 API (version 2019-04-30).\n\nWhen you port an application that currently uses the Discovery v1 API to use v2, you must plan how to address the following high-level differences between the two versions.\n\nIn addition to these high-level changes, review the differences at a per-method level to understand what else you might need to change. For more information, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\n* v2 organizes data by project and collections; there is no concept of an environment. For example, compare the following requests to get a collection:\n\nv1 [Get collection](https:\/\/cloud.ibm.com\/apidocs\/discoverygetcollection)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":0.0325224749,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":0.0325224749,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":0.0317460317,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_03164-1607-3518","score":0.0305361305,"text":"\nFor more information about it, read the [Slack blog post](https:\/\/medium.com\/slack-developer-blog\/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17. On the Event Subscriptions page in Slack, find the Subscribe to Bot Events section. Click Add Bot User Event, and then select the event types you want to subscribe to. You must select at least one of the following types:\n\n\n\n* message.im: Listens for message events that are posted in a direct message channel.\n* app_mention: Listens for only message events that mention your app or bot.\n\nChoose the app_mention entry in normal font, not the app_mention entry that is in bold font.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-slack"},{"document_id":"ibmcld_04111-35313-36062","score":0.0300768883,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":0.0296312555,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":0.029198636,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-34153-35639","score":0.0287784679,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_03126-3707-6008","score":0.015625,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_04146-1603-3385","score":0.015625,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12385-1815-3858","score":0.0163934426,"text":"\nThis way, you can assign a single policy to the access group rather than an individual policy for each user or service ID. For more information about using access groups, see [What makes a good access group strategy?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setupaccessgroup_strategy)\n\n\n\n\n\n\n\n Organize secrets in your Secrets Manager instance by using secret groups \n\nUse secret groups to narrow the scope of access to specific secrets at an instance level.\n\n\n\n1. Create secret groups to assign even more granular access to a group of secrets, such as those that map to a specific application. To create a secret group, go to the Secrets Manager UI > Secret groups > Create.\n\nIf you're familiar with using resource groups, think of organizing secrets in a secret group similar to the way that you organize resources in resource groups. As an admin, you create secret groups to control access to secrets in your instance. For example, you can create a secret group that contains only the secrets that are used to authenticate to a specific resource or system. Then, you assign the secret group to an IAM access group so that only your selected users or service IDs are able to access those secrets. For more information about managing secret groups, see [Organizing your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-groups).\n\nA default secret group is created for you when you create a Secrets Manager instance. It's important that you create your secret groups first because you can't change the assignment of secrets after you create them. If you accidentally assign a secret to the wrong secret group, or if you don't want a secret to belong to the default secret group, delete the secret and create a new one.\n2. Optionally, use secret groups to allow privileged access to specific resources in your account.\n\nSecret groups can be used to grant direct access to resources that otherwise wouldn't be possible through IAM. For example, assume that User A has no access to Service A in IAM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets"},{"document_id":"ibmcld_04105-1672-3877","score":0.0163934426,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_12465-4-1958","score":0.0161290323,"text":"\n* UI\n* API\n* Terraform\n\n\n\n\n\n\n\n Organizing your secrets \n\nWhen you work with IBM Cloud\u00ae Secrets Manager, you can create groups to organize your secrets and control who on your team has access to them. Then, if you don't need them anymore, you can delete the groups.\n\nSimilar to the way that\n\nresource groupshelp to ensure correct policy enforcement at the platform level, you can create secret groups at the instance level to organize secrets.\n\nZoom\n\n![The image shows two examples of a secret group and how they're mapped to access groups. One where the reader role is assigned and one where the manager role is assigned. The content is explained fully in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/\/images\/secret-group.svg)\n\nFigure 1. Assigning access to secret groups\n\nAs shown in the previous image, users with Reader access to a secret group can see that the group exists and understand which secrets are assigned to it. Users with Writer access can view and edit the secret group and secrets themselves. By design, the default secret group inherits all of the same permissions that are set for the instance.\n\nYou can choose to group your secrets by phase of development, specific to the type of roles that people on your team have, or in any way that might help you. Each secret can be mapped to one group only and the mapping occurs at the time of secret creation.\n\nTo learn about the suggested guidelines for using secret groups, check out [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n Before you begin \n\nBefore you begin, be sure that you have the required level of access. To create and manage secret groups, you need the [Manager service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n\n\n Creating secret groups","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-groups"},{"document_id":"ibmcld_04105-7-2225","score":0.0161290323,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_12478-0-935","score":0.0158730159,"text":"\n\n\n\n\n\n\n  Why can't I delete my secret group? \n\nYou try to use IBM Cloud\u00ae Secrets Manager to delete a secret group, but you're unable to complete the action.\n\n  What\u2019s happening \n\nYou have a secret group that you no longer need. When you try to delete it in the Secrets Manager UI, you get the following error:\n\nDelete group failed\nAn error occurred and the secret group couldn't be deleted.\n\n  Why it\u2019s happening \n\nSecret groups are a way to organize and assign access policies to your secrets. By deleting a secret group, you render all the secrets in that group useless. For that reason, you cannot delete a secret group that contains secrets.\n\n  How to fix it \n\nTo delete a secret group, delete all the secrets that are associated with it and then delete the group itself.\n\nTo learn more about secret groups, check out [Organizing your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-groups).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-troubleshoot-secret-group"},{"document_id":"ibmcld_04105-3403-5572","score":0.0158730159,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_12498-3109-5107","score":0.015625,"text":"\nAnd this is why it's so important to establish a centralized place to manage all these things as we build out more applications and microservices. As we have more of these, the problem becomes more complex. If it falls into the wrong hands, how is protected? How do we block it from getting to that point? How was that data isolated?\n\nWhen we look at the damage that this can cause, we're looking in the millions of dollars, for example, for a data breach. In terms of developer operations, if you're not properly managing these, forget even the case in which a bad actor hasn't been involved, but it can be confusing for teams to use this. So what we need to do is make sure that we have it, again, centralized improperly stored so that we can leverage these secrets in the correct way and they can properly communicate with services.\n\nOK, now, let's look at the next layer of the onion in a more complicated example.\n\nNow let's go back to Jane, the enterprise developer. Jane \u2013 our \"E dev\" here \u2013 needs again to have access to that development repo that she's referring to earlier. Let's go ahead and call this, maybe it's GitHub. So what she needs to be able to do is have write access and so she's going to need to request the information that's going to give her access to that role. So that's where a secrets manager service comes in in a perfect, complementary fashion.\n\nA secrets manager service can securely store these credentials, along with other types of secrets, in a centralized way for her to be able to access or maybe other services to access, like we'll see in a second. But when it's done, it's given her the peace of mind that her user credentials are securely stored and now she can worry about authenticating with the service and getting her job done because secrets manager is going to take care of that for her.\n\nHowever, what's really important for secrets manager service to do is interact with the cloud service provider's IAM, or identity and access management service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_15453-5897-6935","score":0.015625,"text":"\nAssign a floating IP address to the Hyper Protect Virtual Server for VPC instance and click Save.\n9. To open the PayNow website, copy and paste the floating IP address and use your browser to open the PayNow website under the URL https:\/\/<floatingip>:8443\/index.html.\n\n\n\nNow, by using Confidential Computing with IBM Cloud Hyper Protect Virtual Server for VPC, you can ensure that you have a level of data security that is unmatched in the industry.\n\n\n\n\n\n\n\n Next steps \n\nCheck out the [demo video](https:\/\/mediacenter.ibm.com\/media\/IBM+Cloud+Show+Me-+Hyper+Protect+Services+for+Confidential+Computing+Demo\/1_f7e970ig) that demonstrates the data protection that is provided by Confidential Computing by comparision between two servers:\n\n\n\n* One without Confidential Computing, where a malicious root user can dump contents of the server memory that's not protected to steal PII and credit card data.\n* One with Confidential Computing, where even the root user can\u2019t access the server memory as it's protected by the Hyper Protect platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-financial-transaction-confidential-computing-on-hyper-protect-virtual-server-for-vpc"},{"document_id":"ibmcld_00773-7-2050","score":0.0153846154,"text":"\nUsing Delivery Pipeline Tekton Pipelines with externalized properties \n\nYou can run pipelines that contain pipeline properties that are not stored with the Delivery Pipeline. By using these externalized properties, you can manage pipeline environment properties in a Git repository (repo) and use version control and tracking.\n\nAfter a pipeline is externalized, pipeline runs occur in the same way, depending on the triggers that are configured for the pipeline. The values of any properties that are externalized and specified by way of the pipeline UI are overridden by the values in the UI when the property names and property types match.\n\n\n\n Configuring a pipeline to use externalized properties \n\nThe latest private worker agent versions support external properties natively. This support uses [Kustomize](https:\/\/kustomize.io\/) and [External Secrets](https:\/\/external-secrets.io\/), and requires a pipeline that is configured to use external properties.\n\nAs of Kubernetes version 1.14, Kustomize is included in Kubernetes to provide a declarative means of cluster configuration and Kubernetes object creation by using yaml files. To use externalized properties, your pipelines require a kustomization.yaml file.\n\nBy using the External Secrets operator, you can synchronize secrets from external APIs with Kubernetes secrets. Supported providers include [IBM Cloud\u00ae Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started). By using the operator, you can represent secrets and providers within yaml files that are stored in a repo, such as Git. To use externalized secure properties, your pipeline definitions must provide yaml files that define both a SecretStore and an ExternalSecret.\n\n\n\n Configuring a cluster \n\nPipelines with externalized environment properties are supported on [pipeline private worker installations](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=ui) at version 0.14.9 or later, or on IBM-provided managed workers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-external-properties"},{"document_id":"ibmcld_16286-1338-3308","score":0.0153846154,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02776-3988-5695","score":0.0327868852,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_13616-13587-15670","score":0.0322580645,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_04997-3175-3972","score":0.0317460317,"text":"\nSee [IBM Cloud Docs: Enabling the HIPAA Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedenabling-hipaa) for additional information.\n\n\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nPlease visit [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) page to learn about IBM\u2019s GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey.\n\n\n\n* [IBM Data Processing Addendum (DPA)](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=dpa)\n\n\n\n\n\n\n\n Privacy shield \n\nIBM Cloud Object Storage is privacy shield certified. For more information please visit [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compliance"},{"document_id":"ibmcld_12035-7-1995","score":0.03125,"text":"\nCompliance \n\nIBM Cloud\u00ae Schematics actively participates in several industry compliance programs. As compliance focal, you can use the Schematics goals to check that your organization is adhering to the external and internal standards for your industry. For more information about monitoring compliance, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nTo monitor your resources with Schematics, see [Managing security and compliance with Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-monitoring-instances).\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nAbout GDPR and how Schematics adheres to it, see [General Data Protection Regulation](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdpr). View [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) to learn about IBM's GDPR readiness journey and the GDPR capabilities and offerings to support your compliance journey.\n\n\n\n\n\n Privacy shield \n\nSchematics is privacy shield that is certified. For more information, see the [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/us-en\/privacy\/privacy-shield).\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nSchematics is audited by a Third-party security firm and meet ISO 27001, ISO 27017, ISO 27018, and ISO 27701 requirements. For more information, see the [Schematics Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the Schematics compliance page cover the Schematics service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27017\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-compliance"},{"document_id":"ibmcld_09492-16883-18851","score":0.0307692308,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-Security"},{"document_id":"ibmcld_12297-14875-16224","score":0.0303030303,"text":"\n* [Creating network zones by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-zone-ui)\n\n\n\n* [Understanding network rules](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-network-rules)\n\n\n\n* [Create network rules by using the CBR API](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-api)\n* [Creating network rules by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-ui)\n\n\n\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-next-steps)\n\n\n\n[Data privacy and governance](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-data-privacy-and-governancedata-privacy-and-governance)\n\n[General Data Protection Regulation (GDPR)](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprgeneral-data-protection-regulation-gdpr)\n\n\n\n* [How do you audit access to Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprhow-do-i-audit-access-to-ibm-schematics)\n* [Supporting classifications of personal data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprsupported-classifications-of-personal-data)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_09513-12728-14481","score":0.0298507463,"text":"\nThis is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-Security"},{"document_id":"ibmcld_09105-6159-7945","score":0.0294117647,"text":"\n<br> <br>When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key. <br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional. An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required. The base64-encoded key material, an existing key-wrapping key, that you want to store and manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keyshow-to-encode-root-key-material).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keys"},{"document_id":"ibmcld_09060-4951-6938","score":0.0289855072,"text":"\nThe unique identifier of the target key ring that you would like the newly create key to be a part of. If unspecified, the header is automatically set to 'default' and the key will sit in the default key ring in the specified Key Protect service instance. For more information, see [Grouping keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys). \n correlation_ID Optional.The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A human-readable name for convenient identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_09059-7769-9779","score":0.0285714286,"text":"\nA human-readable name for convenient identification of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description An extended description of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nIf the expirationDate is provided in your create key request, the key will transition to the deactivated state within one hour past the key's expiration date.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00589-8040-10059","score":0.0327868852,"text":"\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_07578-414710-416563","score":0.0322580645,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-414684-416537","score":0.0317460317,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-419683-421572","score":0.03125,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-419665-421554","score":0.0307692308,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00531-7-2145","score":0.0303030303,"text":"\nAuthenticating with IBM Cloudant FAQ \n\nIBM Cloud\u00ae Identity and Access Management (IAM) combines managing user identities, services, and access control into one approach. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae integrates with IBM Cloud Identity and Access Management.\n\n\n\n What is the difference between IBM Cloudant legacy and IAM access controls? \n\n\n\n IBM Cloud IAM \n\n\n\n* Centrally managed access management across IBM Cloud.\n* Allows a user or service to access many different resources by using the same set of credentials (for example, same username and password or IAM API key).\n* IAM API keys can be granted access to account management functions, like creating new databases.\n\n\n\n\n\n\n\n IBM Cloudant legacy \n\n\n\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\n Why is the Use only IAM mode preferred? \n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\n How can I create an instance by using the command line? \n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p '{\"legacyCredentials\": false}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-authenticating-cloudant"},{"document_id":"ibmcld_00579-7-1988","score":0.0298507463,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00589-9560-11733","score":0.0294117647,"text":"\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_03630-7-2200","score":0.0289855072,"text":"\nAbout RAID \n\nRAID (Redundant Array of Independent Disks) creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance. Following are the three key concepts in RAID:\n\n\n\n* Mirroring: copying data to more than one disk\n* Striping: splitting data across more than one disk\n* Error correction (fault tolerance): redundant data is stored to allow problems to be detected and possibly fixed.\n\n\n\nAlthough many different levels of RAID exist, IBM chooses to support the most common RAID types: 0, 1, 5, 6, and 10. The different RAID levels use one or more of the following techniques, depending on the system requirements. The main purpose of using RAID is to improve reliability by using either 3Ware 9550SX Raid SATA or an Adaptec SA-SCSI RAID controller for all RAID solutions deployed.\n\nRAID is not a backup solution. Rather, RAID creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance.\n\nRAID 0 (Striped set without parity \/ Non-Redundant Array) Implements data striping, where file blocks are written across multiple disks in fragments that require a minimum of two disks. The advantage of a RAID 0 is that the read\/write speed is dramatically increased. The more disks that are in the array, the greater the bandwidth. The disadvantage to a RAID 0 is that it has no fault tolerance. If a single drive fails, the array is broken. Also, RAID 0 does not implement error checking. So, any error is also unrecoverable. A common solution for fault tolerance is to have a drive outside of the array that is used as backup storage in a hardware failure.\n\nRAID 1 (Mirrored set without parity) Implements data mirroring. Data is duplicated on 2 or 4 disks through a hardware raid controller and provides some fault tolerance. The array is recoverable if at least one drive does not fail. It provides faster read performance than a single drive and provides drive redundancy if a drive failure occurs. Write speed is slightly reduced.\n\nRAID 5 (Striped set with dual distributed parity) Implements data striping at a block level and distributes parity among the disks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-raid-levels"},{"document_id":"ibmcld_05138-7979-9034","score":0.0285714286,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":0.0327868852,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":0.0322580645,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_03618-1804-3397","score":0.0158730159,"text":"\nThe TPM device is integrated within the server system and provides a range of Intel TXT security-related functions.\n\n\n\n\n\n What does Intel TXT does for you \n\nIntel TXT is especially advantageous for large enterprises subject to compliance and audit regulations, such as healthcare, financial services, and government organizations. It helps assure that tracking of all trusted resources can be integrated, managed, and reported on with the relevant compliance organizations (HIPAA, PCI, FedRAMP, ISO, FISMA, and SSAE 16). For the first time, these organizations are able to certify that a cloud computing system is secured for workloads such as\n\n\n\n* Governance and enterprise risk\n* Information and lifecycle management\n* Compliance and audit\n* Application security\n* Identity and access management\n* Incident response\n\n\n\nFor more information about Intel TXT on IBM Cloud Bare Metal Servers, see [Intel\u00ae Trusted Execution Technology](https:\/\/www.ibm.com\/cloud\/bare-metal-servers\/intel-txt).\n\n\n\n\n\n Special technical notice \n\nIntel TXT is provided by Intel\u00ae and operates on the IBM Cloud Bare Metal Servers that require specific technical knowledge to support and manage. The IBM Cloud current delivery model can turn Intel\u00ae TXT either on or off. IBM Cloud can't assist with configuration of Intel TXT settings because of the sensitivity of customer environments and data. The recommendation is that you either include staff who is trained in Intel TXT technologies or engage with a consulting firm with expertise in orchestrating root of trust and measured launch environment (MLE) architecture.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-hardware-monitroing-security-controls"},{"document_id":"ibmcld_14708-2831-4126","score":0.0158730159,"text":"\nThis action allows data to be received from the proxy servers during backup and restore processes.\n\nufw status\nStatus: active\nTo Action From\n-- ------ ----\n6162\/tcp ALLOW 10.38.207.157 Allow Veeam Mgmt from Veeam BUR server\n2500\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n6162\/tcp ALLOW OUT Anywhere Veeam transport rule\n2500\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n\nZoom\n\n![Veeam backup](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/veeam-cr-sa-lhbr-proxy.svg)\n\nFigure 2. Veeam backup\n\n\n\n Best practices for a Linux hardened repository \n\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_07679-0-891","score":0.015625,"text":"\n\n\n\n\n\n\n  AU-14 - Session Audit \n\n\n\n  Control requirements \n\nAU-14 - 0\n:   The information system provides the capability for authorized users to select a user session to capture\/record or view\/hear.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Running operator actions through a bastion host](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion)\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nSession audits include, for example, monitoring keystrokes, tracking websites visited, and recording information and\/or file transfers. Session auditing activities are developed, integrated, and used in consultation with legal counsel in accordance with applicable federal laws, Executive Orders, directives, policies, regulations, or standards.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-au-14"},{"document_id":"ibmcld_07118-10351-11416","score":0.015625,"text":"\n[Shows the data source options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-0.png)\n\nFigure 19. Data source options\n2. In the Collection name field, add FRED papers.\n\nZoom\n\n![Shows the Web crawl name field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-1.png)\n\nFigure 20. Web crawl connector\n3. In the Starting URLs field, add the following URL:\n\nhttps:\/\/research.stlouisfed.org\/wp\n\nZoom\n\n![Shows the Starting URLs field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-2.png)\n\nFigure 21. Starting URL field\n\nYou will add only one starting URL. In a real scenario, you might add multiple URLs that go to other pages with information about the same topic. By adding more URLs, you can expand the breadth of the expertise of your assistant.\n4. Click Add.\n5. Click the Edit icon for the URL that you just added.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-assistant-fred"},{"document_id":"ibmcld_05075-3718-5743","score":0.0153846154,"text":"\nHowever, legal holds are more flexible and don't have a defined temporal component. Instead they simply remain in effect until removed. Legal holds can be freely placed and removed by any user who has the cloud-object-storage.object.put_object_lock_legal_hold and cloud-object-storage.object.put_object_lock_legal_hold_version actions.\n\nLegal holds have the additional benefit of acting as method for applying indefinite retention on an object.\n\nLegal holds and retention periods operate independently. Legal holds have no impact on retention periods, and vice-versa.\n\nImagine an object with both a legal hold and a retention period. When the retention period ends, the object version remains protected until the legal hold is removed. If you remove a legal hold while an object version is subject to a retention period it remains protected until the retention period is complete.\n\nObjects locked and stored with a retention period cannot be deleted until retention period expires and any associated legal hold is removed.\n\nLocking objects with a Governance Mode is not supported.\n\n\n\n\n\n\n\n Getting started with Object Lock \n\nIn order to get started, there are some some prerequisites:\n\n\n\n* You'll need the Writer or Manager platform role on a bucket, or a custom role with the appropriate actions (such as cloud-object-storage.bucket.put_object_lock_configuration) assigned.\n* Object Versioning must be enabled\n* You will need to use Standard pricing plan, see [pricing](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-billing) for details.\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_14708-3638-5837","score":0.0153846154,"text":"\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_05075-10227-12120","score":0.0151515152,"text":"\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer \n cloud-object-storage.object.get_object_lock_retention Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_retention Manager, Writer \n cloud-object-storage.object.get_object_lock_retention_version Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_retention_version Manager, Writer \n cloud-object-storage.object.get_object_lock_legal_hold Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_legal_hold Manager, Writer \n cloud-object-storage.object.get_object_lock_legal_hold_version Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_legal_hold_version Manager, Writer \n\n\n\nBe advised that users with the Writer role are capable of making objects un-deletable for many years (possibly thousand of years). Be careful, and consider crafting custom roles that do not allow most users to set a Retain Until Date.\n\n\n\n\n\n Activity Tracker events \n\nObject Lock generates additional events.\n\n\n\n* cloud-object-storage.bucket-object-lock.create\n* cloud-object-storage.bucket-object-lock.read\n* cloud-object-storage.object-object-lock-legal-hold.create\n* cloud-object-storage.object-object-lock-legal-hold.read\n* cloud-object-storage.object-object-lock-retention.create\n* cloud-object-storage.object-object-lock-retention.read\n\n\n\nFor cloud-object-storage.bucket-object-lock.create events, the following fields provide extra information:\n\n\n\n Field Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_07118-11077-12656","score":0.0151515152,"text":"\nFigure 21. Starting URL field\n\nYou will add only one starting URL. In a real scenario, you might add multiple URLs that go to other pages with information about the same topic. By adding more URLs, you can expand the breadth of the expertise of your assistant.\n4. Click Add.\n5. Click the Edit icon for the URL that you just added.\n\nZoom\n\n![Shows the Starting URLs field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-3.png)\n\nFigure 22. Edit starting URL\n6. In the Maximum number of links to follow field, change the value to 5.\n\nZoom\n\n![Shows the Starting URLs field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-4.png)\n\nFigure 23. Starting URL settings\n\nBy changing the value to 5, you indicate that you want the service to process the page that you specified plus you want it to follow up to 5 links from the starting page.\n7. Click Save, and then click Finish.\n\n\n\nThe Discovery service crawls the web page that you specified starting with the page that you specified as the starting URL.\n\nWhile the website is being crawled and the data indexed, let's go back to our Watson Assistant service instance. It's time to connect the action that we created to this Discovery project.\n\n\n\n\n\n Step 5: Add a search extension \n\nLet's connect your assistant to your Discovery data.\n\n\n\n1. From the navigation panel in Watson Assistant, click Environments.\n\nZoom\n\n![Shows the Environments menu item in the navigation panel.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-assistant-fred"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-1541-3629","score":0.0163934426,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05168-15740-17188","score":0.0163934426,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_05032-1541-3629","score":0.0161290323,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_06808-1384-2991","score":0.0161290323,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_04939-55110-56793","score":0.0158730159,"text":"\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_04866-7-2136","score":0.0158730159,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05044-55090-56773","score":0.015625,"text":"\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05032-7-2136","score":0.015625,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7925-10174","score":0.0153846154,"text":"\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https:\/\/{endpoint}\/{bucket-name}?protection= path style\nPUT https:\/\/{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":0.0153846154,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06981-12510-14371","score":0.0322664585,"text":"\nAlthough, it might be difficult to know which field to search later for information that you need if the field names don't match the content. The default set are representative field types that are meant to help you get started. Only the text and table fields have special significance. Do not use them to identify anything other than text and tables.\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a question-and-answer pair (often in an FAQ), the answer to the question. \n author Name of author or authors. \n footer Use this tag to denote meta-information about the document (such as the page number or references), that appear at the end of the page. \n header Use this tag to denote meta-information about the document that appears at the start of the page. \n question In a question-and-answer pair (often in an FAQ), the question. \n subtitle The secondary title of the document. \n table_of_contents Use this tag on lists in the document table of contents. \n text By default, every block of text in the document is labeled as text. Apply different labels only to blocks of text with special meaning. \n title The main title of the document. \n table Use this tag to annotate tables in your document. \n image Images are not shown in the document preview. If you enable OCR, text from an image or diagram is displayed in the preview instead. If you want to prevent text from some images from being included in search results, tag the image text as an image. You can exclude the image field from the index later. \n\n\n\n\n\n\n\n Reusing SDU models \n\nAfter you define a model with the SDU tool, you can save it and reuse it in other collections by exporting it from one collection and importing it to another.\n\nTo reuse a model, complete the following steps:\n\n\n\n1. Export the model that you want to reuse. From the SDU toolbar menu, select Export model.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_06981-10904-13027","score":0.0294117647,"text":"\nContinue annotating documents until Watson can correctly and consistently map different types of content to the appropriate fields for you.\n8. After you teach Watson to identify fields, click Apply changes and reprocess.\n\n\n\nCustom fields that you define by using the SDU tool are indexed as root-level fields.\n\n\n\n What to do next \n\nWhen you build a user-trained model, you change where information is stored in your documents. Next, change how the search results are configured. By default, search results are retrieved from passages or the text field. You might have a better field to use as the source of the result body. For more information, see [Changing the result content](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-resultsquery-results-content).\n\nIf your project is being used by a virtual assistant, update the search skill configuration to pull the answer body from a different field. For more information, see [Configure the search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-configure).\n\nYou can apply enrichments, either custom or prebuilt enrichments, to the new root fields that are generated by the SDU model.\n\nIf you want to return shorter text snippet with a search result, you can split your documents based on one of the new fields that you defined, such as chapter or section.\n\n\n\n\n\n Available fields \n\nThe following fields are available for you to apply to documents by using the Smart Document Understanding tool.\n\nThe fields are arbitrary. You can apply the image field to every title in the document if you want. Although, it might be difficult to know which field to search later for information that you need if the field names don't match the content. The default set are representative field types that are meant to help you get started. Only the text and table fields have special significance. Do not use them to identify anything other than text and tables.\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a question-and-answer pair (often in an FAQ), the answer to the question. \n author Name of author or authors.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_02361-22962-24900","score":0.0163934426,"text":"\nIn the UI, you can define custom views, dashboards, parsing templates, screens, and exclusion rules that you can use to view and analyze data.\n\nTo reuse resource definitions that you define in your auditing instance, you can export these resources from an IBM Cloud Activity Tracker instance as a JSON file. Then, you can import the definitions into other auditing instances. For example, you can reuse your resources across different environments for your stage, pre-production, and production instances. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-reuse_resource_definitions).\n\nBackup resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from an auditing instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision an auditing instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for an auditing instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_09755-1450-3171","score":0.0161290323,"text":"\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.\n* Go to [IBM Developer Answers](https:\/\/developer.ibm.com\/answers\/topics\/ibm-cloud\/) to ask general questions about the IBM Cloud Monitoring service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and monitoring.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case) and [manage](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-gettinghelp"},{"document_id":"ibmcld_09275-30068-31881","score":0.0161290323,"text":"\nFor example, you can reuse your logging resources across different environments for your stage, pre-production, and production logging instances. [Learn more](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-reuse_resource_definitions).\n\nBackup logging resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from a logging instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision a logging instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for a logging instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_16692-1490-3300","score":0.0158730159,"text":"\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.\n* Go to [IBM Developer Answers](https:\/\/developer.ibm.com\/answers\/topics\/ibm-cloud\/) to ask general questions about the IBM Cloud Security and Compliance Center Workload Protection service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and workload-protection.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case) and [manage](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-gettinghelp"},{"document_id":"ibmcld_07578-1149786-1151494","score":0.015625,"text":"\nTo get in touch, you can join us on Slack.\n\n\n\n1. [Request an invitation](https:\/\/cloud.ibm.com\/kubernetes\/slack) to the workspace by entering your email.\n2. Check your email for an invitation.\n3. Click Join now to go to the sign-in page.\n4. Create an account by entering your name and a password.\n5. When you're in, search for the channel appid-at-ibm.\n6. Join the channel.\n\n\n\nWelcome! Now that you're up and running, feel free to ask questions, give feedback, and help others.\n\nUsing the Slack channel is not a replacement for opening a support ticket. If you encounter a more serious issue, issues with IBM Cloud that don't relate to App ID, or need to share more information than you are comfortable sharing in a public forum, open a support ticket.\n* Why do I need to allowlist my redirect URI?\n\nA redirect URI is the callback endpoint of your application. When you allowlist your URI, you're giving App ID the OK to send your users to that location. At runtime, App ID validates the URI against your allowlist before it redirects the user. This process can help prevent phishing attacks and lessens the possibility that an attacker is able to gain access to your user's tokens. For more information about redirect URIs, see [Adding redirect URIs](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpadd-redirect-uri).\n\nDo not include any query parameters in your URL. They are ignored in the validation process. Example URL: http:\/\/host:[port]\/path\n* How does encryption work in App ID?\n\nCheck out the following table for answers to commonly asked questions about encryption.\n\n\n\nTable 2. Frequently asked questions about how App ID handles encryption\n\n Question Answer \n\n Why do you use encryption?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07224-7650-9752","score":0.015625,"text":"\nRe-upload the documents in your collection. After uploading is complete, you are redirected to the Overview screen.\n\n\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a Q\/A pair (often in an FAQ), the answer to the question. \n author Name of author (or authors). \n footer Use this tag to denote meta-information about the document (such as the page number or references), that appear at the bottom of the \n header Use this tag to denote meta-information about the document that appears at the top of the page. \n question In a Q\/A pair (often in an FAQ), the question. \n subtitle The secondary title of the document being annotated. \n table_of_contents Use this tag on listings in the document table of contents. \n text Use this tag for standard copy text, including paragraphs, definitions, or any set of words that is not a title, part of a table, answer, author, subtitle, header, or a footer. \n title The main title of the document being annotated. \n table Use this tag to annotate tables in your document. \n image Use this tag to annotate images and diagrams in your document. \n\n\n\n\n\n\n\n Splitting documents \n\nThe Manage fields tab contains the option to Improve query results by splitting your documents. This option allows you to split your documents into segments based on a field name. After the document splits, each segment is a separate document that is enriched, indexed, and returned as a separate query result.\n\nDocuments are split based on a single field name, for example: title, author, question.\n\nConsiderations:\n\n\n\n* The number of segments per document is limited to 250. Any document content remaining after 249 segments are stored within segment 250.\n* Each segment counts towards the document limit of your plan. Discovery indexes segments, until the plan limit is reached. For document limits, see [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans).\n* PDF and Word metadata, as well as any custom metadata, is extracted and included in the index with each segment. Every segment of a document includes identical metadata.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu"},{"document_id":"ibmcld_16727-1152419-1154127","score":0.0153846154,"text":"\nTo get in touch, you can join us on Slack.\n\n\n\n1. [Request an invitation](https:\/\/cloud.ibm.com\/kubernetes\/slack) to the workspace by entering your email.\n2. Check your email for an invitation.\n3. Click Join now to go to the sign-in page.\n4. Create an account by entering your name and a password.\n5. When you're in, search for the channel appid-at-ibm.\n6. Join the channel.\n\n\n\nWelcome! Now that you're up and running, feel free to ask questions, give feedback, and help others.\n\nUsing the Slack channel is not a replacement for opening a support ticket. If you encounter a more serious issue, issues with IBM Cloud that don't relate to App ID, or need to share more information than you are comfortable sharing in a public forum, open a support ticket.\n* Why do I need to allowlist my redirect URI?\n\nA redirect URI is the callback endpoint of your application. When you allowlist your URI, you're giving App ID the OK to send your users to that location. At runtime, App ID validates the URI against your allowlist before it redirects the user. This process can help prevent phishing attacks and lessens the possibility that an attacker is able to gain access to your user's tokens. For more information about redirect URIs, see [Adding redirect URIs](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpadd-redirect-uri).\n\nDo not include any query parameters in your URL. They are ignored in the validation process. Example URL: http:\/\/host:[port]\/path\n* How does encryption work in App ID?\n\nCheck out the following table for answers to commonly asked questions about encryption.\n\n\n\nTable 2. Frequently asked questions about how App ID handles encryption\n\n Question Answer \n\n Why do you use encryption?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05158-5495-7180","score":0.0153846154,"text":"\nFor the parameters to set a region or endpoint, refer to the documentation for [Cloud Object Storage CLI](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli) or [AWS CLI](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-aws-cli).\n\n\n\n\n\n How do I copy or move files to another bucket in a different location? \n\nRefer to [Move data between buckets](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-region-copy) for an example of how to use the rclone command line utility for copying data. If you use other 'sync' or 'clone' tools, be aware that you might need to implement a script to move files to a bucket in a different location because multiple endpoints are not allowed in a command.\n\n\n\n\n\n Other support options \n\n\n\n* If you have technical questions about Object Storage, post your question on [Stack Overflow](https:\/\/stackoverflow.com\/search?q=object-storage+ibm) and tag your question with ibm and object-storage.\n* For questions about the service and getting started instructions, use the [IBM Developer dW Answers forum](https:\/\/developer.ibm.com\/answers\/topics\/objectstorage\/). Include the objectstorage tag.\n\n\n\n\n\n\n\n Next Steps \n\nFor more information about asking questions, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatarasking-a-question).\n\nSee [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\nFor more information about opening an IBM support ticket, see how to [create a request](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-troubleshooting-cos"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08867-20399-21926","score":0.0320184426,"text":"\n+-------------------------------------------+\nSubscription Name: 30 Day Self-Supported Red Hat OpenShift Container Platform, 2-Core Evaluation\nProvides: Red Hat Ansible Engine\nRed Hat Software Collections (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise Infrastructure\nRed Hat JBoss Core Services\nRed Hat Enterprise Linux Fast Data path\nRed Hat OpenShift Container Platform for Power\nJBoss Enterprise Application Platform\n:\nRed Hat OpenShift Container Platform Client Tools for Power\nRed Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise JBoss EAP add-on\nRed Hat OpenShift Container Platform\nRed Hat Gluster Storage Management Console (for RHEL Server)\nRed Hat OpenShift Enterprise JBoss A-MQ add-on\nRed Hat Enterprise Linux for Power, little endian Beta\nRed Hat OpenShift Enterprise Client Tools\n:\nRed Hat OpenShift Enterprise Application Node\n:\nRed Hat OpenShift Service Mesh\n:\nRed Hat OpenShift Enterprise JBoss FUSE add-on\nSKU: SER0419\nContract: 123456789\nPool ID: 1a2345bcd6789098765abcde43219bc3\nProvides Management: Yes\nAvailable: 10\nSuggested: 1\nService Level: Self-Support\nService Type: L1-L3\nSubscription Type: Stackable\nStarts: 12\/03\/2018\nEnds: 01\/02\/2019\nSystem Type: Physical\n7. Exit the secure shell to return to your OpenShift installation directory inside your container.\n\nexit\n\nExample output:\n\nlogout\nConnection to 169.47.XXX.XX closed.\n\/go\/bin\/terraform-ibm-openshift \n\n\n\n2. Finish setting up and registering the nodes with the Red Hat Network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"},{"document_id":"ibmcld_14491-1340-3282","score":0.0315136476,"text":"\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"},{"document_id":"ibmcld_10422-7-1877","score":0.031024531,"text":"\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_14492-10142-11408","score":0.0305503731,"text":"\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [VMware Solutions and Red Hat OpenShift overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro)\n* [Red Hat OpenShift Container Platform 4.7 documentation](https:\/\/docs.openshift.com\/container-platform\/4.7\/welcome\/index.html)\n* [Red Hat OpenShift Container Platform 4.7 release notes](https:\/\/docs.openshift.com\/container-platform\/4.7\/release_notes\/ocp-4-7-release-notes.html)\n* [What's new in Red Hat OpenShift](https:\/\/www.openshift.com\/learn\/whats-new)\n* [Succeeding with Red Hat OpenShift and VMware\u2019s Software-Defined Datacenter (SDDC)](https:\/\/blog.openshift.com\/red-hat-openshift-and-vmware-better-together\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10702-7-1940","score":0.0300904977,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10422-1393-2886","score":0.0296442688,"text":"\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.10\/release_notes\/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https:\/\/github.com\/kubernetes\/kubernetes\/tree\/master\/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_07968-7-1612","score":0.0292110874,"text":"\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial).\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"},{"document_id":"ibmcld_13144-9759-11433","score":0.0163934426,"text":"\nThe Pods, Builds, Services and Routes are visible.\n\nZoom\n\n![App Details](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution55-openshift-microservices\/ocp45-topo-app-details.png)\n\nApp Details\n\n\n\n* Pods: Your Node.js application containers\n* Builds: The auto-generated build that created a Docker image from your Node.js source code, deployed it to the Red Hat OpenShift container registry, and kicked off your deployment config\n* Services: Tells Red Hat OpenShift how to access your Pods by grouping them together as a service and defining the port to listen to\n* Routes: Exposes your services to the outside world using the LoadBalancer provided by the IBM Cloud network\n\n\n\n3. Click on View Logs next to your completed Build. This shows you the process that Red Hat OpenShift took to install the dependencies for your Node.js application and build\/push a Docker image. The last entry should looks like this:\n\nSuccessfully pushed image-registry.openshift-image-registry.svc:5000\/example-health\/patient-health-frontend@sha256:f9385e010144f36353a74d16b6af10a028c12d005ab4fc0b1437137f6bd9e20a\nPush successful\n4. Click back to the Topology and select your app again.\n5. Click on the URL under Routes to visit your application. Enter any string for username and password, for instance test:test because the app is running in demonstration mode.\n\n\n\nThe Node.js app has been deployed to Red Hat OpenShift Container Platform. To recap:\n\n\n\n* The \"Example Health\" Node.js application was deployed directly from GitHub into your cluster.\n* The application was examined in the Red Hat OpenShift on IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_10462-8619-10498","score":0.0161290323,"text":"\nIf you created other priority classes in your cluster, you can check to make sure that they don't set a globalDefault by running oc describe priorityclass <name>. \n description Optional: Tell users why to use this priority class. Enclose the string in quotations (\"\"). \n\n\n\n4. Create the priority class in your cluster.\n\noc apply -f filepath\/priorityclass.yaml\n5. Verify that the priority class is created.\n\noc get priorityclasses\n\n\n\nGreat! You created a priority class. Let your team know about the priority class and which priority class, if any, that they must use for their pod deployments.\n\n\n\n\n\n Assigning priority to your pods \n\nAssign a priority class to your pod spec to set the pod's priority within your Red Hat OpenShift on IBM Cloud cluster.\n\nBefore you begin:\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Ensure that you have the [Writer or Manager IBM Cloud IAM service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) in the namespace that you want to deploy the pods to.\n* [Understand how priority scheduling works](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_prioritypriority_scheduling), as priority can preempt existing pods and affect how your cluster's resources are consumed.\n\n\n\nComplete the following steps to check the importance of other deployed pods so that you can choose the correct priority class for your pods in relation to what already is deployed.\n\n\n\n1. View the priority classes that other pods in the namespace use.\n\noc get pods -n <namespace> -o custom-columns=NAME:.metadata.name,PRIORITY:.spec.priorityClassName\n2. Get the details of the priority class and note the value number. Pods with higher numbers are prioritized before pods with lower numbers. Repeat this step for each priority class that you want to review.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_priority"},{"document_id":"ibmcld_11768-7-2036","score":0.0158730159,"text":"\nUpdating Satellite location control plane hosts \n\nIBM provides version updates for your hosts that are assigned to the Satellite location control plane. The version updates include OpenShift Container Platform, the operating system, and security patches. You choose when to apply the host version updates by detaching the hosts from your location, reloading the host machine in the infrastructure provider, and reattaching and reassigning the host to the Satellite location control plane.\n\n\n\n Considerations before you update control plane hosts \n\nReview the following considerations before you update your Satellite location control plane hosts.\n\nHow can I tell if a version update is available?\n: Version updates for hosts become available as the Red Hat OpenShift on IBM Cloud team packages new versions for worker nodes. Typically, worker node version updates are released every two weeks.\n: You might check for a version update to meet your required security cadence, such as updates on a monthly or bi-monthly basis. To review available version updates, see the [Version change log for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nDoes updating the hosts impact the cluster masters that run in the Satellite location control plane?\n: Yes. Because the cluster masters run in your Satellite location control plane, make sure that you have enough extra hosts in your control plane before you update any hosts. To attach extra hosts, see [Attaching capacity to your Satellite location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts).\n\nDo the hosts in my Satellite-enabled IBM Cloud services have to run the same version as my Satellite location control plane?\n: No, the hosts that are assigned to the Satellite location control plane do not have to run the same version as the hosts that are assigned to Satellite-enabled IBM Cloud services that run in the location. However, all hosts in the location must run a supported version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-location"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-1033-2260","score":0.031778058,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-394005-396150","score":0.0315449578,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":0.0310544054,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05713-1178-2700","score":0.0161290323,"text":"\nAbout \n\n[Understanding IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewoverview)\n\n\n\n* [What is IBM Cloud Kubernetes Service and how does it work?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-are-containers-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits)\n* [Comparison of offerings and their combinations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovdifferentiation)\n* [Comparison of free and standard clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_07578-565403-567284","score":0.0158730159,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_10154-7-1896","score":0.0158730159,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_16727-565357-567238","score":0.015625,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10170-12206-14575","score":0.015625,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_05777-1455-3483","score":0.0153846154,"text":"\nYour worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n\n\n\n\n\n Why should I use IBM Cloud Kubernetes Service? \n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n\n\n\n\n\n Can I get a free cluster? \n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_10214-7-1980","score":0.0151515152,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14112-7-1387","score":0.0163934426,"text":"\nGetting started with virtualization \n\nYou can use the virtualization solution to run multiple virtual machines in a single dedicated environment within IBM Cloud\u00ae Classic Infrastructure. Virtual machines that run on the IBM Cloud network can integrate with other physical and virtual devices on the network and can be managed through both the console and API. Running virtual machines on the IBM Cloud proprietary architecture and automated platform offers high levels of stability suitable for enterprise-level virtualization, and virtualization on a smaller scale.\n\n\n\nTable 1. Getting started with Virtualization\n\n Get started \n\n __ 1. For more information about virtualization options, see [Citrix XenServer](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-what-is-citrix-xenserver-), [Hyper-V](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-what-is-hyper-v-), [Virtuozzo](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-what-is-virtuozzo-), and [VMware](https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-vmware-getting-started). \n __ 2. [Set up a hypervisor](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-setting-up-a-hypervisor). [Setting up a virtual machine Network](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-setting-up-a-virtual-machine-network) is an important part of this process. \n __ 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-getting-started"},{"document_id":"ibmcld_02826-1915-3049","score":0.0163934426,"text":"\nExample taxomony \n\nThe following are examples of cloud deployments and cloud service providers.\n\nCloud deployment model\n: Public, Private, Hybrid, Multi-Cloud, Distributed Cloud\n\nCloud platform\n: IBM Cloud, AWS, Azure, GCP, other cloud\n\nThe following table illustrates component options for the Containers domain across various Public Cloud Service Providers. Note that this is just a sample and not a comprehensive list of available services on each cloud provider. How to make component architecture decisions for your solution is covered in [Designing a cloud solution by using the architecture framework](https:\/\/cloud.ibm.com\/docs\/architecture-framework?topic=architecture-framework-create-solution).\n\n\n\nTable 1. Component options for Containers domain across various Public Cloud Service Providers\n\n Aspect Domain IBM Cloud AWS Azure Google Cloud Platform \n\n Compute Containers IBM Kubernetes Service <br>Red Hat OpenShift on IBM Cloud Elastic Kubernetes Service <br>Elastic Container Service <br>Red Hat OpenShift on AWS Azure Kubernetes Service <br>Azure Red Hat OpenShift Google Kubernetes Engine <br>Red Hat OpenShift on GCP","title":"","source":"https:\/\/cloud.ibm.com\/docs\/architecture-framework?topic=architecture-framework-taxonomy"},{"document_id":"ibmcld_14008-7-1553","score":0.0161290323,"text":"\nFAQ: Servers (general) \n\n\n\n My virtual server is down. What do I do? \n\nIf your virtual server is down, use the following steps to bring it back up:\n\n\n\n1. Try to access the server by using the [KVM console](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-access-kvm-console). Depending on the output, you might need to create a [support case](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-gettinghelp).\n2. Try to power your server off and on. For more information, see [Powering server on or off](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-managing-virtual-serverspower-on-off) or [Rebooting a device](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-managing-virtual-serversreboot).\n\n\n\n* [Why can't I log in to a virtual server through SSH?](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servertroubleshoot-vs-cannot-ssh-into-server)\n* [Why is my server not responding?](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servertroubleshoot-vs-device-not-responding)\n* [Why does the portal show that my server is disconnected even though it's running?](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servertroubleshoot-vs-portal-shows-server-disconnected-but-running)\n\n\n\n\n\nFor more help, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-gettinghelp).\n\n\n\n\n\n What do I do if my bare metal server is down?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-servers-general-"},{"document_id":"ibmcld_13144-9759-11433","score":0.0161290323,"text":"\nThe Pods, Builds, Services and Routes are visible.\n\nZoom\n\n![App Details](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution55-openshift-microservices\/ocp45-topo-app-details.png)\n\nApp Details\n\n\n\n* Pods: Your Node.js application containers\n* Builds: The auto-generated build that created a Docker image from your Node.js source code, deployed it to the Red Hat OpenShift container registry, and kicked off your deployment config\n* Services: Tells Red Hat OpenShift how to access your Pods by grouping them together as a service and defining the port to listen to\n* Routes: Exposes your services to the outside world using the LoadBalancer provided by the IBM Cloud network\n\n\n\n3. Click on View Logs next to your completed Build. This shows you the process that Red Hat OpenShift took to install the dependencies for your Node.js application and build\/push a Docker image. The last entry should looks like this:\n\nSuccessfully pushed image-registry.openshift-image-registry.svc:5000\/example-health\/patient-health-frontend@sha256:f9385e010144f36353a74d16b6af10a028c12d005ab4fc0b1437137f6bd9e20a\nPush successful\n4. Click back to the Topology and select your app again.\n5. Click on the URL under Routes to visit your application. Enter any string for username and password, for instance test:test because the app is running in demonstration mode.\n\n\n\nThe Node.js app has been deployed to Red Hat OpenShift Container Platform. To recap:\n\n\n\n* The \"Example Health\" Node.js application was deployed directly from GitHub into your cluster.\n* The application was examined in the Red Hat OpenShift on IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_14109-7-2316","score":0.0158730159,"text":"\nFAQs: Hyper-V \n\n\n\n What are the requirements to run Hyper-V? \n\nSee [Hyper-V: Hardware requirements](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-hyper-v-hardware-requirements)\n\n\n\n\n\n What operating systems can be installed on a virtual machine? \n\nSee [Obtaining installation media](https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-setting-up-hyper-v&locale=enobtaining-installation-media)\n\n\n\n\n\n How many virtual machines can a server run? \n\nThe number of virtual machines a server can run varies depending upon server processors, RAM, and hard disk space.\n\n\n\n\n\n Is the RAM customizable on each virtual machine? \n\nYes. You can use Hyper-V to customize the system resources for each virtual machine, including memory.\n\n\n\n\n\n How much RAM does a virtual machine need? \n\nRAM needs vary based on requirements for the virtual machine. Check the system requirements for your guest operating system. The amount of memory that is provided to a virtual machine can be changed at any time.\n\n\n\n\n\n Can a virtual machine access to more than one processor? \n\nYou can grant a virtual machine access to multiple processors with any Windows virtual machine. However, Linux virtual machines are limited to a single processor.\n\n\n\n\n\n Can hard disk sizes change after a virtual machine is created? \n\nYes.\n\n\n\n\n\n Does each virtual operating system need to have a license? \n\nWindows virtual machines are licensed through IBM Cloud. Linux virtual machines are freely licensed and require no action.\n\n\n\n\n\n Will the virtual machines have access to the private network? \n\nYes. Virtual machines can connect to both a public and private network.\n\n\n\n\n\n What advantages are there to providing private network access to virtual machines? \n\nProviding private network access to virtual machines allows virtual machines to communicate with each other. Private network access also allows virtual machines to communicate with other internal systems such as NAS and iSCSI and any other servers that you have with IBM Cloud.\n\n\n\n\n\n Can virtual machines use the secondary IP block that came with the server? \n\nNo. The secondary IP that was provided with your server is routed specifically to work on the physical server and not a virtual machine. You need portable IP blocks to connect your virtual machine to the network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-faqs-hyper-v"},{"document_id":"ibmcld_16729-104404-106143","score":0.0158730159,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14049-1604-3633","score":0.015625,"text":"\n[Reserved virtual server](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-reserved-virtual-serversabout-reserved-virtual-servers) IBM-managed, multi-tenancy virtual server deployments with guaranteed capacity for a contract term \n [Dedicated virtual server](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-dedicated-virtual-servers) IBM-managed, single-tenancy virtual server deployments \n\n\n\n\n\n\n\n Provisioning a virtual server \n\nAfter you decide upon a deployment option, begin the provisioning process. For more information, refer to the following topics.\n\nBecause you started the provisioning process with a third-party image, you cannot change the image type during the provisioning process.\n\n\n\nTable 2. Provisioning information\n\n Provisioning instructions Description \n\n [Provisioning public instances](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-ordering-vs-publicordering-vs-public) Provision public instances with various options \n [Provisioning transient instances](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-ordering-vs-transientordering-vs-transient) Provision transient instances with various options \n [Provisioning reserved capacity and instances](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-provisioning-reserved-capacity-and-instancesprovisioning-reserved-capacity-and-instances) Provision reserved capacity and instances with various options \n [Provisioning dedicated hosts and instances](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-provisioning-dedicated-instances) Provision private instances or dedicated instances on dedicated hosts. \n\n\n\n\n\n\n\n Next steps \n\nAfter your virtual server is provisioned and available to use, you can configure your virtual servers by using the IBM Cloud console or SoftLayer API. For more information, see [Configuring virtual servers](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-configuring-virtual-serversconfiguring-virtual-servers).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-ordering-3P"},{"document_id":"ibmcld_10702-7-1940","score":0.015625,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_13963-1725-3470","score":0.0153846154,"text":"\nFor more information, see the single-tenant environment, [Dedicated virtual server](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-dedicated-virtual-servers) offering.\n\nThe following families of public instances are available for this offering.\n\n\n\nTable 1. Public virtual server family selections\n\n Families Description \n\n [Balanced](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilesbalanced) Best for common cloud workloads that require a balance of performance and scalability. Uses network-attached storage. \n [Balanced local storage](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilesbalanced-local-storage) Best for large database workloads that require high I\/O performance with low latency. \n [Variable compute](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilesvariable-compute) Best for workloads that don\u2019t require steady, high-CPU performance. \n [Compute](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilescompute) Best for moderate to high web traffic workloads. \n [Memory](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilesmemory) Best for memory caching and real-time analytics workloads. \n [GPU](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilesgpu) Best for high-performance workloads. \n\n\n\nSome of these families are also available for IBM Cloud\u00ae Virtual Servers for Virtual Private Cloud. For more information, see [Virtual Servers for VPC](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic-vsi?topic=vpc-on-classic-vsi-getting-started).\n\n\n\n Next steps","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-public-virtual-servers"},{"document_id":"ibmcld_14497-7-1724","score":0.0153846154,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14324-1656-3457","score":0.0163934426,"text":"\nWhen you manage user accounts, instances, clusters, and services in IBM Cloud for VMware Solutions, an event is generated.\n\nThe following table provides the actions that generate and send management events to Activity Tracker.\n\n\n\nTable 2. Description of actions that generate management events\n\n Action Description \n\n vmware-solutions.account-apikey.update The infrastructure API key for an account is updated. \n vmware-solutions.account-notification.update The notification setting for an account is updated. \n vmware-solutions.instance-secure-data.wipe The instance-secure data is wiped. \n vmware-solutions.instance-bss-account.migrate An instance is migrated to a BSS account. \n vmware-solutions.vcs.create A VMware vCenter Server\u00ae instance is created. \n vmware-solutions.vcs.delete A vCenter Server instance is deleted. \n vmware-solutions.vcs-host.add A host is added to a vCenter Server instance. \n vmware-solutions.vcs-host.remove A host is removed from a vCenter Server instance. \n vmware-solutions.vcs.update A vCenter Server instance is updated. \n vmware-solutions.vcs-cluster.create A cluster is created for a vCenter Server instance. \n vmware-solutions.vcs-cluster.delete A cluster is deleted for a vCenter Server instance. \n vmware-solutions.vcs-nsx-license.update The VMware NSX\u00ae license is updated for a vCenter Server instance. \n vmware-solutions.vcs-nfs-storage.add NFS storage is added to a vCenter Server instance. \n vmware-solutions.vcs-nfs-storage.remove NFS storage is removed from a vCenter Server instance. \n vmware-solutions.vcs-plan.update A vCenter Server instance's plan is updated. \n vmware-solutions.vss.create A vSphere instance is created. \n vmware-solutions.vss.update A vSphere instance is updated. \n vmware-solutions.vss-template.remove A vSphere template is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-at-events"},{"document_id":"ibmcld_07578-221033-223165","score":0.0163934426,"text":"\nIn some regions, dedicated hosts have a limitation on the number of virtual server instances that can be placed on them at one time. You can try to provision the cluster with a smaller number of virtual server instances to overcome this.\n* Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation?\n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffice from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a range of multiple IP addresses.\n* Does the Spectrum Symphony offering support multiple key pairs to establish SSH to all of the nodes?\n\nYes, the Spectrum Symphony offering supports multiple single key pairs that can be provided for access to all of the nodes that are part of the cluster. In addition, Spectrum Symphony has a feature where each node of the cluster can be accessed through passwordless SSH.\n* What storage types are available through this offering?\n\nIn the Spectrum Symphony offering, you can use Spectrum Scale scratch storage or persistent storage. A scratch storage configuration uses virtual server instances with instance storage. A persistent storage configuration uses bare metal servers with locally attached NVMe storage.\n* Which Linux operating system is supported for worker nodes?\n\nThe solution supports custom images based on RHEL 8.6 for virtual server instance worker nodes, and it supports the use of the stock RHEL 8.6 VPC images for bare metal worker nodes. At this time, custom images are not supported for use with VPC bare metal servers.\n* Can I use a custom resolver that is already associated with a VPC?\n\nYes, the solution supports the use of a custom resolver that is already associated to a VPC. If a VPC already has a custom resolver, the automation makes uses of it and the DNS service and associates the new DNS domain that is created from the solution for hostname resolution.\n* Can I associate a single VPC with multiple DNS zones that have the same name?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16728-33801-35239","score":0.0161290323,"text":"\n[solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Provision vCenter Appliance](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vcenter)Provision vCenter Appliance Solution tutorial\n\nIn this tutorial, you will deploy a vCenter for a VMware Deployment in IBM Cloud VPC and a floating VLAN interface for it.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Provision vSAN storage cluster](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vsan)Provision vSAN storage cluster Solution tutorial\n\nIn this tutorial, a vSAN cluster is created using the local disks attached the Bare Metal Servers for VPC. This phase is optional, if you use NFS.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Public frontend and private backend in a Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-public-app-private-backend)Public frontend and private backend in a Virtual Private Cloud Solution tutorial\n\nThis tutorial walks you through creating your own IBM Cloud\u00ae Virtual Private Cloud (VPC) with multiple subnets and a virtual server instance (VSI) in each subnet. A VPC is your own, private cloud on shared cloud infrastructure with logical isolation from other virtual networks.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_16727-221007-223139","score":0.0161290323,"text":"\nIn some regions, dedicated hosts have a limitation on the number of virtual server instances that can be placed on them at one time. You can try to provision the cluster with a smaller number of virtual server instances to overcome this.\n* Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation?\n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffice from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a range of multiple IP addresses.\n* Does the Spectrum Symphony offering support multiple key pairs to establish SSH to all of the nodes?\n\nYes, the Spectrum Symphony offering supports multiple single key pairs that can be provided for access to all of the nodes that are part of the cluster. In addition, Spectrum Symphony has a feature where each node of the cluster can be accessed through passwordless SSH.\n* What storage types are available through this offering?\n\nIn the Spectrum Symphony offering, you can use Spectrum Scale scratch storage or persistent storage. A scratch storage configuration uses virtual server instances with instance storage. A persistent storage configuration uses bare metal servers with locally attached NVMe storage.\n* Which Linux operating system is supported for worker nodes?\n\nThe solution supports custom images based on RHEL 8.6 for virtual server instance worker nodes, and it supports the use of the stock RHEL 8.6 VPC images for bare metal worker nodes. At this time, custom images are not supported for use with VPC bare metal servers.\n* Can I use a custom resolver that is already associated with a VPC?\n\nYes, the solution supports the use of a custom resolver that is already associated to a VPC. If a VPC already has a custom resolver, the automation makes uses of it and the DNS service and associates the new DNS domain that is created from the solution for hostname resolution.\n* Can I associate a single VPC with multiple DNS zones that have the same name?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16728-32699-34193","score":0.0158730159,"text":"\n[solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Provision IBM Cloud VPC Subnets and configure Distributed Virtual Switch Portgroups for VMs](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-newvm)Provision IBM Cloud VPC Subnets and configure Distributed Virtual Switch Portgroups for VMs Solution tutorial\n\nThis tutorial presents a simple example to deploy a VMware virtual machine running on VMware cluster and attached to IBM Cloud VPC subnet using a VLAN interface and allow the virtual machine to vMotion between hosts.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Provision NFS storage and attach to cluster](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nfs)Provision NFS storage and attach to cluster Solution tutorial\n\nIn this tutorial, an NFS file share is created in IBM Cloud VPC and it is attached to a VMware cluster as a Datastore. This phase is optional, if you use vSAN as your preferred storage option.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Provision vCenter Appliance](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vcenter)Provision vCenter Appliance Solution tutorial\n\nIn this tutorial, you will deploy a vCenter for a VMware Deployment in IBM Cloud VPC and a floating VLAN interface for it.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_14747-54967-56898","score":0.0158730159,"text":"\n: Review the following information about Caveonix RiskForesight for the 4.1 release.\n\n\n\n* Caveonix RiskForesight is offered as a per-host license for new deployments of Caveonix on VMware Regulated Workloads and Security and Compliance Readiness Bundle instances. For vCenter Server deployments, Caveonix is still offered as license packs that are priced per virtual machine (VM).\n* A Caveonix RiskForesight license is valid for five years.\n* Deleting Caveonix RiskForesight deletes the initial Caveonix RiskForesight license that was associated with the service.\n\n\n\nVeeam on bare metal server\n: You can install Veeam v11 on a bare metal server. This new feature is supported only for vSphere 7.0 with NSX-T.\n\nREST APIs\n: The following API updates are available:\n\n\n\n* The VMware Solutions API provides support for the additional edge services cluster and workload cluster on multizone instances.\n* The VMware Solutions API provides support for the following services on multizone instances: Caveonix RiskForesight, HyTrust CloudControl, Veeam, and vRealize Operations and Log Insight.\n* The network option for selecting a private only network or a public and private network is available through the VMware Solutions Shared API.\n\n\n\n\n\n\n\n 29 January 2021 \n\nVMware Regulated Workloads\n: Starting with the 4.0 release, you can now order VMware Regulated Workloads directly from the VMware Solutions main page. The VMware Regulated Workloads offering includes a secure-by-default architecture that follows IBM's unique policy controls framework, provides continuous compliance monitoring, and offers the highest level of data encryption (FIPS 140-2 Level 4). For VMware Regulated Workloads, only VMware vSphere 7.0 Update 1a is supported.\n\nVMware Solutions Dedicated - VMware vSphere 7.0 Update 1a support\n: You can order vSphere 7.0 Update 1a with your VMware vCenter Server with NSX-T instances and VMware vSphere with NSX-T clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmwaresolutions-relnotes"},{"document_id":"ibmcld_13214-1316-2623","score":0.015625,"text":"\nThis tutorial requires:\n\n\n\n* Common [prereqs](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmwarevpc-bm-vmware-prereqs) for VMware Deployment tutorials in IBM Cloud VPC\n\n\n\nThis tutorial is part of series, and requires that you have completed the related tutorials. Make sure you have successfully completed the required previous steps:\n\n\n\n* [Provision a IBM Cloud VPC for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vpcvpc-bm-vmware-vpc)\n* [Provision IBM Cloud DNS Services for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-dnsvpc-bm-vmware-dns)\n* [Provision bare metal servers for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-bmsvpc-bm-vmware-bms)\n* [Provision vCenter Appliance](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vcentervpc-bm-vmware-vcenter)\n* [Provision vSAN storage cluster](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vsanvpc-bm-vmware-vsan) or\n* [Provision NFS storage and attach to cluster](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nfsvpc-bm-vmware-nfs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-newvm"},{"document_id":"ibmcld_02114-30398-32544","score":0.015625,"text":"\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--category CATEGORY\n: Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all options. Default is Developer tools.\n\n\n\n\n\n Example \n\nibmcloud catalog offering add-category --catalog dev-catalog --offering dev-offering --category dev_ops\n\n\n\n\n\n\n\n ibmcloud catalog offering categories \n\nRun the following command to retrieve the category of a product version.\n\nibmcloud catalog offering version categories [--catalog CATALOG] [--offering OFFERING] [--output OUTPUT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Example \n\nRetrieve the category of a product that is called dev-offering and located in the dev-catalog.\n\nibmcloud catalog offering version categories --catalog dev-catalog --offering dev-offering\n\n\n\n\n\n\n\n ibmcloud catalog offering version get-controls \n\nRun the following command to get the security and compliance controls from a version. Controls are safeguards that are used to meet security and compliance requirements.\n\nibmcloud catalog offering version get-controls [--version-locator VERSION_NUMBER] [--output OUTPUT]\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified version that you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering version add-controls \n\nRun the following command to add security and compliance controls to a version. Controls are safeguards that are used to meet security and compliance requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_13218-2297-3549","score":0.0153846154,"text":"\n* [Provision a IBM Cloud VPC for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vpcvpc-bm-vmware-vpc)\n* [Provision IBM Cloud DNS Services for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-dnsvpc-bm-vmware-dns)\n* [Provision bare metal servers for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-bmsvpc-bm-vmware-bms)\n* [Provision vCenter Appliance](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vcentervpc-bm-vmware-vcenter)\n* [Provision vSAN storage cluster](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-vsanvpc-bm-vmware-vsan) or [Provision NFS storage and attach to cluster](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nfsvpc-bm-vmware-nfs)\n* [Provision IBM Cloud VPC network interfaces for NSX-T](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-hostsvpc-bm-vmware-nsx-t-vlannics)\n\n\n\n[Login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) with IBM Cloud CLI with username and password, or use the API key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-deploy"},{"document_id":"ibmcld_04491-30390-32536","score":0.0153846154,"text":"\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--category CATEGORY\n: Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all options. Default is Developer tools.\n\n\n\n\n\n Example \n\nibmcloud catalog offering add-category --catalog dev-catalog --offering dev-offering --category dev_ops\n\n\n\n\n\n\n\n ibmcloud catalog offering categories \n\nRun the following command to retrieve the category of a product version.\n\nibmcloud catalog offering version categories [--catalog CATALOG] [--offering OFFERING] [--output OUTPUT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Example \n\nRetrieve the category of a product that is called dev-offering and located in the dev-catalog.\n\nibmcloud catalog offering version categories --catalog dev-catalog --offering dev-offering\n\n\n\n\n\n\n\n ibmcloud catalog offering version get-controls \n\nRun the following command to get the security and compliance controls from a version. Controls are safeguards that are used to meet security and compliance requirements.\n\nibmcloud catalog offering version get-controls [--version-locator VERSION_NUMBER] [--output OUTPUT]\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified version that you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering version add-controls \n\nRun the following command to add security and compliance controls to a version. Controls are safeguards that are used to meet security and compliance requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10358-2392-3900","score":0.0163934426,"text":"\nBuild app containers from [images in the internal, public, or private registries](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-images).\n3. Specify your [app requirements in a YAML file](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_appsapp_yaml), which declares the configuration of the Kubernetes object.\n\n\n\n2. Version your app:\n\n\n\n1. Version 4: To plan customized configurations for more than one environment, such as development, testing, and production environments, [use the Kustomize tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_appskustomize) to manage your configuration YAML file.\n2. If you want to run your app in multiple clusters, public and private environments, or even multiple cloud providers, [package your application to help automate deployments](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploypackaging).\n\n\n\n\n\nNeed help? Check out [Troubleshooting apps and integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_apps).\n\n\n\n\n\n Deploy your app \n\nDeploy your app to the cluster by running your app configuration file.\n\n\n\n* [Deploying apps through the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_appdeploy_apps_ui).\n* [Deploying apps through the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_appdeploy_apps_cli).\n* [Deploying apps to specific worker nodes by using labels](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_appnode_affinity).\n\n\n\nNeed help?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-learning-path-dev"},{"document_id":"ibmcld_08259-0-511","score":0.0163934426,"text":"\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-release-notes"},{"document_id":"ibmcld_10281-5616-6727","score":0.0161290323,"text":"\nNAME READY UP-TO-DATE AVAILABLE AGE\nrouter-default 2\/2 2 2 26m\n2. Check whether the Ingress controller's load balancer service exists and is assigned a public external IP address (classic clusters) or a hostname (VPC clusters).\n\n\n\n* If a service that is named router-default is listed and is assigned an IP address (classic clusters) or a hostname (VPC clusters), continue to the next step.\n* If no router-default service is created after several minutes, [review ways to get help](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\noc get svc -n openshift-ingress\n\nExample output\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nrouter-default LoadBalancer 172.21.47.119 169.XX.XX.XX 80:31182\/TCP,443:31154\/TCP 27m\nrouter-internal-default ClusterIP 172.21.51.30 <none> 80\/TCP,443\/TCP,1936\/TCP 26m\n\n\n\n5. Check again whether the Ingress subdomain and secret are created. If they are not available, but you verified that all the components in steps 1 - 3 exist, [review ways to get help](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\nibmcloud oc cluster get -c <cluster_name_or_ID>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ingress_subdomain"},{"document_id":"ibmcld_10392-250715-251723","score":0.0161290323,"text":"\n: Updated the [CLI reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli) to reflect multiple changes for the release of version [0.3.34](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog) of the IBM Cloud Kubernetes Service CLI plug-in.\n\nNew! Red Hat OpenShift on IBM Cloud clusters\n: With the Red Hat OpenShift on IBM Cloud beta, you can create IBM Cloud Kubernetes Service clusters with worker nodes that come installed with the Red Hat OpenShift container orchestration platform software. You get all the advantages of managed IBM Cloud Kubernetes Service for your cluster infrastructure environment, along with the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/3.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments. To get started, see [Tutorial: Creating a Red Hat OpenShift on IBM Cloud cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_10140-34792-36631","score":0.0158730159,"text":"\n* Removes the deprecated region get, region set, and region ls commands from help output.\n* Updates command structure to the new spaced format in help output.\n* Adds a warning to the output of legacy cluster config behavior. For more information, see the [version 1.0 plug-in documentation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n* Fixes a bug so that worker reload and messages commands now fail if the command errors.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.23 \n\nVersion 0.4.23 of the CLI was released on 16 September 2019.\n\n\n\n* Decreases startup time for the plug-in.\n* Fixes a Go version issue for macOS users.\n* Improves debug tracing.\n* In ibmcloud oc logging filter commands, the syntax of the --logging-config option changes from accepting multiple values in a comma-separated list to requiring repeated options.\n* Minor bug and security fixes.\n* Updates message, warning, and help text.\n\n\n\n\n\n\n\n Version 0.4.3 \n\nVersion 0.4.3 of the CLI was released on 4 September 2019.\n\n\n\n* Adds deprecation warnings for legacy commands to error messages that are sent to stderr.\n\n\n\n\n\n\n\n Version 0.4.1 \n\nVersion 0.4.1 of the CLI was released on 3 April 2019.\n\n\n\n* Sets the Red Hat OpenShift on IBM Cloud plug-in to the redesigned format by default. This redesigned version includes changes such as categorical lists instead of an alphabetical list of commands in the output of ibmcloud oc help, spaced-structured commands instead of hyphenated-structure commands, repeated options instead of multiple values in comma-separated lists, and more. For a full list of the changes between version 0.3 and 0.4, see the comparison table in [Using the beta Red Hat OpenShift on IBM Cloud plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_10702-7-1940","score":0.0158730159,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10534-530364-531637","score":0.015625,"text":"\n* [Is the service highly available?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsha_sla)\n* [What compliance standards does the service meet?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsstandards)\n* [Can I use IBM Cloud and other services with my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_integrations)\n* [Does IBM support third-party and open source tools that I use with my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_thirdparty_oss)\n* [What am I charged for? Can I estimate and control costs in my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges)\n* [Can I downgrade my cluster to a previous version?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsdowngrade)\n\n\n\n\n\n\n\n Troubleshooting \n\n[Getting help and support for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helpget-help)\n\n\n\n* [General ways to resolve cluster issues](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helphelp-general)\n* [Reviewing issues and status](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helphelp-cloud-status)\n* [Feedback and questions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helpfeedback-qs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_01476-7-2157","score":0.015625,"text":"\nSetting up Container Registry as a private registry on Red Hat OpenShift \n\nYou can add value to your Red Hat\u00ae OpenShift\u00ae Container Platform clusters by using IBM Cloud\u00ae Container Registry even where an internal registry is already provided.\n\nFor example, if you have multiple clusters, Container Registry integrates conveniently with Red Hat OpenShift Container Platform clusters so that you can build, share, synchronize, and scan image assets across clusters. For more information, see [Choosing an image registry solution](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_registry_options).\n\nYou can set up Container Registry to work with the internal registry of [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_rhosregistry_rhos_rhoks) or [other Red Hat OpenShift Container Platform providers](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_rhosregistry_rhos_os).\n\n\n\n Set up Red Hat OpenShift on IBM Cloud to use Container Registry \n\nBy default, your Red Hat OpenShift on IBM Cloud clusters are set up with an internal registry that stores images locally in your cluster. The clusters are also set up with image pull secrets in the default project to pull images that you store in your private Container Registry repositories.\n\nYou can use either registry separately or in combination. When you set up the Red Hat OpenShift on IBM Cloud internal registry to import images from Container Registry, you get the advantage of a private registry that is common to multiple clusters. Another benefit is that copies of the pulled images from Container Registry are stored locally on the cluster, therefore reducing latency and external traffic, but you are subject to storage limitations.\n\nTo set up your Red Hat OpenShift on IBM Cloud clusters to use the internal registry in combination with Container Registry, see the following topics in the Red Hat OpenShift on IBM Cloud documentation:\n\n\n\n* [Importing images from IBM Cloud Container Registry into the internal registry image stream](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryimagestream_registry).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_rhos"},{"document_id":"ibmcld_10140-30424-32058","score":0.0153846154,"text":"\n* Deprecates the --disable-deployment option of the ibmcloud oc alb configure vpc-classic command.\n\n\n\n* VPC-specific command updates:\n\n\n\n* Fixes the [ibmcloud oc zone rm](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_zone_rm) command for VPC multizone clusters.\n* For the [ibmcloud oc vpcs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_vpcs) command, defaults to list only generation 1 (vpc-classic) VPCs.\n* Revises the ibmcloud oc worker-pool create vpc-classic command to remove the --disable-disk-encrypt option and to hide the --hardware option because it only accepts one value.\n\n\n\n* Help documentation updates:\n\n\n\n* Add deprecation warnings to encourage you to use the newer classic subcommands. For example, use ibmcloud oc cluster create classic instead of ibmcloud oc cluster create.\n* Adds links to the Red Hat OpenShift on IBM Cloud documentation in various help topics.\n* Standardizes formatting in help text, such as adding single quotes around variable names or styling for URLs.\n* Updates the help text in various languages.|\n\n\n\n\n\n\n\n\n\n Version 0.4.66 \n\nVersion 0.4.66 of the CLI was released on 19 December 2019.\n\n\n\n* Adds a Status field to the ibmcloud oc alb cert get command. The previous Status field is now called State.\n* Fixes a bug so that help text is now properly displayed for some commands, such as ibmcloud oc flavors and ibmcloud oc subnets.\n\n\n\n\n\n\n\n Version 0.4.64 \n\nVersion 0.4.64 of the CLI was released on 11 December 2019.\n\n\n\n* Adds the --entitlement option to the ibmcloud oc cluster create and ibmcloud oc worker-pool create commands.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_12730-0-1429","score":0.0153846154,"text":"\n\n\n\n\n\n\n  Change log: Red Hat OpenShift Kubernetes OCP4 profile \n\nIn this change log, you can learn about the latest changes, improvements, and updates for the Red Hat OpenShift Kubernetes OCP4 profile. The change log lists changes that were made, ordered by the version number.\n\n\n\n  Profile versioning \n\nWhen specifications or controls are edited, removed from, or added to a profile in a way that is not compatible with the current version, a new version is released. To take advantage of the changes in a new version, update your attachments to use the newest profile version.\n\nThis profile is consistently updated and is not an exhaustive list of all the controls that might be required for every organization. Be sure to validate the available controls to determine where you might need to supplement your workloads with other security measures.\n\n\n\n  Active versions \n\nThe following table shows the service behavior changes for each version date. Switching to a later version date activates all changes that are introduced in earlier versions.\n\n\n\nTable. Active versions of the Red Hat OpenShift Kubernetes OCP4 profile\n\n Version number   Release date \n\n Version 1.0.0    2023-06-07   \n\n\n\n\n\n\n\n\n\n  Version 1.0.0 \n\nNow available\n:   Released today, 6 June 2023, the Red Hat OpenShift Kubernetes OCP4 profile is a collection of controls designed to validate the configuration of your IBM Cloud Red Hat OpenShift clusters.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-openshift-profile"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02340-10222-10984","score":0.0163934426,"text":"\nFirst, you need to create a Scripted REST API on the ServiceNow website. After the Scripted REST API is configured, you also need to create a Scripted REST API Resource. The request method needs to be set to HTTP POST. Then, you need to provide a code for the resource to run.\n\nWhen you are ready with the process and have the URL for your Scripted REST API, you can start to use it on the IBM Cloud Notification distribution list page and create webhooks.\n\nTo get to know the complete ServiceNow webhook integration process, follow the instructions on the [How to Integrate Webhooks Into ServiceNow](https:\/\/community.servicenow.com\/community?id=community_blog&sys_id=886d2a29dbd0dbc01dcaf3231f9619b0) blog post. This blog walks you through the steps in detail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-webhook-distribution-list"},{"document_id":"ibmcld_14490-7-2135","score":0.0163934426,"text":"\nManaging Red Hat OpenShift for VMware \n\nReview the following information to manage your Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service after deployment.\n\n\n\n Rotating the Red Hat OpenShift certificates (required) \n\nRed Hat OpenShift for VMware uses kubelet client certificates that must be rotated periodically for security purposes. Red Hat OpenShift mainly automates the rotation process, but requires manual approval of certificate signing requests (CSRs). Therefore, it is important that you understand the Red Hat OpenShift certificate rotation schedule to avoid expired certificates.\n\nThe initial certificates that are created during installation expire 24 hours after they are created. IBM's automation process, which installs Red Hat OpenShift, handles the approval of the CSRs for this initial rotation, which is done by running a script on the bastion for the first 30 hours. The script is named \/root\/approve-csr.sh and its log file is named \/root\/approve-csr.log.\n\nFor the script to run successfully, the initial kubeadmin credentials must be the same until the initial certificate rotation is complete. Do not change the kubeadmin credentials for the first 24 hours. If the credentials are changed, you must monitor and approve the CSRs for the initial certificate rotation. For more information, see [Approving the CSRs for your machines](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.htmlinstallation-approve-csrs_installing-vsphere).\n\nDo not restart any of the Red Hat OpenShift cluster virtual machines (VMs) or the bastion VM until the first certificate rotation is done.\n\nAfter the initial certificate rotation, certificates are renewed every 30 days. You must establish a process to approve the CSRs for every certificate rotation. According to Red Hat\u00ae, you can approve CSRs when they reach 80% of their expiration period, which is approximately 25 days into the lifespan of the CSRs.\n\nIf you do not approve CSRs in time and the certificates expire, you can recover from expired control plane certificates and get the Red Hat OpenShift cluster operational again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_managing"},{"document_id":"ibmcld_09508-4607-6675","score":0.0161290323,"text":"\nFor production environments, the IBM SRE team highly discourages requests to run sql scripts with insert\/update\/delete statement(s). These are considered high risk and can break overall data integrity. SRE will only execute statements that have been tested by the client on their non-production environments. Every effort should be made to use [automation scripts](https:\/\/www.ibm.com\/docs\/en\/maximo-manage\/continuous-delivery?topic=scripts-automation) or standard tools through the Maximo front end rather than altering data directly. If a SQL script of this type is required, clients can request this via [IBM case ticket](https:\/\/www.ibm.com\/mysupport), with sql script attached along with business justification as to why its needed and why changing from Maximo front end is not possible. There is a 3 day lead time for SQL scripts. The case needs to include:\n\n\n\n* SQL Script (as an attachment)\n* Design or description of what the script is doing to the data\n* Business justification of why the script is required\n* Technical justification of why the script's commands cannot be done via Maximo front end using DB configuration\n* Request to take full offline backup of target database prior to running script\n\n\n\nSQL Script Limitations:\n\n\n\n* SQL scripts cannot be run in Non-Production environments.\n* DBC Scripts are not allowed in any environment.\n* Backups will be done in offline mode which will require target site to be down \/ unavailable. Backups can take several hours based on database size.\n* IBM SRE team is not responsible for script not working, script corrections and any issues that arise during or after sql execution. If issues arise, IBM SRE can only restore from backup.\n* Any outages caused by the execution of the script and time to recover will not be counted as an SLA breach.\n\n\n\n\n\n\n\n How to Access IBM COS (Cloud Object Storage) Buckets \n\n\n\n* To access IBM COS bucket you have to configure Rclone. Rclone is the utility via which you can access IBM COS bucket(s) and upload\/download the content.\n* To configure Rclone please use steps below.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-support"},{"document_id":"ibmcld_14493-7-1757","score":0.0161290323,"text":"\nRed Hat OpenShift Bastion node setup \n\nTo enable the deployment, a virtual machine (VM) is provisioned to run the Red Hat\u00ae OpenShift\u00ae installation steps and host an HTTP Server. This VM is known as the bastion node. The bastion node is connected to the Red Hat OpenShift logical switch and the ESG firewall and NAT rules are configured to allow SSH access from the jump-server or remote device.\n\nThe bastion node runs Red Hat\u00ae Enterprise Linux\u00ae, and it is used to host the scripts, files, and tools to provision the bootstrap, control-plane, and compute nodes. After the deployment, it is recommended to keep the bastion node as an administrative node for the cluster.\n\nThe bastion node setup consists of the following steps:\n\n\n\n1. Provision a Red Hat VM.\n2. Register the Red Hat VM.\n3. Install NGINX (HTTP Server).\n4. Generate an SSH private key and add it to the agent.\n\n\n\n\n\n Provisioning a Red Hat VM \n\nProvision a Red Hat VM based on the following specifications. Use the vCenter Server user interface or by using the PowerCLI script that is documented later in this document to provision the VM. Record you NAT address, which is configured in the NSX ESG.\n\n\n\nTable 1. Red Hat VM - provision\n\n VM IP address Gateway Disk (GB) Memory (GB) vCPU NAT address \n\n bastion 192.168.133.8 192.168.133.1 50 2 1 10.208.59.197 \n\n\n\nUse the following table to record your deployment details:\n\n\n\nTable 2. Red Hat VM deployment\n\n Parameter Example Your deployment \n\n vCenter Server IP address \n vCenter Server user \n vCenter Server password \n Logical Switch OpenShift-LS \n vCenter Server instance data store vsanDatastore \n VM name bastion \n ISO file name rhel-8.x-x86_64-dvd.iso \n IP address 192.168.133.8 \n Netmask 255.255.255.0 \n Default gateway 192.168.133.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro"},{"document_id":"ibmcld_00474-2629-4401","score":0.0158730159,"text":"\nredis_password = \"<make_up_a_password>\"\n\n\n\n\n\n\n\n Step 3. Create the infrastructure \n\n\n\n1. Create all the infrastructure that you need by running the Terraform script:\n\nterraform apply --auto-approve\n\nThe Terraform folder contains a number of simple scripts, which you can see in the following list:\n\nmain.tf\n: Tells Terraform to use the IBM Cloud.\n\nvariables.tf\n: Contains the variable definitions whose values are populated from terraform.tfvars.\n\nredis.tf\n: Creates a Databases for Redis instance and some credentials to access it.\n\ncloudant.tf\n: Creates an IBM Cloudant free-tier instance and some credentials to access it.\n\nIt takes several minutes for the resources to be ready. Now you have an IBM Cloudant instance and a Databases for Redis instance that you can access.\n\nYou can have only one free-tier instance per account. If you already have one, you must delete it, or change the plan variable to standard.\n2. Check out these instances by visiting the Resources section of your IBM Cloud\u00ae account.\n\n\n\nThe Terraform script outputs several bits of information that you use in the next steps.\n\n\n\n\n\n Step 4. Run the service \n\nIn this step, you run a script that creates all the environment variables that your service needs and then runs the service.\n\nIn the terminal, type the following command:\n\n.\/build.sh\n\nWhen you run this script, it takes the data output from the Terraform script and uses the jq facility to parse the content and create the environment variables needed. It then runs the script (server.js) that initializes the database and populates it with data.\n\n\n\n\n\n Step 5. Visit your website \n\n\n\n1. Open a browser and visit https:\/\/localhost:8080. See the button for each team in the following screen capture:\n\nZoom\n\n![{Click the button for each team.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services"},{"document_id":"ibmcld_11640-2259-4018","score":0.0158730159,"text":"\nRed Hat's SAP Data Intelligence (SDI) Observer, SLC Bridge and SDI runtime components require separate projects\/namespaces for the related pods that will be deployed.\n\nIn the RHA, the sample project names (i.e. namespaces) are sdi, sdi-observer and sap-slcbridge. Following these naming conventions of the Red Hat article, create the related projects as follows.\n\n\n\n1. create the projects\n\n$ oc new-project sdi-observer\n$ oc new-project sap-slcbridge\n$ oc new-project sdi\n\n\n\n\n\n\n\n Deploying Red Hat's SAP Data Intelligence (SDI) Observer \n\nSAP Data Intelligence (SDI) Observer monitors SDI and SLC Bridge namespaces and applies changes to SDI deployments to allow SDI to run on OpenShift.\n\nThe projects' namespaces and Container Registry names used in the following steps are the same as those used in previous steps.\n\n\n\n1. SDI Observer needs a secret with credentials for registry.redhat.io\n\nFollow the section [4.2.1. Prerequisites for Connected OpenShift Cluster](https:\/\/access.redhat.com\/articles\/5100521sdi-observer-prereq-online) in the RHA and save your rht-registry-secret.yaml in the \/sap\/install directory. This yaml file will be required to automatically set the respective parameters below.\n2. Get information about Red Hat's SDI Observer installation script\n\nReview the section [4.2.3. Instantiation of Observer's Template](https:\/\/access.redhat.com\/articles\/5100521sdi-observer-instantiate) in the RHA to confirm the deployment instructions and the source URL are valid.\n3. Download the installation script\n\ncurl -O https:\/\/raw.githubusercontent.com\/redhat-sap\/sap-data-intelligence\/master\/observer\/run-observer-template.sh\n4. Edit the downloaded script file in your favorite editor; especially, mind the following parameters:\n\nFLAVOUR=ubi-build","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-rhos-di-dataintelligence"},{"document_id":"ibmcld_11680-2847-4756","score":0.015625,"text":"\nBy default, your hosts get a cpu, an os, and a memory label, but you might want to add more to control the auto assignment, such as env=prod or service=database. Note that the default value for os is rhel.\n4. Enter a file name for your script or use the name that is generated for you.\n5. Select RHEL or RHCOS to download the host script for your host system.\n6. Click Download script to generate the host script and download the script to your local machine. Note that the token in the script is an API key, which should be treated and protected as sensitive information.\n\n\n\n* To get the host attachment script from the CLI:\n\n\n\n1. Generate a script to run on your machines to attach them to your location by using the sat host attach command and specify the host operating system by using the --operating-system command option. When you run the command to generate the script, you might also want to include labels to identify the purpose of the hosts, such as use:satloc. Your hosts are automatically assigned labels for the CPU and memory size if these values can be detected on the machine.\n\nExample host attach command for a RHCOS host.\n\nibmcloud sat host attach --location <location_name> [-hl \"use=satloc\"] --operating-system RHCOS\n\nExample host attach command for a RHEL host.\n\nibmcloud sat host attach --location <location_name> [-hl \"use=satloc\"] --operating-system RHEL\n\nExample output\n\nCreating host registration script...\nOK\nThe script to attach hosts to Satellite location 'mylocation' was downloaded to the following location:\n<filepath_to_script>\/register-host_mylocation_attach_hypershift.ign\n\n\n\n\n\n2. Optional: If your hosts are RHEL hosts, you need to update the [required packages](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-reqs) on your hosts before you can run the script. If your hosts are running the latest Red Hat CoreOS images, you do not need to update the packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts"},{"document_id":"ibmcld_12666-5872-8212","score":0.015625,"text":"\nTransfer the backups of the key management, Object Storage, and database services related to the Data Security Broker deployment, as well as the Data Security Broker Manager backup files, to a reliable backup storage location.\n\n\n\n\n\n\n\n Restore procedure \n\nThe Data Security Broker deployment can be recovered in a disaster recovery situation to a state that was previously backed up, provided that all the dependent services are also recovered in the same manner. This applies to any services that has suffered a irrecoverable failure. If the dependent services were not affected, all that is required is to ensure that the network connectivity between the Data Security Broker deployment and the dependent services is restored.\n\nSince Data Security Broker Manager contains all the configuration and metadata needed for a Data Security Broker deployment, the goal of the process is to restore Data Security Broker Manager to a previous state so that a new shield can be deployed to enforce the previously configured security policies.\n\n\n\n\n\n Restoring Data Security Broker Manager deployed on a Kubernetes or Red Hat OpenShift cluster to a previous state \n\nA new Data Security Broker Manager deployment needs to be set up in a Kubernetes or Red Hat OpenShift cluster, in order to return Data Security Broker Manager to its previous state. The administrator carrying out the restore operation requires network connectivity to the cluster as well as access to a workstation with permission to use the command-line tools for Kubernetes or Red Hat OpenShift cluster.\n\nTo restore a Data Security Broker deployment, follow the steps:\n\n\n\n1. Log in to the workstation using command-line tools, and use the recently installed Data Security Broker Manager to access the Kubernetes or Red Hat OpenShift cluster.\n2. To create a temporary storage area on the workstation, copy the Data Security Broker Manager backup files there. The names of the backup files includes the following:\n\n\n\nRelease-DSB.<release>MONGO.tar.gz\nRelease-DSB.<release>BM.tar.gz\n\n\n\n1. To restore the Data Security Broker Manager configuration files and MongoDB collections, create and execute the script provided below. As an input to the script, specify the location of the temporary storage location for backup files.\n\n\n\n!\/bin\/bash\nif [ $ -eq 0 ]\nthen\necho \"No arguments supplied\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_dr"},{"document_id":"ibmcld_14341-0-681","score":0.0153846154,"text":"\n\n\n\n\n\n\n  Step 3 - Application configuration \n\nThis step uses the Caveonix RiskForesight\u2122 configuration script. For the \u201call-in-one\u201d deployment, this script is started through the IBM Cloud\u00ae for VMware Solutions automation.\n\nFor scaling, the client needs to call the script to provision the partially distributed topology or the fully distributed topology.\n\nThe script configures the following RiskForesight services:\n\n\n\n*  Caveonix Apps (API, Central Collector)\n*  Elastic Search\n*  PostgresSQL\n*  Remote Collector\n*  UI\n*  Kafka\n*  Kibana\n*  Certificates for all services\n\n\n\nAt the end of this step, the application components are installed on the required virtual machines.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-caveonix-step3"},{"document_id":"ibmcld_14497-4136-6209","score":0.0153846154,"text":"\n* Load-balancer - An NSX ESG load-balancer service is used to front end the Red Hat OpenShift APIs, both internal and external, and the Red Hat OpenShift router. The load balancer is configured so that Port 6443 and 22623 point to the bootstrap and control plane nodes, while ports 80 and 443 are configured to point to the worker nodes.\n* Webserver - A web server is needed to hold the ignition configurations and installation images for the installation of RHEL CoreOS. NGINX is installed on the bastion node to provide this function.\n* Persistent Storage - To support the persistent storage requirements, the vSphere cloud provider is used to provide storage volumes up to the Red Hat OpenShift platform backed by any supported vSphere datastore that is, VMware\u00ae vSAN\u2122, NFS, or iSCSI. Red Hat OpenShift can deliver storage through static or dynamic provisioning. The preferred method is to use dynamic provisioning. Dynamic provisioning automatically triggers the creation of the persistent volume and its backend VMDK file. For dynamic provisioning, a default StorageClass for the Red Hat OpenShift cluster is defined and a PersistentVolumeClaim in Kubernetes is created.\n\n\n\nAccess to the environment for this build process is done through a \"jump-server\" or remote device:\n\n\n\n* You can have a Microsoft Windows\u00ae or Linux Virtual Server Instance (VSI) installed alongside your vCenter Server instance to provide administrative access to the environment. This VSI has internet access for the remote connection to the server and for downloading files. It also has private network access for connecting to vCenter and to the bastion node.\n* You can have a remote device (laptop or desktop) connected through the IBM Cloud SSL VPN to the IBM Cloud Private network. This remote device has access to the internet to download the required files and can connect to vCenter and the bastion node through the SSL VPN.\n\n\n\n\n\n\n\n Scripts overview \n\nThis build process uses the following scripting tools and scripts:\n\n\n\n* govc is a vSphere CLI pre-compiled for Linux, OSX, and Windows.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05173-10345-12132","score":0.0327868852,"text":"\n* To install Watson OpenScale, set aiopenscale to true.\n* To install Cognos Dashboards, set cde to true.\n* To install Db2 Data Gate, set datagate to true.\n* To install Db2 Warehouse, set db2wh to true.\n* To install Db2 Data Management Console, set dmc to true.\n* To install RStudio Server, set rstudio to true.\n* To install Apache Spark, set spark to true.\n* To install Scheduling, set scheduler to true.\n* To install Watson Knowledge Catalog, set wkc to true.\n* To install Watson Machine Learning, set wml to true.\n* To install Watson Machine Learning Accelerator, set wmla to true.\n* To install Watson Query, set dv to true.\n* To install Watson Studio, set wsl to true.\n\n\n\nIf you don't select any services to install in this step, only the IBM Cloud Pak for Data control plane will be installed.\n\nIf you want to install a service later, you can return to the Deployment values section and set the appropriate parameter to true or you can select a service from the IBM Cloud Pak for Data Services catalog and follow the installation instructions for the service.\n\nFor more information, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html).\n\n\n\n\n\n Step 6. Install IBM Cloud Pak for Data \n\n\n\n1. Ensure that you have assigned a license for IBM Cloud Pak for Data to the deployment.\n2. Confirm that you have read and agree to the license agreements.\n3. Click Install.\n\n\n\nThe IBM Cloud Pak\u00ae for Data automated installation makes the following changes to ensure that services can be installed successfully:\n\n\n\n* Sets kernel parameters. For more information, see [Kernel parameter settings](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/prep-cluster-node-kernel.html).\n* Enables noroot squash on worker nodes for Network File System (NFS).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data"},{"document_id":"ibmcld_05174-10419-12206","score":0.0322580645,"text":"\n* To install Watson OpenScale, set aiopenscale to true.\n* To install Cognos Dashboards, set cde to true.\n* To install Db2 Data Gate, set datagate to true.\n* To install Db2 Warehouse, set db2wh to true.\n* To install Db2 Data Management Console, set dmc to true.\n* To install RStudio Server, set rstudio to true.\n* To install Apache Spark, set spark to true.\n* To install Scheduling, set scheduler to true.\n* To install Watson Knowledge Catalog, set wkc to true.\n* To install Watson Machine Learning, set wml to true.\n* To install Watson Machine Learning Accelerator, set wmla to true.\n* To install Watson Query, set dv to true.\n* To install Watson Studio, set wsl to true.\n\n\n\nIf you don't select any services to install in this step, only the IBM Cloud Pak for Data control plane will be installed.\n\nIf you want to install a service later, you can return to the Deployment values section and set the appropriate parameter to true or you can select a service from the IBM Cloud Pak for Data Services catalog and follow the installation instructions for the service.\n\nFor more information, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html).\n\n\n\n\n\n Step 6. Install IBM Cloud Pak for Data \n\n\n\n1. Ensure that you have assigned a license for IBM Cloud Pak for Data to the deployment.\n2. Confirm that you have read and agree to the license agreements.\n3. Click Install.\n\n\n\nThe IBM Cloud Pak\u00ae for Data automated installation makes the following changes to ensure that services can be installed successfully:\n\n\n\n* Sets kernel parameters. For more information, see [Kernel parameter settings](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/prep-cluster-node-kernel.html).\n* Enables noroot squash on worker nodes for Network File System (NFS).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-getting-started"},{"document_id":"ibmcld_04504-1175-2776","score":0.0317460317,"text":"\nUse the ibmcloud plugin install PLUGIN_NAME command to install a specific plug-in. For example, use the following command to install the IBM Cloud Code Engine CLI plug-in:\n\nibmcloud plugin install code-engine\n\nLooking up 'code-engine' from repository 'IBM Cloud'...\nPlug-in 'code-engine 1.23.2' found in repository 'IBM Cloud'\nAttempting to download the binary file...\n54.29 MiB \/ 54.29 MiB [============================================] 100.00% 10s\n56929376 bytes downloaded\nInstalling binary...\nOK\nPlug-in 'code-engine 1.23.2' was successfully installed into \/Users\/username\/.bluemix\/plugins\/code-engine. Use 'ibmcloud plugin show code-engine' to show its details.\n\n\n\n\n\n Installing all plug-ins \n\nUse the plugin install -a command to install all the latest available plug-ins that are in the repository:\n\nibmcloud plugin install -a\n\n\n\n\n\n Installing multiple plug-ins \n\nUse the plugin install PLUGIN_NAME@VERSION command to install multiple plug-ins at the same time. For example, use the following command to install the container-service@1.0.506 and the secrets-manager@0.1.25 plug-ins:\n\nibmcloud plugin install container-service@1.0.506 secrets-manager@0.1.25\n\nFor more information, see [ibmcloud plugin install](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settingsibmcloud_plugin_install).\n\n\n\n\n\n\n\n Confirming installed plug-ins \n\nUse the plugin list command to confirm that all required plug-ins are installed in IBM Cloud CLI. The plugin list command returns the following information for each plugin that is installed:\n\n\n\n* The plug-in name.\n* The current version of the plug-in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-plug-ins"},{"document_id":"ibmcld_14493-6240-7938","score":0.03125,"text":"\nAdd your SSH private key to the ssh-agent:\n\nssh-add \/root\/.ssh\/id_rsa\n\n\n\n\n\n\n\n\n\n Downloading the installation tools \n\nFor more information about installing Red Hat OpenShift 4.7, see [Installing a cluster on vSphere with user-provisioned infrastructure](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.html).\n\nFor more information about how to access the Red Hat OpenShift user provider infrastructure, see [Internet and Telemetry access for Red Hat OpenShift Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.htmlcluster-entitlements_installing-vsphere).\n\nBefore you install the Red Hat OpenShift Container Platform, you need to download a number of files onto the bastion node and then extract them. The following actions are completed:\n\n\n\n* Download unzip to extract the downloaded files.\n* Create an installation directory and make it the working directory.\n* Download the Red Hat OpenShift installation and client tools.\n* Extract the downloaded bundles.\n* Move commands to \/usr\/local\/bin for ease of use.\n* Install Git to download the Red Hat OpenShift installer.\n* Clone the installer repository to the bastion node.\n* Download and extract Terraform to the \/usr\/local\/bin directory for ease of use.\n\n\n\nThese commands are used in the SSH session to the bastion node that has root privileges. Replace 4.x with the current Red Hat OpenShift version, for example, 4.7.\n\n Download unzip\nyum install -y wget unzip\n\n Create an installation directory and make it the working directory\nmkdir -p \/opt\/ocpinstall\ncd \/opt\/ocpinstall\n\n Download the OpenShift installer and client tools","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro"},{"document_id":"ibmcld_04442-2443-4242","score":0.0307692308,"text":"\nEach plug-in returns the current version installed, whether there is a more recent version available for update, and if the version of the plug-in installed supports private endpoint use.\n\nibmcloud plugin list\n\n\n\n\n\n ibmcloud plugin show \n\nShow details of an installed plug-in.\n\nibmcloud plugin show PLUGIN-NAME\n\n\n\n\n\n ibmcloud plugin install \n\nInstall a specific version of a plug-in to IBM Cloud CLI from the specified path or repository, or all latest available plug-ins in the repository.\n\nibmcloud plugin install PLUGIN_PATH|PLUGIN_NAME [-r REPO_NAME] [-v VERSION] [-f]\n\nibmcloud plugin install [-a, --all] [-r REPO_NAME] [-f]\n\nibmcloud plugin install LOCAL-PATH\/TO\/PLUGIN | URL [-f]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If you are installing a single plug-in, and no version is specified, the command selects the latest available version to install. If the '-a, --all' flag is specified, the command installs all latest available plug-ins in the repository.\n\nCommand options:\n\nPLUGIN_PATH|PLUGIN_NAME\n: If -r REPO_NAME is not specified, the plug-in is installed from the specified local path or remote URL.\n\n-a, --all (optional)\n: Install all latest available plug-ins in the repository.\n\n-r REPO_NAME (optional)\n: The name of the repository where the plug-in binary is located. If no repository is specified, the command uses the default plug-in repository IBM Cloud.\n\n-v VERSION (optional)\n: Version of the plug-in to be installed. Accepts specific semantic version or constraint.\n\n-f\n: Force installs the plug-in without confirmation.\n\nThe IBM Cloud CLI has the official repository name of IBM Cloud.\n\nExamples:\n\nInstall a plug-in from the local file:\n\nibmcloud plugin install \/downloads\/new_plugin\n\nInstall a plug-in from the remote URL:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settings"},{"document_id":"ibmcld_05187-7-1663","score":0.0303030303,"text":"\nInstalling services \n\nIf you deploy IBM Cloud Pak for Data on IBM Cloud, you can install a subset of the services that are available in the Cloud Pak for Data services catalog.\n\nYou can install services by using two different methods. The supported methods depend on the services that you want to install:\n\n\n\n* Some services can be installed from the [Cloud Pak for Data installation page](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global) in the IBM Cloud catalog.\n* Some services can be installed by creating a catalog source and an operator subscription for each service. For general information and prerequisites, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html). To use this method, you must:\n\n\n\n* Use the Red Hat OpenShift command-line interface (oc CLI) to connect to the cluster. For more information, see [Connecting to the cluster from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_oc_cli).\n* Create an operator subscription for each service that you plan to install. For more information, see [Creating OLM objects for an express installation](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install-platform-express-olm.html).\n\n\n\n\n\nUse the links in the following table to learn how to install each of these services.\n\n\n\n Service Install from the Cloud Pak for Data installation page Install by using the CLI \n\n [Analytics Engine Powered by Apache Spark](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/spark.html) \u2713 \u2713 \n [Cognos Analytics](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/ca.html) \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-install-services"},{"document_id":"ibmcld_04504-2340-3690","score":0.0298507463,"text":"\nFor more information, see [ibmcloud plugin install](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settingsibmcloud_plugin_install).\n\n\n\n\n\n\n\n Confirming installed plug-ins \n\nUse the plugin list command to confirm that all required plug-ins are installed in IBM Cloud CLI. The plugin list command returns the following information for each plugin that is installed:\n\n\n\n* The plug-in name.\n* The current version of the plug-in.\n* Whether a more recent version of the plugin is available.\n* Whether the plug-in version supports private endpoint use.\n\n\n\nibmcloud plugin list\n\n\n\n\n\n Updating installed plug-ins \n\nUse the plugin update command to update the plug-ins that are installed in IBM Cloud CLI. The plugin update command returns the following information for each plugin that is installed:\n\n\n\n* The current plug-in version.\n* The latest plug-in version that is available.\n\n\n\nibmcloud plugin update\n\n\n\n\n\n Related information \n\nYou can also install a plug-in from a URL, download a plug-in, or install a plug-in binary locally:\n\n\n\n* To install a plug-in locally or from a URL, see [ibmcloud plugin install](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settingsibmcloud_plugin_install).\n* To download a plug-in, see [How do I download a plug-in?](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibm-cli-faqcli-install-download-local)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-plug-ins"},{"document_id":"ibmcld_02598-2975-4802","score":0.0294117647,"text":"\nOn Windows systems, there is a maximum path length, which is exceeded when you try to install all of the dependencies in a deep level folder.\n\n How to fix it \n\nYou can fix this problem in one of the following ways:\n\n\n\n* Ensure that you have installed the correct version of Node.js. For more information, see [Installing the Developer Toolkit](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-creating_apis).\n* If you had to upgrade a program, try the installation again.\n\n\n\nIf that does not work, install API Connect at a level higher than the likely C:\/program files\/nodejs\/bin\/node_modules... folder. If you install at a top-level directory, you will not see this error.\n\n\n\n\n\n Unable to install the developer toolkit on Mac OS X \n\nAfter you provision the API Connect service, you try to install the developer toolkit and the installation fails.\n\n What\u2019s happening \n\nThe following errors are displayed during the developer toolkit installation:\n\nAgreeing to the Xcode\/iOS license requires admin\nprivileges, please re-run as root via sudo\n\n Why it\u2019s happening \n\nYou recently upgraded or installed Xcode and have not agreed to the license yet.\n\n How to fix it \n\n\n\n1. Enter the following command to validate your Xcode license:\n\n\n\nsudo xcode-select\n\n\n\n2. Reinstall the developer toolkit.\n\n\n\n\n\n\n\n Unable to install the developer toolkit on Ubuntu \n\nAfter you provision the API Connect service, you try to install the developer toolkit and the installation fails.\n\n What\u2019s happening \n\nThe following errors are displayed during the developer toolkit installation:\n\nsqlite3@3.1.1 install \/usr\/local\/lib\/node_modules\/strong-pm\/node_modules\/minkelite\/node_modules\/sqlite3\nnode-pre-gyp install --fallback-to-build\n\/usr\/bin\/env: node: No such file or directory\nnpm WARN This failure might be due to the use of legacy binary \"node\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-apic_troubleshoot"},{"document_id":"ibmcld_04442-3871-5648","score":0.0289855072,"text":"\n-v VERSION (optional)\n: Version of the plug-in to be installed. Accepts specific semantic version or constraint.\n\n-f\n: Force installs the plug-in without confirmation.\n\nThe IBM Cloud CLI has the official repository name of IBM Cloud.\n\nExamples:\n\nInstall a plug-in from the local file:\n\nibmcloud plugin install \/downloads\/new_plugin\n\nInstall a plug-in from the remote URL:\n\nibmcloud plugin install http:\/\/example.com\/downloads\/my-plugin\n\nInstall the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin install container-service -r \"IBM Cloud\"\n\nor you can run:\n\nibmcloud plugin install container-service\n\nInstall the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin install container-service -v 0.1.425\n\nInstall all latest available plug-ins from the official plug-in repository:\n\nibmcloud plugin install --all\n\nInstall all latest available plug-ins from the official plug-in repository without confirmation:\n\nibmcloud plugin install --all -f\n\nInstall multiple plug-ins at the same time:\n\nibmcloud plugin install container-service@0.1.425 secrets-manager@0.1.25\n\n\n\n\n\n ibmcloud plugin download \n\nDownload a specific version of a plug-in to IBM Cloud CLI from the specified repository, or all latest available plug-ins in the repository.\n\nibmcloud plugin download PLUGIN_NAME [-r REPO_NAME] [-v VERSION] [-d, --dest DOWNLOAD_DIRECTORY] [-f]\n\nibmcloud plugin download [-a, --all] [-r REPO_NAME] [-f]\n\nibmcloud plugin download URL [-f] [-d DOWNLOAD_DIRECTORY]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If you are downloading a single plug-in, and no version is specified, the command selects the latest available version to download.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settings"},{"document_id":"ibmcld_04727-3143-4678","score":0.0285714286,"text":"\nLog in with root.\n2. Run yum -y install rsync.\n\n\n\n\n\n\n\n\n\n Windows systems \n\nComplete the following steps to install rsync on your Windows 2012, 2012R2, or 2016 system.\n\n\n\n1. Download Cygwin setup-x86_64 ([https:\/\/cygwin.com\/install.html](https:\/\/cygwin.com\/install.html)).\n2. Install downloaded setup ([https:\/\/cygwin.com\/setup-x86_64.exe](https:\/\/cygwin.com\/setup-x86_64.exe)).\n3. Follow through all of the steps until you see a list of all Linux packages.\n4. Select rsync (in net category section).\n5. Select OpenSSH (in net category section).\n6. Click Continue and finish installation.\n7. Open \u2018Cygwin Terminal\u2019, type rsync command, and press enter.\n8. If the output shows rsync command details with options, then it is installed.\n\n\n\n\n\n\n\n\n\n Step 3: Install OpenSSH \n\n\n\n Linux systems \n\nIf you have a Linux system, you don't need to install OpenSSH because it is installed by default.\n\n\n\n\n\n Windows systems \n\n\n\n Windows 2016 \n\nTo install OpenSSH on your Windows 2016 system, review the following information:\n\n\n\n1. Microsoft's documentation on [Installation of OpenSSH for Windows Server 2019 and Windows 10](https:\/\/docs.microsoft.com\/en-us\/windows-server\/administration\/openssh\/openssh_install_firstuse)\n2. GitHub instructions on [Installation of OpenSSH for Windows](https:\/\/github.com\/MicrosoftDocs\/windowsserverdocs\/blob\/master\/WindowsServerDocs\/administration\/OpenSSH\/OpenSSH_Install_FirstUse.md)\n\n\n\n\n\n\n\n Windows 2012 and 2012R2 \n\nTo install OpenSSH on your Windows 2012 or 2012R2 system, review the following information:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-data-migration-classic-to-vpc"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10041-5131-6632","score":0.0327868852,"text":"\nDELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET\/v1\/clusters\/{idOrName}\/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/services\/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/webhooks List all webhooks for a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-5113-6614","score":0.0322580645,"text":"\nDELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET\/v1\/clusters\/{idOrName}\/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/services\/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/webhooks List all webhooks for a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05638-2606-4547","score":0.0317460317,"text":"\nTo view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is being deleted and cluster infrastructure is being dismantled. You can't access the cluster.\n\n\n\n\n\n Deploy failed \n\nReview the following description of the Deploy failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe deployment of the Kubernetes master can't be completed. You can't resolve this state. Contact IBM Cloud support by opening an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n\n\n Deploying \n\nReview the following description of the Deploying cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master is not fully deployed yet. You can't access your cluster. Wait until your cluster is fully deployed to review the health of your cluster.\n\n\n\n\n\n Normal \n\nReview the following description of the Normal cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nAll worker nodes in a cluster are up and running. You can access the cluster and deploy apps to the cluster. This state is considered healthy and does not require an action from you.\n\nAlthough the worker nodes might be normal, other infrastructure resources, such as [networking](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-coredns_lameduck) and [storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_storage_file), might still need attention. If you just created the cluster, some parts of the cluster that are used by other services such as Ingress secrets or registry image pull secrets, might still be in process.\n\n\n\n\n\n Pending \n\nReview the following description of the Pending cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-states-reference"},{"document_id":"ibmcld_10041-8604-10172","score":0.03125,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-8586-10154","score":0.0307692308,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-15253-16718","score":0.0303030303,"text":"\nDELETE\/v1\/alb\/albs\/{albID} Disable an ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.delete \n DELETE\/v1\/alb\/clusters\/{idOrName}\/albsecrets Delete an ALB secret that is imported from Secrets Manager from a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.delete \n GET\/v1\/alb\/albs\/{albID} View details of an ALB in a classic cluster. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v1\/alb\/albtypes List the ALB types that are supported in classic clusters. containers-kubernetes.cluster.read N\/A \n GET\/v1\/alb\/clusters\/{idOrName} List all ALBs in a classic cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v1\/alb\/clusters\/{idOrName}\/albsecrets View details of an ALB secret that you imported from Secrets Manager to a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.list \n GET\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Check if automatic updates for Ingress ALBs are enabled in a classic cluster. containers-kubernetes.cluster.update cluster-alb-policy.get \n GET\/v2\/alb\/getAlb View details of an ALB. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v2\/alb\/getAlbImages List supported Ingress controller images. containers-kubernetes.cluster.read alb-image.list \n GET\/v2\/alb\/getClusterAlbs List all ALBs in a cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v2\/alb\/getMigrationStatus Get the status of the Ingress migration process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-3930-5493","score":0.0298507463,"text":"\nGET\/v2\/getCACert Get the cluster's CA certificate. containers-kubernetes.cluster.view cluster-ca-certificate.get \n POST\/v2\/rotateCACert Rotate the cluster's CA certificate. containers-kubernetes.cluster.create cluster-ca-certificate.rotate \n POST\/v2\/createCA Create a CA certificate. cluster-ca-certificate.create containers-kubernetes.cluster.create \n\n\n\n\n\n\n\n Cluster \n\nReview the following cluster API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for IBM Cloud Kubernetes Service.\n\n\n\nCluster API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n DELETE\/v1\/clusters\/{idOrName} Delete a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.delete \n DELETE\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook Delete an audit webhook configuration. containers-kubernetes.cluster.operate containers-kubernetes.cluster.delete \n DELETE\/v1\/clusters\/{idOrName}\/services\/{namespace}\/{serviceInstanceId} Unbind an IBM Cloud service from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.service.delete \n DELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05567-15233-16698","score":0.0294117647,"text":"\nDELETE\/v1\/alb\/albs\/{albID} Disable an ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.delete \n DELETE\/v1\/alb\/clusters\/{idOrName}\/albsecrets Delete an ALB secret that is imported from Secrets Manager from a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.delete \n GET\/v1\/alb\/albs\/{albID} View details of an ALB in a classic cluster. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v1\/alb\/albtypes List the ALB types that are supported in classic clusters. containers-kubernetes.cluster.read N\/A \n GET\/v1\/alb\/clusters\/{idOrName} List all ALBs in a classic cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v1\/alb\/clusters\/{idOrName}\/albsecrets View details of an ALB secret that you imported from Secrets Manager to a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.list \n GET\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Check if automatic updates for Ingress ALBs are enabled in a classic cluster. containers-kubernetes.cluster.update cluster-alb-policy.get \n GET\/v2\/alb\/getAlb View details of an ALB. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v2\/alb\/getAlbImages List supported Ingress controller images. containers-kubernetes.cluster.read alb-image.list \n GET\/v2\/alb\/getClusterAlbs List all ALBs in a cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v2\/alb\/getMigrationStatus Get the status of the Ingress migration process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10094-7-1844","score":0.0289855072,"text":"\nCluster states \n\nYou can view the current cluster state by running the ibmcloud oc cluster ls command and locating the State field.\n\n\n\n Aborted \n\nReview the following description of the Aborted cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nYou sent a delete request before the Kubernetes master deployment completed. After your cluster is deleted, it is removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Critical \n\nReview the following description of the Critical cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master can't be reached or all worker nodes in the cluster are down. If you enabled IBM Key Protect in your cluster, the Key Protect container might fail to encrypt or decrypt your cluster secrets. If so, you can view an error with more information when you run oc get secrets.\n\n\n\n\n\n Create failed \n\nReview the following description of the Create failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster cannot be created. Delete the failed cluster and try to create another one. If the issue persists when creating additional clusters, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud oc worker ls --cluster <cluster_name_or_ID>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-states-reference"},{"document_id":"ibmcld_05638-7-1853","score":0.0285714286,"text":"\nCluster states \n\nYou can view the current cluster state by running the ibmcloud ks cluster ls command and locating the State field.\n\n\n\n Aborted \n\nReview the following description of the Aborted cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nYou sent a delete request before the Kubernetes master deployment completed. After your cluster is deleted, it is removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n\n\n Critical \n\nReview the following description of the Critical cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master can't be reached or all worker nodes in the cluster are down. If you enabled IBM Key Protect in your cluster, the Key Protect container might fail to encrypt or decrypt your cluster secrets. If so, you can view an error with more information when you run kubectl get secrets.\n\n\n\n\n\n Create failed \n\nReview the following description of the Create failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster cannot be created. Delete the failed cluster and try to create another one. If the issue persists when creating additional clusters, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud ks worker ls --cluster <cluster_name_or_ID>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-states-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-891912-893651","score":0.0327868852,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":0.0322580645,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14984-1616-3476","score":0.0317460317,"text":"\nFor more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. For more information, see [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\nTo restore a volume, the backup snapshot must be in a stable state.\n\nYou can't simultaneously restore a boot and a data volume.\n\n\n\n Restoring from a bootable backup \n\nWhen you restore from a bootable backup snapshot, you create a boot volume that you use to provision another instance. The boot volume uses a general-purpose profile and is limited to 250 GB. Because the bootable backup snapshot is not fully provisioned, in the beginning the performance is slower than when you use a regular boot volume. For more information, see [Performance impact](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-boot-perf).\n\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_14996-1525-3435","score":0.03125,"text":"\nAfter the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. For more information, see [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\nTo restore a volume, the backup snapshot must be in a stable state.\n\nYou can't simultaneously restore a boot and a data volume.\n\n\n\n Restoring from a bootable backup \n\nWhen you restore from a bootable backup snapshot, you create a boot volume that you use to provision another instance. The boot volume uses a general-purpose profile and is limited to 250 GB. Because the bootable backup snapshot is not fully provisioned, in the beginning the performance is slower than when you use a regular boot volume. For more information, see [Performance impact](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-boot-perf).\n\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_15111-8694-10574","score":0.0307692308,"text":"\nVolume names must begin with a lowercase letter and be unique across the entire VPC infrastructure.\n\nYou can change the name of an existing volume in the UI. For more information, see [Managing Block Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagerename).\n\n\n\n\n\n Does the volume need to be pre-warmed to achieve expected throughput? \n\nYou do not have to pre-warm a volume. You can see the specified throughput immediately upon provisioning the volume when you create the volume from an image. You can experience degraded performance when you provision the volume by restoring a snapshot.\n\n\n\n\n\n What is a Block Storage for VPC snapshot? \n\nSnapshots are a point-in-time copy of your Block Storage for VPC boot or data volume that you manually create. The first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n\n\n\n\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n\n\n\n\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_15916-7-1904","score":0.0303030303,"text":"\nFAQs for Block Storage for VPC Snapshots \n\nThe following questions often arise about the Block Storage for VPC Snapshots offering. If you have other questions you'd like to see answered here, provide feedback by using the Open doc issue or Edit topic links at the end of the topic.\n\n\n\n What is a snapshot? \n\nSnapshots are a point-in-time copy of your Block Storage for VPC boot or data volume that you manually create. To create a snapshot, the original volume must be attached to a running virtual server instance. The first snapshot is a full backup of the volume. Subsequent snapshots of the same volume record only the changes since the last snapshot. You can access a snapshot of a boot volume and use it to provision a new boot volume. You can create a data volume from a snapshot (called restoring a volume) and attach it to an instance. Snapshots are persistent; they have a lifecycle that is independent from the original volume.\n\n\n\n\n\n What is a backup snapshot? \n\nBackup snapshots, also called backups, are scheduled snapshots that are created by using the Backup for VPC service. For more information, see [Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n\n\n\n\n\n What is a bootable snapshot? \n\nA bootable snapshot is a copy of a boot volume. You can use this snapshot to create another boot volume when you provision a new instance.\n\n\n\n\n\n What is a fast restore snapshot? \n\nA [fast restore snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=uisnapshots-vpc-use-fast-restore) is a clone of a snapshot that is stored within one or more zones of a VPC region. The original snapshot is stored in IBM Cloud Object Storage. When you perform a restore, data can be restored faster from a clone than from the snapshot in Object Storage.\n\n\n\n\n\n How many snapshots can I take? \n\nYou can take up to 750 snapshots per volume in a region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-faqs&interface=ui"},{"document_id":"ibmcld_15051-1531-3437","score":0.0298507463,"text":"\nBilling Think about the number of backup snapshots that you want to take and other [billing considerations](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=apisnapshots_vpc_considerations) as the number of backup snapshots grows. \n Volume restore Evaluate when you might want to restore a volume from a backup. Keep in mind that restoring from a backup is a manual operation and not immediate such as a disaster recovery solution. \n Fast-restore You can create and cache a copy of the backup snapshot in one or more zones of the region where your volume resides. Fast-restore can be used in disaster recovery scenarios when you need to restore volumes in a different zone of the same region. The fast restore feature can achieve a<br><br>recovery time objective<br><br>(RTO) quicker than restoring from a regular snapshot. Evaluate when to enable snapshots for [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restoresnapshots-vpc-use-fast-restore). \n Cross-regional copy <br><br>New You can create and store a copy of the backup snapshot in another region, and use it to create volumes in the target region. This feature can be used in disaster recovery scenarios when you need to start your virtual server instance and data volumes in a different region. Think about whether you need to restore data in other regions. \n Naming Make sure you have a unique name for your backup policy. For example, if you have a method for naming volumes, you might name a backup policy by using a similar convention. Naming conventions for backups that are created by the plan are the same as snapshots. For more information, see [Naming snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-naming). \n Creating backups: \n Prerequisites Verify that the volume is attached to a virtual server instance and that the instance is in a running state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-planning"},{"document_id":"ibmcld_07578-960693-962572","score":0.0294117647,"text":"\nASV scanning of LBaaS data-plane appliances is solely a customer responsibility. IBM does not use ASVs to scan data-plane appliances because these scans can negatively impact customer workload functions and performance.\n* What is a snapshot?\n\nSnapshots are a point-in-time copy of your Block Storage for VPC boot or data volume that you manually create. To create a snapshot, the original volume must be attached to a running virtual server instance. The first snapshot is a full backup of the volume. Subsequent snapshots of the same volume record only the changes since the last snapshot. You can access a snapshot of a boot volume and use it to provision a new boot volume. You can create a data volume from a snapshot (called restoring a volume) and attach it to an instance. Snapshots are persistent; they have a lifecycle that is independent from the original volume.\n* What is a backup snapshot?\n\nBackup snapshots, also called backups, are scheduled snapshots that are created by using the Backup for VPC service. For more information, see [Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What is a bootable snapshot?\n\nA bootable snapshot is a copy of a boot volume. You can use this snapshot to create another boot volume when you provision a new instance.\n* What is a fast restore snapshot?\n\nA [fast restore snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=uisnapshots-vpc-use-fast-restore) is a clone of a snapshot that is stored within one or more zones of a VPC region. The original snapshot is stored in IBM Cloud Object Storage. When you perform a restore, data can be restored faster from a clone than from the snapshot in Object Storage.\n* How many snapshots can I take?\n\nYou can take up to 750 snapshots per volume in a region. Deleting snapshots from this quota makes space for more snapshots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-960569-962448","score":0.0289855072,"text":"\nASV scanning of LBaaS data-plane appliances is solely a customer responsibility. IBM does not use ASVs to scan data-plane appliances because these scans can negatively impact customer workload functions and performance.\n* What is a snapshot?\n\nSnapshots are a point-in-time copy of your Block Storage for VPC boot or data volume that you manually create. To create a snapshot, the original volume must be attached to a running virtual server instance. The first snapshot is a full backup of the volume. Subsequent snapshots of the same volume record only the changes since the last snapshot. You can access a snapshot of a boot volume and use it to provision a new boot volume. You can create a data volume from a snapshot (called restoring a volume) and attach it to an instance. Snapshots are persistent; they have a lifecycle that is independent from the original volume.\n* What is a backup snapshot?\n\nBackup snapshots, also called backups, are scheduled snapshots that are created by using the Backup for VPC service. For more information, see [Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What is a bootable snapshot?\n\nA bootable snapshot is a copy of a boot volume. You can use this snapshot to create another boot volume when you provision a new instance.\n* What is a fast restore snapshot?\n\nA [fast restore snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=uisnapshots-vpc-use-fast-restore) is a clone of a snapshot that is stored within one or more zones of a VPC region. The original snapshot is stored in IBM Cloud Object Storage. When you perform a restore, data can be restored faster from a clone than from the snapshot in Object Storage.\n* How many snapshots can I take?\n\nYou can take up to 750 snapshots per volume in a region. Deleting snapshots from this quota makes space for more snapshots.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15926-1517-3367","score":0.0285714286,"text":"\nHowever, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\nYou can restore a volume in a different region by using a cross-regional copy of a snapshot. For more information, see [Cross-regional snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_crossregion_copy).\n\nYou can also choose to restore a volume by using a fast restore snapshot clone. For more information about fast restore, see the [FAQs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-faqs&interface=uifaq-snapshot-fr).\n\nYou can restore volumes at various stages of the VPC lifecycle.\n\n\n\n* When you provision a virtual server instance, you can specify a snapshot of a boot or a snapshot of data volume. The restored boot volume is used to start the new instance. Restored data volumes are automatically attached to the instance as auxiliary storage.\n* When you want to add a new auxiliary storage to your existing instance, you can restore a data volume from a nonbootable snapshot.\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1128451413}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08739-8238-10173","score":0.0163934426,"text":"\n* With TDE, you can encrypt sensitive data on database storage media, such as table spaces and files, and on backup media. Transparent Data Encryption ensures that sensitive data is encrypted, meets compliance, and provides functionality that streamlines encryption operations. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTDE uses a two-tiered key hierarchy that is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-database.svg)\n\nFigure 5. Transparent Database Encryption by using the standard PKCS #11 API\n* IBM Db2 default encryption protects key database files and database backup images from inappropriate access while they are stored on external storage media. The database system automatically encrypts and decrypts data when it is used by authorized users and applications. Typically, database users do not need to be aware of default encryption and database client applications do not need to be adapted specifically.\n\nDb2 default encryption uses a two-tiered key hierarchy: Data is encrypted with a data encryption key (DEK). The DEK is encrypted with a master key and is stored in encrypted form with the database or the backup image. A unique DEK is generated by Db2 for each encrypted database and for each encrypted backup. A master key is used to encrypt a DEK. Each encrypted database is associated with one master key at one time.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_09888-7087-9070","score":0.0163934426,"text":"\nFor details on configuring TLS for channels please see the following [topic](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_configure_chl_ssl).\n\nThe Advanced Message Security (AMS) feature, which provides a higher level of protection for sensitive data is available for use at the application or queue manager. It is strongly recommended that sensitive data should be encrypted by the application using AMS, to ensure that it is fully protected as it flows between the application and the queue manager and through the system. For details on configuring AMS for client applications see the following [topic](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_app_ams).\n\nThe queue manager source IP address is dynamic and will change if a queue manager is restarted or fails over to another host. The source IP address is shared by multiple queue managers and therefore should not be used as the only mechanism for authenticating an incoming connection on a receiver channel.\n\n\n\n\n\n Securing data in transit \n\nThe predefined administration and application channels in your MQ on Cloud queue manager are configured by default with TLS security. Enabling TLS causes the administration or application connections to encrypt the conversation thus protecting sensitive data and credentials. The following documents will explain how to enable TLS should a channel not have it, along with securing remote administration and application connections.\n\n\n\n Enabling TLS security for MQ channels in MQ on Cloud \n\nAs mentioned previously, a queue manager created at MQ version 9.2.2r1 (or above) will have TLS enabled on its predefined channels by default. However, queue managers deployed at a lower version than 9.2.2r1, which have been upgraded to version 9.2.2r1 or above will not have TLS enabled by default. The below document explains the process of how you can enable TLS on a channel which does not have it set, along with how to create a trusted keystore file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-security"},{"document_id":"ibmcld_12667-7-2097","score":0.0161290323,"text":"\nData Encryption using IBM Cloud Databases for PostgreSQL \n\n\n\n Overview \n\nData Security Broker functions as an application-level encryption (ALE) equivalent in this mode encrypting data on a field-level basis. This is performed using Data Security Broker Manager to enumerate the data schema and enable an encryption key mapping.\n\n\n\n\n\n Procedure \n\nComplete the following steps to encrypt the data with Data Security Broker Manager on an IBM Cloud PostgreSQL Database:\n\n\n\n1. Login to Data Security Broker Manager.\n2. Click on an application and select the drop down which is present in the Migration Details field in the right side and click Encrypt.\n3. Select the Database and the table where you have the data created and select the Column which needs to be encrypted. Choose the Data Protection policy, Encryption mode, and masking mode for the encryption process and click Review.\n\nZoom\n\n![Encryption](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/57ab3ec034294d8a6de510b97bec3035d4654761\/security-broker\/images\/encryption_schema.svg)\n\nStandard Encryption\n4. Choose Deploy Policy & Migrate Data under the Deployment Plan option. There are three options that you can choose to implement your data encryption policy. For more information on Deployment plans, see Deployment Plans in IBM Cloud Data Security Broker. Select the Security Broker Shield service IP address in the Migration Shield field and click Save to start the encryption process.\n5. The status of the application shows Migrating when the encryption process starts.\n6. Once the encryption is complete, the status is changed to Protected. You can view more information by clicking Migration Details in the Applications sidebar.\n\n\n\nIf there is new data which gets inserted in the database, by default, the data is encrypted by using the default data encryption policy that is being selected by the user.\n\n\n\n\n\n Reference \n\n\n\n\n\n Format Preserving Encryption (FPE) Supported Data Types \n\nThe following tables lists the FPE supported data types for the data encryption in Data Security Broker Manager:\n\n\n\n\n\n PostgreSQL \n\n\n\nTable 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_encrypt_data"},{"document_id":"ibmcld_16628-0-1541","score":0.0161290323,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_09081-7-2309","score":0.0158730159,"text":"\nProtecting data with envelope encryption \n\nKey Protect uses envelope encryption to assist in protecting your Key Protect data. Envelope encryption involves encrypting your data with a Data Encryption Key, then encrypting the Data Encryption Key with a root key. This topic describes the process of envelope encryption and how to use Key Protect to encrypt and decrypt your data.\n\nWhen working with sensitive data, it is important to use advanced encryption techniques to prevent a data breach. If you have large amounts of confidential data, it is often helpful to use a Key Management System to assist in keeping your data secure. Key Protect uses the envelope encryption technique to keep your data resilient. Envelope encryption is the process of using encrypted keys, Data Encryption Keys and Root Keys, to protect your sensitive data.\n\nImagine that you plan to send a letter to a colleague. You want to discuss information that is highly sensitive, so you generate a secret code (Data Encryption Key) that is used to write (encrypt) the message in the letter. The letter is delivered to a mailbox (wrapped Data Encryption Key) that can only be opened by those with a copy of the mailbox key (Root key), including the colleague. Anyone who does not have an exact copy of the key will be unable to open the mailbox and see it's contents. When your colleague uses the key to unlock (unencrypt) the mailbox, they will need to know the secret code that the letter is written in to be able to understand the message. Everyone who is not aware of the secret code will conclude that the letter is a random mix of characters and will not be able to understand the letter's contents.\n\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_00045-7-1433","score":0.0158730159,"text":"\nKey management by application \n\nThis topic describes how to manage column encryption keys by application. It explains how to provide master keys and how to write and read encrypted data using these master keys.\n\n\n\n Providing master keys \n\nTo provide master keys:\n\n\n\n1. Set the class implementing EncryptionPropertiesFactory:\n\nparameter name: \"parquet.crypto.factory.class\"\nparameter value: \"com.ibm.parquet.key.management.IBMKeyToolsFactory\"\n2. Pass the explicit master keys, in the following format:\n\nparameter name: \"parquet.encryption.key.list\"\nparameter value: \"<master key ID>:<master key (base64)> , <master key ID>:<master key (base64)>..\"\n\nFor example:\n\nsc.hadoopConfiguration.set(\"parquet.crypto.factory.class\",\"com.ibm.parquet.key.management.IBMKeyToolsFactory\")\nsc.hadoopConfiguration.set(\"parquet.encryption.key.list\" , \"k1:iKwfmI5rDf7HwVBcqeNE6w== , k2:LjxH\/aXxMduX6IQcwQgOlw== , k3:rnZHCxhUHr79Y6zvQnxSEQ==\")\n\nThe length of master keys before base64 encoding can be 16, 24 or 32 bytes (128, 192 or 256 bits).\n\n\n\n\n\n\n\n Writing encrypted data \n\nTo write encrypted data:\n\n\n\n1. Specify which columns to encrypted, and which master keys to use:\n\nparameter name: \"parquet.encryption.column.keys\"\nparameter value: \"<master key ID>:<column>,<column>;<master key ID>:<column>,...\"\n2. Specify the footer key:\n\nparameter name: \"parquet.encryption.footer.key\"\nparameter value: \"<master key ID>\"\n\nFor example:\n\ndataFrame.write","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-key-management-application-serverless"},{"document_id":"ibmcld_08766-5724-7551","score":0.015625,"text":"\n[Application encryption by using PKCS #11](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/application-encryption-pkcs11.svg)\n\nFigure 3. Application encryption by using PKCS #11\n\n\n\n\n\n Databases encryption by using the PKCS 11 API \n\nWith Hyper Protect Crypto Services, you can encrypt Oracle\u00ae Database by using Transparent Data Encryption (TDE) and encrypt IBM Db2\u00ae Database by using Db2 default encryption.\n\n\n\n* With TDE, you can encrypt sensitive data on database storage media, such as table spaces and files, and on backup media. Transparent Data Encryption ensures that sensitive data is encrypted, meets compliance, and provides functionality that streamlines encryption operations. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTDE uses a two-tiered key hierarchy that is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-database.svg)\n\nFigure 4. Transparent Database Encryption by using the standard PKCS #11 API\n* IBM Db2 default encryption protects key database files and database backup images from inappropriate access while they are stored on external storage media. The database system automatically encrypts and decrypts data when it is used by authorized users and applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_12678-7-2410","score":0.015625,"text":"\nKnown issues (Limitations) \n\nUse this topic to find the details of the limitations that are applicable to the Data Security Broker software.\n\n\n\n Application-level Encryption: \n\nData Security Broker encryption gives database applications a no-code way to implement application-level encryption. Application-level encryption can be implemented by including a database proxy that intercepts and encrypts sensitive data in accordance with the pre-established data protection policy.\n\nData Security Broker encryption has some restrictions, like any other approaches to the application-level encryption implementation. The various aspects of the application level encryption limitations are explained below:\n\nPerformance hit Data encryption consumes more time and resources than data decryption. This overhead is normally negligible. If the proxy (Shield) has an appropriately sized CPU and Memory, there should not be any noticeable performance penalties. Most users experience a 10--20% reduction in the overall application performance. This can be mitigated by horizontal scaling. In the event of failure, Shield can be horizontally scaled by adding more of them behind a load balancer.\n\nKey management You must have a place to store your secret key or key file. You can use IBM Key Protect. IBM Key Protect provides full encryption visibility and control, allowing you to see and manage data encryption and the entire key lifecycle from a single location. Alternatively, you can secure the information with a password, but this reduces security, depending on the level of your password's strength.\n\nAccessibility If your key file is lost, your data is also lost. So, make a backup of your data and your key.\n\nDatabase operations carried out on encrypted versions of the data The information is kept in encrypted form in the database and the database engine and, consequently, the database administrator is never permitted to see the information in form of the plaintext.\n\nMany of today's server and network technologies allow for easier configuration and implementation to minimize the impact on utilization. Implementing encryption of data in transit from endpoint to endpoint both remotely and internally is mandatory in today's cyber risk environment.\n\nThe following are considered equality check operators and are supported:\n\n\n\n* =\n* <>\n* IS NULL\n* IS NOT NULL\n* IN\n* NOT\n* JOIN (all types)\n* GROUP BY","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_limitations"},{"document_id":"ibmcld_13108-7-2001","score":0.0153846154,"text":"\nAbout Key Protect \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae is a full-service encryption solution that allows data to be secured and stored in IBM Cloud using the latest envelope encryption techniques that leverage FIPS 140-2 Level 3 certified cloud-based hardware security modules.\n\nSensitive data should not be stored on any cloud provider unencrypted (as \"plaintext\", in other words). But just as with any method of encryption, going back to the earliest known ciphertexts created thousands of years ago, the trick is not just to encrypt information so that it cannot be decoded easily but to protect the ciphers used to encrypt and decrypt it (since having a cipher is as good as having the data).\n\nWhile it is possible to set up a hardware security module (HSM) on premises to manage your data, this kind of system can be very expensive to establish and manage. Cloud-based storage, where encrypted data must be accessible at scale and at speed from a variety of permissioned actors, is less expensive, but has its own difficulties. How can you be sure that the data is secure when the key used to encrypt it (what's known as a \"data encryption key\") could exist on dozens if not hundreds of computers spread all over the world? In that scenario, your data is only as secure as the computers and connections of those with the data encryption key.\n\nThe solution is a key management system like Key Protect, which keeps data secure by encrypting the data encryption keys (DEKs) that encrypt your plaintext data with root keys managed by IBM via an impenetrable HSM. In this kind of a system, known as \"envelope encryption\", the process of decrypting the data means first \"unwrapping\" the encrypted DEK (opening its envelope, in other words) and then using the DEK to decrypt the data.\n\nFor more information about envelope encryption works, check out [Protecting data with envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption).\n\n\n\n What Key Protect offers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/key-protect?topic=key-protect-about"},{"document_id":"ibmcld_15105-4-2010","score":0.0153846154,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Creating block storage volumes with customer-managed encryption \n\nBy default, Block Storage for VPC boot and data volumes are encrypted with IBM-managed encryption. You can also create customer-managed encrypted volumes by using a supported key management service to create or import your customer root key. Your data is protected while in transit and while at rest.\n\n\n\n Before you begin \n\nTo create block storage volumes with customer-managed encryption, you must first provision a key management service and create or import your customer root key (CRK). You must also authorize access between Cloud Block Storage and the key management service. When you complete these prerequisites, you can start creating block storage volumes that use customer-managed encryption.\n\nFor more information about prerequisite steps, see [Prerequisites for setting up customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-planningbyok-encryption-prereqs).\n\n\n\n\n\n Creating customer-managed encryption data volumes in the UI \n\nThis procedure explains how to specify customer-managed encryption when you create a stand-alone block storage volume. You can also specify customer-managed encryption for volumes that are created during instance provisioning. For more information, see [Creating virtual server instances with customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-instances-byok).\n\nFollow these steps to specify customer-managed encryption from the UI:\n\n\n\n1. In the [IBM Cloud console](https:\/\/cloud.ibm.com\/login), go to menu icon ![menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg) > VPC Infrastructure > Storage > Block storage volumes to view a list of your block storage volumes.\n2. Select New volume.\n3. Enter the information in Table 1 to define your new block storage volume.\n4. Update the fields in the Encryption section (see Table 2). When your changes are complete, click Create Volume.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-encryption"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14598-9419-11893","score":0.0325224749,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_14738-7598-10031","score":0.0322664585,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_12738-3824-6006","score":0.0161290323,"text":"\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilites for security and regulation compliance\nThe rows are read from left to right. The first column describes the task that the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n IBM Responsibilities Your Responsibilities \n\n Meet security and compliance objectives Provide a secure service that complies with key standards. For more information about data security, see [How do I know that my data is safe](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-security)? Ensure that you are properly securing your workloads and data so that you are meeting the regulatory standards for your organization. For more information about bucket requirements for results storage, see [Storing and processing data](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-storage). \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilites for disaster recovery\nThe rows are read from left to right. The first column describes the task that the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n IBM responsibilities Your responsibilities \n\n Back up of management and configuration data Conduct backups of configurations such as attachments and scan settings. \n Back up of scan results Conduct backups of your Cloud Object Storage data according to best practices. \n Recovery of configuration Conduct recovery in the original region when availability is returned. \n Recovery of scan results Conduct recovery of your Cloud Object Storage data according to best practices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-responsibilities"},{"document_id":"ibmcld_01092-7-2034","score":0.0158730159,"text":"\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.idrca.doc\/overview\/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dr"},{"document_id":"ibmcld_00057-5736-7021","score":0.015625,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n General <br><br> * Restore or rebuild the provisioning environments in the affected regions.<br> * Restore existing Spark clusters, where possible.<br><br><br> <br><br> * Track instance state.<br> * Provision new Spark instances in alternatively available regions.<br> * Ensure that the Spark instance is stateless by making sure that all data, metadata and applications reside outside of the cluster. This activity must be completed before disaster recovery can be initiated.<br> * Provision a new service instance in an alternatively available region if the current instances can't be accessed.<br> * Track instance state.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-responsibilities-serverless"},{"document_id":"ibmcld_15843-7468-9604","score":0.015625,"text":"\nAudit records IBM provides audit records of the VPC resource lifecycle through IBM Cloud Activity Tracker. The Customer uses IBM Cloud Activity Tracker tooling to monitor audit records. \n Security groups and ACLs IBM provides the ability to restrict access to virtual server instances by using security groups and networks ACLs. The Customer uses security groups and network ACLs to secure their virtual server instances, such as restricting what IP addresses can SSH into the instance. \n Public Network Access IBM provides options to use a public gateway or floating IP addresses. The Customer chooses how to connect their workload to the public internet, if applicable, either through a public gateway or floating IP. \n Access restriction IBM provides security measures for customers to restrict access to resources and resource groups. The Customer restricts user access to the appropriate resources and resource groups. \n Activity tracker IBM provides logging and monitoring tools. The Customer integrates IBM Cloud Activity Tracker and IBM Cloud Monitoring data into their auditing and monitoring processes. \n Encryption IBM Cloud VPN for VPC supports encrypted traffic by using IKE\/IPsec policies. The Customer ensures that their connection is encrypted end-to-end, if required. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Load balancer and VPN disaster recovery IBM Cloud Load Balancer and VPN for VPC have off-site storage and replication of configuration data in an out-of-region disaster recovery node with daily backups. This data is fully managed by IBM Cloud and no customer input is required to ensure service recovery, although there can be up to a 24-hour loss of configuration data. The Customer sets up their backup and recovery strategies for workload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpc"},{"document_id":"ibmcld_00057-4367-6381","score":0.0153846154,"text":"\nAccess control of the service instance through IAM <br><br> * Verify the user's permissions on the service instance before allowing access.<br><br><br> <br><br> * Maintain responsibility for any service roles that you create for your instances.<br><br><br> \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n General <br><br> * Maintain controls commensurate to various industry compliance standards.<br> * Monitor, isolate, and recover instances.<br> * Monitor and report the health of instances in the various interfaces.<br> * Secure cluster access through TLS\/SSH (data plane in the IBM Services account).<br> * Integrate IBM Analytics Engine with IBM Cloud Identity and Access Management (IAM).<br><br><br> <br><br> * Set up and maintain security and regulation compliance for the IBM Analytics Engine instances.<br><br><br> \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-responsibilities-serverless"},{"document_id":"ibmcld_08669-4740-6634","score":0.0153846154,"text":"\nYou are responsible for the security and compliance of your application data.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM responsibilities Your responsibilities \n\n Applications Maintain controls that are commensurate to [various industry compliance standards](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-security-and-compliancecompliance-ready). Set up and maintain security and regulation compliance for your apps and data. For example, you can enable extra security settings to meet your compliance needs by choosing how and when to [import](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [wrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-wrap-keys), [rotate](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [rewrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-rewrap-keys), and [delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) keys. \n Encryption IBM is responsible for the encryption of keys. Keep your root of trust, the master key parts, on either your workstation or smart cards. \n Master key backups IBM never touches your master key. Backup your master key in a regular basis to your smart card or workstation. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_09883-8517-10612","score":0.0151515152,"text":"\nQueue Manager <br><br> * Maintain controls to meet industry compliance standards such as ISO27k<br> * Provide default queue manager resources that are TLS enabled<br> * Monitor, isolate, and recover the queue manager<br> * Automatically apply security patch updates<br> * Disable certain insecure actions such as channel exits<br> * Continuously monitor queue manager images to detect vulnerability and security compliance issue<br><br><br> <br><br> * Configure queue manager security such as TLS and AMS on queue manager resources<br> * Configure authority records for queue manager resources to limit access to only required users and applications<br><br><br> \n\n\n\n\n\n\n\n Disaster recovery \n\nYou and IBM share responsibilities for the set up and maintenance of your IBM MQ on IBM Cloud environment. You are responsible for disaster recovery of your application data.\n\n\n\nTable 6. Responsibilities for disaster recovery\nThe rows are read from left to right. The resource area of comparing responsibilities is in the first column, with the responsibilities of IBM in the second column and your responsibilities in the third column.\n\n Resource IBM responsibilities Your responsibilities \n\n Queue Manager <br><br> * Backup queue manager configuration daily<br> * Recover required infrastructure<br> * Provision new infrastructure in a backup availability zone, if recovery is not possible<br> * Redeploy queue managers to new availability zone<br> * Restore queue manager configuration from previous backup<br><br><br> <br><br> * [Register for disaster recovery notifications](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_dr_notifications)<br> * Reset channel sequence numbers so that channels will successfully communicate<br><br><br> \n\n\n\n\n\n\n\n Applications and data \n\nYou are completely responsible for the applications and data that you use with IBM MQ on IBM Cloud . However, IBM provides various tools to help you set up, manage, secure, integrate and optimize your apps as described in the following table.\n\n\n\nTable 7. Applications and data\nThe rows are read from left to right.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_responsibilities"},{"document_id":"ibmcld_07285-5829-8487","score":0.0151515152,"text":"\nIdentity and access IBM provides the function to restrict access to resources through the IBM Cloud console and REST APIs. The Customer is responsible for managing access to resources through IBM Cloud Identity and Access Management (IAM). \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks, such as security controls implementation and compliance certification.\n\n\n\nTable 5. Responsibilities for security and regulation compliance\n\n Task IBM Responsibilities Your Responsibilities \n\n Encryption IBM does not provide encryption capabilities. The Customer is responsible for encryption of data on disk, in motion, and in backups. The Customer is also responsible for choosing and managing appropriate additional security features. If the Customer uses Key Protect (Bring Your Own Key), or another form of encryption, the Customer is responsible for managing the service authorization and keys. \n Security IBM is responsible for ensuring the security of data on disk and data in motion within its infrastructure. The Customer is responsible for restricting user access to the appropriate resources and resource groups. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks, such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Diversity IBM provides diverse network options for consumption. The Customer must ensure diversity of Direct Link is deployed. \n Redundancy IBM provides diverse network options for consumption. Direct Link is not a redundant service. The Customer is responsible for establishing redundancy, as needed, via BGP schema. The Customer must also understand that Direct Link is not a redundant service. While IBM Cloud supplies Diverse Router (XCR) options, failover must be built into the BGP scheme a customer deploys between multiple Direct Links. \n Host service in multiple regions IBM is responsible for hosting this service in multiple regions. The Customer is responsible for designing and deploying their workload in a way that achieves the wanted availability and Disaster Recovery capabilities by using provided tools. For example, deploy in different zones of a region, use at least two load balancers that are located in different zones, and either use DNS records to point to the load balancers, or ensure that your application can handle a list of IP addresses that it can connect to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-responsibilities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15493-2770-3452","score":0.0163934426,"text":"\nUpdated IAM granular IAM actions without administrator permission\n\n Operation Previous action Current action \n\n List routing tables in a vpc is.vpc.vpc.read is.vpc.routing-table.list \n Read a routing table in a vpc is.vpc.vpc.read is.vpc.routing-table.read \n Create a new routing table in a vpc is.vpc.vpc.update is.vpc.routing-table.create \n Update routing table is.vpc.vpc.update is.vpc.routing-table.update \n Create, update, and delete routes in a routing table in a vpc is.vpc.vpc.update is.vpc.routing-table.update \n Delete a routing table in a vpc is.vpc.vpc.update is.vpc.routing-table.delete \n Operate a routing table in a vpc is.vpc.vpc.operate is.vpc.routing-table.operate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-iam-actions-vpc-routing-tables"},{"document_id":"ibmcld_13121-9936-12177","score":0.0163934426,"text":"\nThe rule has been enforced and, based on how you tried to access the registry, the access has been denied. The reason is that rule allows access from a specific VPC only. The Cloud Shell environment and its IP address, as documented in the logs in the requestData->environment fields, differ. Therefore, the request is denied.\n\n\n\nWhen working with the Activity Tracker logs, you can utilize query strings like the following to easily find the relevant log records:\n\n\n\n* When in report mode, \"context restriction\" permit OR deny returns the log lines with access which would have rendered a Permit or Deny.\n* In report mode, you can use \"context restriction\" permit to only show access which would have been the permitted. Similarly, use \"context restriction\" deny for denied access.\n* Last, when in enforced mode, use a query string like context restriction rendered for log lines related to denied access.\n\n\n\nMonitoring a new rule is recommended for 30 days prior to enforcing it. Learn more about [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor) both in report-only and enabled mode in the CBR documentation.\n\nIn order to prepare for the deployment of CBR objects with Terraform in a section further down, go to the browser tab with the [CBR rules](https:\/\/cloud.ibm.com\/context-based-restrictions\/rules). There, delete the previously created rule by clicking on its dot menu and selecting Remove and then confirming with Delete. Thereafter, click on Network zones and delete the previously created zone.\n\n\n\n\n\n Step 5: Define the access strategy for your cloud resources \n\nTo set up the right set of rules for context-based restrictions (CBRs), you should have defined the access strategy for your cloud resources. All resources should be protected by identity and access management (IAM). It means, that authentication and authorization checks should be performed before a user or service ID accesses a resource. CBRs add to the protection by cutting off network access based on origin criteria and other rules, but they do not replace proper IAM configuration. Additionally, many services support limiting network traffic to private endpoints, thereby already reducing access options.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security"},{"document_id":"ibmcld_14953-7386-9187","score":0.0161290323,"text":"\nsubnet is.subnet.public-gateway.attach Public Gateway was attached to Subnet \n subnet is.subnet.public-gateway.detach Public Gateway was detached from Subnet \n subnet is.subnet.public-gateway.read A subnet public-gateway attachment was retrieved \n\n\n\n\n\n\n\n Virtual private endpoints events \n\nThe following table lists the actions that are related to virtual private endpoints and the generation of events.\n\n\n\nTable 9. Actions that generate events for virtual private endpoints\n\n Resource Action Description \n\n endpoint-gateway is.endpoint-gateway.endpoint-gateway.create Endpoint gateway was created \n endpoint-gateway is.endpoint-gateway.endpoint-gateway.delete Endpoint gateway was deleted \n endpoint-gateway is.endpoint-gateway.endpoint-gateway.update Endpoint gateway was updated \n\n\n\n\n\n\n\n VPC events \n\n\n\nTable 10. Actions that generate events for VPC\n\n Resource Action Description \n\n vpc is.vpc.vpc.create VPC was created \n vpc is.vpc.vpc.update VPC was updated \n vpc is.vpc.vpc.delete VPC was deleted \n vpc is.vpc.vpc.read One or more VPC was retrieved \n vpc is.vpc.address-prefix.create Address Prefix was added to VPC \n vpc is.vpc.address-prefix.update VPC Address Prefix was updated \n vpc is.vpc.address-prefix.delete Address Prefix was removed from VPC \n vpc is.vpc.address-prefix.read One or more address prefixes were retrieved \n vpc is.vpc.vpc-route.create Route was added to VPC \n vpc is.vpc.vpc-route.update VPC Route was updated \n vpc is.vpc.vpc-route.delete Route was removed from VPC \n\n\n\n\n\n\n\n VPN gateway events \n\nThe following table lists the actions that are related to site-to-site VPN gateways and the generation of events.\n\n\n\nTable 11. Actions that generate events for site-to-site VPN gateways\n\n Resource Action Description \n\n vpn is.vpn.vpn-gateway.create VPN gateway was created","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-at-events"},{"document_id":"ibmcld_05149-2956-5004","score":0.0161290323,"text":"\nAn IP address that is allowed by context-based restrictions can still be denied by the bucket firewall.\n\n\n\n About legacy bucket firewalls \n\nThere are some rules around setting a firewall:\n\n\n\n* A user that sets or views a firewall must have the Manager role on the bucket.\n* A user with the Manager role on the bucket can view and edit the list of allowed IP addresses from any IP address to prevent accidental lockouts.\n* The Object Storage Console can still access the bucket, provided the user's IP address is authorized.\n* Other IBM Cloud services are not authorized to bypass the firewall. This limitation means that other services that rely on IAM policies for bucket access (such as Aspera, SQL Query, Security Advisor, Watson Studio, Cloud Functions, and others) will be unable to do so.\n\n\n\nWhen a firewall is set, the bucket is isolated from the rest of IBM Cloud. Consider how this may impact applications and workflows that depend on other services directly accessing a bucket before enabling the firewall. This can be avoided by using [service references and context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis&interface=uiservice-attribute) instead.\n\nAccess from a VPC environment can pass allowed_network_type checks, and VPC-zone underlay IP addresses can be added to the allowed_ip list. It is not possible to restrict access to an overlay IP for an individual VPC VSI or bare-metal server.\n\nFirst, make sure that you have an instance of Object Storage and have provisioned at least one bucket. If not, follow the [getting started tutorial](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) to obtain the prerequisites and become familiar with the console.\n\n\n\n Set a list of authorized IP addresses using a legacy firewall \n\n\n\n1. Start by selecting Storage to view your resource list.\n2. Next, select the service instance with your bucket from within the Storage menu. This takes you to the Object Storage Console.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall"},{"document_id":"ibmcld_15790-987-2174","score":0.0158730159,"text":"\n* For more information on creating a VPC, see [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started&interface=uicreate-and-configure-vpc).\n\n\n\n* security-group\n\n\n\n* For more information, see [About security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups&interface=ui).\n\n\n\n* subnet\n\n\n\n* For more information on creating a subnet, see [Using the IBM Cloud console to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console), [Using the REST APIs to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-rest-apis), or [Using the CLI to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-clicreate-a-subnet-cli).\n* For more information on deleting a subnet, see [Deleting VPC resources by using the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-console), [Deleting VPC resources by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-cli), or [Deleting VPC resources by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-api).\n\n\n\n* floating-ip","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quota-troubleshooting"},{"document_id":"ibmcld_16507-7-2044","score":0.0158730159,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_15790-1791-3014","score":0.015625,"text":"\n* For more information on deleting a subnet, see [Deleting VPC resources by using the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-console), [Deleting VPC resources by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-cli), or [Deleting VPC resources by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-api).\n\n\n\n* floating-ip\n\n\n\n* For more information on creating a floating IP, see [Using the IBM Cloud console to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console), [Using the REST APIs to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-rest-apis), or [Using the CLI to create VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-clicreate-a-subnet-cli).\n* For more information on deleting a floating IP, see [Deleting VPC resources by using the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-console), [Deleting VPC resources by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-cli), or [Deleting VPC resources by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-using-api).\n\n\n\n* network-acl","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quota-troubleshooting"},{"document_id":"ibmcld_02953-2323-4257","score":0.015625,"text":"\n[Location](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/location.png) icon next to it.\n\nIf you are not already on the Dialog page, open it.\n7. To check or set the value of a context variable, click the Manage context link.\n\nAny context variables that you defined in the dialog are displayed.\n\nIn addition, a $timezone context variable is listed. The Try it out pane user interface gets user locale information from the web browser and uses it to set the $timezone context variable. This context variable makes it easier to deal with time references in test dialog exchanges. Consider doing something similar in your user application. If not specified, Greenwich Mean Time (GMT) is used.\n\nYou can add a variable and set its value to see how the dialog responds in the next test dialog turn. This capability is helpful if, for example, the dialog is set up to show different responses based on a context variable value that is provided by the user.\n\n\n\n1. To add a context variable, specify the variable name, and press Enter.\n2. To define a default value for the context variable, find the context variable you added in the list, and then specify a value for it.\n\n\n\nSee [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information.\n8. Continue to interact with the dialog to see how the conversation flows through it.\n\n\n\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_15243-15216-16532","score":0.0153846154,"text":"\nImage ibmcloud is image [List all images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referenceimages-list) \n Boot volume ibmcloud is volumes [List all volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referencevolumes-list) \n Profile ibmcloud is instances [List all virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referenceinstances-list) \n Keys ibmcloud is keys [List all keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-referencekeys)<br><br>If you don't have any available SSH keys, use [Create a key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-referencekey-create) to create one.<br><br>Note: RSA and Ed25519 are the two types of SSH keys that you can use. However, you can't use the Ed25519 SSH key type with Windows or VMware images. You can use only RSA SSH keys for these images. <br>For more information, see [Getting started with SSH keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys). \n VPC ibmcloud is vpcs [List all VPCs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referencevpcs-list) \n Subnet ibmcloud is subnets [List all subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referencesubnets-list) \n Zone ibmcloud is zones [List all regions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referencezones-list)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers"},{"document_id":"ibmcld_00450-9976-11836","score":0.0153846154,"text":"\nIn other words, the replicator database implementation is similar to a _changes feed consumption application, with ?include_docs=true set.\n\nFor replication, this implementation difference means that for nonadmin users, a user_ctx property that includes the user's name and a subset of their roles must be defined in the replication document. This requirement is addressed by a validation function present in the default design document of the replicator database. The function validates each document update. This validation function also ensures that a nonadmin user can't set a username property in the user_ctx property that doesn't correspond to the correct username. The same principle also applies for roles.\n\nSee the following example delegated replication document:\n\n{\n\"_id\": \"my_rep\",\n\"source\": \"https:\/\/$ACCOUNT:$PASSWORD@$SERVER.com:5984\/foo\",\n\"target\": \"https:\/\/$ACCOUNT:$PASSWORD@$ACCOUNT.cloudant.com\/bar\",\n\"continuous\": true,\n\"user_ctx\": {\n\"name\": \"joe\",\n\"roles\": [\"erlanger\", \"researcher\"]\n}\n}\n\nFor admins, the user_ctx property is optional. If the property is missing, the value defaults to a user context with the name null and an empty list of roles.\n\nThe empty list of roles means that design documents aren't written to local targets during replication. If you want to write design documents to local targets, then a user context with the _admin role must be set explicitly.\n\nAlso, for admins, the user_ctx property can be used to trigger a replication for another user. This user context is passed to local target database document validation functions.\n\nThe user_ctx property applies to local endpoints only.\n\nIn summary, for admins, the user_ctx property is optional. While for regular (nonadmin) users, it's mandatory. When the roles property of user_ctx is missing, it defaults to the empty list [ ].\n\n\n\n\n\n Performance-related options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replication"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-93516-95314","score":0.0163934426,"text":"\n-A All number types Unary negative operator. The type of the result is the same as the type of A. \n +A All number types Unary positive operator. The type of the result is the same as the type of A. \n A All number types Bitwise NOT operator. The type of the result is the same as the type of A. \n\n\n\n\n\n\n\n Arithmetic operators \n\n\n\nTable 51. Arithmetic operators.\n\n Operator Operand types Description \n\n A + B All number types Returns the result of adding A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A - B All number types Returns the result of subtracting B from A. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A * B All number types Returns the result of multiplying A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. If the operation causes an overflow, cast at least one of the operators to a type that is higher in the type hierarchy. \n A \/ B All number types Returns the result of dividing A by B. The type of the result is DOUBLE. \n A % B All number types Returns the remainder after dividing A by B. For example, 13.7 % 3 returns 1.7. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A DIV B Integer types Returns the integer part of the result of dividing A by B. For example, 13.7 DIV 3 returns the integer 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_04516-52086-53381","score":0.0163934426,"text":"\n--tags or -t Optional Tags can be used multiple times to search for and locate agent policies faster. \n --target-file or tf Optional Path to the JSON file containing the definition of the policy. \n --output or -o Optional Specify output format, only JSON is supported. \n --no-prompt Optional Set this flag to run the command without user prompts. \n\n\n\n\n\n Using the payload file \n\nYou can provide a payload file to specify certain parameters for the policy create command. Then, you pass the file name to the command by using the --target-file command option.\n\nYou need to replace the <...> placeholders with the actual values. For example, \"<SELECTOR_KIND>\" as \"ids\".\n\nSyntax\n\n{\n\"target\": {\n\"selector_kind\": \"<SELECTOR_KIND>\",\n\"selector_ids\": [\n\"<SELECTOR_ID>\"\n]\n},\n\"parameter\": {\n\"agent_assignment_policy_parameter\": {\n\"selector_kind\": \"<SELECTOR_KIND>\",\n\"selector_scope\": [{\n\"kind\": \"<WORKSPACE>\",\n\"tags\":\n\"dev:<ENVIRONMENT>\",\n\"demo\"\n],\n\"resource_groups\":\n\"<RESOURCE_GROUP>\"\n],\n\"locations\":\n\"<LOCATION>\"\n]\n}]\n}\n}\n}\nShow more\n\nExample\n\n{\n\"target\": {\n\"selector_kind\": \"ids\",\n\"selector_ids\": [\n\"demo-agent-one\"\n]\n},\n\"parameter\": {\n\"agent_assignment_policy_parameter\": {\n\"selector_kind\": \"scoped\",\n\"selector_scope\": [{\n\"kind\": \"workspace\",\n\"tags\":\n\"dev:test\",\n\"demo\"\n],\n\"resource_groups\":\n\"test\"\n],","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-schematics-cli-reference"},{"document_id":"ibmcld_00708-29824-30761","score":0.0161290323,"text":"\n\"title\": \"User Profile Standard v2 Schema\",\n\"type\": \"object\",\n\"properties\": {\n\"id\": {\n\"type\": \"string\"\n},\n\"profile_name\": {\n\"type\": \"string\"\n},\n\"profile_version\": {\n\"type\": \"string\"\n},\n\"controls\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"control_specifications\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_count\": {\n\"type\": \"number\"\n},\n\"assessments\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_method\": {\n\"type\": \"string\"\n},\n\"assessment_description\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_count\": {\n\"type\": \"number\"\n},\n\"parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_12258-52086-53381","score":0.0161290323,"text":"\n--tags or -t Optional Tags can be used multiple times to search for and locate agent policies faster. \n --target-file or tf Optional Path to the JSON file containing the definition of the policy. \n --output or -o Optional Specify output format, only JSON is supported. \n --no-prompt Optional Set this flag to run the command without user prompts. \n\n\n\n\n\n Using the payload file \n\nYou can provide a payload file to specify certain parameters for the policy create command. Then, you pass the file name to the command by using the --target-file command option.\n\nYou need to replace the <...> placeholders with the actual values. For example, \"<SELECTOR_KIND>\" as \"ids\".\n\nSyntax\n\n{\n\"target\": {\n\"selector_kind\": \"<SELECTOR_KIND>\",\n\"selector_ids\": [\n\"<SELECTOR_ID>\"\n]\n},\n\"parameter\": {\n\"agent_assignment_policy_parameter\": {\n\"selector_kind\": \"<SELECTOR_KIND>\",\n\"selector_scope\": [{\n\"kind\": \"<WORKSPACE>\",\n\"tags\":\n\"dev:<ENVIRONMENT>\",\n\"demo\"\n],\n\"resource_groups\":\n\"<RESOURCE_GROUP>\"\n],\n\"locations\":\n\"<LOCATION>\"\n]\n}]\n}\n}\n}\nShow more\n\nExample\n\n{\n\"target\": {\n\"selector_kind\": \"ids\",\n\"selector_ids\": [\n\"demo-agent-one\"\n]\n},\n\"parameter\": {\n\"agent_assignment_policy_parameter\": {\n\"selector_kind\": \"scoped\",\n\"selector_scope\": [{\n\"kind\": \"workspace\",\n\"tags\":\n\"dev:test\",\n\"demo\"\n],\n\"resource_groups\":\n\"test\"\n],","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference&interface=cli"},{"document_id":"ibmcld_00684-29824-30761","score":0.0158730159,"text":"\n\"title\": \"User Profile Standard v2 Schema\",\n\"type\": \"object\",\n\"properties\": {\n\"id\": {\n\"type\": \"string\"\n},\n\"profile_name\": {\n\"type\": \"string\"\n},\n\"profile_version\": {\n\"type\": \"string\"\n},\n\"controls\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"control_specifications\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_count\": {\n\"type\": \"number\"\n},\n\"assessments\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_method\": {\n\"type\": \"string\"\n},\n\"assessment_description\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_count\": {\n\"type\": \"number\"\n},\n\"parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_10396-21546-22637","score":0.0158730159,"text":"\npath: \/\nport: 9080\ninitialDelaySeconds: 45\nperiodSeconds: 5\nvolumeMounts:\n- name: pvmount\nmountPath: \/test\nvolumes:\n- name: pvmount\npersistentVolumeClaim:\nclaimName: wasliberty\n---\n\napiVersion: policy\/v1beta1\nkind: PodDisruptionBudget\nmetadata:\nname: wasliberty\nspec:\nmaxUnavailable: 1\nselector:\nmatchLabels:\napp: wasliberty\n---\n\napiVersion: v1\nkind: Service\nmetadata:\nname: wasliberty\nlabels:\napp: wasliberty\nspec:\nports:\n- port: 9080\nselector:\napp: wasliberty\ntype: NodePort\n---\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: wasliberty\nlabels:\napp: wasliberty\ndata:\nVERSION: \"1.0\"\nLANGUAGE: en\n---\n\napiVersion: v1\nkind: Secret\nmetadata:\nname: wasliberty\nlabels:\napp: wasliberty\ntype: Opaque\ndata:\nusername: dXNlcm5hbWU=\npassword: cGFzc3dvcmQ=\n---\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\nname: wasliberty\nannotations:\nvolume.beta.kubernetes.io\/storage-class: \"ibmc-file-bronze\"\nlabels:\nbillingType: \"hourly\"\napp: wasliberty\nspec:\naccessModes:\n- ReadWriteMany\nresources:\nrequests:\nstorage: 24Gi\nShow more\n\n\n\n\n\n Packaging apps for reuse in multiple environments with Kustomize","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_apps"},{"document_id":"ibmcld_04341-29805-30742","score":0.015625,"text":"\n\"title\": \"User Profile Standard v2 Schema\",\n\"type\": \"object\",\n\"properties\": {\n\"id\": {\n\"type\": \"string\"\n},\n\"profile_name\": {\n\"type\": \"string\"\n},\n\"profile_version\": {\n\"type\": \"string\"\n},\n\"controls\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"control_specifications\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_count\": {\n\"type\": \"number\"\n},\n\"assessments\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_method\": {\n\"type\": \"string\"\n},\n\"assessment_description\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_count\": {\n\"type\": \"number\"\n},\n\"parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_00911-2983-4509","score":0.015625,"text":"\nThese property names are set in the delivery pipeline Properties page.\n\napiVersion: tekton.dev\/v1beta1\nkind: Task\nmetadata:\nname: cm-echo-props\nspec:\nsteps:\n- name: cm-show-props\nimage: ubuntu\nenv:\n- name: SECURE_VALUE\nvalueFrom:\nsecretKeyRef:\nname: secure-properties\nkey: apikey\n- name: ENVIRONMENT\nvalueFrom:\nconfigMapKeyRef:\nname: environment-properties\nkey: environment\ncommand: [\"\/bin\/bash\", \"-c\"]\nargs:\n- echo -e \"environment from ConfigMap is >>\";\necho $ENVIRONMENT;\necho \"\";\necho -e \"apikey from Secrets is >>\";\necho $SECURE_VALUE\nShow more\n\n\n\n\n\n Accessing all values \n\nYou can add all of the key-value pairs from the ConfigMap and Secret to your Task environment:\n\napiVersion: tekton.dev\/v1beta1\nkind: Task\nmetadata:\nname: cm-secrets-props\nspec:\nsteps:\n- name: cm-show-full-env\nimage: ubuntu\nenvFrom:\n- configMapRef:\nname: environment-properties\n- secretRef:\nname: secure-properties\ncommand: [\"\/bin\/bash\", \"-c\"]\nargs:\n- echo -e \"The environment for this Step is \";\nenv\nShow more\n\n\n\n\n\n\n\n Managed worker virtual machine (VM) sizing \n\nWhen you run a pipeline by using the IBM Managed Worker pool, a VM with a specific default memory is allocated. Although most jobs can run successfully with the provided memory, certain pipelines require extra memory for intensive tasks.\n\nUsers can specify a label on their tasks to indicate whether a task requires more (or less) memory for a specific task. This ability to identify the specific amount of resources that are required benefits resource usage and eventual cost savings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tekton_environment"},{"document_id":"ibmcld_13498-94895-96764","score":0.0153846154,"text":"\nA % B All number types Returns the remainder after dividing A by B. For example, 13.7 % 3 returns 1.7. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A DIV B Integer types Returns the integer part of the result of dividing A by B. For example, 13.7 DIV 3 returns the integer 4. \n A & B All number types Returns the result of bitwise AND of A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. \n `A B` All number types \n A ^ B All number types Returns the result of bitwise XOR of A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. \n\n\n\n\n\n\n\n String operator \n\n\n\nTable 52. String operator.\n\n Operator Operand types Description \n\n `A B` \n\n\n\n\n\n\n\n Comparison operators \n\n\n\nTable 53. Comparison operators.\n\n Operator Operand types Description \n\n A = B All primitive types Returns TRUE if A is equal to B, FALSE otherwise. \n A == B All primitive types Synonym for the equal (=) operator. \n A <> B All primitive types Returns NULL if A or B is NULL, TRUE if A is not equal to B, FALSE otherwise. \n A != B All primitive types Synonym for the not equal (<>) operator. \n A < B All primitive types Returns NULL if A or B is NULL, TRUE if A is less than B, FALSE otherwise. \n A <= B All primitive types Returns NULL if A or B is NULL, TRUE if A is less than or equal to B, FALSE otherwise. \n A !> B All primitive types Returns NULL if A or B is NULL, TRUE if A is not greater than B, FALSE otherwise. \n A > B All primitive types Returns NULL if A or B is NULL, TRUE if A is greater than B, FALSE otherwise. \n A >= B All primitive types Returns NULL if A or B is NULL, TRUE if A is greater than or equal to B, FALSE otherwise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_06056-3468-5769","score":0.0153846154,"text":"\nIf the production environment needs more than one more worker node, you might resize down some worker pools in development, create a worker pool that uses on demand worker nodes, or add more contracts to the reservation. If you are concerned about a development environment using up your production environment resources, consider creating separate reservations for the different environments.\n\n\n\n Reservation usage and lifecycle \n\nHow can I use my reservation?\n: You can use your reservation to create worker pools in new or existing clusters. Your reservation is account-wide, so you can use the reserved worker nodes in different clusters, worker pools, and even resource groups. However, because prices vary by zone, you can't use reserved worker nodes across different metros or multizone regions. You also can't used reserved instances from other IBM Cloud infrastructure services, such as virtual server instances, for your worker nodes, but must use the IBM Cloud Kubernetes Service reservations.\n\nDoes a reservation guarantee computing capacity in a zone?\n: Reserving worker nodes does not guarantee compute capacity whenever you want to create a worker pool. Instead, you reserve a certain number of worker nodes for a term so that you lock in the discounted price that is associated with the reservation.\n\nHow do I know how many reserved worker nodes I need?\n: See [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing).\n\nWhat kind of workloads are best suited for reservations?\n: The following workloads are good candidates to run on reserved worker nodes:\n\n\n\n* Production workloads\n* Mission-critical workloads that must run 24\/7\n* Predictable workloads that have continuous usage and steady states\n* Workloads that you want to increase high availability for by creating replicas in different zones and regions\n\n\n\nCan I convert existing worker nodes to reserved worker nodes to save money?\n: No. Instead, you can create reservations and contracts for the worker nodes in your clusters. Then, create worker pools in your existing clusters that use the reserved worker nodes. Consider using labels to reschedule your existing workloads to the new reserved worker pools. Then, delete your old, on demand worker pools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07549-2803-4897","score":0.0315449578,"text":"\nCopyright \u00a9 2007 Free Software Foundation, Inc. <https:\/\/fsf.org\/>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.PreambleThe GNU General Public License is a free, copyleft license for software and other kinds of works.The licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.When we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.To protect your rights, we need to prevent others from denying you these rights, or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.For example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.Developers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and\/or modify it.For the developers' and authors' protection, the GPL clearly explains that there is no warranty for this free software.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_15476-1717-3467","score":0.0306217859,"text":"\nLifecycle for CentOS operating systems\n\n Operating sytem End of support License model \n\n CentOS 8 minimal 31 December 2021 Free \n CentOS 7.9 minimal 30 June 2024 Free \n\n\n\n\n\n\n\n Debian \n\nThe following table describes the end of support date and license model for Debian operating systems. This guest OS is a free operating system. For more information, see [Debian community](https:\/\/www.debian.org\/).\n\n\n\nTable 2. Lifecycle for Debian operating systems\n\n Operating sytem End of support License model \n\n Debian 11 minimal 01 June 2026 Free \n Debian 10 minimal 01 June 2024 Free \n Debian 9 minimal 30 June 2022 Free \n\n\n\n\n\n\n\n Fedora CoreOS \n\nThe version of Fedora\u00ae CoreOS is updated regularly, with the previous release deprecating when a new version is released. This guest OS is a free operating system. For more information, see [Fedora](https:\/\/getfedora.org\/).\n\n\n\nTable 3. Lifecycle for Fedora CoreOS operating systems\n\n Operating sytem End of support License model \n\n Fedora CoreOS latest N\/A Free \n\n\n\n\n\n\n\n Red Hat Enterprise Linux (RHEL) \n\nThe following table describes the end of support date and license model for Red Hat\u00ae Enterprise Linux\u00ae operating systems. This guest OS is a paid operating system. For more information, see [Red Hat Enterprise Linux](https:\/\/www.redhat.com\/en\/technologies\/linux-platforms\/enterprise-linux).\n\n\n\nTable 4. Lifecycle for Red Hat Enterprise Linux (RHEL) operating systems\n\n Operating sytem End of support License model \n\n RHEL 9.0 minimal 31 May 2024 Pay-as-you-Go \/ BYOL \n RHEL 9.0 (SAP HANA and SAP applications) 31 May 2026 Pay-as-you-Go \n RHEL 8.6 minimal 31 May 2024 Pay-as-you-Go \/ BYOL \n RHEL 8.6 (SAP HANA and SAP applications) 31 May 2026 Pay-as-you-Go \n RHEL 8.4 minimal 31 May 2023 Pay-as-you-Go \/ BYOL","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-guest-os-lifecycle"},{"document_id":"ibmcld_11347-10510-12848","score":0.0305503731,"text":"\nWhen you attempt to resize the memory as well as CPU of a deployed virtual server instance through a single request it may fail due to the following reasons:\n\n\n\n* There is no free memory available on the host.\n* There is no free memory available on the logical partition as the resources on it are running.\n* The free memory available on the logical partition is less than that of the desired value indicated in the resizing request.\n* You have made multiple attempts for resizing.\n* Currently, there is no preference for memory or CPU on what should be resized first. If the first request being processed fails, the second one will also fail automatically.\n\n\n\nExample: When the currently allocated memory for the logical partition is 4GB and you are trying to reduce the value to 2GB and the logical partition at the time of request does not have free 2GB memory for resizing (considering the logical partition is using upto 3.2 GB for running resources in it), then there is a possibility that both the CPU and memory resize will fail.\n\n\n\n\n\n You request for resizing the memory but you get a partial resize \n\nWhen you attempt to resize the memory of a deployed virtual server instance through a request, it may partially resize or in the worst scenarios even fail due to the following reasons:\n\n\n\n* There is no free memory available on the host will result in failed request.\n* There is no free memory available on the logical partition as the resources are running on it. This will result in a failed request.\n* The free memory available on the logical partition is less than that of the desired value indicated in the resizing request. This will result in a partial resize.\n* You have made multiple attempts for resizing. This will result in a failed request.\n\n\n\nExample:When the currently allocated memory for the logical partition is 4GB and you are trying to reduce the value to 2GB and the logical partition at the time of request does not have free 2GB memory for resizing (considering the logical partition is using upto 3 GB for running resources in it) and can free up only 1 GB, then the partial resize should be possible to reduce the memory to 3GB.\n\nIn the current cloud environment, it may take upto 1.5 hours approximately for the change in memory to be updated to places referring to the memory of the logical partition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-modifying-server"},{"document_id":"ibmcld_07578-754408-756389","score":0.0163934426,"text":"\nYes, NetScaler VPX appliances support High Availability (HA) configurations.\n\nNetScaler VPX servers are not redundant, unless configured in HA mode with a partner. As part of your back up and recovery strategy, it is highly recommended to deploy an HA environment when using NetScaler VPX.\n\nIt is also important to provide redundancy for other hardware and software components. For example, power supplies and local disk drives may not have redundancy. A failure in these components may result in data loss.\n* Does the IBM Cloud NetScaler offering include SSL VPN functionality?\n\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-754871-756890","score":0.0161290323,"text":"\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04145-7-2180","score":0.0158730159,"text":"\nFAQs for IBM Cloud Internet Services \n\nHave a question about IBM Cloud\u00ae Internet Services? Review these frequently asked questions, which provide answers to provisioning concerns, application access, and other common inquiries.\n\n\n\n What do I get with a Free Trial Plan? \n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n\n\n\n\n\n How many Free Trial instances can I have? \n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n\n\n\n\n\n Can I downgrade from Standard to the Free Trial? \n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n\n\n\n\n\n My Free Trial has expired. What are my options? \n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n\n\n\n\n\n What happened to Enterprise Package plans? \n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_11650-6280-7614","score":0.0158730159,"text":"\n* Allow inbound DNS traffic (UDP port 53)\n* Allow inbound SSH traffic (TCP port 22)\n\n\n\nAfter the successful deployment of the infrastructure, the Terraform script calls the Ansible Playbook, which automatically installs the SAP application. Access creating single-tier VPC for SAP by using Terraform to get the detailed steps about using Terraform only for the creation of a VPC for SAP.\n\n\n\n\n\n Ansible for SAP installation \n\nAnsible is an automation tool for the deployment several IT tasks. This solution performs the automated deployment of SAP HANA 2.0 DB on Red Hat Enterprise Linux 7.6 for SAP HANA on stand-alone SAP HANA box VSI. For more information about Ansible, check out the documentation available on the Ansible page.\n\nThe deployment is done by the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found on [the Ansible core page](https:\/\/docs.ansible.com\/ansible-core\/devel\/index.html).\n\nThe Ansible playbook is called directly by the Terraform script. The Terraform script is run in one run. During the run, the first steps are Terraform specific for creating the VPC, and it continues automatically with the second, Ansible, steps for the installation of the SAP system.\n\nThis automation is offered free of charge however, the provisioned infrastructure comes at cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-hana-vpc-background"},{"document_id":"ibmcld_11142-7-1829","score":0.015625,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_04082-13243-15143","score":0.0153846154,"text":"\nHow does pricing work on the IBM Blockchain Platform for IBM Cloud? \n\nIBM Blockchain Platform for IBM Cloud is priced based on the VPCs that you allocate to your blockchain nodes on the IBM Kubernetes Service. For more information, see [Pricing for IBM Blockchain Platform for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing).\n\n\n\n\n\n What are the limitations of the free IBM Blockchain Platform using the IBM Cloud Kubernetes Service free cluster? \n\n\n\n* Preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.\n* Selecting a specific Kubernetes zone when deploying a node.\n* Overriding node configuration during or after deployment by using the console or APIs.\n* Adding or removing ordering nodes to an ordering service. The free offering only supports a single node Raft ordering service.\n\n\n\nSee [Find out how to preview the platform free for 30 days](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for more information on how to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-faq"},{"document_id":"ibmcld_13096-4887-5549","score":0.0153846154,"text":"\nYou must manually configure logrotate and journald to leave a small percentage of the file systems free. To do this, configure SystemKeepFree=15% in \/etc\/systemd\/journald.conf.\n\nCheck regularly that a percentage of the file system is still free. For the logrotatation configuration, make sure that your log files do not get too large. Compress and remove log files (or move them to your data volume) before they break your system.\n\nLogging configuration recommendations:\n\n\n\n* Create a non-root user for each application and run each application with that non-root user.\n* Configure the application's logging and log rotation as the user who runs the application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-protect_vs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03310-1389-3175","score":0.0163934426,"text":"\nThe following table shows examples of the shorthand syntax that you can use to write context variables in condition expressions.\n\n\n\n Shorthand syntax Full syntax in SpEL \n\n $card_type context['card_type'] \n $(card-type) context['card-type'] \n $card_type:VISA context['card_type'] == 'VISA' \n $card_type:(MASTER CARD) context['card_type'] == 'MASTER CARD' \n\n\n\nYou can include special characters, such as hyphens or periods, in context variable names. However, doing so can lead to problems when the SpEL expression is evaluated. The hyphen could be interpreted as a minus sign, for example. To avoid such problems, reference the variable by using either the full expression syntax or the shorthand syntax $(variable-name) and do not use the following special characters in the name:\n\n\n\n* Parentheses ()\n* More than one apostrophe ''\n* Quotation marks \"\n\n\n\nWhen you refer to a context variable in a text response or a dialog node condition, you can use the short syntax.\n\nFor example, Hello, $name. If the $name context variable contains Sam, then the response is shown as Hello, Sam.\n\nIf you want to reference a context variable by using the full syntax in a text response, be sure to surround the context variable in <? ?>. For example, Hello, <? context['name'] ?>.\n\nIf you want to reference a context variable that has multiple fields, such as $context.integrations.chat.browser_info.page_url. To use the full sytnax, specify <? context['integrations']['browser_info'] ?>.\n\n\n\n\n\n Shorthand syntax for entities \n\nThe following table shows examples of the shorthand syntax that you can use when referring to entities.\n\n\n\n Shorthand syntax Full syntax in SpEL \n\n @year entities['year']?.value \n @year == 2016 entities['year']?.value == 2016 \n @year != 2016 entities['year']?.value != 2016","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"},{"document_id":"ibmcld_12537-4970-7359","score":0.0161290323,"text":"\nReview each service's documentation to learn more about how they integrate with context-based restrictions.\n\nYou can also skip APIs to restrict all operations on the service that you select.\n\n\n\n\n\n\n\n Contexts \n\nContexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.\n\n\n\n* If a context includes network zones, then access is granted only when the request is created from within one of those zones.\n* If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those types.\n* If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be granted.\n\n\n\n\n\n Network zone \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets.\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services.\n\n\n\n\n\n IP addresses \n\nCustomers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.\n\n\n\n\n\n VPCs \n\nIf you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don\u2019t have to find the IP addresses that the VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.\n\n\n\n\n\n Service references \n\nA service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.\n\nThe following is a list of services that you can add to a network zone as a service reference:\n\n\n\nTable 1. Services that are compatible with service references.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-context-restrictions-whatis"},{"document_id":"ibmcld_01790-5035-7392","score":0.0158730159,"text":"\nYou can also skip APIs to restrict all operations on the service that you select.\n\n\n\n\n\n\n\n Contexts \n\nContexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.\n\n\n\n* If a context includes network zones, then access is granted only when the request is created from within one of those zones.\n* If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those types.\n* If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be granted.\n\n\n\n\n\n Network zone \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets.\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services.\n\n\n\n\n\n IP addresses \n\nCustomers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.\n\n\n\n\n\n VPCs \n\nIf you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don\u2019t have to find the IP addresses that the VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.\n\n\n\n\n\n Service references \n\nA service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.\n\nThe following is a list of services that you can add to a network zone as a service reference:\n\n\n\nTable 1. Services that are compatible with service references.\n\n Service Service type \n\n All Account Management services Account Management","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis"},{"document_id":"ibmcld_01193-10778-12087","score":0.015625,"text":"\nAdd a service reference for the Event Streams service to the required network zone.\n2. Ensure that access from this zone is permitted by way of the context-based restrictions rules applicable to other Cloud services.\n\n\n\nFor more information about service reference creation, see [Service references](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatisservice-attribute).\n\n\n\n\n\n Coexistence of context-based restrictions rules and private IP allowlists \n\nContext-based restrictions rules now supersede the use of private IP allowlists as the recommended approach for implementing allowlists against an Event Streams instance. The use of private IP allowlists continues to be supported but is now deprecated.\n\nIf both context-based restrictions rules and IP allowlists are defined against the same Event Streams instance, the IP allowlist is ignored because the context-based restrictions rules override any previous private IP allowlist.\n\n\n\n\n\n Migrating from private IP allowlists to context-based restrictions \n\nThe customer is responsible for migration. You can create IP allowlist definitions again as context-based restrictions network zones and apply them to the service instance by creating a context-based restrictions rule. You can then delete the previous private IP allowlist.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-restrict_access"},{"document_id":"ibmcld_15129-1577-3432","score":0.0153846154,"text":"\nFor more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services. Context-based restrictions can be created for IBM Cloud VPC or any of its child services; for example, [subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-subnets-vpc), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practice), and [block storage volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storage&interface=cli).\n\nSee the [rule creation section](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbrcbr-rules) for details on how you can create rules with the required attributes for each service.\n\n\n\n\n\n Creating network zones \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services\n\n\n\n\n\n Service references \n\nA service reference, defined as part of a network zone, allows the given service to talk to the restricted resources or APIs that are targeted by a particular context-based restriction policy. The following table includes service references that need to be included when using context-based restrictions in the context of VPC Infrastructure Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr"},{"document_id":"ibmcld_15130-1577-3446","score":0.0151515152,"text":"\nFor more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services. Context-based restrictions can be created for IBM Cloud VPC or any of its child services; for example, [subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-subnets-vpc), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practice), and [block storage volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storage&interface=cli).\n\nSee the [rule creation section](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=clicbr-rules) for details on how you can create rules with the required attributes for each service.\n\n\n\n\n\n Creating network zones \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services\n\n\n\n\n\n Service references \n\nA service reference, defined as part of a network zone, allows the given service to talk to the restricted resources or APIs that are targeted by a particular context-based restriction policy. The following table includes service references that need to be included when using context-based restrictions in the context of VPC Infrastructure Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=cli"},{"document_id":"ibmcld_01193-9087-11253","score":0.0149253731,"text":"\n* The Administration functions for the service instance itself (for example the IBM Cloud CLI service-instance-create, service-instance-delete or service-instance-update commands, or equivalent) are not under the scope of the context-based restrictions rules that are created against an Event Streams instance.\n\n\n\n\n\n Managing context-based restrictions settings \n\nCreating context-based restrictions rules is a two-step process:\n\n\n\n1. Create a network zone with list of allowed IP addresses, allowed VPCs, or reference a service. For more information, see [Creating network zones](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-createnetwork-zones-create).\n2. Create rules that specify one or more network zones against the Event Streams resource. For more information about rule creation, see [Creating rules](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-create&interface=uicontext-restrictions-create-rules).\n\n\n\nNext, note the following considerations:\n\n\n\n* You must be the account owner or have an access policy with the administrator role on all account management services to restrict access.\n* After creating or updating a zone or a rule, it can take a few minutes for the change to take effect.\n\n\n\n\n\n\n\n Supporting connections between services (service-to-service) with context-based restrictions \n\nIf an Event Streams service instance is configured to use [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-managing_encryption), the service must also be granted the ability to connect to the selected IBM Key Management Services.\n\nThe administrator of the account can set this up as follows:\n\n\n\n1. Add a service reference for the Event Streams service to the required network zone.\n2. Ensure that access from this zone is permitted by way of the context-based restrictions rules applicable to other Cloud services.\n\n\n\nFor more information about service reference creation, see [Service references](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatisservice-attribute).\n\n\n\n\n\n Coexistence of context-based restrictions rules and private IP allowlists","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-restrict_access"},{"document_id":"ibmcld_16263-5674-7641","score":0.0147058824,"text":"\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-migrationapi-migration-state)).\n\n\n\nRefer to the v2 [API Reference ](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message) for complete documentation of the v2 response format.\n\n\n\n\n\n Let the assistant maintain state \n\nFor most applications, you can now remove any code included for maintaining state. It is no longer necessary to save the context and send it back to Watson Assistant with each turn of the conversation. The context is automatically maintained by Watson Assistant and can be accessed by your dialog as before.\n\nNote that with the v2 API, the context is by default not included in responses to the client application. However, your code can still access context variables if necessary:\n\n\n\n* You can still send a context object as part of the message input. Any context variables that you include are stored as part of the context maintained by Watson Assistant. (If the context variable you send already exists in the context, the new value overwrites the previously stored value.)\n\nMake sure the context object that you send conforms to the v2 format. All user-defined context variables that are sent by your application should be part of the skill context; typically, the only global context variable you might need to set is system.user_id, which is used by Plus and Premium plans for billing purposes.\n* You can still retrieve context variables from either the global or skill context. To have the context object included with message responses, use the return_context property in the message input options. For more information, see [Accessing context data in dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-migration"},{"document_id":"ibmcld_03117-7179-9311","score":0.0144927536,"text":"\n- The conversation context is now organized into two objects:\n\n- The global context contains system-level context data shared by all skills used by the assistant.\n\n- The skill context contains any user-defined context variables used by your dialog skill.\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](api-migration-state)).\n\nRefer to the v2 [API Reference ](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message){: external} for complete documentation of the v2 response format.\n\n Let the assistant maintain state {: api-migration-state}\n\nFor most applications, you can now remove any code included for the purpose of maintaining state. It is no longer necessary to save the context and send it back to Watson Assistant with each turn of the conversation. The context is automatically maintained by Watson Assistant and can be accessed by your dialog as before.\n\nNote that with the v2 API, the context is by default not included in responses to the client application. However, your code can still access context variables if necessary:\n\n- You can still send a context object as part of the message input. Any context variables you include are stored as part of the context maintained by Watson Assistant. (If the context variable you send already exists in the context, the new value overwrites the previously stored value.)\n\nMake sure the context object you send conforms to the v2 format. All user-defined context variables sent by your application should be part of the skill context; typically, the only global context variable you might need to set is system.user_id, which is used by Plus and Premium plans for billing purposes.\n\n- You can still retrieve context variables from either the global or skill context. To have the context object included with message responses, use the return_context property in the message input options. For more information, see [Accessing context data](\/docs\/assistant?topic=assistant-api-client-get-context).\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-migration"},{"document_id":"ibmcld_02914-5621-7418","score":0.0142857143,"text":"\n* [Adding context variables to a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-var-slots)\n\n\n\n\n\n Passing context from the application \n\nPass information from the application to the dialog by setting a context variable and passing the context variable to the dialog.\n\nFor example, your application can set a $time_of_day context variable, and pass it to the dialog which can use the information to tailor the greeting it displays to the user.\n\n![Shows a Welcome node that uses response conditions to check for the value of the $time_of_day context variable that is passed to the dialog from the application.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/set-context.png)\n\nIn this example, the dialog knows that the application sets the variable to one of these values: morning, afternoon, or evening. It can check for each value, and depending on which value is present, return the appropriate greeting. If the variable is not passed or has a value that does not match one of the expected values, then a more generic greeting is displayed to the user.\n\n\n\n\n\n Passing context from node to node \n\nThe dialog can also add context variables to pass information from one node to another or to update the values of context variables. As the dialog asks for and gets information from the user, it can keep track of the information and reference it later in the conversation.\n\nFor example, in one node you might ask users for their name, and in a later node address them by name.\n\n![Shows an introductions node that asks the user for their name, and stores it as a context variable. The next node refers to the user by name by using the $username context variable.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09647-1993-2943","score":0.0163934426,"text":"\nThe list of eligible server applications includes Microsoft SQL Server database software, Microsoft Exchange Server, Microsoft SharePoint Server, Microsoft Skype for Business Server, Microsoft System Center servers, and Microsoft Dynamics 365 Server for Customer Service and Sales applications. (Note: For SQL Server customers with core-based licensing and Software Assurance coverage, broader benefits are available under [Azure Hybrid Benefit](https:\/\/azure.microsoft.com\/en-us\/pricing\/hybrid-benefit\/) rights. For more information, see Azure Hybrid Benefit. The steps described below do not apply to Azure Hybrid Benefit use.) The Windows Server operating system licenses remain assigned to customers\u2019 on-premises hardware with their applicable license terms. For additional information and a full list of eligible products, please refer to the [Microsoft Product Terms](https:\/\/www.microsoft.com\/en-us\/licensing\/product-licensing\/products?rtc=1).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-microsoft-license-mobility"},{"document_id":"ibmcld_11652-3001-4951","score":0.0163934426,"text":"\nWithin the Public Subnet, the [SAP router](https:\/\/support.sap.com\/en\/tools\/connectivity-tools\/saprouter.html) and the jump host provide secure connections to the virtual server instances. The SAP router is a software application that provides a remote connection between the customer's network and SAP. The SAP Router and jump host are within a single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional SAP products and analytics solutions and offerings that are acquired from Sybase. For a comprehensive list of which SAP Business Analytics products benefits from SAP router connections, see [SAP Note 1478974](https:\/\/launchpad.support.sap.com\/\/notes\/1478974).\n\nA jump host is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their premises. These SAP virtual server instances can be in a separate security zone but must be on same IBM Cloud region. The customer connection to the jump host follows the same rules as the direct connection from customer premises to the virtual server instance SAP instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. This architecture uses two defined security groups; this arrangement is the simplest method for separating the public and private subnets. You can add more security groups if you require more isolation.\n\n\n\n\n\n Virtual server instances on SAP NetWeaver 7.x APAB stack, JAVA stack, and dual stack (ABAP+JAVA) architectural design on IBM Cloud\u00ae VPC on Unix \n\n\n\n Standard system \n\nIn a standard system, all main instances run on a single virtual server instance within a private subnet. For more information, see [About virtual server instances for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers). The virtual server instance has these components:\n\nZoom\n\n![Figure 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-refarch-nw-db2"},{"document_id":"ibmcld_05727-8804-11229","score":0.0161290323,"text":"\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nIBM Cloud Kubernetes Service provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_transport"},{"document_id":"ibmcld_11664-3334-5110","score":0.0161290323,"text":"\nConvert your IBM Cloud account to use [Virtual routing and forwarding (VRF) on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud), using the steps described in [Converting to virtual routing and forwarding](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process).\n\nEnabling VRF permanently alters networking for your IBM Cloud account. Be sure that you have understood both the benefits and minor tradeoffs, which impact your account and resources. After you enable VRF, it cannot be disabled.\n3. Enable the Cloud Service Endpoints (CSE) to provide a secure and unmetered connection to services on IBM Cloud from the IBM Cloud Classic Infrastructure private network. Follow the steps in [enabling service endpoints](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpointservice-endpoint).\n\nThis is not the same as Virtual Private Endpoints (VPE), which is the upgraded equivalent functionality for IBM Cloud VPC Infrastructure environment; this has more benefits that include IAM access control, endpoint with IP in the Subnet Range of the VPC, and does not require Virtual routing and forwarding (VRF).\n\n\n\n\n\n\n\n Provisioning your VMware Software-Defined Datacenter \n\nThe IBM Cloud\u00ae console requires a unique log-in ID, which is an IBMid. Use the following steps to order your IBM Cloud for VMware Solutions Dedicated. Additional information can be found under [Ordering IBM Cloud for VMware Dedicated, vCenter Server instance and vSphere clusters](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_orderinginstance).\n\n\n\n1. Log in to the [IBM Cloud console](https:\/\/cloud.ibm.com) with your unique credentials.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-vmware-sddc-set-up-infrastructure"},{"document_id":"ibmcld_10170-8677-11078","score":0.0158730159,"text":"\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequent.\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_11554-1776-3838","score":0.0158730159,"text":"\nVPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n\n\n SAP products architecture on IBM Cloud VPC \n\nA [Virtual Private Cloud (VPC)](https:\/\/www.ibm.com\/cloud\/learn\/vpc?mhsrc=ibmsearch_a&mhq=VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with its included virtual server instances. This represents an Infrastructure as a Service (IaaS) within IBM Cloud that offers all of the benefits of isolated, secure, and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering uses virtual instances with native and VLAN networking to communicate to each other within a data center; however, the instances are restricted in one well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods. What\u2019s new with IBM Cloud VPC is a network orchestrator layer concept that eliminates the pod boundaries and restrictions, so this new concept handles all the networking for every virtual instance running within VPC across regions and zones.\n\n\n\n\n\n 1. Highly available system for SAP NetWeaver on IBM Cloud VPC \n\nIn a highly available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the SAP application server consists of two virtual server instances, each of them located in the same zone within the region by using placement groups. Placement groups assure that both cluster resources and cloud resources are also located in different compute nodes as specified in the following placement groups section.\n\nZoom\n\n![Figure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"},{"document_id":"ibmcld_07578-565403-567284","score":0.015625,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16095-7-1863","score":0.015625,"text":"\nUse a VPC\/VPN gateway for secure and private on-premises access to cloud resources \n\nThis tutorial will incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIBM offers a number of ways to securely extend an on-premises computer network with resources in the IBM Cloud. This allows you to benefit from the elasticity of provisioning cloud resources when you need them and removing them when no longer required. Moreover, you can easily and securely connect your on-premises capabilities to the IBM Cloud services.\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular [strongSwan](https:\/\/www.strongswan.org\/) VPN Gateway is used to represent the on-premises VPN gateway.\n\n\n\n Objectives \n\n\n\n* Access a virtual private cloud (VPC) environment from an on-premises data center\n* Securely reach cloud services using private endpoint gateways\n* Use DNS on-premises to access cloud resources over VPN\n\n\n\nThe following diagram shows the resources created by this tutorial\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution46-vpc-vpn\/vpc-site2site-vpn-tutorial.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nA terraform configuration will create the following resources:\n\n\n\n1. The infrastructure (VPC, Subnets, Security Groups with rules, Network ACL and VSIs).\n2. The Object Storage and Databases for PostgreSQL private endpoint gateways to data services.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-site2site-vpn"},{"document_id":"ibmcld_16727-565357-567238","score":0.0153846154,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14884-7-2123","score":0.0153846154,"text":"\nAbout virtual server instances for VPC \n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility.\n\nWith virtual server instances for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture. After you provision an instance, you control and manage those infrastructure resources.\n\n\n\n How are virtual server instances for VPC different from other IBM virtual server offerings? \n\nIn the IBM Cloud Virtual Servers for Classic infrastructure offering, instances use native subnet and VLAN networking to communicate to each other within a data center (and single pod). Using subnet and VLAN networking in one pod works well until you must scale up or have large virtual resource demands that require resources to be created between pods. (Adding appliances for VLAN spanning can get expensive and complicated!)\n\nIBM Cloud VPC adds a network orchestration layer that eliminates the pod boundary, creating increased capacity for scaling instances. The network orchestration layer handles all of the networking for all virtual server instances that are within a VPC across regions and zones. With the software-defined networking capabilities that VPC provides, you have more options for multi-vNIC instances and larger subnet sizes.\n\nTo review and start deploying compute resources, see the following topics:\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Virtual Servers for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles) IBM Cloud Virtual Servers for VPC provide the advanced security of a private cloud with the agility and ease of a public cloud. Virtual servers for VPC offer the best network performance (up to 80 Gbps), best security, and fastest provisioning times.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":0.0327868852,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":0.0322580645,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-7085-8964","score":0.0317460317,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":0.03125,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":0.0307692308,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04488-133306-134586","score":0.0303030303,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-96989-98298","score":0.0298507463,"text":"\nThe ibmcloud resource service-instance-create command requires a service plan name and a location, which is in the catalog. show the catalog offerings for cloud object storage (COS) and Key Protect\n$ ibmcloud catalog service cloud-object-storage\n\n$ ibmcloud catalog service kms\n create a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_01660-8584-10307","score":0.0294117647,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_09055-104201-105670","score":0.0289855072,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- <\/section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS\/KP authorization policy<-- <\/ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_00558-2925-4840","score":0.0285714286,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8065735964}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05013-2864-3381","score":0.0163934426,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_01025-1621-3657","score":0.0161290323,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n\n\n\n\n\n I'm getting an error when creating a new instance. What's the problem? \n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n\n\n\n\n\n I'm getting an error when creating a new schema or database. What's the problem? \n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n\n\n\n\n\n Why can\u2019t I open the web console? \n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_07578-496072-498088","score":0.0158730159,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-496054-498070","score":0.015625,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02143-0-1216","score":0.0153846154,"text":"\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondlite"},{"document_id":"ibmcld_07578-1323355-1325090","score":0.0151515152,"text":"\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1326020-1327755","score":0.0149253731,"text":"\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":0.0147058824,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":0.0144927536,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-7085-8964","score":0.0142857143,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3780021004}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01644-7-1911","score":0.0163934426,"text":"\nManaging your account settings \n\nAs an IBM Cloud\u00ae account owner, you can change the account name and view your account type. If you have an access policy with the Operator role or higher on all account management services, you can view and update the account name.\n\n\n\n Viewing your account settings \n\nTo view your account settings, in the IBM Cloud console, go to Manage > Account, and select Account settings in the IBM Cloud console.\n\n\n\n\n\n Editing the account name \n\nTo edit your account name, go to Manage > Account, and select Account settings in the IBM Cloud console. In the Account section, click the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/edit-tagging.svg), type your new account name, and click Submit.\n\n\n\n\n\n Viewing your account type \n\nTo view your account type, go to Manage > Account, and select Account settings in the IBM Cloud console. Details about your account type are listed in the Account Type section. For more information about the features that are included with your account, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nYou can change your account to a different type by upgrading or converting your account. See [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n Closing an account \n\nWe're sad to see you go! If there's any way we can assist you before you decide to close your account, [reach out to us](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n* To close a Lite account, go to Manage > Account, select Account settings in the IBM Cloud console. From the account settings page, click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_settings"},{"document_id":"ibmcld_07578-1076793-1078629","score":0.0163934426,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12546-1569-3760","score":0.0161290323,"text":"\nAccess within the account is separate from the enterprise, and users don't automatically get access within the enterprise when the account is imported.\n* Resources within the account are not changed. Users with the correct access permissions can continue to view usage information for resources in the account.\n\n\n\nTo import existing accounts into an enterprise, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Billing service within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\n\n\n Importing an account in the console \n\nTo import an existing account, complete the following steps:\n\n\n\n1. Log in to your enterprise account, and go to Manage > Enterprise in the IBM Cloud console.\n2. Click Accounts to view the accounts and account groups in the enterprise. In the Accounts section, select Add > Import account.\n3. Select the account that you want to import.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. If you want to add the account to an account group, select the account group to be its parent. The parent that you select determines where in the enterprise hierarchy the account exists.\n5. Review the information about impacts to your account, and select I understand the impact to my account. Then, click Import.\n\nAfter the account is imported to the enterprise, it can't be removed. Be sure you want to permanently move the account to the enterprise.\n\n\n\n\n\n\n\n Importing accounts by using the CLI \n\n\n\n1. Find the ID of the account that you want to import to the enterprise.\n\nibmcloud account list\n2. If you want to add the account to an account group, find the names and IDs of existing account groups in the enterprise.\n\nibmcloud enterprise account-groups --recursive\n3. Import the account into the enterprise, specifying the account ID for the --account ID parameter. If you don't specify a parent account group, the account is added directly under the enterprise.\n\nibmcloud enterprise account-import --account-id ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-add"},{"document_id":"ibmcld_16727-1079289-1081125","score":0.0161290323,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00696-1740-4173","score":0.0158730159,"text":"\nWhen you log in, any of the following types of accounts might be associated with your user credentials:\n\n\n\n* Personal account\n* Corporate account\n* Corporate individual account\n\n\n\n\n\n Personal accounts \n\nTypically, each user has their own account that is their personal account. You can easily identify your personal account because it usually contains your name, for example, John Smith's Account.\n\nYou have full rights over all objects that are created in your personal account. You can invite other users to join your account, assign them rights over objects that you create, and assign them rights to create objects in your account. Because of these rights, the personal data of other users might be in your account, and your personal data might be in other user's accounts.\n\nIf you have permission to create an object in an account, you also have the right to modify and delete it, regardless of which account the object is stored in. When two users collaborate, they often share a personal account.\n\n\n\n\n\n Corporate accounts \n\nA corporate account is set up by your company. Typically, you are added automatically to the account, rather than being invited. Although corporate accounts provide users with a place to work, communicate, and share resources and charging, this set up is just a convention. A corporate account is really no different than a personal account. Objects that are created in a corporate account are associated with the account and users can be invited to the account.\n\nTeams of people who work for a corporation often collaborate by using a corporate account.\n\n\n\n\n\n Corporate individual accounts \n\nWhen you work for a corporation, the work in your account might be legally owned by the corporation. Many users who work for a corporation have a corporate individual account. If you log in to your account by using credentials that contain your corporation's name and also have what appears to be a personal account, the work within your personal account might belong to the corporation.\n\nA corporate individual account is no different from any other account. You can invite users to a corporate individual account and objects that are created in a corporate individual account are owned by the account.\n\nIf you work for a corporation that owns your work, a personal account that usually contains your name is considered a corporate individual account.\n\n\n\n\n\n\n\n Modifying, exporting, and deleting personal data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_personal_data"},{"document_id":"ibmcld_01660-7085-8964","score":0.0158730159,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_12559-4953-7138","score":0.015625,"text":"\nTo import an existing account, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Enterprise and Billing account management services within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\nComplete the following steps to import the example UX-UI account to the Design account group:\n\n\n\n1. From the enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, click Add > Import account.\n3. Select UX-UI from the Account list.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. Select Design as the parent of the UX-UI account. This determines where in the enterprise hierarchy the account exists.\n5. Review the information about the impacts to your account, and select I understand the impact to my account. Then, click Import.\n\n\n\nRepeat the steps to import more accounts.\n\n\n\n\n\n Step 4: Create new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\nComplete the following steps to create the example Web account in your enterprise:\n\n\n\n1. From the Enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter Web as the name of the account.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"},{"document_id":"ibmcld_07578-1075256-1077185","score":0.015625,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12573-4001-5682","score":0.0153846154,"text":"\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group. This option is exclusive with --parent-account-group and --parent-enterprise.\n\n--parent-enterprise (required)\n: Set enterprise as the parent. This option is exclusive with --parent-account-group and --parent-account-group-id.\n\n\n\n\n\n\n\n ibmcloud enterprise account-show \n\nDisplay details of an account.\n\nibmcloud enterprise account-show (-n, --name NAME | --id ID)\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of the account. This option is exclusive with --id.\n\n\n\n\n\n\n\n ibmcloud enterprise accounts \n\nList accounts.\n\nibmcloud enterprise accounts [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID] [--recursive]\n\n\n\n Command options \n\n--parent-account-group ACCOUNT_GROUP_NAME (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant accounts.\n\n\n\n\n\n\n\n ibmcloud enterprise account-import \n\nImport a stand-alone account.\n\nibmcloud enterprise account-import (--account-id ID) [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID]\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_16727-1077752-1079681","score":0.0153846154,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-123564-124806","score":0.0163934426,"text":"\n[Creating classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_12570-2467-4288","score":0.0163934426,"text":"\nibmcloud catalog entry-visibility ID [--global]\n\n\n\n Command options \n\n--global\n: Operate in global scope\n\n\n\n\n\n Examples \n\nGet visibility of resource j402-dnf1i in global scope:\n\nibmcloud catalog entry-visibility 'j402-dnf1i' --global\n\n\n\n\n\n\n\n ibmcloud catalog entry-visibility-set \n\nUpdate the visibility of an existing catalog entry(catalog admin of an account only):\n\nibmcloud catalog entry-visibility-set ID [--includes-add LIST] [--includes-remove LIST] [--excludes-add LIST] [--excludes-remove LIST] [--owner ID or Email] [--restrict] [--unrestrict] [-c PARAMETERS_AS_JSON] [--global]\n\n\n\n Command options \n\n--includes-add\n: Adding an account (or list of comma-separated accounts) to the includes list, granting visibility to the entry. Email or Account GUIDs are acceptable.\n\n--includes-remove\n: Removing an account (or list of comma-separated accounts) from the includes list, revoking visibility to the entry. Email or Account GUIDs are acceptable.\n\n--excludes-add\n: Adding an account (or list of comma-separated accounts) to the excludes list. Email or Account GUIDs are acceptable.\n\n--excludes-remove\n: Removing an account (or list of comma-separated accounts) from the excludes list, revoking visibility to the entry. If the account was set by global admins, the account admins can't remove the account. Email or Account GUIDs are acceptable.\n\n--owner\n: Changing the owner of an object. Email or Account GUIDs are acceptable.\n\n--restrict\n: Changing the restriction of the visibility object to 'Private'.\n\n--unrestrict\n: Changing the restriction of the visibility object to 'Public'.\n\n-c\n: Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration parameters, see documentation for the particular catalog entry.\n\n--global","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_catalog"},{"document_id":"ibmcld_12297-159404-160750","score":0.0161290323,"text":"\n[Blueprint create fails](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails)\n\n\n\n* [Blueprint create fails with an invalid blueprint template: failed to clone Git repository error](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails1)\n* [Blueprint create fails with an invalid blueprint template: unable to find file error](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails2)\n* [Blueprint create fails with the requested resource group as invalid](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails3)\n* [Blueprint create fails with the error blueprint JSON validation failed: field missing or invalid in config](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails4)\n* [Blueprint create fails with the error blueprint JSON validation failed - field missing or invalid](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails5)\n* [Why is Schematics not able to clone the private GitHub repository?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failstsg-privategithub)\n* [Why is Schematics not able to clone the public GitHub repository?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failstsg-publicgithub)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_04377-2888-4609","score":0.0161290323,"text":"\nRename an organization. This operation can be done only by an org manager.\n\nibmcloud account org-rename OLD_ORG_NAME NEW_ORG_NAME [-r, --region REGION]\n\n\n\n Command options \n\nOLD_ORG_NAME (required)\n: The old name of the org that is to be renamed.\n\nNEW_ORG_NAME (required)\n: The new name of the org that is to be renamed.\n\n-r, --region REGION (optional)\n: Region name. Default to current region if not specified.\n\n\n\n\n\n\n\n ibmcloud account spaces \n\nList all account spaces:\n\nibmcloud account spaces [-o ORG_NAME] [-r REGION-NAME]\n\n\n\n Command options \n\n-o ORG_NAME (optional)\n: Organization name. List the spaces under the organization specified. Default to current organization if not specified.\n\n-r REGION-NAME (optional)\n: Region name. List the spaces under the region specified. Default to current region if not specified.\n\n\n\n\n\n Examples \n\nList all spaces:\n\nibmcloud account spaces\n\nList all spaces of org org_example in JSON format:\n\nibmcloud account spaces -o org_example --output JSON\n\n\n\n\n\n\n\n ibmcloud account space \n\nShow the information of a specific space:\n\nibmcloud account space SPACE_NAME [-o ORG_NAME] [--guid] [--security-group-rules]\n\n\n\n Command options \n\nSPACE_NAME (required)\n: Name of space to be shown.\n\n-o ORG_NAME\n: Organization name. Default to current organization if not specified.\n\n--guid\n: Retrieve and display the space's guid. All other output for the space is suppressed. This option is exclusive with --output.\n\n--security-group-rules\n: Retrieve the rules for all the security groups associated with the space.\n\n\n\n\n\n Examples \n\nShow the information of space space_example:\n\nibmcloud account space space_example\n\nShow the GUID of space space_example:\n\nibmcloud account space space_example --guid","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_account"},{"document_id":"ibmcld_05713-131400-132874","score":0.0158730159,"text":"\n* [Deciding on your cluster setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersprepare_cluster_level)\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersnext_steps)\n\n\n\n[Creating classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_04377-4199-5928","score":0.0158730159,"text":"\n: Retrieve and display the space's guid. All other output for the space is suppressed. This option is exclusive with --output.\n\n--security-group-rules\n: Retrieve the rules for all the security groups associated with the space.\n\n\n\n\n\n Examples \n\nShow the information of space space_example:\n\nibmcloud account space space_example\n\nShow the GUID of space space_example:\n\nibmcloud account space space_example --guid\n\nShow the information of space space_example in JSON format:\n\nibmcloud account space space_example --output JSON\n\nShow the security group rules of space space_example:\n\nibmcloud account space space_example --security-group-rules\n\n\n\n\n\n\n\n ibmcloud account org-users \n\nDisplay users in the specified organization by role:\n\nibmcloud account org-users ORG_NAME [-r, --region REGION] [-a, --all]\n\n\n\n Command options \n\nORG_NAME (required)\n: The name of the organization.\n\n-a, -all (optional)\n: List all the users in the specified organization, not grouped by role.\n\n-r, --region REGION (optional)\n: Region name. Default to current region if not specified.\n\n\n\n\n\n\n\n ibmcloud account org-user-add \n\nAdd a user into org (org manager required):\n\nibmcloud account org-user-add USER_NAME ORG [-r, --region REGION]\n\n\n\n Command options \n\nUSER_NAME (required)\n: The name of the user. ORG (required)\n: The name of the organization.\n\n-r, --region REGION (optional)\n: Region name. Default to current region if not specified.\n\n\n\n\n\n\n\n ibmcloud account org-user-remove \n\nRemove a user from org (org manager or user only):\n\nibmcloud account org-user-remove USER_NAME ORG [-f, --force]\n\n\n\n Command options \n\n--force, -f\n: Force deletion without confirmation.\n\n\n\n\n\n\n\n ibmcloud account org-roles \n\nGet all organization roles of the current user:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_account"},{"document_id":"ibmcld_10534-124536-125809","score":0.015625,"text":"\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n[Creating Satellite clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatellite-clusters)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatcluster-prereqs)\n* [Creating Red Hat OpenShift clusters on Satellite from the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatcluster-create-console)\n* [Creating Red Hat OpenShift clusters on Satellite from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatcluster-create-cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_09120-136019-137237","score":0.015625,"text":"\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1\nID: crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:b3933ab0-d579-46fc-8ed5-351aea657b9a::\nGUID: b3933ab0-d579-46fc-8ed5-351aea657b9a\nLocation: us-south\nState: active\nType: service_instance\nSub Type: kms\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:04:40Z\nUpdated at: 2020-06-15T16:04:40Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the Key Protect (KP) instance id (GUID)\n$ KP_INSTANCE_ID=b3933ab0-d579-46fc-8ed5-351aea657b9a\n\n create a policy for COS to read KMS; source is COS, target is KMS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_16034-11047-13098","score":0.0153846154,"text":"\n* Removed security group network interface commands security-group-network-interface, security-group-network-interface-add, security-group-network-interface-remove and security-group-network-interfaces.\n\n\n\n\n\n\n\n Note \n\n\n\n* Support for primary_ipv4_address property in primary-network-interface and network-interface options for the instance-create, instance-create-from-template, instance-template-create and instance-template-create-override-source-template commands were removed. Use primary_ip property to create the resource with wanted IP address.\n* Support for IPV4 option for the instance-create, instance-network-interface-create, instance-create-from-template, instance-template-create and instance-template-create-override-source-template commands were removed. Use the address option to create the resource with wanted IP address.\n* Support for PNIC-IP option and primary_ipv4_address property in network-interface option for the bare-metal-server-create command was removed. Use primary_ip property in network-interface option and pnic-rip-address option to create the bare metal server with wanted IP address.\n* Support for IP option for the bare-metal-server-network-interface-create command was removed. Use address option to create the bare-metal-server-network-interface with wanted IP address.\n\n\n\n\n\n\n\n\n\n v3.5.0 \n\nVersion 3.5.0 was released on 2022-03-25.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer-listener-create,load-balancer-listener-update, load-balancer-pool-create and load-balancer-pool-update commands to support UDP protocol.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.4.0 \n\nVersion 3.4.0 was released on 2022-02-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template commands to support metadata service.\n* Update instance-create and instance-create-from-template commands to support trusted profile.\n\n\n\n\n\n\n\n Removed commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_08988-137273-138491","score":0.0153846154,"text":"\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1\nID: crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:b3933ab0-d579-46fc-8ed5-351aea657b9a::\nGUID: b3933ab0-d579-46fc-8ed5-351aea657b9a\nLocation: us-south\nState: active\nType: service_instance\nSub Type: kms\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:04:40Z\nUpdated at: 2020-06-15T16:04:40Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the Key Protect (KP) instance id (GUID)\n$ KP_INSTANCE_ID=b3933ab0-d579-46fc-8ed5-351aea657b9a\n\n create a policy for COS to read KMS; source is COS, target is KMS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01468-7-2067","score":0.0163934426,"text":"\nManaging quota limits for storage and pull traffic \n\nYou can limit the amount of storage and pull traffic that can be used in your IBM Cloud account by setting and managing custom quota limits in IBM Cloud\u00ae Container Registry.\n\n\n\n Setting quota limits for storing and pulling images \n\nYou can limit the amount of storage and pull traffic to your private images by setting your own quota limits.\n\nWhen you upgrade to the IBM Cloud Container Registry standard plan, you benefit from unlimited amount of storage and pull traffic to your private images. To avoid exceeding your preferred payment level, you can set individual quotas for the amount of storage and pull traffic. Quota limits are applied to all\n\nnamespacesthat you set up in IBM Cloud Container Registry. If you're using the free service plan, you can also set custom quotas within your free amount of storage and pull traffic.\n\nTo set a quota, complete the following steps.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n3. Change the quota limit for storage and pull traffic. To change the pull traffic usage, specify the traffic option, and replace <traffic_quota> with the value in megabytes that you want to set for the pull traffic quota. If you want to change the amount of storage in your account, specify the storage option, and replace <storage_quota> with the value in megabytes that you want to set.\n\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quota"},{"document_id":"ibmcld_07578-1076793-1078629","score":0.0163934426,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00348-11019-12529","score":0.0161290323,"text":"\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Rest Of APAC\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - South America\"\n],\n\"totals\": [\n15, \/\/ Total Hits from start time to end time.\n4.9301e-5, \/\/ Total Bandwidth from start time to end time.\n0, \/\/ Hits by type 0XX\n0, \/\/ Hits by type 200\n0, \/\/ Hits by type 206\n0, \/\/ Hits by type 2XX\n0, \/\/ Hits by type 302\n0, \/\/ Hits by type 304\n0, \/\/ Hits by type 3XX\n0, \/\/ Hits by type 404\n13, \/\/ Hits by type 4XX\n2, \/\/ Hits by type 5XX\n0, \/\/ Hits by type Other\n0, \/\/ Bandwidth by region Australasia\n3.6554e-5, \/\/ Bandwidth by region EMEA\n0, \/\/ Bandwidth by region India\n0, \/\/ Bandwidth by region Japan\n1.1524e-5, \/\/ Bandwidth by region North America\n1.223e-6, \/\/ Bandwidth by region Rest Of APAC\n0 \/\/ Bandwidth by region South America\n],\n\"percentage\": [ \/\/ The percentage of the bandwidth by regions\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\n0, \/\/ Australasia","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-api"},{"document_id":"ibmcld_16727-1079289-1081125","score":0.0161290323,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00348-10050-11511","score":0.0158730159,"text":"\n\"type\": \"INTEGRATED\",\n\"names\": [\n\"TotalHits\",\n\"TotalBandwidth\",\n\"0XX\",\n\"200\",\n\"206\",\n\"2XX\",\n\"302\",\n\"304\",\n\"3XX\",\n\"404\",\n\"4XX\",\n\"5XX\",\n\"Other\",\n\"Australasia\",\n\"EMEA\",\n\"India\",\n\"Japan\",\n\"North America\",\n\"Rest Of APAC\",\n\"South America\"\n],\n\"descriptions\": [\n\"All hits to the Edge servers from the end-users.\",\n\"Total number of megabytes transferred between the Edge to the end user.\",\n\"Number of hits that returned response code - 0XX\",\n\"Number of hits that returned response code - 200\",\n\"Number of hits that returned response code - 206\",\n\"Number of hits that returned response code - 2XX\",\n\"Number of hits that returned response code - 302\",\n\"Number of hits that returned response code - 304\",\n\"Number of hits that returned response code - 3XX\",\n\"Number of hits that returned response code - 404\",\n\"Number of hits that returned response code - 4XX\",\n\"Number of hits that returned response code - 5XX\",\n\"Number of hits that returned response code not within 2XX to 5XX\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-api"},{"document_id":"ibmcld_03729-1672-3956","score":0.0158730159,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_01468-1672-3502","score":0.015625,"text":"\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000\n\n\n\n\n\n\n\n Reviewing quota limits and usage \n\nYou can review your quota limits and check your current storage and pull traffic usage for your account.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n\n\n\n\n\n\n\n Staying within quota limits \n\nIf you exceed the quota limits that are set for your IBM Cloud account, you can free up storage and change your service plan or quota limits so that you can continue pushing and pulling images to and from your namespace.\n\nFrom 1 February 2022, both [tagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nTo free up image storage in your IBM Cloud account, complete the following steps.\n\nDepending on the size of the image, it might take a while for the image to be removed and for the storage to be available.\n\n\n\n1. Find the names of the images that you want to remove.\n\n\n\n* To list only tagged images, run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quota"},{"document_id":"ibmcld_01660-8584-10307","score":0.015625,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_11421-1359-2601","score":0.0153846154,"text":"\nVOLUME GROUP: rootvg VG IDENTIFIER: 00f6db0a00004c000000016b94f02\nVG STATE: active PP SIZE: 32 megabyte(s)\nVG PERMISSION: read\/write TOTAL PPs: 639 (20448 megabytes)\nMAX LVs: 256 FREE PPs: 477 (15264 megabytes)\nLVs: 12 USED PPs: 162 (5184 megabytes)\nOPEN LVs: 11 QUORUM: 2 (Enabled)\nTOTAL PVs: 1 VG DESCRIPTIORS: 2\nSTALE PVs: 0 STALE PPs: 0\nACTIVE PVs: 1 AUTO ON: yes\nMAX PPs per VG: 32512\nMAX PPs per PV: 1016 MAX PVs: 32\nLTG size(Dynamic): 512 kilobyte(s) AUTO SYNC: no\nHOT SPARE: no BB POLICY: relocatable\nPV RESTRICTION: none INFINITE RETRY: no\nDISK BLOCK SIZE: 512 CRITICAL VG: no\nFS SYNC OPTION: no CRITICAL PVs: no\n\nShow more\n\nRunning the df -g command displays information about the total space and available space on a file system. In this instance, the rootvg volume group has enough space for creating a new file system, expanding an existing one, and storing the mksysb source image.\n\nThe storage information is shown as follow:\n\n df -g\nFilesystem GB blocks Free %Used Iused %Iused Mounted on\n\/dev\/hd4 0.09 0.06 41% 2619 17% \/\n\/dev\/hd2 2.16 0.26 89% 36565 37% \/usr\n\/dev\/hd9var 0.19 0.16 17% 953 3% \/var\n\/dev\/hd3 0.22 0.22 1% 33 1% \/tmp\n\/dev\/hd1 0.03 0.03 2% 7 1% \/home\n\/dev\/hd11admin 0.12 0.12 1% 5 1% \/admin\n\/proc - - - - - \/proc","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-restoring-aix-mksysb-image"},{"document_id":"ibmcld_03704-1531-3564","score":0.0153846154,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07280-34964-36511","score":0.0163934426,"text":"\nibmcloud dl locations|locs OFFERING_TYPE [\u2013-output format] [--help|-h]\n\n\n\n Command options \n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Values are dedicated or connect.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl locations dedicated\n* ibmcloud dl locs dedicated --output json\n\n\n\n\n\n\n\n\n\n ibmcloud dl offering-speeds \n\nLists all offering speeds for an offering type.\n\nibmcloud dl offering-speeds|ospeeds OFFERING_TYPE [--output format] [--help|-h]\n\n\n\n Command options \n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Values are dedicated or dedicated_hosting.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl offering-speeds dedicated\n* ibmcloud dl ospeeds dedicated_hosting --output json\n\n\n\n\n\n\n\n\n\n ibmcloud dl port \n\nView details of a port.\n\nibmcloud dl port PORT_ID [--help|-h] [--output format]\n\n\n\n Command options \n\nPORT_ID\n: Specify the ID of the port.\n\n--help|-h\n: Get help on this command. Optional.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl port a771366f-2c8c-49f6-a23b-9d49fad035a3\n* ibmcloud dl port a771366f-2c8c-49f6-a23b-9d49fad035a3 --output json","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-cli"},{"document_id":"ibmcld_07578-1076793-1078629","score":0.0163934426,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07280-33738-35344","score":0.0161290323,"text":"\nibmcloud dl loa GATEWAY_ID [--file OUTPUT_DIRECTORY_PATH] [--help|-h]\n\n\n\n Command options \n\nGATEWAY_ID\n: Specify the ID of the gateway.\n\n--file OUTPUT_DIRECTORY_PATH\n: Specify the output directory path. For example, specify to download the LOA in the \/tmp directory. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl loa 5cc19d0a-792c-4595-adfc-f90fc650de01\n* ibmcloud dl loa 5cc19d0a-792c-4595-adfc-f90fc650de01 --file \/tmp\n\n\n\n\n\n\n\n\n\n ibmcloud dl location \n\nRetrieves location-specific information for a specific offering type.\n\nibmcloud dl location|loc LOCATION_NAME OFFERING_TYPE [--help|-h] [--output format]\n\n\n\n Command options \n\nLOCATION_NAME\n: Specify the name of the location.\n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Currently only dedicated is supported.\n\n--help|-h\n: Get help on this command. Optional.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl location \"Washington 2\" dedicated\n* ibmcloud dl loc \"Washington 2\" dedicated --output json\n\n\n\n\n\n\n\n\n\n ibmcloud dl locations \n\nList the locations for a specific Direct Link offering type.\n\nibmcloud dl locations|locs OFFERING_TYPE [\u2013-output format] [--help|-h]\n\n\n\n Command options \n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Values are dedicated or connect.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-cli"},{"document_id":"ibmcld_16727-1079289-1081125","score":0.0161290323,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08063-4144-5315","score":0.0158730159,"text":"\n\"offering\": {\n\"name\": \"Cloud Object Storage\",\n\"type\": {\n\"group\": \"crn_service_name\",\n\"key\": \"cloud-object-storage\",\n\"kind\": \"service\",\n\"id\": \"dff97f5c-bc5e-4455-b470-411c3edbe49c\"\n}\n},\n\"resources\": [\n{\n\"crn\": \"crn:v1:staging:public:cloud-object-storage:global:a\/2dded3de4a4d4a098ebd0998be5cc845:723a59c4-9338-43fe-9dc4-e4a87cc78c8e::\",\n\"note\": \"Resource note\"\n}\n]\n}'\n\nOfferingType offeringType = new OfferingType.Builder()\n.group(OfferingType.Group.CRN_SERVICE_NAME)\n.key(\"cloud-object-storage\")\n.build();\nOffering offeringPayload = new Offering.Builder()\n.name(\"Cloud Object Storage\")\n.type(offeringType)\n.build();\nCreateCaseOptions createCaseOptions = new CreateCaseOptions.Builder()\n.type(\"technical\")\n.subject(\"Example technical case\")\n.description(\"This is an example case description. This is where the problem would be described.\")\n.offering(offeringPayload)\n.severity(4)\n.build();\n\nResponse<Case> response = service.createCase(createCaseOptions).execute();\nCase xCase = response.getResult();\n\nSystem.out.println(xCase);\n\noffering_type = OfferingType(\ngroup='crn_service_name',\nkey='cloud-object-storage'\n)\noffering_payload = Offering(\nname='Cloud Object Storage',","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_11503-7-2078","score":0.0158730159,"text":"\nQiskit Runtime plans \n\nThe Qiskit Runtime service offers these plans for running quantum programs:\n\n\n\n* Lite Plan: Simulator access plan (free)\n* Standard Plan: Quantum hardware and simulator access plan\n\n\n\n\n\n Lite plans \n\nA free plan that gives you access to quantum simulators to help you get started with Qiskit Runtime. It does not include access to IBM Quantum systems. The following simulators are included in this plan:\n\n\n\n* ibmq_qasm_simulator: A general-purpose simulator for simulating quantum circuits both ideally and subject to noise modeling. The simulation method is automatically selected based on the input circuits and parameters.\n\n\n\n* Type: General, context-aware\n* Simulatable Qubits: 32\n\n\n\n* simulator_statevector: Simulates a quantum circuit by computing the wave function of the qubit\u2019s state vector as gates and instructions are applied. Supports general noise modeling.\n\n\n\n* Type: Schr\u00f6dinger wave function\n* Simulated Qubits: 32\n\n\n\n* simulator_mps: A tensor-network simulator that uses a Matrix Product State (MPS) representation for the state that is often more efficient for states with weak entanglement.\n\n\n\n* Type: Matrix Product State\n* Simulated Qubits: 100\n\n\n\n* simulator_stabilizer: An efficient simulator of Clifford circuits. Can simulate noisy evolution if the noise operators are also Clifford gates.\n\n\n\n* Type: Clifford\n* Simulated Qubits: 5000\n\n\n\n* simulator_extended_stabilizer: Approximates the action of a quantum circuit by using a ranked-stabilizer decomposition. The number of non-Clifford gates determines the number of stabilizer terms.\n\n\n\n* Type: Extended Clifford (for example, Clifford+T)\n* Simulated Qubits: 63\n\n\n\n\n\n\n\n\n\n Standard plan \n\nA pay-as-you-go plan for accessing IBM Quantum systems and simulators. Build your own programs and access all the benefits of Qiskit Runtime by running on real quantum hardware.\n\n\n\n\n\n Pricing overview \n\nThe Lite plan is free. The Standard plan charges you per Qiskit Runtime second when running on physical systems. The following diagram illustrates what is included in a QR second.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans"},{"document_id":"ibmcld_08063-5034-6357","score":0.015625,"text":"\nResponse<Case> response = service.createCase(createCaseOptions).execute();\nCase xCase = response.getResult();\n\nSystem.out.println(xCase);\n\noffering_type = OfferingType(\ngroup='crn_service_name',\nkey='cloud-object-storage'\n)\noffering_payload = Offering(\nname='Cloud Object Storage',\ntype=offering_type\n)\n\ncase = case_management_service.create_case(\ntype='technical',\nsubject='Example technical case',\ndescription='This is an example case description. This is where the problem would be described.',\noffering=offering_payload,\nseverity=4,\n).get_result()\n\nprint(json.dumps(case, indent=2))\n\nofferingType, _ := caseManagementService.NewOfferingType(\ncasemanagementv1.OfferingTypeGroupCRNServiceNameConst,\n\"cloud-object-storage\",\n)\nofferingPayload, _ := caseManagementService.NewOffering(\n\"Cloud Object Storage\",\nofferingType,\n)\n\ncreateCaseOptions := caseManagementService.NewCreateCaseOptions(\n\"technical\",\n\"Example technical case\",\n\"This is an example case description. This is where the problem would be described.\",\n)\ncreateCaseOptions.SetSeverity(4)\ncreateCaseOptions.SetOffering(offeringPayload)\n\ncaseVar, response, err := caseManagementService.CreateCase(createCaseOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(caseVar, \"\", \" \")\nfmt.Println(string(b))\n\nconst offeringType = {\ngroup: 'crn_service_name',","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_01660-7085-8964","score":0.015625,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_15545-232015-233745","score":0.0153846154,"text":"\n* --catalog-offering: The CRN for the IBM Cloud catalog offering. If specified, the latest version of that offering is used. For more information about creating a catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --catalog-offering-version: The CRN for the version of a IBM Cloud catalog offering. For more information about creating a version for the catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --total-volume-bandwidth: The amount of bandwidth (in megabits per second) that is allocated exclusively to instance storage volumes. An increase in this value results in a corresponding decrease to total network bandwidth.\n* --boot-volume: BOOT_VOLUME_JSON|@BOOT_VOLUME_JSON_FILE, boot volume attachment in JSON or JSON file. For the data schema, see the boot_volume_attachment property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --volume-attach: VOLUME_ATTACH_JSON|@VOLUME_ATTACH_JSON_FILE, volume attachment in JSON or JSON file, list of volumes. For the data schema, see the volume_attachments property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --keys: Comma-separated IDs or names of SSH keys. SSH keys can either be of type RSA or Ed25519. Ed25519 can be used only if the operating system supports this key type. Ed25519 can't be used with Windows or VMware images.\n* --dedicated-host: ID or name of the host destination where the instance is placed.\n* --dedicated-host-group: ID or name of the host group destination where the instance is placed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_09433-7-1472","score":0.0153846154,"text":"\nService plans \n\nDifferent pricing plans are available that you can choose for an IBM Log Analysis instance. Each plan defines the number of days that data is retained for search, the number of users allowed to manage the data, and the logging features that are enabled.\n\n\n\nTable 1. List of service plans\n\n Plan Number of days that data is available for search Number of users per plan Plan Name Plan ID \n\n HIPAA 30 day log search 30 25 hipaa-30-day a9b3eb07-5096-448b-ba34-53711d74742b \n 30 days log search 30 Unlimited 30-day deda35aa-662b-4b06-9f6e-05e0b55cc577 \n 14 days log search 14 Unlimited 14-day 0b3a45e0-def0-4935-8c74-26976f281751 \n 7-day log search 7 Unlimited 7-day 209cbd52-f3e2-47cb-94ce-6b84fafcf22b \n Lite Data is not available for search 1 lite abcf7f02-de22-4c7f-98a1-e8a592093d83 \n\n\n\nIBM Log Analysis offers a Lite plan that you can use to view your logs as they pass through the system. You can view logs by using log tailing. You can also design filters to prepare for upgrading to a longer retention period plan. You cannot use an instance on the Lite plan to receive streamed data. This plan has a 0-day retention period.\n\n\n\n Features by plan \n\nThe following tables outline the different features that are included in each service plan:\n\n\n\nTable 2. List of features available for each service plan\n\n Feature HIPAA 30 day log search plan 30 day log search plan 14 days log search plan 7 days log search plan Lite plan \n\n Live streaming tail !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-service_plans"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12552-7-1847","score":0.0163934426,"text":"\nFAQs about enterprises \n\nFAQs for your IBM Cloud\u00ae enterprise might include questions about importing accounts, moving accounts and account groups, and inviting users to your enterprise. To find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n How do I set up an enterprise account? \n\nTo set up an enterprise, you must be the account owner or an administrator on the Billing account management service. You use the IBM Cloud console to create an enterprise account, enter the name of your company, provide your company's domain, create your enterprise structure, and more. For more information, see [Setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n\n\n\n\n\n When I create an enterprise, does my IBM Cloud account become the enterprise account? \n\nNo, your IBM Cloud account does not become the enterprise account. Your account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n\n\n\n\n\n Can I use my IBM Cloud account to create multiple enterprise accounts? \n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n\n\n\n\n\n Can an existing enterprise be a child of another enterprise? \n\nNo, an existing IBM Cloud enterprise account can't be imported into another enterprise.\n\n\n\n\n\n How do I add child accounts to my enterprise? \n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-faqs"},{"document_id":"ibmcld_02660-1509-3609","score":0.0163934426,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_16727-1133881-1135817","score":0.0161290323,"text":"\nYour account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n* Can an existing enterprise be a child of another enterprise?\n\nNo, an existing IBM Cloud enterprise account can't be imported into another enterprise.\n* How do I add child accounts to my enterprise?\n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise. For more information, see [Import existing accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uiexisting_accounts_tutorial) and [Create new accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uicreate-accounts_tutorial).\n* Can I import a Lite account into an enterprise?\n\nYes, but your Lite account is automatically upgraded to a Pay-As-You-Go account. Billing for the account is then managed at the enterprise level. For more information, see [Centrally managing billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n* Can I remove my account from an enterprise?\n\nAfter you import your account into an enterprise, you can't remove it.\n* Can I move an account within an enterprise?\n\nYes, you can move your account anywhere within an enterprise. For example, you can move your account directly under the enterprise or from one account group to another.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16271-12437-13388","score":0.0161290323,"text":"\nConfirm that if you select No, the action ends.\n* Try including additional information in your initial message. For example, try typing I want to withdraw $50 from my savings account. Confirm that the assistant does not ask you again to specify the information you already provided.\n\n\n\nThat's it! You built a simple action that includes multiple steps, collects information that it stores as action variables, and conditions its responses based on what your customer chooses. There is a lot more you can do with actions, but all of it is built on this basic pattern.\n\n\n\n\n\n Action limits \n\nThe number of actions, steps, and variables you can create depends on your Watson Assistant [plan type](https:\/\/www.ibm.com\/products\/watson-assistant\/pricing\/).\n\n\n\nPlan details\n\n Plan Actions Steps Variables \n\n Lite 100 1,000 2,000 \n Trial 100 1,000 2,000 \n Plus 2,000 5,000 8,000 \n Enterprise 2,000 5,000 8,000 \n Enterprise with Data Isolation 2,000 5,000 8,000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview"},{"document_id":"ibmcld_07578-1131400-1133341","score":0.0158730159,"text":"\nYour account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n* How do I add child accounts to my enterprise?\n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise. For more information, see [Import existing accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uiexisting_accounts_tutorial) and [Create new accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uicreate-accounts_tutorial).\n* Can I import a Lite account into an enterprise?\n\nYes, but your Lite account is automatically upgraded to a Pay-As-You-Go account. Billing for the account is then managed at the enterprise level. For more information, see [Centrally managing billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n* Can I remove my account from an enterprise?\n\nAfter you import your account into an enterprise, you can't remove it.\n* Can I move an account within an enterprise?\n\nYes, you can move your account anywhere within an enterprise. For example, you can move your account directly under the enterprise or from one account group to another. For more information, see [Moving accounts within the enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-organize).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01705-11723-13541","score":0.0158730159,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12552-1391-3393","score":0.015625,"text":"\n(https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n\n\n\n\n\n Can an existing enterprise be a child of another enterprise? \n\nNo, an existing IBM Cloud enterprise account can't be imported into another enterprise.\n\n\n\n\n\n How do I add child accounts to my enterprise? \n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise. For more information, see [Import existing accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uiexisting_accounts_tutorial) and [Create new accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uicreate-accounts_tutorial).\n\n\n\n\n\n Can I import a Lite account into an enterprise? \n\nYes, but your Lite account is automatically upgraded to a Pay-As-You-Go account. Billing for the account is then managed at the enterprise level. For more information, see [Centrally managing billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Can I remove my account from an enterprise? \n\nAfter you import your account into an enterprise, you can't remove it.\n\n\n\n\n\n Can I move an account within an enterprise? \n\nYes, you can move your account anywhere within an enterprise. For example, you can move your account directly under the enterprise or from one account group to another. For more information, see [Moving accounts within the enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-organize).\n\n\n\n\n\n Can I move an account group? \n\nNo, it\u2019s not possible to move an account group within the enterprise.\n\n\n\n\n\n Can I edit an account name from within the enterprise? \n\nNo, you can't edit the name of an account from within your enterprise. To edit the name of an account, go to Manage > Account in the IBM Cloud console, and select Account settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-faqs"},{"document_id":"ibmcld_07578-447531-449109","score":0.015625,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12540-4798-6573","score":0.0153846154,"text":"\nBy default, the enterprise is created with the currently logged-in user in the following roles:\n\n\n\n* The contact for the enterprise, which identifies a focal person to notify with enterprise-related concerns\n* The owner of the enterprise account, which has full access to manage the enterprise account\n\n\n\nYou can specify the IBMid for a different user on the --primary-contact-id option. The same user is assigned to both roles.\n3. Review the impact to your account, and confirm that you want to continue by entering y.\n\nAccount abcde12345fghij67890 will be incorporated into enterprise My new enterprise\n(which cannot be undone). Do you want to proceed? [y\/N]> y\n\n\n\nAfter the enterprise is created, two new IDs are displayed. The first ID is associated with the enterprise, and the second ID identifies the enterprise account, which you use to manage the enterprise.\n\nID: 09876jihgf54321edcba\nEnterprise Account ID: edcba12345jihgf67890\n\nThe account that you used to create the enterprise is now a part of the enterprise. Run the [ibmcloud enterprise accounts](https:\/\/cloud.ibm.com\/docs\/account?topic=cli-ibmcloud_enterpriseibmcloud_enterprise_accounts) command to view the two accounts in your enterprise: the enterprise account, and the account you used to create the enterprise.\n\n\n\n\n\n Creating an enterprise by using the API \n\nYou can programmatically create an enterprise by calling the Enterprise Management API as shown in the following sample request. For detailed information about the API, see [Enterprise Management API](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/enterprise).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X POST \"https:\/\/enterprise.cloud.ibm.com\/v1\/enterprises\n-H \"Authorization: Bearer <IAM_Token>\"\n-H 'Content-Type: application\/json'\n-d '{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-create-enterprise"},{"document_id":"ibmcld_16727-447513-449091","score":0.0153846154,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11601-7-2113","score":0.0163934426,"text":"\nGetting help and support from IBM Cloud or SAP \n\nIf you experience problems with IBM Cloud, you have several options to get help with determining the cause of the problem and finding a solution.\n\nWhich support option depends on the level of support (and urgency), and whether the problem is with the Offering or running SAP Workloads using the Offering.\n\nOptions include:\n\n\n\n* IBM Cloud Support Case, using the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter)\n* SAP support incident, using the [SAP ONE Support Launchpad](https:\/\/launchpad.support.sap.com\/)\n* IBM Cloud Docs\n\n\n\nFor previous users of IBM Cloud Classic Infrastructure (formerly Softlayer), please be aware these Support Cases were previously termed Support Tickets.\n\n\n\n IBM Cloud Support \n\nIBM Cloud Support handles any support questions and issues that might arise - available through live web chat, phone, and case-based support.\n\nEach IBM Cloud account automatically comes with customer support at no cost and covers most cases which are placed each day; this is the Basic level of support.\n\nThe types of available and response time of support, depends on the support level of the account. Your support plan also determines the severity level that you can assign to support cases. For more information, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\nYou can change your current support plan at any time by contacting IBM Cloud sales expert.\n\nFor full information about opening an IBM Cloud Support case, or about support levels and ticket severities, see [IBM Cloud Support documentation](https:\/\/cloud.ibm.com\/docs\/get-support).\n\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https:\/\/www.ibm.com\/cloud\/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-help-support"},{"document_id":"ibmcld_02114-3084-4665","score":0.0163934426,"text":"\nABDemoTestCatalog 7a246530-e191-45e2-87cc-07c8c7033d2b short-description 2019-08-19 17:43:48.59 +0000 UTC\n\n\n\n\n\n\n\n ibmcloud catalog get \n\nRun the following command to retrieve information for a particular catalog in the account.\n\nibmcloud catalog get --catalog CATALOG [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only supported alternative is JSON. For example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName Current State Version Locator\ndev-catalog\n|__dev-offering\n| |__Openshift\n| |__1.0.0 Draft 480fb4e3-d7ba-4e9b-9d4c-42f0ab811040.fd8f91a3-8027-4919-ad6d-c5189a4a8ee\n\n\n\n\n\n\n\n ibmcloud catalog delete \n\nRun the following command to delete a particular catalog in the account.\n\nibmcloud catalog delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog search \n\nRun the following command to search the public catalog for published products, including services and software.\n\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04621-52393-53675","score":0.0161290323,"text":"\n* Add support for .NET ASP.NET Core 2.2.5\n* Add support for .NET Runtime 1.1.12\n* Add support for .NET Runtime 1.1.13\n* Add support for .NET Runtime 2.1.5\n* Add support for .NET Runtime 2.1.10\n* Add support for .NET Runtime 2.1.11\n* Add support for .NET Runtime 2.2.4\n* Add support for .NET Runtime 2.2.5\n* Add support for .NET SDK 1.1.13\n* Add support for .NET SDK 1.1.14\n* Add support for .NET SDK 2.1.507\n* Add support for .NET SDK 2.2.107\n* Add support for .NET SDK 2.2.203\n* Add support for .NET SDK 2.2.204\n* Remove support for .NET ASP.NET Core 2.1.7\n* Remove support for .NET ASP.NET Core 2.1.8\n* Remove support for .NET ASP.NET Core 2.2.1\n* Remove support for .NET ASP.NET Core 2.2.2\n* Remove support for .NET Runtime 1.0.11\n* Remove support for .NET Runtime 1.0.12\n* Remove support for .NET Runtime 1.1.10\n* Remove support for .NET Runtime 1.1.11\n* Remove support for .NET Runtime 2.0.7\n* Remove support for .NET Runtime 2.0.9\n* Remove support for .NET Runtime 2.1.7\n* Remove support for .NET Runtime 2.1.8\n* Remove support for .NET Runtime 2.2.1\n* Remove support for .NET Runtime 2.2.2\n* Remove support for .NET SDK 1.0.4\n* Remove support for .NET SDK 1.1.11\n* Remove support for .NET SDK 1.1.12\n* Remove support for .NET SDK 2.1.504\n* Remove support for .NET SDK 2.2.104","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_04491-3084-4665","score":0.0161290323,"text":"\nABDemoTestCatalog 7a246530-e191-45e2-87cc-07c8c7033d2b short-description 2019-08-19 17:43:48.59 +0000 UTC\n\n\n\n\n\n\n\n ibmcloud catalog get \n\nRun the following command to retrieve information for a particular catalog in the account.\n\nibmcloud catalog get --catalog CATALOG [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only supported alternative is JSON. For example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName Current State Version Locator\ndev-catalog\n|__dev-offering\n| |__Openshift\n| |__1.0.0 Draft 480fb4e3-d7ba-4e9b-9d4c-42f0ab811040.fd8f91a3-8027-4919-ad6d-c5189a4a8ee\n\n\n\n\n\n\n\n ibmcloud catalog delete \n\nRun the following command to delete a particular catalog in the account.\n\nibmcloud catalog delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog search \n\nRun the following command to search the public catalog for published products, including services and software.\n\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_04621-27822-29084","score":0.0158730159,"text":"\n* Add support for .NET ASP.NET Core 3.1.12\n* Add support for .NET ASP.NET Core 3.1.13\n* Add support for .NET ASP.NET Core 5.0.3\n* Add support for .NET ASP.NET Core 5.0.4\n* Add support for .NET Runtime 2.1.25\n* Add support for .NET Runtime 2.1.26\n* Add support for .NET Runtime 3.1.12\n* Add support for .NET Runtime 3.1.13\n* Add support for .NET Runtime 5.0.3\n* Add support for .NET Runtime 5.0.4\n* Add support for .NET SDK 2.1.813\n* Add support for .NET SDK 2.1.814\n* Add support for .NET SDK 3.1.406\n* Add support for .NET SDK 3.1.407\n* Add support for .NET SDK 5.0.200\n* Add support for .NET SDK 5.0.201\n* Remove support for .NET ASP.NET Core 2.1.22\n* Remove support for .NET ASP.NET Core 2.1.23\n* Remove support for .NET ASP.NET Core 3.1.9\n* Remove support for .NET ASP.NET Core 3.1.10\n* Remove support for .NET ASP.NET Core 5.0.0\n* Remove support for .NET Runtime 2.1.22\n* Remove support for .NET Runtime 2.1.23\n* Remove support for .NET Runtime 3.1.9\n* Remove support for .NET Runtime 3.1.10\n* Remove support for .NET Runtime 5.0.0\n* Remove support for .NET SDK 2.1.810\n* Remove support for .NET SDK 2.1.811\n* Remove support for .NET SDK 3.1.403\n* Remove support for .NET SDK 3.1.404\n* Remove support for .NET SDK 5.0.100\n* Update Node.js version to 10.23.0","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_12577-3084-4665","score":0.0158730159,"text":"\nABDemoTestCatalog 7a246530-e191-45e2-87cc-07c8c7033d2b short-description 2019-08-19 17:43:48.59 +0000 UTC\n\n\n\n\n\n\n\n ibmcloud catalog get \n\nRun the following command to retrieve information for a particular catalog in the account.\n\nibmcloud catalog get --catalog CATALOG [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only supported alternative is JSON. For example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName Current State Version Locator\ndev-catalog\n|__dev-offering\n| |__Openshift\n| |__1.0.0 Draft 480fb4e3-d7ba-4e9b-9d4c-42f0ab811040.fd8f91a3-8027-4919-ad6d-c5189a4a8ee\n\n\n\n\n\n\n\n ibmcloud catalog delete \n\nRun the following command to delete a particular catalog in the account.\n\nibmcloud catalog delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog search \n\nRun the following command to search the public catalog for published products, including services and software.\n\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_12867-1702-3746","score":0.015625,"text":"\n[Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My Products.\n2. Select the product that you're onboarding, and click Support.\n3. Select your product's support provider.\n\n\n\n1. If you select Community, provide the support statement and the URL for the support community, and select the languages in which support is provided.\n2. If you select Third-party, use the following steps to complete the necessary fields.\n\n\n\n\n\n\n\n\n\n Providing your product's support information \n\nIf your product has third-party or IBM Cloud provided support, you need to add at least one support detail. The details that you provide are displayed on your product details page in the catalog. At minimum, support must be available 8 hours a day, Monday through Friday. The recommended support coverage is 24 hours a day, 7 days a week, and 365 days a year.\n\nDon't add details that have personal information, for example, personal emails.\n\nUse the following steps to add support details for your product:\n\n\n\n1. From the Partner Center Support tab, provide your product's support statement.\n\nFor the support statement, describe the provided support for your product and Add any additional support information that isn't provided in the other fields.\n2. Click Add support details, provide your support availability, then click Save to add each detail. You must add at least 1 support detail for your product.\n\n\n\nTable 1. Support details\n\n Support detail Description \n\n Email Your company email where users can contact support. \n Chat The URL for where users can get direct contact with a support representative. \n Slack The URL for the company Slack channel. \n Phone number The company phone number where users can get direct contact with a support representative. \n Other Any additional information, email, URL, or phone number that you want to provide. \n\n\n\n3. After you add all of your product's support details, provide the required URLs for your product.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-support-details"},{"document_id":"ibmcld_03435-20211-22413","score":0.015625,"text":"\nAccount usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-at_events_acc_mgt"},{"document_id":"ibmcld_12832-1696-3740","score":0.0153846154,"text":"\n[Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My Products.\n2. Select the product that you're onboarding, and click Support.\n3. Select your product's support provider.\n\n\n\n1. If you select Community, provide the support statement and the URL for the support community, and select the languages in which support is provided.\n2. If you select Third-party, use the following steps to complete the necessary fields.\n\n\n\n\n\n\n\n\n\n Providing your product's support information \n\nIf your product has third-party or IBM Cloud provided support, you need to add at least one support detail. The details that you provide are displayed on your product details page in the catalog. At minimum, support must be available 8 hours a day, Monday through Friday. The recommended support coverage is 24 hours a day, 7 days a week, and 365 days a year.\n\nDon't add details that have personal information, for example, personal emails.\n\nUse the following steps to add support details for your product:\n\n\n\n1. From the Partner Center Support tab, provide your product's support statement.\n\nFor the support statement, describe the provided support for your product and Add any additional support information that isn't provided in the other fields.\n2. Click Add support details, provide your support availability, then click Save to add each detail. You must add at least 1 support detail for your product.\n\n\n\nTable 1. Support details\n\n Support detail Description \n\n Email Your company email where users can contact support. \n Chat The URL for where users can get direct contact with a support representative. \n Slack The URL for the company Slack channel. \n Phone number The company phone number where users can get direct contact with a support representative. \n Other Any additional information, email, URL, or phone number that you want to provide. \n\n\n\n3. After you add all of your product's support details, provide the required URLs for your product.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-saas-support-details"},{"document_id":"ibmcld_02114-5507-7076","score":0.0153846154,"text":"\nAvailable options are name, displayname, kind, provider, created, and updated.\n\n--reverse (optional)\n: Flag is only valid for services search. Use it to reverse the sorting order.\n\n--fields FIELDS (optional)\n: Flag is only valid for services search. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName ID Category\n2 Zone VPC f10d9ae9-ac94-4718-b24a-3994241ae2a4-global Networking\nApache Qml0bmFtaS1hcGFjaGU=-global Developer Tools\nApache Airflow Qml0bmFtaS1haXJmbG93-global Databases\nApache Airflow Qml0bmFtaS1haXJmbG93-global Developer Tools\n\n\n\n\n\n\n\n ibmcloud catalog filter get \n\nRun the following command to retrieve filter details for either the account or a particular catalog.\n\nibmcloud catalog filter get --catalog CATALOG [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This field applies only to enterprise accounts.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nAccount: The IBM Cloud catalog is visible to all users in this account.\n\nFilter:\nIncluding IBM Cloud catalog\n\nType Include Tags\nPricing plan false Free\nProvider false Third Party\n\n\n\n\n\n\n\n ibmcloud catalog filter create \n\nRun the following command to create a new filter. If a filter exists, this command overrides the current filter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05838-12220-14151","score":0.0327868852,"text":"\nYou can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_10189-3187-5240","score":0.0322580645,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-3185-5238","score":0.0317460317,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10290-70537-72315","score":0.03125,"text":"\nibmcloud oc cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud oc cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud oc cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud oc cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10642-1365-3347","score":0.0307692308,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10189-1607-3670","score":0.0303030303,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-1605-3668","score":0.0298507463,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_05891-71325-73333","score":0.0294117647,"text":"\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-72055-74063","score":0.0289855072,"text":"\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10246-14143-16190","score":0.0285714286,"text":"\nCheck the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10070-7-1616","score":0.0163934426,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05612-7-1934","score":0.0163934426,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_05608-7-1899","score":0.0161290323,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_10070-4689-6311","score":0.0161290323,"text":"\nWhat else can I do to increase the security and compliance of my cluster? \n\nSee [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nThese steps apply to clusters that run Red Hat OpenShift version 4.5 or later only.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Create a project for the resources to run the benchmark.\n\noc create ns ibm-kube-bench-test\n2. Create a ConfigMap with the config and node configuration files from the [kube-samples](https:\/\/github.com\/IBM-Cloud\/kube-samples\/tree\/master\/cis-kube-benchmark\/cis-1.5\/ibm) GitHub repository.\n\n\n\n1. Download the the config and node configuration files into a local directory called ibm. You can also clone the repository and navigate into the ibm directory.\n\n\n\n* [config file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/cis-kube-benchmark\/cis-1.5\/ibm\/config.yaml)\n* [node file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/cis-kube-benchmark\/cis-1.5\/ibm\/node.yaml)\n\n\n\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05615-17992-19657","score":0.0158730159,"text":"\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05615-7-1945","score":0.0158730159,"text":"\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05614-18132-19807","score":0.015625,"text":"\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123"},{"document_id":"ibmcld_05616-7-1945","score":0.015625,"text":"\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"},{"document_id":"ibmcld_05613-18132-19805","score":0.0153846154,"text":"\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122"},{"document_id":"ibmcld_05611-7-1955","score":0.0153846154,"text":"\nVersion 1.20 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.20. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-120"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.6713860725}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-7173-9446","score":0.0327868852,"text":"\nWhen specified in combination with PARTITIONED BY, it sorts the rows within each partition by the sort order that is specified in the SORT BY clause. When specified in combination with PARTITIONED INTO, the same is done, which is often referred to as clustering the rows by the specified columns into the fixed number of partitions specified by PARTITIONED INTO. When specified without the PARTITIONED clause, it is equivalent to an ORDER BY clause specified at the top level of the SQL SELECT statement. If PARTITIONED INTO is specified, the ORDER BY clause is ignored.\n\n\n\n Partition by columns \n\nWhen you use the PARTITIONED BY (column-list) clause without specifying INTO x BUCKETS\/OBJECTS, you can store the query result by using Hive-style partitioning, which is to create partitions that contain only rows that have certain values for one or more columns. Choose this physical layout if the stored object is further analyzed by using SQL queries that specify predicates on the partition columns.\n\nFor example, a result object that contains worldwide order data has a column country to represent the country that the order is initiated from. Partitioning the result object by the column PARTITIONED BY (country), would create a result object with a partition for each country present in the query result.\n\nWhen the result object is stored this way on Cloud Object Storage, each SQL query that contains a predicate, such as country = 'USA' or country in ('MALTA', 'ITALY', 'VATICAN CITY'), benefits from this physical layout. The reason is that during SQL query execution partitions must be read only if they contain data for the countries of interest. This layout tremendously cuts down the I\/O traffic of the SQL query.\n\nSee the following extra remarks on Hive-style partitioning.\n\n\n\n* Hive-style partitions have an eye-catching naming scheme because the column names that are used for partitioning are part of the partition object prefix, for example, \/order\/COUNTRY=USA\/part-m-00000.snappy.parquet.\n* Hive-style partitions do not contain any values for partition columns since their values are stored in the object prefix of the partition. Thus, if you copy a HIVE-style partition and rename the object prefix by removing the partition column values, you lose data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13480-4908-6825","score":0.0322580645,"text":"\nIncorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.\n\nTo clean up catalog entries for unused data, use the DROP TABLE statement. This statement removes the table definition from the catalog without affecting the actual data on Object Storage:\n\nDROP TABLE customers\n\n\n\n\n\n Partitioned tables \n\nYou can manage a table in the catalog that references data that is organized in multiple partitions on Object Storage. The naming of the objects must adhere to the Hive-style partition naming convention: The object names must include the structure \/columm=value\/. The column must be a column name that is included in the schema definition of the CREATE TABLE statement. You can also have more than one partitioning columns in the object names, such as \/columm1=value\/column2=value\/.\n\nFollowing is an example list of object names on Object Storage that is partitioned on the country column with the Hive-style partition naming convention:\n\ncustomers_partitioned.csv\/country=Germany\/cust-1.csv\ncustomers_partitioned.csv\/country=Germany\/cust-2.csv\ncustomers_partitioned.csv\/country=Spain\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_00576-8941-10714","score":0.0317460317,"text":"\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)\n* [Partitioned databases - data design](https:\/\/blog.cloudant.com\/2019\/03\/05\/Partition-Databases-Data-Design.html)\n\n\n\n\n\n\n\n Making the most of the primary index \n\nIBM Cloudant has a primary index on the document's _id attribute. This index allows documents to be retrieved by _id (GET \/db\/id) or a range of _ids (GET \/db\/_all_docs?startkey=\"a\"&endkey=\"z\"). By storing data in the primary key and ensuring that each _id is unique, the primary index can be used to fetch documents and ranges of documents without secondary indexing. See the following list of ideas:\n\n\n\n* If you have something unique in your object that would be useful to query against, use it as your _id field, for example, bob.smith@gmail.com, isbn9780241265543, or oakland,ca.\n* If your objects contain a hierarchy, model that in your _id: usa:ca:oakland or books:fiction:9780241265543. The hierarchy goes from largest to smallest, so you can use the primary index to find all the cities in usa or all the cities in usa:ca, without secondary indexing.\n* If you're storing time-series data, encoding time at the start of your _id sorts the primary index by time, for example, 001j40Ox1b2c1B2ubbtm4CsuLB4L35wQ.\n* Partitioned databases group documents that share a partition key together. A partition key must have many values and must not include hot spots to avoid directing a large proportion of your application's traffic to a few partitions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00381-3303-3948","score":0.03125,"text":"\nSierra Leone,\nSan Marino,\nSenegal,\nSomalia,\nSuriname,\nSao Tome and Principe,\nEl Salvador,\nSint Maarten,\nSyrian Arab Republic,\nSwaziland,\nTurks and Caicos Islands,\nChad,\nFrench Southern Territories,\nTogo,\nThailand,\nTajikistan,\nTokelau,\nTurkmenistan,\nTunisia,\nTonga,\nEast Timor,\nTurkey,\nTrinidad and Tobago,\nTuvalu,\nTaiwan,\nTanzania, United Republic of,\nUkraine,\nUganda,\nUSA Minor Outlying Islands,\nUnited States,\nUruguay,\nUzbekistan,\nVatican City State,\nSt Vincent and the Grenadines,\nVenezuela,\nVirgin Islands, British,\nVirgin Islands, U.S.,\nViet Nam,\nVanuatu,\nWallis and Futuna,\nSamoa,\nYemen,\nMayotte,\nSouth Africa,\nZambia,\nZimbabwe\n]\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-geoblocking-class"},{"document_id":"ibmcld_13480-6528-8270","score":0.0307692308,"text":"\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table \n\nThis data partitioning is reflected in the PARTITIONED BY clause of the following CREATE TABLE statement:\n\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (country)\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nAutomatic schema detection also recognizes partitioned tables from the structure of the object names, so the same table definition is created from the following statement:\n\nCREATE TABLE customers\nUSING CSV\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nIf your data on Object Storage does not adhere to this naming convention, you can convert it to a Hive-partitioned layout by using Data Engine in a data preparation step. Use SELECT * to copy the data to a new location and specify [PARTITION BY](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencepartitionedClause) in the INTO clause:\n\nSELECT * FROM cos:\/\/us-geo\/sql\/customers.csv\nINTO cos:\/\/us-geo\/mybucket\/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13118-27377-28138","score":0.0303030303,"text":"\nnull 7634piweba3y.prodigy.comGET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null25218 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 4441 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 1414 ntigate.nt.comGET \/images\/const... 20001\/Jul\/1995:04:1...\n null45308line03.pm1.abb.mi...GET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null 669 source.iconz.co.nzGET \/images\/WORLD... 20001\/Jul\/1995:04:1...\n null 234 source.iconz.co.nzGET \/images\/USA-l... 20001\/Jul\/1995:04:1...\n null 363 source.iconz.co.nzGET \/images\/MOSAI... 20001\/Jul\/1995:04:1...\n null13372 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n+---------------------------+-----+--------------------+--------------------+------------+--------------------+\n\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"},{"document_id":"ibmcld_00530-9526-10355","score":0.0298507463,"text":"\n\"Person_name\": \"Robert De Niro\",\n\"Movie_year\": map[string][]interface{}{\n\"$in\": []interface{}{1978, 2009},\n},\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a392eb9f2\",\n\"_rev\": \"1-9faa75d7ea524448b1456a6c69a4391a\",\n\"Movie_runtime\": 183,\n\"Movie_rating\": \"R\",\n\"Person_name\": \"Robert De Niro\",\n\"Movie_genre\": \"DW\",\n\"Movie_name\": \"Deer Hunter, The\",\n\"Person_pob\": \"New York, New York, USA\",\n\"Movie_year\": 1978,\n\"Person_dob\": \"1943-08-17\"\n}\n],\n\"bookmark\": \"g2w ... c2o\"\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-example-movies-demo-database"},{"document_id":"ibmcld_00530-4127-5130","score":0.0294117647,"text":"\nservice = CloudantV1.new_instance()\n\nresponse = service.post_find(\ndb='my-movies',\nselector={'Person_name': 'Zoe Saldana'}\n).get_result()\n\nprint(response)\n\npostFindOptions := service.NewPostFindOptions(\n\"my-movies\",\nmap[string]interface{}{\n\"Person_name\": \"Zoe Saldana\",\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a3941110b\",\n\"_rev\": \"1-556aec0e89fa13769fbf59d651411528\",\n\"Movie_runtime\": 162,\n\"Movie_rating\": \"PG-13\",\n\"Person_name\": \"Zoe Saldana\",\n\"Movie_genre\": \"AVYS\",\n\"Movie_name\": \"Avatar\",\n\"Movie_earnings_rank\": \"1\",\n\"Person_pob\": \"New Jersey, USA\",\n\"Movie_year\": 2009,\n\"Person_dob\": \"1978-06-19\"\n}\n],\n\"bookmark\": \"g2wA ... Omo\"\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-example-movies-demo-database"},{"document_id":"ibmcld_10067-2911-4724","score":0.0289855072,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various oc commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr-tutorial"},{"document_id":"ibmcld_05595-2977-4795","score":0.0285714286,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various kubectl commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr-tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01150-7555-8196","score":0.0327868852,"text":"\nTopic names are backed up by Event Streams, although it is recommended good practice for users to back up topic names and the configuration data for those topics.\n\nIf you have configured your Event Streams instance in a Multi-Zone Region, a regional disaster is very unlikely. However, we recommend that users do plan for such circumstances. If a user's instance is no longer available because of a disaster (and a remote DR instance is not already set up), the user should consider configuring a new instance in a new region and restoring their topics and data from backup if available. Applications can then be pointed at the new instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-faqs"},{"document_id":"ibmcld_05608-1309-3624","score":0.0322580645,"text":"\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_14774-18795-21198","score":0.0317460317,"text":"\nWhile this design has only one backup server instance, it is recommended to deploy Enterprise Manager when encryption is used for backup or backup copy jobs. It is advised to install the Enterprise Manager server on the recovery site so it is available for disaster recovery.\n* Proxy server - This proxy is used for management components that are located in the recovery region.\n* Repository - A location used to store backup files for the management components in the recovery region and also the target for backup copy jobs from the protected region.\n* SFTP\/SMB server - These servers are not Veeam services but native Windows services that are used for file-level backups of some of the management components. A Veeam file copy job copies files to the protected region for extra protection.\n\n\n\nReview the following Veeam design decisions:\n\n\n\n* For optimal performance and availability, placing the Veeam components on separate virtual and physical servers is considered best practice. However, this practice increases complexity in smaller environments. Therefore, the all-in-one deployment scenario for use case 1 is selected.\n* As the total number of protected VMs is low, the embedded database option for the database for use case 1 is selected.\n* The bare metal servers with direct attached storage option are used as it provides a backup infrastructure that is separated from the virtualized infrastructure compute and storage.\n* In a two-site environment, it is best practice to install the Veeam Backup server component in the DR site. In a disaster situation, Veeam Backup server is available to start the recovery.\n* Deploy Enterprise Manager to use password loss protection. Enterprise Manager administrators can unlock backup files by using a challenge-response mechanism.\n* It is recommended that the proxy is as close as possible to the source data with a high-bandwidth connection. The traffic from the source to the proxy is not yet optimized, meaning that 100% of the backup data is transferred over this link. A good connection is required between proxy and repository as optimized data (normally 50% of the source data size) is transferred across this link. Therefore, place proxies in both the protected and recovery regions.\n* Proxies can be hosted on Windows Server or Linux OS with almost no performance differences. For the all-in-one deployment scenario, a Windows OS is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_10070-1149-3304","score":0.03125,"text":"\n* [Version 4.9](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_00951-13787-15219","score":0.0307692308,"text":"\nThe clone, fork, and new types instruct the Git tool integration to create the target repo (repo_url) on the premise that this repo does not exist. If the tool integration finds the target repo, it fails by design.\n\n How to fix it \n\nChange the type from clone, fork, or new to clone_if_not_exists, fork_if_not_exists, or new_if_not_exists. These types instruct the Git tool integration to create the target repo if it does not exist, or to use the target repo as-is if it does exist.\n\nAlthough you can use other methods to resolve this error, these methods are not recommended because you might lose information. These methods also might require changes to your Terraform that are not good practices.\n\n\n\n* Change repo_url to a repo that is created when you apply your Terraform again. Changing a Terraform resource after the initial creation to avoid errors during subsequent updates is an anti-pattern. This method also leaves the previously created repos intact, but no longer bound to the toolchain.\n* Change type to existing, and then apply your Terraform again. Changing a Terraform resource after the initial creation to avoid errors during subsequent updates is an anti-pattern.\n* Manually delete the target repo, and then apply your Terraform again. Manual changes between otherwise automated Terraform operations are not recommended. If you delete the repo, the deletion cannot be undone, and can cause permanent data loss.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-troubleshoot-git"},{"document_id":"ibmcld_12453-9092-11379","score":0.0303030303,"text":"\nWhen you update a root CA certificate, the change impacts your entire public-key infrastructure. To minimize impact, it is recommended that you set a long validity period for your root CA certificate. In Secrets Manager, the default TTL for root certificates is 10 years.\n\n\n\n\n\n\n\n Choosing an algorithm for generating keys \n\nBefore you create a certificate authority in Secrets Manager, you must choose a key algorithm for generating the public and private keys for your CA. The public and private key-pair is used to authenticate an SSL\/TLS connection. If you're not sure where to start, you can use the following suggested guide for selecting a key algorithm.\n\n\n\n1. Choose an algorithm family.\n\nThe key algorithm that you select determines the encryption algorithm and key size to use to generate keys and sign certificates. As a best practice, use the same algorithm family for all certificates that belong to a certificate chain. Secrets Manager supports the following families of algorithms.\n\n\n\nTable 2. Supported algorithm families and key sizes\n\n Algorithm family Description Supported key sizes \n\n RSA Widely used and compatible with most browsers and servers, RSA is the industry standard for public-key cryptography. 2048 bits <br>4096 bits \n Elliptic curve (EC) Generates stronger keys and smaller certificates. For example, a 256-bit EC key is equivalent in encryption strength to a 3072-bit RSA key. 224 bits <br>256 bits <br>384 bits <br>521 bits \n\n\n\n2. Choose a key size.\n\nThe key size or length that you select determines the encryption strength. The larger the key size for an algorithm family, the more difficult it is to break. Keep in mind that longer key lengths results in more data to store and transmit, which can impact the performance of your certificate. As a best practice, choose a key size that is appropriate for the TTL or validity period of your certificate.\n\nFor longer living certificates, it is recommended to use longer key lengths to provide more encryption protection.\n\n\n\n\n\n\n\n\n\n Using certificate authority unauthenticated endpoints \n\nIf you're using leaf certificates that are issued by a CA in Secrets Manager for your applications, use the following API calls to gain access to the issuing CA Certificate Revocation List (CRL) and CA certificate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-create-certificates"},{"document_id":"ibmcld_04113-7-2190","score":0.0298507463,"text":"\nBest practices for CIS setup \n\nBecause IBM Cloud\u00ae Internet Services is positioned at the edge of your network, you\u2019ll need to take a few steps to guarantee a smooth integration with your CIS services. Here are some recommended best practices for integrating CIS with your origin servers.\n\nYou can do these steps either before or after you change your DNS and activate our proxy service. These recommendations allow CIS to connect to your origin servers properly. They\u2019ll help you prevent any issues with API or HTTPS traffic, and help your logs capture the correct IP addresses of your customers, rather than the protective CIS IP addresses.\n\nHere\u2019s what you\u2019ll need to set up:\n\n\n\n* Restore the originating IPs of your customers\n* Incorporate CIS IP addresses\n* Make sure your security settings don't interfere with API traffic\n* Configure your security settings as strictly as possible\n\n\n\n\n\n Best practice 1: Know how to restore the originating IPs of your customers \n\nAs a reverse proxy, CIS provides the origination IP in these headers:\n\n\n\n* CF-Connecting-IP\n* X-Forwarded-For\n* True-Client-IP (optional)\n\n\n\nYou can restore user IP addresses using a variety of tools, for infrastructures such as Apache, Windows IIS, and NGINX.\n\n\n\n\n\n Best practice 2: Incorporate CIS IP addresses to make integration smoother \n\nHere are the two steps to take:\n\n\n\n* Remove any rate limiting of CIS IP addresses\n* Set up your ACLs to allow only CIS IP addresses and other trusted parties\n\n\n\nYou can find the updated list of IP ranges for IBM CIS [at this location](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses).\n\n\n\n\n\n Best practice 3: Review your security settings to make sure they don\u2019t interfere with API traffic \n\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_14710-7-1982","score":0.0294117647,"text":"\nVeeam backup proxy \n\nA backup proxy is a Veeam\u00ae component that sits between the backup server and other components of the backup infrastructure. While the backup server administers tasks, the proxy processes jobs and delivers backup traffic to the backup repository. Key design elements of backup proxies include the following details:\n\n\n\n* By default, the role of the backup proxy is assigned to the backup server. It is recommended to deploy dedicated backup proxies.\n* For scaling, backup proxies can be scaled-out or scaled-up.\n* A backup proxy can be deployed on either a physical or virtual Windows\u00ae-based or Linux\u00ae-based server.\n* In practice, performance differences don't exist between Windows and Linux proxies. Therefore, the OS decision can be based on such things as licensing.\n* Backup proxies run the following components and services:\n\n\n\n* The Veeam Installer Service is an auxiliary service that is installed only on the Windows-based server and is used to analyze, install, and upgrade the components.\n* The Veeam Data Mover performs the data processing tasks that include retrieving virtual machine (VM) data from storage, compressing, de-duplicating, encrypting, and sending data to the backup repository.\n\n\n\n* Ideally, plan for one physical core or one vCPU and 2 GB of RAM for each configured proxy task, where a proxy task processes one VM disk.\n* For virtual backup proxy servers, it is recommended to configure proxies with maximum of 8 vCPUs to avoid scheduling issues.\n* Typically, virtual backup proxy servers use 4, 6, or 8 vCPUs.\n* For a physical backup proxy, consider a 20-core server with 48 GB RAM and dual 10 GB NICS.\n* The traffic from the source to the backup proxy is not optimized, for example, compressed or de-duped. Therefore, 100% of the backup data is transferred over this connection.\n* Between the backup proxy and backup repository, optimized data typically about 50% of the source data size is transferred over this connection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-vp"},{"document_id":"ibmcld_07498-0-1649","score":0.0289855072,"text":"\n\n\n\n\n\n\n  Enterprise account architecture \n\nLarge enterprises that allow an account structure, cross account networking, resource deployment, and billing to develop organically run the risk of encountering governance, scaling, security, and accounting issues. This document provides a recommendation for how to address these concerns across accounts so that a robust, compliant, and scalable solution can be achieved.\n\nThis recommendation extends and compliments the account and resource level guidance that is found in the [IBM Cloud Framework for Financial Services](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-about) and other IBM Cloud best practices such as:\n\n\n\n*  [Cloud best practices for IT executives](https:\/\/www.ibm.com\/downloads\/cas\/NYWPPW6K)\n*  [Best practices for setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-best-practices)\n*  [Best practices for organizing resources and assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setup)\n*  [Best practices for organizing users, teams, and applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)\n*  [Best practices for working with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-best-practices)\n*  [Best practices for billing and usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-best-practices)\n*  [Advanced networking for IBM Cloud VPC](https:\/\/www.ibm.com\/cloud\/architecture\/content\/course\/advanced-networking-for-vpc)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-about"},{"document_id":"ibmcld_09109-8993-10845","score":0.0285714286,"text":"\nTo encode your key material, first you should download and install [OpenSSL](https:\/\/github.com\/openssl\/opensslfor-production-use).\n\nOnce OpenSSL has been downloaded and installed, there are two recommended commands for encoding the key material. Both methods are equivalent, in that they convert a string , whether <key_material_string> or , as you can see below, into a base64 string. If your material is in a file (for example, you might have a file with credentials, not just an encrypted key, that you want to store in Key Protect), the best option is to issue:\n\n {: pre}\nopenssl base64 -in <infile> -out <outfile>\n\nReplace the variables in the example request according to the following table.\n\n\n\nTable 2. Describes the variables that are needed to base64-encode your key material.\n\n Variable Description \n\n infile The name of the binary file where your key material string resides. <br> <br>Ensure that the file is not larger than 7,500 bytes. \n outfile The name of the file where your base64-encoded key material will be created once the command has run. \n\n\n\nIf you want to output the base64 material in the command line directly rather than a file, run the command openssl enc -base64 <<< '<key_material_string>', where key_material_string is the key material input for your imported key.\n\nIf you want to base 64 encode key material which is not in a file, you can issue:\n\n {: pre}\necho -n <password> | base64\n\nWhere \"password\" is the key material you want to use.\n\nTo avoid extra characters, for example an extra new line, it is a best practice to copy the base64 to the clipboard, especially when the base64 string is going to be posted in the console.\n\n\n\n\n\n Using OpenSSL to create and encode new key material \n\nUse this process to create a random base64-encoded key material with a specific byte length. 32 bytes (256 bits) is recommended.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05821-7-2076","score":0.0163934426,"text":"\nUnderstanding high availability and disaster recovery \n\nUse the built-in Kubernetes and IBM Cloud\u00ae Kubernetes Service features to make your cluster more highly available and to protect your app from downtime when a component in your cluster fails.\n\n\n\n About high availability \n\nHigh availability (HA) is a core discipline in an IT infrastructure to keep your apps up and running, even after a partial or full site failure. The main purpose of high availability is to eliminate potential points of failures in an IT infrastructure. For example, you can prepare for the failure of one system by adding redundancy and setting up failover mechanisms.\n\nWhat level of availability is best?\n: You can achieve high availability on different levels in your IT infrastructure and within different components of your cluster. The level of availability that is correct for you depends on several factors, such as your business requirements, the Service Level Agreements that you have with your customers, and the resources that you want to expend.\n\nWhat level of availability does IBM Cloud offer?\n: See [How IBM Cloud ensures high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime).\n\nThe level of availability that you set up for your cluster impacts your coverage under the [IBM Cloud HA service level agreement terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas). For example, to receive full HA coverage under the SLA terms, you must set up a multizone cluster with a total of at least 6 worker nodes, two worker nodes per zone that are evenly spread across three zones.\n\nWhat are the other cluster components that support highly available architecture?\n: See [Overview of potential points of failure in IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-hafault_domains).\n\nWhere is the service located?\n: See [Locations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zonesregions-and-zones).\n\nWhat am I responsible to configure disaster recovery options for?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha"},{"document_id":"ibmcld_05259-5125-6683","score":0.0163934426,"text":"\nNote that you cannot delete a job run without also deleting any associated pods. Any attempt to delete with the propagationPolicy=Orphan option is rejected.\n\n\n\n\n\n Serving CRD methods \n\n\n\nServing CRDs for Code Engine\n\n Group Version Kind \n\n serving.knative.dev v1 Configuration \n serving.knative.dev v1 Revision \n serving.knative.dev v1 Route \n serving.knative.dev v1 Service \n\n\n\nFor more information about these CRDs, see [Knative Serving API Specification](https:\/\/github.com\/knative\/specs\/blob\/main\/specs\/serving\/knative-api-specification-1.0.md).\n\n\n\n\n\n Source-to-image CRD methods \n\n\n\nSource-to-image CRDs for Code Engine\n\n Group Version Kind \n\n shipwright.io v1alpha1 Build \n shipwright.io v1alpha1 BuildRun \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view the Source-to-image CRD details by using one of the following methods.\n\n\n\n* Use kubectl explain --api-version='shipwright.io\/v1alpha1' <KIND>.\n* [Download the Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).\n\n\n\n\n\n\n\n Subscription CRD methods \n\n\n\nSubscription CRDs for Code Engine\n\n Group Version Kind \n\n sources.codeengine.cloud.ibm.com v1alpha1 CosSource \n sources.knative.dev v1 PingSource \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view the Subscription CRD details by using one of the following methods.\n\n\n\n* Use kubectl explain --api-version='sources.knative.dev\/<VERSION>' <KIND>.\n* [Download the Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-api"},{"document_id":"ibmcld_10231-7-2093","score":0.0161290323,"text":"\nUnderstanding high availability and disaster recovery \n\nUse the built-in Red Hat OpenShift, Kubernetes, and IBM Cloud\u00ae features to make your Red Hat OpenShift cluster more highly available and to protect your app from downtime when a component in your cluster fails.\n\n\n\n About high availability \n\nHigh availability (HA) is a core discipline in an IT infrastructure to keep your apps up and running, even after a partial or full site failure. The main purpose of high availability is to eliminate potential points of failures in an IT infrastructure. For example, you can prepare for the failure of one system by adding redundancy and setting up failover mechanisms.\n\nWhat level of availability is best?\n: You can achieve high availability on different levels in your IT infrastructure and within different components of your cluster. The level of availability that is correct for you depends on several factors, such as your business requirements, the Service Level Agreements that you have with your customers, and the resources that you want to expend.\n\nWhat level of availability does IBM Cloud offer?\n: See [How IBM Cloud ensures high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime).\n\nThe level of availability that you set up for your cluster impacts your coverage under the [IBM Cloud HA service level agreement terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas). For example, to receive full HA coverage under the SLA terms, you must set up a multizone cluster with a total of at least 6 worker nodes, two worker nodes per zone that are evenly spread across three zones.\n\nWhat are the other cluster components that support highly available architecture?\n: See [Overview of potential points of failure in Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-hafault_domains).\n\nWhere is the service located?\n: See [Locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zonesregions-and-zones).\n\nWhat am I responsible to configure disaster recovery options for?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha"},{"document_id":"ibmcld_16628-0-1541","score":0.0161290323,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_03137-4194-5167","score":0.0158730159,"text":"\nIf it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autocorrection"},{"document_id":"ibmcld_04085-7-1799","score":0.0158730159,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_02932-7-1953","score":0.015625,"text":"\nCorrecting user input \n\nAutocorrection fixes misspellings that users make in the utterances that they submit as user input. When autocorrection is enabled, the misspelled words are automatically corrected. And it is the corrected words that are used to evaluate the input. When given more precise input, your assistant can more often recognize entity mentions and understand the user's intent.\n\nAutocorrection is enabled automatically for all new English-language dialog skills. It is available as a beta feature in French-language dialog skills. You must turn it on to use it with French-language skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\nAutocorrection corrects user input in the following way:\n\n\n\n* Orignal input: letme applt for a memberdhip\n* Corrected input: let me apply for a membership\n\n\n\nWhen your assistant evaluates whether to correct the spelling of a word, it does not rely on a simple dictionary lookup process. Instead, it uses a combination of Natural Language Processing and probabalistic models to assess whether a term is, in fact, misspelled and should be corrected.\n\n\n\n Turning autocorrection on or off \n\nAutocorrection helps your assistant understand user input. It is enabled automatically for some languages and available, but disabled in others.\n\nIf you decide to disable it, you must turn it off entirely. You cannot disable autocorrection for a single word or phrase.\n\nIf you find that a domain-specific term is being corrected that shouldn't be, you can prevent the correction from happening by adding the term or phrase to your training data. For more details, see [Autocorrection rules](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-checkdialog-runtime-spell-check-rules).\n\nTo turn autocorrection on or off, complete the following steps:\n\n\n\n1. Click the Skills icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-check"},{"document_id":"ibmcld_03824-7-1809","score":0.015625,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_13741-9267-11290","score":0.0153846154,"text":"\nEach word\/translation pair in a model tells the service how to pronounce a word when it occurs in input text.\n\nYou can use custom models to create application-specific translations for unusual words for which the service's regular pronunciation rules might yield imperfect pronunciations. For example, your application might routinely encounter domain-specific terms, special terms with foreign origins, personal or geographic names, or abbreviations and acronyms. By using customization, you can define translations that tell the service how you want such terms to be pronounced.\n\nYou can define the custom entry for a word\/translation pair based on other words, or you can create pronunciations based on phoneme symbols in the standard International Phonetic Alphabet (IPA) or the proprietary IBM Symbolic Phonetic Representation (SPR). Customization is available for all languages.\n\n\n\n* For more information about customization, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro).\n* For more information about using phonetic IPA and SPR symbols, see [Understanding phonetic symbols](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-symbols).\n\n\n\nIBM Cloud\n\nYou must have the Standard or Premium pricing plan to use customization. Users of the Lite plan cannot use the customization interface. For more information about pricing plans, see the Text to Speech service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/text-to-speech).\n\n\n\n Creating a custom voice \n\nIBM Cloud\n\nPremium customers can work with IBM to train a new custom voice for their specific application needs. A custom voice is a unique voice that is based on audio training data that the customer provides. IBM can train a custom voice with as little as one hour of training data.\n\nTo request a custom voice or for more information, complete and submit this [IBM Request Form](https:\/\/form.asana.com\/?k=CBuXK1uwlAf5ek6FwB6mcg&d=8612789739828).\n\n\n\n\n\n\n\n Using Tune by Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-features"},{"document_id":"ibmcld_11164-6586-7646","score":0.0153846154,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05342-35727-36837","score":0.0327868852,"text":"\n_) \/ \/( (_ )( \/ \/ ) _)\n(____)_)__) ___\/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=\/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPWD=\/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap-secret"},{"document_id":"ibmcld_05436-35667-36777","score":0.0322580645,"text":"\n_) \/ \/( (_ )( \/ \/ ) _)\n(____)_)__) ___\/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=\/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPWD=\/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret"},{"document_id":"ibmcld_05557-5511-7293","score":0.0317460317,"text":"\nIn Kubernetes cluster versions 1.21 and later, Konnectivity replaced the OpenVPN solution. If you have cluster version 1.21 and later, and your webhook uses the ClusterIP, you must update your webhook to use a Kubernetes service instead.\n\nYou can configure a webhook by referencing the webhook app as a Kubernetes service, or by referencing the webhook app as an IP address or publicly registered DNS name.\n\nExample configuration for referencing the webhook app as a Kubernetes service\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nservice:\nname: admission-webhook\nnamespace: default\npath: \/validate\nport: 443\n\nExample configuration for referencing the webhook app as an IP address or publicly registered DNS name\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nurl: https:\/\/WEBHOOK_URL:443\/validate\n\nShow more\n\nNote the following limitations for referencing the webhook app as an IP address or DNS name:\n\n\n\n* If the URL is a DNS, then this DNS must be a publicly registered DNS name. Private DNS configurations are not supported.\n* If the URL is an external IP address, which means the webhook service is outside of the cluster, the control plane network is used to connect to the service. The control plane must be able to reach the IP address. If, for example, the IP address is from an on-premises network and the control plane can't reach the IP address, the webhook service does not work.\n* If the URL is a cluster IP address, which means the webhook service is inside of the cluster, the Kubernetes API needs to connect to cluster network. If you have cluster version 1.21 and later, and your webhook uses the cluster IP address, you must update your webhook to use a Kubernetes service instead.\n\n\n\n\n\n\n\n\n\n I need help with a broken webhook. What can I do?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooks"},{"document_id":"ibmcld_11886-2994-4812","score":0.03125,"text":"\nFor more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/).\n\nIf you choose a custom access option, some Satellite Config components might not work. For example, if you grant access to view only certain resources, you cannot use subscriptions to create Kubernetes resources in your cluster group. To view an inventory of your Kubernetes resources in a cluster, Satellite Config must have an appropriate role that is bound to the razee-viewer service account. To deploy Kubernetes resources to a cluster by using subscriptions, Satellite Config must have an appropriate role that is bound to the razee-editor service account.\n\n\n\n\n\n Cluster admin access \n\nGrant the Satellite Config service accounts access to the cluster admin role.\n\nkubectl create clusterrolebinding razee-cluster-admin --clusterrole=razee-cluster-admin --serviceaccount=razeedeploy:razee-viewer --serviceaccount=razeedeploy:razee-editor --serviceaccount=razeedeploy:razee-satcon\n\n\n\n\n\n Custom access, cluster-wide \n\nCreate custom RBAC policies to grant Satellite Config access to the actions and Kubernetes resources that you want for the cluster.\n\n\n\n1. Create a cluster role with the actions and resources that you want to grant. For example, the following command creates a viewer role so that Satellite Config can list all the Kubernetes resources in a cluster, but cannot modify them.\n\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_02683-2805-4831","score":0.0307692308,"text":"\nFor your application and SDK to continue operations during the unlikely scenario of an App Configuration service downtime, across your application restarts, you can configure the SDK to work by using a persistent cache. The SDK uses the persistent cache to store the App Configuration data that is available across your application restarts.\n\n\/\/ 1. default (without persistent cache)\nappConfigClient.setContext(collectionId, environmentId);\n\n\/\/ 2. optional (with persistent cache)\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setPersistentCacheDirectory(\"\/var\/lib\/docker\/volumes\/\");\nappConfigClient.setContext(collectionId, environmentId, configOptions);\n\nWhere:\n\n\n\n* persistentCacheDirectory: Absolute path to a directory that has read and write permission for the user. The SDK creates a file - appconfiguration.json in the specified directory, and it is used as the persistent cache to store the App Configuration service information.\n\n\n\nWhen persistent cache is enabled, the SDK keeps the last known good configuration at the persistent cache. If the App Configuration server being unreachable, the latest configurations at the persistent cache are loaded to the application to continue working.\n\nEnsure that the cache file is not lost or deleted in any case. For example, consider the case when a kubernetes pod is restarted and the cache file (appconfiguration.json) was stored in ephemeral volume of the pod. As pod gets restarted, kubernetes destroys the ephermal volume in the pod, as a result the cache file gets deleted. So, make sure that the cache file created by the SDK is always stored in persistent volume by providing the correct absolute path of the persistent directory.\n\n\n\n\n\n Offline options \n\nThe SDK is also designed to serve configurations, and perform feature flag and property evaluations without being connected to App Configuration service.\n\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setBootstrapFile(\"saflights\/flights.json\");","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_06123-1617-3175","score":0.0303030303,"text":"\nRPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Kubernetes clusters are deployed in different regions, such as us-south and us-east. Each cluster has its own Portworx installation and uses a separate Portworx key-value store that is not shared. To replicate data between clusters, you must set up scheduled replication between these clusters. Because of the higher latency and scheduled replication times, the RPO for this scenario might be up to 15 minutes.\n\n\n\nTo include your cluster in a Portworx disaster recovery configuration:\n\n\n\n1. [Choose the disaster recovery configuration that works for your cluster setup](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/).\n2. Review the prerequisites for the [Metro DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/px-metro\/1-install-px\/prerequisites) and [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/async-dr\/pre-requisites) configuration.\n3. Configure disaster recovery for your cluster. Metro DR:\n\n\n\n1. Choose at least two Kubernetes clusters that are located in the same metro location. If you have one cluster only, you can still configure this cluster for metro disaster recovery, but Portworx can't do a proper failover until a second cluster is configured.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_recovery"},{"document_id":"ibmcld_06004-14210-16020","score":0.0298507463,"text":"\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/cron-jobs\/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/) or [Secret](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_10439-18453-20263","score":0.0294117647,"text":"\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/cron-jobs\/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/) or [Secret](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_07578-534510-536520","score":0.0289855072,"text":"\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-534464-536474","score":0.0285714286,"text":"\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11886-7-2186","score":0.0322664585,"text":"\nGranting Satellite Config access to your clusters \n\nBy default, clusters that you create in a Satellite location have Satellite Config components automatically installed. However, you must grant the service accounts that Satellite Config uses the appropriate access to view and manage Kubernetes resources in each cluster.\n\nSatellite Config requires admin access to your clusters to manage them. You can configure access in one of the following ways.\n\n\n\n* Automatically during cluster creation. Choose this option if you want to use Satellite storage templates.\n* Manually after cluster creation. Choose this option if you want more controlled access and do not plan on using Satellite storage templates.\n\n\n\nIf you do not grant Satellite Config access, you cannot later use the Satellite Config functionality to view or deploy Kubernetes resources for your clusters.\n\n\n\n Automatically granting Satellite Config access to your clusters \n\nYou can give Satellite Config access to your cluster by specifying the relevant option when you create the cluster.\n\nTo give Satellite Config access to manage Kubernetes resources from the console, select Enable cluster admin access for Satellite Config when you create the cluster. To set up access with the CLI, specify the --enable-config-admin option when you create the cluster.\n\nIf you didn't give Satellite Config access at cluster creation time, follow the steps in [Manually granting Satellite Config access to your clusters](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigmanual-setup-clusters-satconfig).\n\n\n\n\n\n Manually granting Satellite Config access to your clusters \n\nIf you did not grant Satellite Config access to your cluster during cluster creation time, you can still set up the access manually.\n\nChoose from the following options.\n\n\n\n* Admin access when you create a Satellite cluster: You can enable admin permissions when you create the cluster in the console or in the CLI by using the --enable-config-admin option in the ibmcloud oc cluster create satellite command. After creating the cluster, you must perform a one-time login by running ibmcloud ks cluster config in the command line.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_07578-380995-382843","score":0.0312805474,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-380969-382817","score":0.030798389,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11886-2994-4812","score":0.0163934426,"text":"\nFor more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/).\n\nIf you choose a custom access option, some Satellite Config components might not work. For example, if you grant access to view only certain resources, you cannot use subscriptions to create Kubernetes resources in your cluster group. To view an inventory of your Kubernetes resources in a cluster, Satellite Config must have an appropriate role that is bound to the razee-viewer service account. To deploy Kubernetes resources to a cluster by using subscriptions, Satellite Config must have an appropriate role that is bound to the razee-editor service account.\n\n\n\n\n\n Cluster admin access \n\nGrant the Satellite Config service accounts access to the cluster admin role.\n\nkubectl create clusterrolebinding razee-cluster-admin --clusterrole=razee-cluster-admin --serviceaccount=razeedeploy:razee-viewer --serviceaccount=razeedeploy:razee-editor --serviceaccount=razeedeploy:razee-satcon\n\n\n\n\n\n Custom access, cluster-wide \n\nCreate custom RBAC policies to grant Satellite Config access to the actions and Kubernetes resources that you want for the cluster.\n\n\n\n1. Create a cluster role with the actions and resources that you want to grant. For example, the following command creates a viewer role so that Satellite Config can list all the Kubernetes resources in a cluster, but cannot modify them.\n\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_05525-70102-71582","score":0.0161290323,"text":"\nKubernetes v1.13.5 v1.14.1 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.14.1) and [Kubernetes 1.14 blog](https:\/\/kubernetes.io\/blog\/2019\/03\/25\/kubernetes-1-14-release-announcement\/). <br>The Kubernetes default role-based access control (RBAC) policies no longer grant access to [discovery and permission-checking APIs to unauthenticated users](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/rbac\/discovery-roles). This change applies only to new version 1.14 clusters. If you update a cluster from a prior version, unauthenticated users still have access to the discovery and permission-checking APIs. \n Kubernetes admission controllers configuration N\/A N\/A <br><br> * Added NodeRestriction to the --enable-admission-plugins option for the cluster's Kubernetes API server and configured the related cluster resources to support this security enhancement.<br> * Removed Initializers from the --enable-admission-plugins option and admissionregistration.k8s.io\/v1alpha1=true from the --runtime-config option for the cluster's Kubernetes API server because these APIs are no longer supported. Instead, you can use [Kubernetes admission webhooks](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/).<br><br><br> \n Kubernetes DNS autoscaler 1.3.0 1.4.0 See the [Kubernetes DNS autoscaler release notes](https:\/\/github.com\/kubernetes-sigs\/cluster-proportional-autoscaler\/releases\/tag\/1.4.0).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-114_changelog"},{"document_id":"ibmcld_05777-8738-10765","score":0.015625,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_10646-26054-27582","score":0.015625,"text":"\nverbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n\n\n\nTable 3. Understanding the YAML parameters\n\n Parameter Description \n\n kind Use Role to grant access to resources within a specific namespace. Use ClusterRole to grant access to cluster-wide resources such as worker nodes, or to namespace-scoped resources such as pods in all namespaces. \n apiVersion <br><br> * For clusters that run Kubernetes 1.8 or later, use rbac.authorization.k8s.io\/v1.<br> * For earlier versions, use apiVersion: rbac.authorization.k8s.io\/v1beta1.<br><br><br> \n metadata.namespace For kind Role only: Specify the Kubernetes namespace to which access is granted. \n metadata.name Name the role or cluster role. \n rules.apiGroups Specify the Kubernetes [API groups](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-groups) that you want users to be able to interact with, such as \"apps\", \"batch\", or \"extensions\". For access to the core API group at REST path api\/v1, leave the group blank: [\"\"]. \n rules.resources Specify the Kubernetes [resource types](https:\/\/kubernetes.io\/docs\/reference\/kubectl\/cheatsheet\/) to which you want to grant access, such as \"daemonsets\", \"deployments\", \"events\", or \"ingresses\". If you specify \"nodes\", then the kind must be ClusterRole. \n rules.verbs Specify the types of [actions](https:\/\/kubectl.docs.kubernetes.io\/) that you want users to be able to do, such as \"get\", \"list\", \"describe\", \"create\", or \"delete\". \n\n\n\n2. Create the role or cluster role in your cluster.\n\noc apply -f my_role.yaml\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users"},{"document_id":"ibmcld_10214-7502-9481","score":0.0153846154,"text":"\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_reference) or in the following table's links.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10026-37631-39076","score":0.0153846154,"text":"\n--service-instance <cluster_ID> To restrict the policy to a particular cluster, enter the cluster's ID. To get your cluster ID, run ibmcloud oc clusters. If you don't include the service instance, the access policy grants the service ID access to all your clusters, Kubernetes and Red Hat OpenShift. You can also scope the access policy to a region (--region) or resource group (--resource-group-name). \n\n\n\n3. Create an API key for the service ID. Name the API key similar to your service ID, and include the service ID that you previously created, <cluster_name>-id. Be sure to give the API key a description that helps you retrieve the key later. Save your API key in a secure location. You can't retrieve the API key again. If you want to export the output to a file on your local machine, include the --file <path>\/<file_name> option.\n\nibmcloud iam service-api-key-create <cluster_name>-key <service_ID> --description \"API key for service ID <service_ID> in Red Hat OpenShift cluster <cluster_name>\"\n\nExample output\n\nPlease preserve the API key! It can't be retrieved after it's created.\n\nName <cluster_name>-key\nDescription API key for service ID <service_ID> in Red Hat OpenShift cluster <cluster_name>\nBound To crn:v1:bluemix:public:iam-identity::a\/1bb222bb2b33333ddd3d3333ee4ee444::serviceid:ServiceId-ff55555f-5fff-6666-g6g6-777777h7h7hh\nCreated At 2019-02-01T19:06+0000\nAPI Key i-8i88ii8jjjj9jjj99kkkkkkkkk_k9-llllll11mmm1\nLocked false","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster"},{"document_id":"ibmcld_07578-400150-401930","score":0.0151515152,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-haha).\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6934264036,"ndcg_cut_5":0.6934264036,"ndcg_cut_10":0.6934264036}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04156-0-1820","score":0.0327868852,"text":"\n\n\n\n\n\n\n  Getting help and support for CIS \n\nIf you experience an issue or have questions when using CIS, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq) in the product documentation.\n*  Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshoot-your-cis-network-connection) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n*  Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=cis+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cis so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CIS \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CIS.\n\nProvide the following details:\n\n\n\n1.  Provide your CRN:\n\n\n\n*  In the UI, go to the Overview page\n*  In the CLI, run ibmcloud resource service-instances --long\n\n\n\n2.  Provide your Domain name or ID.\n3.  Depending on the issue the following information might also be helpful:\n\n\n\n*  Account ID: Log into [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com) and go to View Profile > Billing\n*  Instance ID: Run the CLI command ibmcloud resource service-instances --long\n*  Geo location\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-gettinghelp"},{"document_id":"ibmcld_00384-0-1839","score":0.0322580645,"text":"\n\n\n\n\n\n\n  Getting help and support for CDN \n\nIf you experience an issue or have questions when using CDN, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faqs) in the product documentation.\n*  Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-troubleshoot-cdn-working) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n*  Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=cdn+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cdn so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CDN \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CDN.\n\nProvide the following details:\n\n\n\n1.  Go to the [All CDNs page](https:\/\/cloud.ibm.com\/cdn).\n2.  From the UI, provide the following information:\n\n\n\n*  (Required) Hostname, for example, example.testingcdn.net\n*  CNAME, for example, example.cdn.appdomain.cloud\n*  HTTPS status, for example, Yes (Wildcard)\n*  Status, for example, Running\n\n\n\nFrom the API, run listDomainMappings or listDomainMappingByUniqueId to get the following domain mapping information:\n\n\n\n*  (Required) domain\n*  cname\n*  protocol\n*  status\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-gettinghelp"},{"document_id":"ibmcld_14241-0-1025","score":0.0317460317,"text":"\n\n\n\n\n\n\n  Contacting IBM Support \n\nIf you need help with IBM Cloud\u00ae for VMware as a Service, create a case from the IBM Cloud Support Center to get assistance.\n\n\n\n  Procedure to create a case for VMware as a Service \n\n\n\n1.  Go to the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n2.  Log in with your IBMid account.\n3.  Select All Products and type VMware as a Service where prompted for the product name, then click IBM Cloud for VMware as a Service.\n4.  Review the various solutions offered. If you do not see an answer to your problem, click Create a case.\n5.  On the New support case page, provide the following information:\n\n\n\n1.  Enter a subject for your issue.\n2.  Describe your issue in detail, such as the error messages, steps to re-create, and the URL that you are accessing.\n3.  Under Add attachments, upload screen captures of the issue.\n4.  If you want to be notified of updates on the issue, select the Email me updates about this case checkbox.\n\n\n\n6.  Click Submit.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-support"},{"document_id":"ibmcld_13830-7-2040","score":0.03125,"text":"\nGetting help and support for Transit Gateway \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae Transit Gateway, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-faqs-for-transit-gateway) in the product documentation.\n* Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-troubleshooting) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=transit-gateway+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and transit-gateway so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for Transit Gateway \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with Transit Gateway.\n\nProvide the following details:\n\n\n\n1. Provide your transit gateway ID:\n\n\n\n* Run ibmcloud tg gateways to get the Transit Gateway ID for the transit gateway in question from the output, and then collect the output of these commands ibmcloud tg gateway GATEWAY_ID and ibmcloud tg connections GATEWAY_ID.\n* In the output of the previous command, get the connection IDs for the connections to the relevant VPCs, and if relevant, the classic infrastructure connection. Also, collect the output of the following command against each connection ID: ibmcloud tg connection GATEWAY_ID CONNECTION_ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-getting-help-and-support"},{"document_id":"ibmcld_07395-7-1761","score":0.0307692308,"text":"\nGetting help and support for DNS Services \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae DNS Services, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-frequently-asked-questions) in the product documentation.\n* Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-troubleshoot-nxdomain) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=dns-svcs+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and dns-svcs so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for DNS Services \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with DNS Services.\n\nProvide the following details:\n\n\n\n1. The specific IDs of affected VPCs.\n2. The IDs of the DNS Services private resource records (if any).\n3. The IDs of zones that have affected private resource records (if any).\n4. The DNS queries made. If possible, give the details on DNS queries related to the issue, including DNS message ID and timestamp for each.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-gettinghelp"},{"document_id":"ibmcld_10771-0-1225","score":0.0303030303,"text":"\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions about IBM Cloud\u00ae Functions, you can get help by joining the IBM Cloud\u00ae Functions community in Slack, asking questions through a forum, or opening an IBM Cloud support case.\n\n\n\n*  To see whether IBM Cloud is available, [check the IBM Cloud status page](https:\/\/cloud.ibm.com\/status?selected=status).\n*  Review the forums to see whether other users ran into the same issue. When you use the forums to ask a question, tag your question so that it is seen by the IBM Cloud development teams.\n\n\n\n*  If you have technical questions about developing functions with IBM Cloud\u00ae Functions, post your question on [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud-functions) and tag your question with ibm-cloud-functions.\n\n\n\n*  See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support) for more details about using the forums.\n*  Contact IBM Support by opening a case. To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support).\n\n\n\nWhen you report an issue, include your activation ID. To get an activation ID, run ibmcloud fn activation list.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-gettinghelp"},{"document_id":"ibmcld_00041-7-1878","score":0.0298507463,"text":"\nGetting help and support for IBM Analytics Engine \n\nIf you experience an issue or have questions when using IBM Analytics Engine, you can use the following resources before you open a support case.\n\n\n\n* Review the [FAQs](https:\/\/test.cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless) in the product documentation.\n* Review the [troubleshooting documentation](https:\/\/test.cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-troubleshooting-serverless) to troubleshoot and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to see whether other users experienced the same problem. When you ask a question, tag the question with ibm-cloud and service-Name, so that it's seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-feedback).\n\n\n\n Providing support case details \n\nTo ensure that the support team can start investigating your case to provide a timely resolution, you must include detailed information along with steps to re-create the issue, if applicable. Review the following types of information to include in your support case for issues with IBM Analytics Engine.\n\n\n\n* The INSTANCE_ID for which the issue occured. For more information about retrieving the INSTANCE_ID, see [Retrieving details of a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details)\n* The APPLICATION_ID for which the issue occured.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-help-and-support"},{"document_id":"ibmcld_08052-7-2152","score":0.0294117647,"text":"\nCustomer Incident Report \n\nIBM Cloud\u00ae works hard to maintain high availability of infrastructure and cloud services. If you're impacted by any event that disrupts your service delivery, a Customer Incident Report (CIR) can be provided. A CIR provides information about how services are impacted and how an issue is getting resolved.\n\nAfter you create a support case, you can view updates about your impacting event from the Manage cases page. For more information, see [Managing your support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases). If the scope of an impacting event is of a larger enterprise-wide scope, a CIR is provided upon request.\n\n\n\n Details about the Customer Incident Report (CIR) \n\nA CIR is provided for larger, enterprise-level issues. They are updates that provide a Root Cause Analysis (RCA) which is the process for determining the underlying cause of a Customer Impacting Event (CIE). Smaller issues that don't affect IBM Cloud at an enterprise level don't provide an RCA or CIR. The Advanced Customer Support (ACS) team that mitigates the issue still provides updates, but they're not a formal RCA.\n\nLarger enterprise-wide issues are events that typically impact multiple user environments or regions. Due to the scope and impact of enterprise issues, IBM Cloud requires a thorough RCA and the CIR is a summary report for the findings of the investigation.\n\nRCA investigations are complex and involve program review, feedback from product specialists, multiple inter-related cloud services, and vendor discussions. If the CIR can't be delivered within the Service Level Objective (SLO), an interim CIR is provided within the five business day SLO. For more information about SLO, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nThe CIR is a point-in-time document that is intended to convey a specific set of information about an impacting incident. The interim CIR document provides the current findings of the ongoing RCA, the next investigative steps, and a timeline for the next expected update.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-cir"},{"document_id":"ibmcld_03839-5438-7096","score":0.0289855072,"text":"\nEnsure that the ticket severity is assigned based on the published criteria that is defined in [Case severity and response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity). For more information, see [IBM Cloud support plan offerings](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport-plans).\n* If you do not purchase support, your IBM Cloud Pay-As-You-Go or Subscription account comes with a free Basic Support plan. In this case, your support case is automatically registered as Sev-4.\n\n\n\nBefore you open a support ticket, you need to [gather your logs](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-manage-consoleibp-console-manage-logs).\n\nFollow these steps to submit a support case.\n\n\n\n1. Log in to [IBM Cloud Service Portal](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) with your IBM ID.\n2. Under Need more help? on the right of the page, click Create a Case.\n3. Fill the Create Case form with your information at least for the following fields.\n\n\n\n* Choose Technical as your case type.\n* In the Category drop-down list, select Blockchain.\n* In the Subject field enter a summary of your issue.\n* In the Description field, describe your issue.\n* Attach any relevant logs or files to demonstrate your issue.\n* Click Email me updates to receive updates on the status of the ticket.\n\n\n\n4. Click the Submit button. You will receive an email notification in a few minutes for this case.\n\n\n\nYou can find your previously submitted cases by clicking My Cases in the IBM Cloud Service Portal. Click and open a case to check its status or provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-support"},{"document_id":"ibmcld_02604-7-2037","score":0.0285714286,"text":"\nUsing the Support Center \n\nNeed help with your API Connect service instance? Visit the IBM Cloud [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to file a case.\n\n\n\n1. On the Support Center page, look in the \"Contact support\" section and click Create a case.\n2. On the Create a Case page, look in the \"Services\" list and click API Connect.\n\nIt's important to create your case with the correct service so that IBM Support can track the case and assign the appropriate people to help you. The list of services depends on your IBM Cloud account. If you don't see API Connect in the \"Services\" list, you can locate it as follows:\n\n\n\n* Locate the \"What do you need help with?\" section.\n* Review the text in that section and click the view all services link.\n* In the complete list of services, locate API Connect and click it (services are listed in alphabetic order).\n\n\n\n3. Describe your problem.\n\nUse the fields on the \"Create a Case\" page to explain your problem. The following list describes important information that assists us with resolving issues that you are having in API Connect.\n\nImportant: Do not include your private key in the support request.\n\n\n\n* For all issues, include the following information:\n\n\n\n* Region and customer service instance impacted\n* Component impacted: API Manager, API calls, Portal\n* URL where error is being seen\n* For Dedicated, identify the customer environment\n* For Reserved plan, use a prefix in the Subject field to indicate the version (such as v5, v2018 or v10) and provider-org. For example: [v10 - providerOrg].\n\n\n\n* For API Manager UI-based issues, additionally include:\n\n\n\n* All error codes returned\n* Time (including time zone) that the problem occurred\n\n\n\n* For Portal-based issues, additionally include the user name of person who encountered the problem\n* For issues with invoking APIs, additionally include:\n\n\n\n* Full API URL impacted - the host name should contain apiconnect.ibmcloud.com\n* HTTP method used\n* Frequency and time (with time zone) of the issue","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-get_help"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":0.0327868852,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06843-4238-6198","score":0.0322580645,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-9696-11699","score":0.0317460317,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06836-7569-8653","score":0.03125,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_16729-294066-295916","score":0.0307692308,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07844-4589-6711","score":0.0303030303,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_12415-7-1973","score":0.0298507463,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_07844-3757-5369","score":0.0294117647,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07844-2925-4586","score":0.0289855072,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07578-1213887-1215935","score":0.0285714286,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8503449055,"ndcg_cut_10":0.8503449055}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09835-0-777","score":0.031099325,"text":"\n\n\n\n\n--------------------\n\n\n\n  Identifying software vulnerabilities \n\nYou can also use the IBM Cloud Monitoring Workload Protection service to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\nThe ability to monitor software vulnerabilities is included when you use the [Graduated Tier - Sysdig Secure + Monitor service plan](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-service_plans). This plan integrates IBM Cloud Security and Compliance Center Workload Protection as part of IBM Cloud Monitoring.\n\nFor more information, see the [IBM Cloud Security and Compliance Center Workload Protection documentation.](https:\/\/cloud.ibm.com\/docs\/workload-protection)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-workoad-protection"},{"document_id":"ibmcld_16696-7-2390","score":0.0308861962,"text":"\nKey features of IBM Cloud Security and Compliance Center Workload Protection \n\nIBM Cloud\u00ae Security and Compliance Center Workload Protection offers functionality to protect workloads, get deep cloud and container visibility, posture management (compliance, benchmarks, CIEM), vulnerability scanning, forensics, and threat detection and blocking.\n\n\n\n Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure \n\n\n\n* Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure and protect workloads and resources that run on IBM Cloud, in other clouds, and on-prem. Presents relevant performance and security data in one location.\n* Is built on open standards for cloud native security and control, including Falco, the open source standard for cloud threat detection, and Open Policy Agent (OPA), the open source standard for policy-as-code.\n* Offers a workload protection platform (WPP) that focuses on management and security controls for workloads.\n* Offers a compliance platform (CP) that focuses on management and compliance controls that are required to meet industry standards and laws.\n* Includes Cloud security posture management (CSPM) to help you secure the infrastructure where workloads are deployed.\n* Includes Kubernetes Security Posture Management (KSPM) to help you secure Kubernetes clusters or Openshift clusters, and the workloads running within it.\n* Offers alerting on violations, and assists with remediation tasks.\n\n\n\n\n\n\n\n Offers host and image scanning, auditing, and runtime vulnerability management capabilities \n\n\n\n* Filters and surfaces vulnerabilities in images, clusters, namespaces, or hosts.\n* Alerts on unscanned images or images when the evaluation status changes with new vulnerabilities.\n* Logs user actions, container activity, and command arguments.\n* Enforces security policies and blocks attacks.\n\n\n\n\n\n\n\n Provides posture management for a distributed environment \n\n\n\n* Schedules customized benchmark tests to run across cloud, hosts, services, or clusters.\n* Controls compliance at cloud, orchestrator, and container level.\n* Tracks and optimizes cloud users permissions and entitlements.\n* Exports results to SIEM, logging clusters, or other tools.\n\n\n\n\n\n\n\n Provides runtime detection and data enrichment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-key-features"},{"document_id":"ibmcld_10510-53754-56042","score":0.0161290323,"text":"\nTo protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry or the [internal registry](https:\/\/docs.openshift.com\/container-platform\/4.11\/registry\/index.html) that is automatically set up in your Red Hat OpenShift cluster, and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI\/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_14459-7-2518","score":0.0161290323,"text":"\nIBM Security Services for SAP on IBM Cloud overview \n\nIBM Security Services for SAP\u00ae on IBM Cloud offer a cybersecurity solution to automate the monitoring and protection of SAP applications on IBM Cloud, and to keep workloads compliant and secure from inside and outside threats. IBM Security Services for SAP on IBM Cloud is a non-IBM product that is offered under terms and conditions from Entrust and Intel, not IBM.\n\nThese services, developed between IBM Security and Onapsis (an IBM Business Partner), are designed to implement and configure Onapsis specifically to your environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, the Onapsis Security Platform delivers a near real-time, preventive, detective, and corrective solution for securing SAP systems and applications. The Onapsis Security Platform provides unmatched coverage and protection with context-aware insight across SAP NetWeaver ABAP, Java\u00ae Platform, Enterprise Edition, and HANA platforms. The platform integrates with network security, security management, and associated workflows.\n\n\n\n Technical specifications for IBM Security Services for SAP \n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors.\n* Methods to implement and avoid defects in ABAP code or SAP Transports.\n* Identifying configuration vulnerabilities for ABAP, Java\u00ae, and HANA environments.\n* Identifying missing or outdated SAP notes and patches.\n* Identifying, monitoring and review of highly privileged SAP accounts.\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution.\n\n\n\n\n\n\n\n Key benefits of IBM Security Services for SAP \n\nYou can expect the following benefits when you request IBM Security Services for SAP:\n\n\n\n* Consultative engagement methods centered on your business objectives.\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team.\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud.\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features.\n* Rapid learning and risk mitigation through access to IBM Cloud experts.\n\n\n\n\n\n\n\n Procedure to request IBM Security Services for SAP \n\n\n\n1. In the IBM Cloud for VMware Solutions console, scroll down to the services section and click IBM Security Services for SAP in the Featured workload solutions category.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managing-ss-sap"},{"document_id":"ibmcld_06063-54813-57067","score":0.0158730159,"text":"\nBut when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI\/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images. Find a person or team in your organization who is responsible for monitoring and removing vulnerabilities. Depending on your organizational structure, this person might be part of a security, operations, or deployment team. Enable [content trust](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) so that images must be approved by a trusted signer before they can be pushed to the container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_11573-21506-21994","score":0.0158730159,"text":"\n* [SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities](https:\/\/launchpad.support.sap.com\/\/notes\/2588225)\n* [SAP Note 1380654 - SAP support in IaaS environments](https:\/\/launchpad.support.sap.com\/\/notes\/1380654)\n* [SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment](https:\/\/launchpad.support.sap.com\/\/notes\/2414097)\n\n\n\nThis automation is offered free of charge however, the provisioned infrastructure comes at cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-create-terraform-3tier-nw-hana-vpc-ansible"},{"document_id":"ibmcld_06836-18833-20499","score":0.015625,"text":"\nPull request pipeline stages setup, test, detect-secrets, and branch-protection. The detect-secrets and branch-protection stages are not custom stages. They are provided by the pipelines by default. \n Continuous integration pipeline stages setup, test, static-scan, containerize, sign-artifact, deploy, acceptance-test, scan-artifact, release, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n continuous deployment pipeline stages setup, deploy, acceptance-test, create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request. The create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request stages are not custom stages. They are provided by the pipelines by default. \n Continuous compliance pipeline stages setup, test, static-scan, scan-artifact, acceptance-test, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n\n\n\n\n\n Example usage \n\n List saved stage results\n$ get_data result\ndetect-secrets\nbranch-protection\n\n Get stage result\n$ get_data result detect-secrets\nsuccess\n\nFor more information about the Stage Results API, see [Using the Stage Results API in custom scripts](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-stage-results).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_11605-7-2426","score":0.015625,"text":"\nIBM Security Services for SAP \n\nIBM Cloud\u00ae Security Services for SAP offer a cybersecurity solution that automates the monitoring and protection of SAP applications on IBM Cloud, and keeps workloads compliant and secure from inside and outside threats.\n\nIBM Services for SAP, developed in partnership with IBM Security Software and other business partners, implement and configure the SAP landscape to meet IT environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, IBM Security Services are able to deliver near real-time preventive, detective, and corrective solutions for securing SAP systems and applications with unmatched coverage and protection. This protection includes context-aware insight across SAP NetWeaver ABAP or Javas and SAP HANA platforms, with network security, security management, and associated workflows.\n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors\n* Methods to implement and avoid defects in ABAP code or SAP Transports\n* Identifying configuration vulnerabilities for ABAP, JAVA, and HANA environments\n* Identifying missing or outdated SAP notes and patches\n* Identifying, monitoring and review of highly privileged SAP accounts\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution\n\n\n\nKey benefits of requesting IBM Security Services for SAP to assist with your IBM Cloud\u00ae for SAP deployments:\n\n\n\n* Consultative engagement methods centered on your business objectives\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features\n* Rapid learning and risk mitigation through access to IBM Cloud experts\n\n\n\nFor more information, see [IBM.com - IBM Security - SAP Security and GRC Strategy Services](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy)\n\n\n\n Procedure to request IBM Security Services for SAP \n\nTo begin with IBM Security Services for SAP, use either:\n\n\n\n* Live Chat with IBM Security Sales, by using [IBM.com - IBM Security](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy) and click Let's talk in the botttom-left","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-security-services"},{"document_id":"ibmcld_16691-7674-9167","score":0.0153846154,"text":"\n[Configure a notification channel](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-notificationsnotifications_create) You can configure a notification channel to get notified about events, anomalies, or security incidents that require attention. \n [Scan container images](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-scan_kube) You can scan container images for vulnerabilities, and other violations. \n [Configure an image scanning alert](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-alert-config) You can set up a runtime Scanning Alert to detect if an image is impacted by newly discovered vulnerabilities. You can scan a repository that hosts container images for vulnerabilities, secrets, and license violations. Then, you can configure an alert on the repository to receive notifications on issues that need your attention. \n [Configure a rule](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-manage_rules) You can create a Detection Rule to detect and respond to anomalous runtime activity. <br>You can create a rule to specify which image versions can be used. \n [Define a policy](https:\/\/cloud.ibm.com\/docs\/docs\/workload-protection?topic=workload-protection-manage_policies) You can configure a policy on a resource and define what to do when 1 or more rules that are included in the policy are noncompliant. <br>Secure includes a number of pre-defined policies that you can use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-getting-started"},{"document_id":"ibmcld_13616-4088-6438","score":0.0153846154,"text":"\n* The IBM Cloud network ports are protected with firewalls, which serve as intrusion detection (IDS) and intrusion prevention (IPS) agents. Details regarding on IBM Cloud intrusion detection management is IBM Confidential information and covered under IBM Cloud SOC2 compliance (see compliance section below).\n* All IBM TRIRIGA SaaS and TRIRIGA Application Suite Managed Service environments are configured for Anti-Malware (Anti-Virus) protection and Endpoint Detection and Response (EDR) technology with associated telemetry.\n\n\n\nStatus and alerts are monitored continuously.\n\nIBM Trust Center - Enterprise IT Security and Trust: [https:\/\/www.ibm.com\/trust\/security](https:\/\/www.ibm.com\/trust\/security)\n\n\n\n\n\n Customer Access \n\n\n\n* IBM TRIRIGA Application Suite Managed Service are public internet based offerings. Customers connect to IBM Cloud using HTTPS encryption over the internet\n* There is no direct link, peering or private cloud option available for the IBM TRIRIGA Application Suite Managed Service offering\n* Every IBM TRIRIGA Application Suite Managed Service customer environment is delivered in a single tenant instance of the application, running on the Openshift platform.\n* All IBM TRIRIGA Application Suite Managed Service customers use HTTPS (SSL) encryption (256 bit) at the browser level to access IBM hosted applications. Connections are SHA-2 and TLS v1.2 compatible\n* IBM obtains and implements externally facing SSL certificates from a trusted Certificate Authority (CA)\n* All databases use native AES-256 encryption (data is encrypted at rest)\n\n\n\nCustomers will not have direct access to the operating system, file system or web application server. Changes need to be requested through a Support ticket.\n\n\n\n* Customers will not have DBAdmin or update access to any database. Updates need to be requested through a support ticket.\n\n\n\n\n\n\n\n Penetration and Vulnerability Testing \n\n\n\n* IBM\u2019s Product Transformation Center (PTC) conducts penetration testing on IBM TRIRIGA Application Suite Managed Service offering annually.\n* IBM performs external and internal vulnerability scanning and subsequent remediation in all IBM TRIRIGA Application Suite Managed Service environments on a quarterly basis per IBM IT Security Standards (ITSS). This includes Operating System, Middleware, Application and TCP\/IP vulnerability scanning.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12389-7-2298","score":0.0163934426,"text":"\nBest practices for rotating and locking secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can design a strategy for rotating your secrets and sensitive data. Review the following suggested guidelines for implementing best practices around your secrets management.\n\n\n\n Define your rotation strategy \n\nAs you use Secrets Manager to design your secrets management strategy, consider how often you want to rotate your secrets based on the internal guidelines for your organization. Determine ahead of time which users or service IDs require access to rotate secrets, and how those secrets can be rotated manually to avoid interruptions to your applications.\n\n\n\n1. Determine a frequency of rotation for your secrets.\n\nAfter you store a secret in Secrets Manager, you decide the frequency of its rotation. You might want to rotate secrets due to personnel turnover, process malfunction, or according to your organization's internal guidelines. Rotate your secrets regularly, for example every 90 days, to meet best practices around secrets management.\n2. Test out rotation workflows for each type of secret that you manage in Secrets Manager.\n\nThe way in which Secrets Manager evaluates a request to rotate a secret differs depending on the type of secret. For example, some secrets are replaced immediately with the data that you provide on rotation, whereas other secrets, such as public certificates, move into an extra validation step. For more information about how Secrets Manager handles rotation requests, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotationmanual-rotate-by-type).\n3. Establish a process for deploying the newest secret versions to your applications.\n\nUse an automated flow to obtain and deploy the latest version of your secret after it is rotated. For more information, see [Avoid application outages by locking your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secretsbest-practices-lock-secrets).\n\n\n\n\n\n\n\n Set up alerts for expiring secrets \n\nConnect to the Event Notifications service so that Secrets Manager can notify you in advance when your secrets or certificates are about to expire.\n\n\n\n1. Set up alerts for your instance by enabling event notifications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secrets"},{"document_id":"ibmcld_12498-8087-10171","score":0.0163934426,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12384-9214-11044","score":0.0161290323,"text":"\n2. In the row for the secret that you want to edit, click the Actions menu ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/actions-icon-vertical.svg)> Edit details.\n3. Use the Automatic rotation option to enable or disable automatic rotation for the secret.\n\n\n\n\n\nRotation is available only for IAM credentials where the reuse key is set to true. The defined rotation interval cannot be higher than the defined time-to-live (TTL). You can set the TTL for secrets by using minute units of time but rotation is not available for those secrets.\n\n\n\n\n\n\n\n Scheduling automatic rotation from the CLI \n\nYou can schedule the automatic rotation of secrets by using the Secrets Manager CLI plug-in.\n\n\n\n Setting an automatic rotation policy for user credentials \n\nSchedule the automatic rotation for user credentials by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n Setting an automatic rotation policy for public certificates \n\nSchedule the automatic rotation for public certificates by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true, \"rotate_keys\": true}'\n\n\n\n\n\n Setting an automatic rotation policy for private certificates \n\nSchedule the automatic rotation for private certificates by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\n\n\n\n\n Setting an automatic rotation policy for IAM credentials \n\nSchedule the automatic rotation for IAM credentials by using the Secrets Manager CLI plug-in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_12498-9696-11699","score":0.0161290323,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12447-4-2115","score":0.0158730159,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Manually rotating secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can manually create new versions of a secret by using the UI or APIs.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. Rotating your credentials limits how long a protected resource can be accessed by a single secret, which can protect your business against the risks that are associated with compromised credentials. Rotate your secrets regularly, for example every 30 or 60 days, so that you're always meeting best practices around secrets management.\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAll the secrets that you store in Secrets Manager can be rotated and replaced on-demand. How Secrets Manager evaluates a request to rotate a secret depends on the secret type.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) Arbitrary secrets are immediately replaced with the data that you provide on rotation. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) IAM credentials, which consist of a service ID and API key, are immediately regenerated according to their initial configuration. If the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12415-7-1973","score":0.0158730159,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12384-4-1975","score":0.015625,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Automatically rotating secrets \n\nYou can schedule automatic rotation for secrets by using IBM Cloud\u00ae Secrets Manager.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. By scheduling automatic rotation of your secrets at regular intervals, you can reduce the likelihood of compromise and ensure that your credentials never expire.\n\nAutomatic rotation is available only for secrets that are generated by Secrets Manager. If the secret was imported initially, you must provide new secret data to rotate it. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAutomatic rotation is supported for [private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates), [public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates), [user credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) and [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials). Depending on the type of secret, automatic rotation takes place immediately on the date and time that you set, or it might need to complete a few extra steps before a new version of the secret can be created.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) The existing certificate value is replaced with new certificate content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_06843-4238-6198","score":0.015625,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12384-10659-12564","score":0.0153846154,"text":"\nSchedule the automatic rotation for private certificates by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\n\n\n\n\n Setting an automatic rotation policy for IAM credentials \n\nSchedule the automatic rotation for IAM credentials by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n\n\n Scheduling automatic rotation with the API \n\nYou can schedule the automatic rotation of secrets by using the Secrets Manager API.\n\n\n\n Setting an automatic rotation policy for user credentials \n\nThe following example request creates an automatic rotation policy for a user credentials (username_password) secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\ncurl -X PATCH\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H 'Content-Type: application\/merge-patch+json' -d '{\n\"rotation\": {\n\"auto_rotate\": true,\n\"interval\": 1,\n\"unit\": \"month\"\n}\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\/{id}\/metadata\"\n\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n Setting an automatic rotation policy for public certificates \n\nIf you prefer to schedule your certificates to be automatically renewed, you can enable automatic rotation for certificates when you order them, or by editing the details of an existing certificate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_00894-7096-9156","score":0.0153846154,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7668091221}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-417176-418645","score":0.0163934426,"text":"\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\nurl\n: IBM Cloudant service URL.\n\nusername\n: The internal IBM Cloudant account name.\n\nFor more information, see [IBM Cloud API keys and Use only IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantibm-cloudant-api-keys-and-use-only-iam_ai).\n\n\n\n\n\nIn most cases, rotating credentials is a straight-forward process:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs\/faqsfind-service-credentials-iam).\n2. Replace the current credential with the newly generated credential.\n3. Delete the no-longer-used service credential.\n\n\n\nHowever, when you rotate the credentials for a replication, if you are using legacy credentials in the replication document, the replication starts from the beginning. To ensure that changes arrive in a timely manner, we advise you to create a new replication once it catches up with deleting the previous replication and the associated service credential. The process is described in the following steps:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs\/faqsfind-service-credentials-iam).\n2. Create a replication with the same settings but new credentials.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12498-8087-10171","score":0.0163934426,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_00589-5073-6581","score":0.0161290323,"text":"\nTo provision an instance as Use both legacy credentials and IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p {\"legacyCredentials\": true}\n\n\n\n\n\n Service credential JSON examples for each option \n\nThe choice between Use only IAM and Use both legacy credentials and IAM access control affects how credentials are delivered to your application when you bind and generate service credentials. When you generate credentials within the primary IBM Cloud IAM interface, API keys are shown in that interface when generated.\n\nYou can also generate credentials from the Service Credentials section of a service instance. Generating service credentials this way creates a service credentials JSON blob that can be pasted into applications with all the details that are needed to access the service instance.\n\nNext, you can see what the service credential JSON looks like and what each value means.\n\nWhen you select Use only IAM, the service credentials that are generated contain only IAM values, and look like the following example.\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"iam_apikey_description\": \"Auto generated apikey during resource-key [...]\",\n\"iam_apikey_name\": \"auto-generated-apikey-050d21b5-5f[...]\",\n\"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Manager\",\n\"iam_serviceid_crn\": \"crn:v1:staging:public:iam-identity::[...]\",\n\"url\": \"https:\/\/76838001-b883-444d-90d0-46f89e942a15-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_12498-9696-11699","score":0.0161290323,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_16727-417150-418627","score":0.0158730159,"text":"\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\nurl\n: IBM Cloudant service URL.\n\nusername\n: The internal IBM Cloudant account name.\n\nFor more information, see [IBM Cloud API keys and Use only IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantibm-cloudant-api-keys-and-use-only-iam_ai).\n\n\n\n\n\nIn most cases, rotating credentials is a straight-forward process:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs?tab=faqsfind-service-credentials-iam).\n2. Replace the current credential with the newly generated credential.\n3. Delete the no-longer-used service credential.\n\n\n\nHowever, when you rotate the credentials for a replication, if you are using legacy credentials in the replication document, the replication starts from the beginning. To ensure that changes arrive in a timely manner, we advise you to create a new replication once it catches up with deleting the previous replication and the associated service credential. The process is described in the following steps:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs?tab=faqsfind-service-credentials-iam).\n2. Create a replication with the same settings but new credentials.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12415-7-1973","score":0.0158730159,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_00483-3212-4996","score":0.015625,"text":"\n: The legacy credentials password that is required for applications to access the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nhost\n: The hostname that is used by applications to locate the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nport\n: The HTTPS port number for accessing the service instance on the host. It's 443 as only HTTPS access is allowed by IBM Cloudant. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nurl\n: The HTTPS URL to access the IBM Cloudant instance. If the Use both legacy credentials and IAM option is chosen, it also includes the embedded legacy username and password.\n\napikey\n: The IAM API key.\n\niam_apikey_description\n: Description of the IAM API key.\n\niam_apikey_name\n: ID of the IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of the service ID.\n\n\n\n\n\n Authentication \n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials in the service credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) and [legacy authentication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication) document for details about using either style of authentication.\n\nThe IBM Cloudant team recommends you use IAM access controls for authentication whenever possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-connecting"},{"document_id":"ibmcld_06843-4238-6198","score":0.015625,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12422-16914-18005","score":0.0153846154,"text":"\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region\nservice_id = \"ServiceId-f4b2deac-fbb5-4bf7-85de-88426701db97\"\nttl = \"1800\"\nname = \"test-iam-credentials-secret\"\nreuse_api_key = true\nsecret_group_id = ibm_sm_secret_group.sm_secret_group_test.secret_group_id\ndepends_on = [\nibm_sm_iam_credentials_configuration.iam_credentials_configuration\n]\n}\n\n\n\n\n\n Deleting IAM credentials \n\nIf you have a service ID or API key that was generated by the IAM credentials secret engine and delete your instance of Secrets Manager, you must also delete the secret from IAM. For more information, see [Managing user API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userapikey).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12479-7-1826","score":0.0153846154,"text":"\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00786-2957-4926","score":0.0163934426,"text":"\nYour IBM Cloud login and password are only used to authenticate with Git Repos and Issue Tracking in a web browser. You cannot use your IBM Cloud user credentials to authenticate from external Git clients. To complete remote Git operations, such as clone or push, from your local Git repo, you must use a personal access token or SSH key to authenticate with Git Repos and Issue Tracking.\n\nThe display name that appears for you throughout Git Repos and Issue Tracking is populated from your IBM Cloud login information. This name might be visible to other users when they search for users to add to their projects. You can update the name that is displayed for you throughout Git Repos and Issue Tracking from your [Profile page](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-git_workinggit_update_name).\n\n\n\n Creating a personal access token \n\nTo authenticate with your Git repo over HTTPS, you must create a personal access token.\n\n\n\n1. On the Git Repos and Issue Tracking User Settings dashboard, from the menu, click your avatar and select Edit profile. Click Access Tokens. On the Access Tokens page, type the name of the application that you want to create an access token for. For example, Git CLI.\n2. Optional: Choose an expiry date for the access token.\n3. Select the api checkbox to create a personal access token that uses api as the scope.\n4. Click Create Personal Access Token. Make note of your access token in a secure location for future use.\n5. On the Git Repos and Issue Tracking User Settings dashboard, from the menu, click your avatar and select Edit profile. Click Account. On the Account page, in the Change username section, find your Git Repos and Issue Tracking username. Your username is also displayed as the first segment of the URL for any personal Git repos that you create.\n6. Use your Git Repos and Issue Tracking username and personal access token to authenticate with your Git repo from an external Git client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-git_working"},{"document_id":"ibmcld_12613-7-2387","score":0.0163934426,"text":"\nIBM Cloud IAM roles \n\nAll services that are organized in a resource group in your account are managed by using IBM Cloud Identity and Access Management (IAM). Account owners are automatically assigned the account administrator role. As the account administrator, you can assign and manage access for users, create resource groups, create access groups, create trusted profiles, view billing details and track usage, and create service instances. You provide access for users, service IDs, access groups, and trusted profiles by creating policies that set a target for the subject of the policy to access and a role that defines what type of access that is allowed.\n\n\n\n IAM roles \n\nYou can manage and define access based on specific roles for users and resources in your account.\n\n\n\n* Platform management roles cover a range of actions, including the ability to create and delete instances, manage aliases, bindings, and credentials, and manage access. The platform roles are administrator, editor, operator, viewer. Platform management roles also apply to [account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesaccount-management-actions-roles) that enable users to invite users, manage service IDs, access policies, catalog entries, and track billing and usage depending on their assigned role on an account management service.\n* Service access roles define a user or service\u2019s ability to perform actions on a service instance, such as accessing the console or performing API calls. The most common service access roles are manager, writer, and reader. Each service maps particular actions for working with the service to each of these roles.\n\nYou might not see all of the roles that are listed here as options when you assign policies in the UI because only the roles available for the service that you chose are displayed. For more information on what roles are enabled and what actions each access role allows for each service, see the documentation for that service.\n* Custom roles for a service can be created on the IAM Roles page by the account owner or a user assigned the administrator role on the role management service.\n\nYou can review the available roles and associated actions for a particular service by going to the [Roles](https:\/\/cloud.ibm.com\/iam\/roles) page, and selecting the service that you want to learn more about.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-userroles"},{"document_id":"ibmcld_12938-2957-4935","score":0.0161290323,"text":"\nYour IBM Cloud login and password are only used to authenticate with Git Repos and Issue Tracking in a web browser. You cannot use your IBM Cloud user credentials to authenticate from external Git clients. To complete remote Git operations, such as clone or push, from your local Git repo, you must use a personal access token or SSH key to authenticate with Git Repos and Issue Tracking.\n\nThe display name that appears for you throughout Git Repos and Issue Tracking is populated from your IBM Cloud login information. This name might be visible to other users when they search for users to add to their projects. You can update the name that is displayed for you throughout Git Repos and Issue Tracking from your [Profile page](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-git_workinggit_update_name).\n\n\n\n Creating a personal access token \n\nTo authenticate with your Git repo over HTTPS, you must create a personal access token.\n\n\n\n1. On the Git Repos and Issue Tracking User Settings dashboard, from the menu, click your avatar and select Edit profile. Click Access Tokens. On the Access Tokens page, type the name of the application that you want to create an access token for. For example, Git CLI.\n2. Optional: Choose an expiry date for the access token.\n3. Select the api checkbox to create a personal access token that uses api as the scope.\n4. Click Create Personal Access Token. Make note of your access token in a secure location for future use.\n5. On the Git Repos and Issue Tracking User Settings dashboard, from the menu, click your avatar and select Edit profile. Click Account. On the Account page, in the Change username section, find your Git Repos and Issue Tracking username. Your username is also displayed as the first segment of the URL for any personal Git repos that you create.\n6. Use your Git Repos and Issue Tracking username and personal access token to authenticate with your Git repo from an external Git client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-git_working"},{"document_id":"ibmcld_12791-3746-5818","score":0.0161290323,"text":"\nTable 2. Roles and example actions for a policy on all IAM account management services\n\n Roles Actions \n\n Viewer All viewer role actions for IAM services \n Operator All operator role actions for IAM services \n Editor All editor role actions for IAM services and the ability to create resource groups \n Administrator All administrator role actions for IAM services and the ability to create resource groups \n User API key creator Create API keys when the account setting to restrict API key creation is enabled \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 3. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_12924-10737-11954","score":0.0158730159,"text":"\ntoolchain.git-repos-and-issue-tracking-repo.evaluate Add user emails after system evaluation of a Git Repos and Issue Tracking repo. Multiple emails that correspond to users with Developer (or greater) access to the repo might be added. The root-action-service-instance CRN identifies the toolchain that contains the Git Repos and Issue Tracking tool integration. \n toolchain.pipeline-stage.start Add user emails when a delivery pipeline stage starts. If the pipeline stage is manually started, the email of the user who started the pipeline is added. If a pipeline stage is triggered by a change to a repository (repo) in the Git Repos and Issue Tracking tool integration, multiple emails that correspond to users with Developer (or greater) access to the repo might be added. The root-action-service-instance CRN identifies the toolchain that contains the pipeline. \n toolchain.pipeline.read Add a user email when the user views a delivery pipeline. The root-action-service-instance CRN identifies the toolchain that contains the pipeline. \n toolchain.pipeline.update Add a user email when the user edits a delivery pipeline. The root-action-service-instance CRN identifies the toolchain that contains the pipeline.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-cd-at-events"},{"document_id":"ibmcld_12818-4-2241","score":0.0158730159,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n How third-party services use the IBM Cloud platform \n\nA third-party service uses the IBM Cloud platform for authentication, access, self-service instance creation, metering, and billing. This topic provides a high-level overview of the platform components that your service uses, and pulls these concepts together into an end-to-end provisioning scenario.\n\n\n\n The IBM Cloud provisioning layer \n\nThe provisioning layer manages the lifecycle of IBM Cloud resources. The provisioning layer is responsible for controlling and tracking the lifecycle of resources in a customer account. Resources are physical or logical components that can be created or reserved for an application or service instance. Examples of resources include database, accounts, processor, memory, and storage limits. In general, resources that are tracked by the provisioning layer are intended to associate usage metrics and billing, but that isn\u2019t always the case. In some cases, the resource might be associated to the provisioning layer to ensure that the resource lifecycle can be managed along with the account lifecycle.\n\n\n\n Resource lifecycle management \n\nThe provisioning layer provides common APIs to control the lifecycle of resources from creation (creating an instance) to binding (creating access credentials) to unbinding (removing access) to deletion (deleting an instance). Additionally, the IBM Cloud platform provides CLIs and a UI that can manage the lifecycle of these resources that don\u2019t require you to create your own facilities.\n\nThe provisioning layer provides APIs to help you manage the following elements of your resource lifecycle:\n\n\n\n* Creating a resource instance\n* Updating a resource instance\n* Binding\n* Resource keys\n* Unbinding\n* Deleting a resource instance\n\n\n\n\n\n\n\n\n\n IBM Cloud Identity and Access Management (IAM) \n\nIdentity Access Management (IAM) enables you to securely authenticate users and control access to all cloud resources consistently across IBM Cloud. The IBM Cloud provisioning layer adopted IAM for authentication and authorization of actions that are taken against the provisioning layer. Third-party product providers use IAM to create an authentication flow (OAuth). See [What is IAM?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-how-it-works"},{"document_id":"ibmcld_00693-26583-28753","score":0.015625,"text":"\nGit Repos and Issue Tracking is an IBM-hosted component of the Continuous Delivery service. All of the data that you provide to Git Repos and Issue Tracking, including but not limited to source files, issues, pull requests, and project configuration properties, is managed securely within Continuous Delivery. However, Git Repos and Issue Tracking supports various mechanisms for exporting, sending, or otherwise sharing data to users and third parties.\n\nThe ability of Git Repos and Issue Tracking to share information is typical of many social coding platforms. However, such sharing might conflict with regulatory controls that apply to your business. After you create a project in Git Repos and Issue Tracking, but before you entrust any files, issues, records, or other data with the project, review the project settings and change any settings that you deem necessary to protect your data. Settings to review include visibility levels, email notifications, integrations, web hooks, access tokens, deploy tokens, and deploy keys.\n\n\n\n Project visibility levels \n\nGit Repos and Issue Tracking projects can have one of the following visibility levels: private, internal, or public.\n\n\n\n* Private projects are visible only to project members. This setting is the default visibility level for new projects, and is the most secure visibility level for your data.\n* Internal projects are visible to all users that are logged in to IBM Cloud.\n* Public projects are visible to anyone.\n\n\n\nTo limit project access to only project members, complete the following steps:\n\n\n\n1. From the project sidebar, click Settings > General.\n2. On the General Settings page, click Visibility > project features > permissions.\n3. Locate the Project visibility setting.\n4. Select Private, if it is not already selected.\n5. Click Save changes.\n\n\n\n\n\n\n\n Project membership \n\nGit Repos and Issue Tracking is a cloud hosted social coding environment that is available to all Continuous Delivery users. If you are a Git Repos and Issue Tracking project Maintainer or Owner, you can invite any user and group members to the project. IBM Cloud places no restrictions on who you can invite to a project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_security"},{"document_id":"ibmcld_12791-34649-36492","score":0.015625,"text":"\nViewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage crn:v1:bluemix:public:iam::::role:Viewer \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name crn:v1:bluemix:public:iam::::role:Operator \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage crn:v1:bluemix:public:iam::::role:Editor \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise crn:v1:bluemix:public:iam::::role:Administrator \n\n\n\nIt's possible to view subscription balances and usage from the Account settings page, but you can't view the Account settings page with the Viewer or Operator roles. To access the Account settings page and your subscription information from that page, you need the Editor role or higher.\n\n\n\n\n\n Catalog management \n\nYou can give users access to view private catalogs and catalog filters, create private catalogs, add software to private catalogs, and set catalog filters.\n\n\n\nTable 5. Roles and example actions for the catalog management service\n\n Roles Actions role_ID value \n\n Viewer View account-level filters set for the IBM Cloud catalog<br><br>View private catalogs crn:v1:bluemix:public:iam::::role:Viewer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_00693-28329-30382","score":0.0153846154,"text":"\n4. Select Private, if it is not already selected.\n5. Click Save changes.\n\n\n\n\n\n\n\n Project membership \n\nGit Repos and Issue Tracking is a cloud hosted social coding environment that is available to all Continuous Delivery users. If you are a Git Repos and Issue Tracking project Maintainer or Owner, you can invite any user and group members to the project. IBM Cloud places no restrictions on who you can invite to a project. Because you can invite anyone into a GitLab project, be careful to invite only those users or groups who are part of your company or organization, unless you explicitly intend otherwise.\n\nFor more information about managing GitLab project members, see [Members of a project](https:\/\/docs.gitlab.com\/ee\/user\/project\/members\/).\n\n\n\n\n\n Project email settings \n\nBy default, Git Repos and Issue Tracking notifies project members by way of email about project activities. These emails typically include customer-owned data that was provided to Git Repos and Issue Tracking by users. For example, if a user posts a comment to an issue, Git Repos and Issue Tracking sends an email to all subscribers that includes information such as a copy of the comment, the user who posted it, and when the comment was posted. To turn off all email notifications for your project, complete the following steps:\n\n\n\n1. From the project sidebar, click Settings > General.\n2. On the General Settings page, click Visibility > project features > permissions.\n3. Select the Disable email notifications checkbox.\n4. Click Save changes.\n\n\n\n\n\n\n\n Project integrations and webhooks \n\nGit Repos and Issue Tracking projects might also be configured with integrations or webhooks to other systems, or equipped with access tokens, deploy tokens, and deploy keys. To review or change the integrations, webhooks, tokens, and keys that might be configured with your project, from the project sidebar, complete the following steps:\n\n\n\n1. From the project sidebar, click Settings.\n2. Click Integrations to work with your project's integrations with other applications.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_security"},{"document_id":"ibmcld_12791-33407-34995","score":0.0153846154,"text":"\nOperator All operator role actions for IAM services crn:v1:bluemix:public:iam::::role:Operator \n Editor All editor role actions for IAM services and the ability to create resource groups crn:v1:bluemix:public:iam::::role:Editor \n Administrator All administrator role actions for IAM services and the ability to create resource groups crn:v1:bluemix:public:iam::::role:Administrator \n User API key creator Create API keys when the account setting to restrict API key creation is enabled crn:v1:bluemix:public:iam-identity::::serviceRole:UserApiKeyCreator \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled crn:v1:bluemix:public:iam-identity::::serviceRole:ServiceIdCreator \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 4. Roles and example actions for the Billing service\n\n Roles Actions role_ID value \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage crn:v1:bluemix:public:iam::::role:Viewer \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name crn:v1:bluemix:public:iam::::role:Operator","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00007-7-2159","score":0.0327868852,"text":"\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00033-7-2292","score":0.0322580645,"text":"\nFAQs \n\n\n\n What is IBM Analytics Engine serverless? \n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n\n\n\n\n\n What are the advantages of IBM Analytics Engine serverless instances? \n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n\n\n Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop? \n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n\n\n\n\n\n Can I change the instance home storage of a serverless instance? \n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n\n\n\n\n\n How is user management and access control managed in a serverless instance? \n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n\n\n\n\n\n How do I define the size of the cluster to run my Spark application? \n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"},{"document_id":"ibmcld_07578-107943-110247","score":0.0317460317,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-107922-110226","score":0.03125,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00007-1713-3490","score":0.0307692308,"text":"\nSee [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https:\/\/cloud.ibm.com\/docs\/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00055-7-1864","score":0.0303030303,"text":"\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"},{"document_id":"ibmcld_00052-7-2119","score":0.0298507463,"text":"\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https:\/\/test.cloud.ibm.com\/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"},{"document_id":"ibmcld_00064-7-2200","score":0.0294117647,"text":"\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_16642-2829-4672","score":0.0289855072,"text":"\nibmcloud login\n\nParameter value:\n\n\n\n* DOMAIN_NAME: The API endpoint for your region. For example, cloud.ibm.com\n\n\n\n3. Get the list of the resource groups for your account and select one of the returned resource groups as the target resource group in which to create the IBM Analytics Engine serverless instance:\n\nibmcloud resource groups\nibmcloud target -g <RESOURCE_GROUP_NAME>\n\nParameter value:\n\n\n\n* RESOURCE_GROUP_NAME: Provide the same name as you specified while provisioning watsonx.data for efficient organizing.\n\n\n\n4. Create a service instance:\n\nibmcloud resource service-instance-create <SERVICE_INSTANCE_NAME> ibmanalyticsengine <PLAN_NAME> <REGION> -p @<PATH_to JSON file with cluster parameters>\n\nParameter value:\n\n\n\n* SERVICE_INSTANCE_NAME: Specify a name for the instance.\n* PLAN_NAME: Specify the plan name as plan_name8afde05e-5fd8-4359-a597-946d8432dd45.\n* REGION: Specify the region where you like to provision the instance.\n\n\n\nNote that currently, standard-serverless-spark is the only supported serverless plan and us-south and eu-de the only supported regions. Choose one that is closer to the region where you have provisioned watsonx.data.\n\n\n\n* PATH_to JSON file: Include the path to the JSON file that contains the provisioning parameters.\n\n\n\nFor example, for the Dallas region:\n\nibmcloud resource service-instance-create MyServiceInstance ibmanalyticsengine standard-serverless-spark us-south -p @provision.json\n\nYou can give the service instance any name you choose. Note that currently, standard-serverless-spark is the only supported serverless plan and us-south and eu-de the only supported regions.\n\nThe provision.json file contains the provisioning parameters for the instance that you want to create.\n\nThe endpoint to your IBM Cloud\u00ae Object Storage instance in the payload JSON file must be the direct endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-provisioning-serverless"},{"document_id":"ibmcld_00055-2916-4719","score":0.0285714286,"text":"\nSet the API endpoint for your region and log in:\n\nibmcloud api https:\/\/cloud.ibm.com\nibmcloud login\n3. Get the list of the resource groups for your account and select one of the returned resource group as the target resource group in which to create the IBM Analytics Engine serverless instance:\n\nibmcloud resource groups\nibmcloud target -g <resource_group_name>\n4. Create a service instance:\n\nibmcloud resource service-instance-create <service_instance_name> ibmanalyticsengine <plan_name> <region> -p @<path_to JSON file with cluster parameters>\n\nFor example, for the Dallas region:\n\nibmcloud resource service-instance-create MyServiceInstance ibmanalyticsengine standard-serverless-spark us-south -p @provision.json\n\nYou can give the service instance any name you choose. Note that currently, standard-serverless-spark is the only supported serverless plan and us-south and eu-de the only supported regions.\n\nThe provision.json file contains the provisioning parameters for the instance you want to create.\n\nThe endpoint to your IBM Cloud Object Storage instance in the payload JSON file should be the direct endpoint. Direct endpoints provide better performance than public endpoints and do not incur charges for any outgoing or incoming bandwidth.\n\nThis is a sample of what the provision.json file can look like. See [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts) for a description of the provisioning parameters in the payload.\n\nNote that both Spark 3.1 and Spark 3.3 are supported. If you don't specify a default Spark runtime version when you create a service instance, Spark 3.1 is taken by default.\n\n{\n\"default_runtime\": {\n\"spark_version\": \"3.1\"\n},\n\"instance_home\": {\n\"region\": \"us-south\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.5585075863}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00054-5565-6372","score":0.0327868852,"text":"\ndf2=spark.sql(\"SELECT * from MYPARQUETBBSPEED\")\n\u00a0 df2.show()\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 generate_and_store_data(spark,sc)\n\u00a0 create_table_from_data(spark,sc)\n\u00a0 time.sleep(30)\nif __name__ == '__main__':\n\u00a0 main()\nShow more\n7. Run the following PySpark script called postgres-parquet-table-select.py to access this Parquet table with metadata from another Spark workload:\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-select-parquet-table-test\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef select_data_from_table(spark,sc):\n\u00a0 df=spark.sql(\"SELECT * from MYPARQUETBBSPEED\")\n\u00a0 df.show()\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 select_data_from_table(spark,sc)\n\u00a0 time.sleep(60)\nif __name__ == '__main__':\n\u00a0main()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"},{"document_id":"ibmcld_00064-5320-7235","score":0.0322580645,"text":"\nIf no IBM Cloud Object Storage instances are found in your account, you can use the REST APIs to update instance home after instance creation.\n\nYou can't change instance home after instance creation. You can only edit the access keys.\n\n\n\n\n\n Default Spark configuration \n\nYou can specify default Spark configurations at the instance level and let that be inherited by Spark applications created on the instance. This is an optional section that you can specify at the time of instance creation. Values specified as instance level defaults can be overridden at the time of submitting Spark applications.\n\nCurrently, the following Apache Spark configurations are supported:\n\n\n\n* spark.driver.memory\n* spark.driver.cores\n* spark.executor.memory\n* spark.executor.cores\n* spark.driver.defaultJavaOptions\n* spark.driver.extraLibaryPathe\n* spark.driver.extraClassPath\n\n\n\nSee [Spark Configuration](https:\/\/spark.apache.org\/docs\/latest\/configuration.html) to understand more about the Apache Spark properties.\n\nAdditionally, you can also specify default values for autoscaling Spark applications at the instance level. See [Autoscaling application configurations](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-appl-auto-scaling) for details.\n\nThe following list shows the default values for Apache Spark configuration settings adapted for IBM Analytics Engine instances:\n\n\n\n* \"spark.driver.memory\": \"4G\"\n* \"spark.driver.cores\": \"1\"\n* \"spark.executor.memory\": \"4G\"\n* \"spark.executor.cores\": \"1\"\n* \"spark.eventLog.enabled\": \"true\"\n\n\n\nFor the default limits and quotas for Analytics Engine instances and the supported Spark driver and executor vCPU and memory combinations, see [Limits and quotas for Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits).\n\nWhen you create an instance you can override the open source default Apache Spark configuration settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_00086-7-1903","score":0.0317460317,"text":"\nSpark user interface \n\nThe Spark user interface (Spark UI) helps you to keep track of various aspects of a running Spark application.\n\nThe list below includes a few examples:\n\n\n\n* current running stage\n* number of tasks in a stage\n* reason for a longer running stage\n* strangler task in a stage\n* whether the executors in the application are used optimally\n* inspect into memory and disk consumption of the driver and executors\n\n\n\nFor details, see the [Spark-UI documentation](https:\/\/spark.apache.org\/docs\/latest\/monitoring.htmlweb-interfaces).\n\nIBM Analytics Engine displays the Spark UI only for the Spark applications that are currently running. You cannot access Spark UI for a completed application.\n\nUse the Spark history server to inspect the run of a completed Spark application. To access the Spark history server, see the [Access Spark history server](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless).\n\n\n\n Accessing the Spark UI \n\nThe Spark UI endpoint of a running Spark application is accessible from the service details page of the IBM Analytics Engine instance.\n\nThe following image shows you an example of the Application tab with the link to the Spark UI of a running application.\n\nZoom\n\n![Shows the ink to Spark-ui of a running application](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/spark_ui.png)\n\nFigure 1. Application tab of IBM Analytics Engine service details page\n\nThe Spark UI endpoint of the running Spark application can also be obtained by invoking the following IBM Analytics Engine REST API endpoints or corresponding SDK methods:\n\n\n\n* [Retrieve the details of a given Spark application](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine-v3get-application)\n* [List Spark applications](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine-v3list-applications)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-user-interface"},{"document_id":"ibmcld_00029-7452-8829","score":0.03125,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00085-7-1802","score":0.0307692308,"text":"\nSpark history server \n\nThe Spark applications that are submitted on an IBM Analytics Engine instance forward their Spark events to the Object Storage bucket that was defined as the instance home. The Spark history server provides a Web UI to view these Spark events. The Web UI helps you to analyze how your Spark applications ran by displaying useful information like:\n\n\n\n* A list of the stages that the application goes through when it is run\n* The number of tasks in each stage\n* The configuration details such as the running executors and memory usage\n\n\n\nSee the [Spark History server documentation](https:\/\/spark.apache.org\/docs\/latest\/monitoring.htmlviewing-after-the-fact) for more details.\n\nYou can disable forwarding Spark events from a Spark application by setting the property spark.eventLog.enabled to false in the Spark application configuration.\n\n\n\n Starting and stopping the Spark history server \n\nBefore accessing the Spark history server, you need to start the server. When you no longer need it, you should stop the server. You will be charged for the CPU cores and memory consumed by the Spark history server while it is running.\n\nThe Spark history server can be started and stopped by using:\n\n\n\n* The [Analytics Engine REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessrest-api)\n* The [Analytics Engine instance UI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessiae-ui)\n\n\n\n\n\n Analytics Engine REST API \n\nYou can use the Analytics Engine REST API:\n\n\n\n1. To view the status of the Spark history server\n\ncurl \"https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_history_server\" --header \"Authorization: bearer <iam token>\"\n2. To start the Spark history server","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless"},{"document_id":"ibmcld_00085-2572-4590","score":0.0303030303,"text":"\nIf the status of the Spark history server is set to Started, you can also click View Spark history to launch the Web UI of the Spark history server in a new browser tab.\n2. To start the Spark history server:\n\n\n\n1. On the Spark history page, click Start history server.\n2. Choose the server configuration and click Start to start the Spark history server.\n\n\n\n3. To stop the Spark history server:\n\n\n\n1. On the Spark history page, click Stop history server.\n\n\n\n\n\n\n\n\n\n\n\n Opening the Spark history server Web UI \n\nYou can open the Spark history Web UI by opening the instance details page of your Analytics Engine service instance, switching to the Spark history tab and clicking View Spark history.\n\nAlternatively, the Spark history server Web UI URL can be obtained through a service endpoint that is made available to you as a service key (also known as a service credential). See [Retrieving service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nEnsure that the Spark history server is running before you open the Web UI.\n\nLog links under the Stages and Executors tabs of the Spark history server UI will not work as logs are not preserved with the Spark events. To review the task and executor logs, enable platform logging. For details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n Accessing the Spark history server REST API \n\nIn addition to the web UI, the Spark history server also provides a REST API which can be queried to view the Spark events generated by your Spark applications. The Spark history server REST API is available as a service endpoint in a service key (also known as service credential). See [Retrieving service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nWhen you invoke the Spark history server REST API, you must specify your IAM token as a bearer token in the Authorization header. E.g.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless"},{"document_id":"ibmcld_00029-8568-9861","score":0.0298507463,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_16661-2308-3705","score":0.0294117647,"text":"\nThe sample below demonstrates how to do some table maintenance operations by using Spark. For more information about the Iceberg Spark table maintenance operations, see [Table Operations](https:\/\/iceberg.apache.org\/docs\/1.2.1\/spark-procedures\/).\n\n\n\n\n\n\n\n Running the sample use case \n\nFollow the steps to run the Spark sample python file.\n\n\n\n Spark sample python file \n\nfrom pyspark.sql import SparkSession\nimport os\n\ndef init_spark():\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a:\/\/lakehouse-bucket\/'\")\n list the database under lakehouse catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_samp_file"},{"document_id":"ibmcld_00064-3561-5813","score":0.0289855072,"text":"\n* There is no limit on the number of Spark applications that can be run in an IBM Analytics Engine service instance.\n\n\n\n\n\n\n\n Default Spark runtime \n\nYou can select which Spark version to use when the instance is provisioned. Currently, you can choose between Spark 3.1 and Spark 3.3. If you don't select a Spark runtime version, Spark 3.1 is taken by default.\n\nThe runtime contains only open source Spark binaries and is configured to help you to quickly get started to create and run Spark applications in the instance. In addition to the Spark binaries, the runtime also includes the geospatial, data skipping, and Parquet modular encryption libraries.\n\nOn a Spark 3.1 or Spark 3.3 runtime, you can submit Spark applications written in the following languages: Scala 2.12, Python 3.9, and R 3.6.3.\n\nNote that the language versions are upgraded periodically to keep the runtime free from any security vulnerabilities.\n\nYou can always override the Spark runtime version when you submit an application. For details on what to add to the payload, see [Passing the runtime Spark version when submitting an application](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-apipass-spark-version).\n\n\n\n\n\n Instance home \n\nInstance home is the storage attached to the instance for instance related data only, such as custom application libraries and Spark history events. Currently, only IBM Cloud Object Storage is accepted for instance home. This instance can be an instance in your IBM Cloud\u00ae account or an instance from a different account.\n\nWhen you provision an instance using the IBM Cloud console, the IBM Cloud Object Storage instances in your IBM Cloud\u00ae account are auto discovered and displayed in a list for you to select from. If no IBM Cloud Object Storage instances are found in your account, you can use the REST APIs to update instance home after instance creation.\n\nYou can't change instance home after instance creation. You can only edit the access keys.\n\n\n\n\n\n Default Spark configuration \n\nYou can specify default Spark configurations at the instance level and let that be inherited by Spark applications created on the instance. This is an optional section that you can specify at the time of instance creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_00095-7-1378","score":0.0285714286,"text":"\nUsing a library set \n\nAfter you have created a library set, you can reference and consume it in your Spark applications. When you run your Spark application in the IBM Analytics Engine instance, the library set is loaded from the instance home and is made available to the Spark application.\n\nA library set is referenced in a Spark application using the \"ae.spark.librarysets\" parameter in the \"conf\" section of the Spark application submission payload.\n\nTo reference a library set when submitting a Spark application:\n\n\n\n1. Get the IAM token. See [Retrieving IAM access tokens](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n2. Issue the following cURL command:\n\ncurl -X POST https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_applications --header \"Authorization: Bearer <IAM token>\" -H \"content-type: application\/json\" -d @submit-spark-app.json\n\nExample for submit-spark-app.json:\n\n{\n\"application_details\": {\n\"application\": \"cos:\/\/<bucket-name>.<cos-name>\/my_spark_application.py\",\n\"arguments\": [\"arg1\", \"arg2\"],\n\"conf\": {\n\"spark.hadoop.fs.cos.<cos-name>.endpoint\":\"https:\/\/s3.us-south.cloud-object-storage.appdomain.cloud\",\n\"spark.hadoop.fs.cos.<cos-name>.access.key\":\"<access_key>\",\n\"spark.hadoop.fs.cos.<cos-name>.secret.key\":\"<secret_key>\",\n\"ae.spark.librarysets\":\"my_library_set\"\n}\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-use-lib-set"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-5443-6857","score":0.0327868852,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16636-0-1664","score":0.0322580645,"text":"\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside \/opt\/presto\/etc\/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift:\/\/<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hudi-conn"},{"document_id":"ibmcld_16641-6629-7897","score":0.0317460317,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-8568-9861","score":0.03125,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_16641-4554-5850","score":0.0307692308,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* BASE_URL: The Analytics Engine URL for the region where you provisioned the instance. For example, api.region.ae.ibmcloud.com.\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n* hms-thrift-endpoint-from-watsonx.data: Specify the credentials for watsonx.data.\n* hms-user-from-watsonx.data: The watsonx.data username.\n* hms-password-from-watsonx.data: The watsonx.data password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-7452-8829","score":0.0303030303,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-4684-5710","score":0.0298507463,"text":"\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\") \n register the required Cloud Object Storage path used in our application, add endpoints for all buckets\n.config(\"spark.hadoop.fs.cos.us-geo.endpoint\", \"https:\/\/s3.us.cloud-object-storage.appdomain.cloud\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.endpoint\", \"https:\/\/iam.cloud.ibm.com\/identity\/token\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.api.key\", '<YourAPIkey>') \n.config(\"spark.sql.hive.metastore.version\", \"3.0\") \n directory where the Hive client has been placed\n.config(\"spark.sql.hive.metastore.jars\", \"\/tmp\/dataengine\/\") \n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-2355-3755","score":0.0294117647,"text":"\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_13481-7-1988","score":0.0289855072,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-6212-7871","score":0.0285714286,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6049306995}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16324-3229-5312","score":0.0327868852,"text":"\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_03330-4-2191","score":0.0322580645,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16233-7-2298","score":0.0317460317,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_07148-7-2060","score":0.03125,"text":"\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question\/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https:\/\/medium.com\/ibm-watson\/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-covidkit"},{"document_id":"ibmcld_07080-6045-7467","score":0.0307692308,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a Conversational Search project. [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"},{"document_id":"ibmcld_02839-7-2335","score":0.0303030303,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03330-3253-5192","score":0.0298507463,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_13160-7-1812","score":0.0294117647,"text":"\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson\/tree\/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_01090-0-821","score":0.0289855072,"text":"\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https:\/\/community.ibm.com\/community\/user\/hybriddatamanagement\/blogs\/jordan-hodges1\/2020\/01\/15\/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SS6NHC\/com.ibm.swg.im.dashdb.apdv.porting.doc\/doc\/c_compat_dcw.html).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dcw"},{"document_id":"ibmcld_01018-0-821","score":0.0285714286,"text":"\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https:\/\/community.ibm.com\/community\/user\/hybriddatamanagement\/blogs\/jordan-hodges1\/2020\/01\/15\/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFMBX\/com.ibm.swg.im.dashdb.apdv.porting.doc\/doc\/c_compat_dcw.html).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-dcw"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09919-7713-9881","score":0.0325224749,"text":"\n: Version 2 entity type support is now available, for all public and premium service instances, for the following languages: Russian and Swedish. For details, see [Entity type systems](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems).\n\n\n\n\n\n 3 August 2022 \n\nSupport for Single Label Classifications\n: Classifications now allows users to pass in a model_type training parameter when creating or updating a model, in order to train a single label classifier. See [Classifications training parameters](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classificationsclassification-training-parameters) for more details.\n\n\n\n\n\n 11 July 2022 \n\nImproved [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) model - Japanese\n: Japanese custom classifications models now train and perform inference faster, with improved model results.\n\nImproved [custom categories](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories) model\n: Model contains improved word filtering, resulting in better category determination.\n\n\n\n\n\n 7 April 2022 \n\nCategories bug fix\n: Fixed a bug in the Version 2 Categories type system.\n\n\n\n\n\n 14 February 2022 \n\nEmotion support\n: Support for emotion is now available, for all public service instances, for French. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\nImproved error handling and validation for emotion\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_09913-6894-8823","score":0.0317540323,"text":"\nClassifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Hebrew \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Hindi \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Italian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Japanese \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-11527-13389","score":0.0312576313,"text":"\nRelations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Romanian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Russian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata X \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Slovak \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Spanish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Swedish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata X \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Turkish","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-3804-5789","score":0.0307765152,"text":"\nIf you are using IBM Cloud\u00ae Dedicated, check with your IBM salesperson to confirm which languages are supported in your environment.\n\n\n\n Arabic \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Chinese (Simplified) \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata \n Relations X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Czech \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Danish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Dutch \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata \n Relations X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n English","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-9920-11906","score":0.0303099885,"text":"\nNorwegian (Bokmal) \n\nPlease note that Natural Language Understanding considers Norwegian (standard language code no) as equivalent to Norwegian-Bokmal (standard language code nb), and uses the same Norwegian-Bokmal model for both language codes.\n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Norwegian (Nyorsk) \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Polish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Portuguese \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Romanian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-5372-7266","score":0.0296442688,"text":"\n* Relevance ranking is not supported.\n\n\n\n\n\n Dutch \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata \n Relations X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n English \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X X (Beta) \n Classifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n Finnish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n French \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09919-9389-11561","score":0.0289915966,"text":"\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics\n: [Tone analytics](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) is now available, for English and French languages only. The tone analytics feature detects excited, frustrated, impolite, polite, sad, satisfied, and sympathetic tones from text.\n\n\n\n\n\n 12 October 2021 \n\nKeyword and syntax support for additional languages\n: Support for keywords and syntax is now available, for all public and premium service instances, for the following languages: Hindi, Romanian, and Turkish. In addition, syntax is available for all supported languages. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\n\n\n\n\n 15 August 2021 \n\nCustom classification feature\n: The [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) feature is now generally available (GA).\n\nCategories stock model updated\n: The [categories stock model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy) has been updated to use the [IAB Tech Lab 2.0 taxonomy](https:\/\/iabtechlab.com\/standards\/content-taxonomy\/).\n\n\n\n\n\n 5 May 2021 \n\nAdvanced Rules beta feature deprecated\n: The advanced rules beta feature is deprecated. As of June 10, 2021, you will not be able to deploy advanced rules models to Natural Language Understanding; existing models will keep running. After June 24, 2021, no advanced rules models will run in Natural Language Understanding.\n\n\n\n\n\n 25 March 2021 \n\nCustom classifications beta feature","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_09118-10321-12086","score":0.0163934426,"text":"\n[View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09920-5038-6185","score":0.0158730159,"text":"\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/console.bluemix.net\/developer\/watson\/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_09906-2727-4077","score":0.0149253731,"text":"\nThe targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"text\": \"I love apples! I do not like oranges.\",\n\"features\": {\n\"sentiment\": {\n\"targets\": [\n\"apples\",\n\"oranges\",\n\"broccoli\"\n]\n},\n\"keywords\": {\n\"emotion\": true\n}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\nShow more\n\nRunnable command for Windows users:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"text\":\"I love apples! I do not like oranges.\",\"features\":{\"sentiment\":{\"targets\":[\"apples\",\"oranges\",\"broccoli\"]},\"keywords\":{\"emotion\":true}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\n\n\n\n\n Next steps \n\n\n\n* View the [API reference](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understanding).\n* Learn how to identify [custom entities and relations](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16306-2449-4025","score":0.0327868852,"text":"\nFor more information, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid). \n Slack The Slack member ID (for example, U2147483697). \n Facebook The Facebook sender ID (for example, 4310101122439797). \n Whatsapp The customer's phone number. \n Phone The customer's phone number. \n SMS with Twilio The customer's phone number. \n\n\n\n\n\n\n\n\n\n chat \n\nIncluded only if the web chat integration is in use.\n\n\n\n Properties \n\n\n\nProperties of the chat object\n\n Name Type Description \n\n browser_info.browser_name String The browser name, such as chrome, edge, or firefox. \n browser_info.browser_version String The browser version, such as 109.0.0. \n browser_info.browser_OS String The operating system of the customer's computer, such as Mac OS. \n browser_info.language String The default locale code of the browser, such as en-US. \n browser_info.page_url String The URL of the web page where the web chat is embedded, not including any query parameters or hashes. \n browser_info.screen_resolution String The height and width of the browser window, such as width: 1440, height: 900. \n browser_info.user_agent String The content of the HTTP User-Agent request header. \n browser_info.client_ip_address String The IP address of the customer's computer. \n browser_info.ip_address_list Array Ann array IP addresses specified by HTTP X-Forwarded-For request headers. \n\n\n\n\n\n\n\n Example JSON \n\n\"chat\": {\n\"browser_info\": {\n\"browser_name\": \"chrome\",\n\"browser_version\": \"109.0.0\",\n\"browser_OS\": \"Mac OS\",\n\"language\": \"en-US\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_02280-0-1181","score":0.0322580645,"text":"\n\n\n\n\n\n\n  Why do I encounter console pages that don't load? \n\nA page in the IBM Cloud\u00ae console might not load properly, and an error message is displayed.\n\n  What\u2019s happening \n\nOne of the following error messages might be displayed:\n\n> BXNUI0001E: The page wasn't loaded because IBM Cloud didn't detect whether a session exists.\n\nor\n\n> BXNUI0016E: The apps and services weren't retrieved because an IBM Cloud page didn't load.\n\nor\n\n> 500 internal server error\n\n  Why it\u2019s happening \n\nAn issue with the browser is causing a console page to not load. Or, there might be a temporary issue with connectivity.\n\n  How to fix it \n\nComplete one or more of the following actions, as necessary:\n\n\n\n*  Refresh or restart your browser.\n*  Log out of the console and log in again.\n*  Use the private browsing mode of your browser.\n*  Clear the cookies and the cache of the browser.\n*  Use a different browser. For the list of supported browsers, see [IBM Cloud prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platform).\n*  If the problem persists, go to the [IBM Cloud Status page](https:\/\/cloud.ibm.com\/status) to check if a service or component has an issue.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_err"},{"document_id":"ibmcld_04083-20934-23210","score":0.0317460317,"text":"\nThis issue can occur when another user or application installs the smart contract onto the peer and you do not have the peer admin identity in your browser wallet.\n\n How to fix it \n\nIn order to view the smart contracts installed on a peer, you need to be a peer admin. Ensure that the peer admin identity exists in your browser wallet. If it does not, you need to import it into your console wallet.\n\n\n\n\n\n My nodes, channels, smart contracts, and identities have disappeared from the console. How can I get them back? \n\n What\u2019s happening \n\nNodes, identities, channels, or smart contracts (or some combination of these) that I successfully deployed into the console are no longer available.\n\n Why it\u2019s happening \n\nOne of the features of IBM Blockchain Platform is that you are now responsible for securing and managing your certificates. Therefore, they are only persisted in the browser local storage to allow you to manage the component. If you are using a private browser window and then switch to another browser or non-private browser window, the identities that you created will be gone from your wallet in the new browser session. Therefore, it is required that you export the identities from the wallet in your private browser session to your file system. You can then import them into your non-private browser session if they are needed. Otherwise, there is no way to recover them.\n\n How to fix it \n\n\n\n* Whenever you create a new organization MSP definition, you generate keys for an identity that is allowed to administer the organization. Therefore, during that process you must click the Generate and then Export buttons to store the generated identity in your wallet and then save it to your file system as a JSON file.\n* To resolve this problem in your browser, you need to import those identities and associate them with the corresponding node:\n\n\n\n* In the browser where you are experiencing the problem, click the Wallet tab followed by Add identity to import the JSON file into your wallet.\n* Click Upload JSON and browse to the JSON file you exported using the Add files button.\n* Click Submit.\n* Now open the peer or ordering service node that this identity was originally associated to, and click on the Settings icon.\n* Click the Associate identity button.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_13793-6227-7787","score":0.03125,"text":"\nGA en-US_EmilyV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_HenryV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_KevinV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_LisaV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_MichaelV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_OliviaV3Voice <br>Female Your browser does not support the audio tag. \n French <br>(Canadian) GA fr-CA_LouiseV3Voice <br>Female Your browser does not support the audio tag. \n French <br>(France) GA fr-FR_NicolasV3Voice <br>Male Your browser does not support the audio tag. \n GA fr-FR_ReneeV3Voice <br>Female Your browser does not support the audio tag. \n German GA de-DE_BirgitV3Voice <br>Female Your browser does not support the audio tag. \n GA de-DE_DieterV3Voice <br>Male Your browser does not support the audio tag. \n GA de-DE_ErikaV3Voice <br>Female Your browser does not support the audio tag. \n Italian GA it-IT_FrancescaV3Voice <br>Female Your browser does not support the audio tag. \n Japanese GA ja-JP_EmiV3Voice <br>Female Your browser does not support the audio tag. \n Korean GA ko-KR_JinV3Voice <br>Female Your browser does not support the audio tag. \n Portuguese <br>(Brazilian) GA pt-BR_IsabelaV3Voice <br>Female Your browser does not support the audio tag. \n Spanish <br>(Castilian) GA es-ES_EnriqueV3Voice <br>Male Your browser does not support the audio tag. \n GA es-ES_LauraV3Voice <br>Female Your browser does not support the audio tag.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices"},{"document_id":"ibmcld_13761-5201-6996","score":0.0307692308,"text":"\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/wav\" --output partial-cheerful-style.wav --data \"{\"text\":\"<express-as style='cheerful'>Oh, that's good news!<\/express-as> Do you need any further help?\"}\" \"{url}\/v1\/synthesize?voice=en-US_EmmaExpressive\"\n\n\n\n\n\n\n\n Emphasizing interjections \n\nWhen you use expressive neural voices, the service automatically detects a number of common interjections based on context. In the resulting audio, it gives them the natural emphasis that a human would use in normal conversation.\n\nTable 2 lists the interjections that the service recognizes and provides examples of how they are pronounced in synthesized speech. The samples use the en-US_AllisonExpressive voice. The table shows the primary spelling of each interjection. The service recognizes alternative spellings for some of the interjections. For example, oh and ohh produce the same sound, as do hmm and hmmm. However, the service produces slightly different pronunciations for other alternative spellings, such as ooh and uhm,\n\n\n\nTable 2. Interjections that are emphasized\n\n Interjection Example sentence Audio sample \n\n aha \"Aha. So that's the secret.\" Your browser does not support the audio tag. \n hmm \"Hmm. I'm not sure I understand.\" Your browser does not support the audio tag. \n huh \"Huh, I hadn't noticed that.\" Your browser does not support the audio tag. \n oh \"Oh, let me get that for you.\" Your browser does not support the audio tag. \n uh \"Uh, let me check.\" Your browser does not support the audio tag. \n uh-huh \"Uh-huh, that's right.\" Your browser does not support the audio tag. \n um \"That's, um, not quite right.\" Your browser does not support the audio tag. \n\n\n\n\n\n Enabling or disabling interjections with SSML","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_13793-4723-6539","score":0.0303030303,"text":"\nEnglish <br>(Australian) GA en-AU_HeidiExpressive <br>Female Your browser does not support the audio tag. \n GA en-AU_JackExpressive <br>Male Your browser does not support the audio tag. \n English <br>(United States) GA en-US_AllisonExpressive <br>Female Your browser does not support the audio tag. \n GA en-US_EmmaExpressive <br>Female Your browser does not support the audio tag. \n GA en-US_LisaExpressive <br>Female Your browser does not support the audio tag. \n GA en-US_MichaelExpressive <br>Male Your browser does not support the audio tag. \n\n\n\n\n\n\n\n Enhanced neural voices \n\nTable 3 lists and provides audio samples for all available enhanced neural voices. The Availability column indicates whether each voice is generally available (GA) for production use or beta. The column also indicates whether each voice is available for\n\nIBM Cloud\n\n,\n\nIBM Cloud Pak for Data\n\n, or both (no product version is cited).\n\n\n\nTable 3. Enhanced neural languages and voices\n\n Language Availability Voice \/ Gender Audio sample \n\n Dutch <br>(Netherlands) Beta nl-NL_MerelV3Voice <br>Female Your browser does not support the audio tag. \n English <br>(United Kingdom) GA en-GB_CharlotteV3Voice <br>Female Your browser does not support the audio tag. \n GA en-GB_JamesV3Voice <br>Male Your browser does not support the audio tag. \n GA en-GB_KateV3Voice <br>Female Your browser does not support the audio tag. \n English <br>(United States) GA en-US_AllisonV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_EmilyV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_HenryV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_KevinV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_LisaV3Voice <br>Female Your browser does not support the audio tag.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices"},{"document_id":"ibmcld_08197-0-402","score":0.0298507463,"text":"\n\n\n\n\n\n\n  Supported browsers \n\nFor a list of supported browsers, see [Required Browsers for IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor Safari, clear the options Prevent cross-site tracking and Block all cookies under Safari > Preferences > Privacy.\n\nIf you encounter problems when you use these browsers, disable your browser plug-ins.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-help-support-browsers"},{"document_id":"ibmcld_14076-2554-4278","score":0.0294117647,"text":"\nIf you use a security group to protect your virtual servers, you need to allow SSH traffic. For more information, see [Creating security groups and rules](https:\/\/cloud.ibm.com\/docs\/security-groups?topic=security-groups-creating-security-groups).\n\n\n\n\n\n\n\n Why can't I access KVM through a browser? \n\nIf you are unable to connect to the KVM console, review the following troubleshooting tips for help. For more information about accessing the KVM, see [Accessing the KVM console for virtual servers](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-access-kvm-console).\n\n\n\n* [Browser needs updating](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-serverupdate-browser)\n* You haven\u2019t [established a VPN connection](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servervpn-connection)\n* Your [credentials are invalid](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servercheck-credentials)\n\n\n\n\n\n Browser needs updating \n\nMake sure that you're using a supported browser. For more information about IBM Cloud\u00ae-supported browsers, see [Browsers](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nThe KVM Console opens in a new browser tab or window. If the KVM Console doesn't open, check the browser for any blocked new windows.\n\nIf you can't access KVM through your browser, you might need to update your browser. Update your browser and try to access KVM.\n\n\n\n\n\n A VPN connection isn't established \n\nMake sure that a connection is established by using the VPN. If a connection isn't established, a warning displays that a VPN connection is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-server"},{"document_id":"ibmcld_06942-4977-6807","score":0.0289855072,"text":"\n[Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/help.svg) from the header of any page in the product user interface to open the Discovery documentation.\n\n\n\n\n\n Browser support \n\nIBM Cloud Pak for Data\n\n\n\n* The minimum required browser software for the product user interface includes the following browsers:\n\nGoogle Chrome\n: Latest version -1 for your operating system\n\nMozilla Firefox\n: Latest regular -1 and Extended Support Release (ESR) version for your operating system\n\nMicrosoft Edge\n: Latest version -1 for Windows\n\nApple Safari\n: Latest version -1 for Mac\n* The IBM Cloud Pak for Data web client where you create service instances supports the IBM Cloud Pak for Data requirements. For more information, see [Supported web browsers](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.6.x?topic=requirements-softwaresoftware-reqs__web)\n\n\n\nIBM Cloud\n\n\n\n* Deployments of Discovery that are managed by IBM Cloud follow the IBM Cloud requirements. For more information, see [Prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platform)\n* For more information about browser support for deployments that are provisioned with Cloud Pak for Data as a Service, see [Which web browsers are supported for Cloud Pak for Data as a Service](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/getting-started\/browser-support.html).\n\n\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support) topic.\n\n\n\n\n\n Beta features \n\nIBM releases services, features, and language support for your evaluation that are classified as beta. These features might be unstable, might change frequently, and might be discontinued with short notice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-about"},{"document_id":"ibmcld_04083-11129-13211","score":0.0285714286,"text":"\nWhy are my console actions failing in my Chrome browser Version 77.0.3865.90 (Official Build) (64-bit)? \n\n What\u2019s happening \n\nThe console has been working successfully, but requests have started to fail. For example, after I create an ordering service and open it I see the error: Unable to get system channel. If you associated an identity without administrative privilege on the ordering service node, you will not be able to view or manage ordering service details.\n\n Why it\u2019s happening \n\nThis problem can be caused by a [bug](https:\/\/bugs.chromium.org\/p\/chromium\/issues\/detail?id=1006243) introduced by the Chrome browser Version 77.0.3865.90 (Official Build) (64-bit) that causes actions from the browser to fail.\n\n How to fix it \n\nTo resolve this problem, open the console in a new browser tab in Chrome. Any identities that you saved in your console wallet will persist in the new browser tab. To avoid this problem you can upgrade your Chrome browser version. Ensure you have downloaded all of your wallet identities to your local machine before closing your browser.\n\n\n\n\n\n When I hover over my node, the status is Status unavailable or Status unknown, what does this mean? \n\n What\u2019s happening \n\nA CA, peer, or ordering node has a gray status box, meaning the status of the node is not available. Ideally, when you hover over any node, the node status should be Running.\n\n Why it\u2019s happening \n\nThis problem can occur if the node is newly created and the deployment process has not completed. If the node is a CA and the status has been gray for more than a few minutes, then it is likely that the deployment process has failed. Peers and ordering nodes take longer to deploy, but this condition can also occur when the health checker that runs against the peer or ordering nodes cannot contact the node. The request for status can fail with a timeout error because the node did not respond within a specific time period, the node could be down, or network connectivity is down.\n\n How to fix it \n\nIf this is a new node, wait a few more minutes for the deployment to complete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":0.0327868852,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":0.0322580645,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16313-10077-11045","score":0.0317460317,"text":"\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16356-7-2036","score":0.03125,"text":"\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16313-8575-10638","score":0.0307692308,"text":"\nFor more information on uploading or downloading example phrases, see [Adding more examples](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-adding-more-examples).\n\n\n\n\n\n\n\n Editing the fallback action \n\nThe built-in Fallback action is automatically provided with each assistant and cannot be deleted. However, you can edit the Fallback action to modify the conversation your users have with the assistant when errors occur. For example, you might want to add steps or modify step conditions to provide more control over how specific error conditions are handled.\n\nTo edit the Fallback action, click Set by assistant in the list of actions, and then click Fallback.\n\nZoom\n\n![Fallback built-in action](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/fallback-action.png)\n\nFallback built-in action\n\nWhenever the Fallback action is triggered, the assistant also sets a value for the Fallback reason session variable. This value indicates what kind of situation led to the Fallback action being triggered. By default, this variable can have one of five values:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a live agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_03353-8238-10149","score":0.0303030303,"text":"\n[Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03027-8135-10108","score":0.0298507463,"text":"\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_13333-7-2349","score":0.0294117647,"text":"\nSpeech activity detection \n\nThe IBM Watson\u00ae Speech to Text service offers two speech activity detection parameters to control what audio is used for speech recognition. The parameters specify the service's sensitivity to non-speech events and to background noise. The parameters are independent: You can use them individually or together.\n\nSpeech activity detection is supported for most language models. For more information, see [Language model support](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputdetection-support).\n\n\n\n How speech activity detection works \n\nSpeech activity detection consumes the input audio stream and determines which parts of the stream to pass for speech recognition. Speech recognition is adversely affected by background speech and noise, causing the service to transcribe the wrong words, to produce words where none are present, or to omit words that are part of the input audio. The speech activity detection feature can help ensure that only relevant audio is processed for speech recognition.\n\nYou can use the feature to control the following aspects of speech recognition:\n\n\n\n* Suppress background speech. Call-center data often contains cross-talk (\"overhearing\") from other agents. You can set a volume threshold below which such background speech is ignored.\n* Suppress background noise. Some audio, such as speech recorded in a factory, can contain a high level of background noise. You can set a threshold below which such background noise is ignored.\n* Suppress non-speech audio events. Background music and tone events, such as audio played to a client who is waiting on hold on a telephone line, can cause inaccurate recognition. Silence can also result in unnecessary recognition or transcription errors. You can set a threshold below which such events are ignored.\n\n\n\nBy default, speech activity detection is configured to provide optimal performance for the general case for each model. For specific cases, the default settings might not be optimal and can lead either to slow transcription or to word insertions and deletions. You are encouraged to experiment with different settings to determine which values work best for your audio.\n\n\n\n\n\n Speech detector sensitivity \n\nUse the speech_detector_sensitivity parameter to adjust the sensitivity of speech activity detection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-detection"},{"document_id":"ibmcld_16364-192793-195089","score":0.0289855072,"text":"\nThe name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service. As such, an update has been made to the algorithm so that accented and non-accented versions of words are treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity may implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16356-1613-3336","score":0.0285714286,"text":"\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input. Use this step to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity.\n\nFor example, you might add darn, dang, and heck as trigger words for the Show warning step:\n\nZoom\n\n![Adding trigger words to the Show warning step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/show-warning-phrases.png)\n\nAdding trigger words to the Show warning step\n\nIn this example, a customer enters darn, dang, or heck, the assistant responds with Please use appropriate language when interacting with the assistant. You can customize this message.\n\nIf the customer triggers the Show warning step again, the Fallback action is triggered. The default setting is if attempts exceed 2 total tries. You can customize this setting.\n\nIn the Fallback action, step 5 has:\n\n\n\n* Profanity detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-566858-568609","score":0.0327868852,"text":"\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact? \n\nIf you have questions, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns).\n* What if I don't want all domains transferred to a single account?\n\n What if I don't want all domains transferred to a single account? \n\nIf you want to have all your domains transferred to multiple accounts, ensure that all domains in your IBM account have the same registrant\/owner email address. If you do not perform this step, domains are moved into independent retail accounts.\n* What if I don't want to move to Hover?\n\n What if I don't want to move to Hover? \n\nIf you don\u2019t think Hover is a suitable option, and you\u2019d rather be set up with a reseller account, Tucows can migrate you to their OpenSRS reseller platform instead. To migrate your account to OpenSRS, reach out to [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns) by 1 October 2021. If you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-566812-568563","score":0.0322580645,"text":"\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact? \n\nIf you have questions, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns).\n* What if I don't want all domains transferred to a single account?\n\n What if I don't want all domains transferred to a single account? \n\nIf you want to have all your domains transferred to multiple accounts, ensure that all domains in your IBM account have the same registrant\/owner email address. If you do not perform this step, domains are moved into independent retail accounts.\n* What if I don't want to move to Hover?\n\n What if I don't want to move to Hover? \n\nIf you don\u2019t think Hover is a suitable option, and you\u2019d rather be set up with a reseller account, Tucows can migrate you to their OpenSRS reseller platform instead. To migrate your account to OpenSRS, reach out to [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns) by 1 October 2021. If you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-568187-570089","score":0.0317460317,"text":"\nIf you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?\n\n What happens if I don\u2019t respond to the email from Hover? \n\nIf you don't respond to the email from Hover, your domains are moved to Tucows\u2019 Retail division, Hover. All emails from Hover are sent directly to the registrant\/owner email addresses on file. Failing to take action will require you to speak with the Hover support team.\n* Can I opt out of being migrated to OpenSRS?\n\n Can I opt out of being migrated to OpenSRS? \n\nYes, you can choose to be migrated to Tucows\u2019 retail domain platform, Hover. You must contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) before 1 October 2021.\n* Are all my brand settings carried over from the ResellOne reseller account?\n\n Are all my brand settings carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-568141-570043","score":0.03125,"text":"\nIf you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?\n\n What happens if I don\u2019t respond to the email from Hover? \n\nIf you don't respond to the email from Hover, your domains are moved to Tucows\u2019 Retail division, Hover. All emails from Hover are sent directly to the registrant\/owner email addresses on file. Failing to take action will require you to speak with the Hover support team.\n* Can I opt out of being migrated to OpenSRS?\n\n Can I opt out of being migrated to OpenSRS? \n\nYes, you can choose to be migrated to Tucows\u2019 retail domain platform, Hover. You must contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) before 1 October 2021.\n* Are all my brand settings carried over from the ResellOne reseller account?\n\n Are all my brand settings carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11913-34045-35103","score":0.0307692308,"text":"\nDo not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-endpoint - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-location - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n\n\n\n\n\n1. Create the storage configuration and specify the updated values. In this example, the osd-device-path parameter is updated to include the device IDs of the disks that you want to use and the num-of-osd value is increased to 2. Do not specify the Object Storage parameters when you create your configuration if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-odf-local"},{"document_id":"ibmcld_11914-34110-35168","score":0.0303030303,"text":"\nDo not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-endpoint - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-location - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n\n\n\n\n\n1. Create the storage configuration and specify the updated values. In this example, the osd-device-path parameter is updated to include the device IDs of the disks that you want to use and the num-of-osd value is increased to 2. Do not specify the Object Storage parameters when you create your configuration if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-odf-local&interface=ui"},{"document_id":"ibmcld_07476-3916-5886","score":0.0298507463,"text":"\nOn the day of migration, the registrant\/owner email address will receive an email from Hover that contains:\n\n\n\n* A welcome message\n* Login instructions\n* Instructions to add your billing info and set up 2FA\n* Steps to double check your account information\n* Hover\u2019s contact information and support hours\n\n\n\nTucows will move all domains with the same registrant\/owner email address into the same Hover account. If all the domains that you manage have the same registrant email, these domains migrate to a single Hover account. If you manage domains for multiple registrants, and therefore have multiple registrant\/owner emails on file, Tucows creates multiple Hover accounts, one for each unique registrant email.\n\n\n\n Specific FAQs (for under 100 domains) \n\n\n\n What if I don't want all domains transferred to a single account? \n\nIf you want to have all your domains transferred to multiple accounts, ensure that all domains in your IBM account have the same registrant\/owner email address. If you do not perform this step, domains are moved into independent retail accounts.\n\n\n\n\n\n What if I don't want to move to Hover? \n\nIf you don\u2019t think Hover is a suitable option, and you\u2019d rather be set up with a reseller account, Tucows can migrate you to their OpenSRS reseller platform instead. To migrate your account to OpenSRS, reach out to [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns) by 1 October 2021. If you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n\n\n\n\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n\n\n\n\n\n What happens if I don\u2019t respond to the email from Hover? \n\nIf you don't respond to the email from Hover, your domains are moved to Tucows\u2019 Retail division, Hover. All emails from Hover are sent directly to the registrant\/owner email addresses on file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-migration"},{"document_id":"ibmcld_03655-0-1101","score":0.0294117647,"text":"\n\n\n\n\n\n\n  FAQs for custom image templates \n\n\n\n  Why don\u2019t I see some of my disks as choices on the 'Create image template' page? \n\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n\n\n\n\n\n  Why did my capture fail? \n\nWhen a capture fails, an error occurred. If the error can be resolved, you might be contacted by our support personnel. Until the error is resolved, a completed image isn't in the portal. If you want to know why the capture failed, you can [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n  Why don't I see my captured images? \n\nIf you don\u2019t see a captured image in your portal, the capture experienced an unrecoverable error. For more information, [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-faqs-image-templates"},{"document_id":"ibmcld_01518-0-1200","score":0.0289855072,"text":"\n\n\n\n\n\n\n  Why don't all my namespaces show in the Resource list? \n\nMy IBM Cloud\u00ae Container Registry namespaces don't all show up in the IBM Cloud Resource list page in the IBM Cloud console.\n\n  What\u2019s happening \n\nWhen you view your namespaces in the IBM Cloud Resource list page, they don't all show up.\n\n  Why it\u2019s happening \n\nOnly namespaces that are assigned to\n\nresource groupsshow in the IBM Cloud Resource list page.\n\nNamespaces created in version 0.1.485 of the Container Registry CLI or later, or in the IBM Cloud console on or after 29 July 2020, are created in the resource group that you specify. If you don't specify a resource group, and a resource group isn't targeted, the default resource group is used.\n\nNamespaces created in version 0.1.484 of the Container Registry CLI or earlier, or in the IBM Cloud console before 29 July 2020, aren't assigned to resource groups.\n\n  How to fix it \n\nIf you want to see all your namespaces in the IBM Cloud Resource list page, you must assign each namespace to a resource group, see [Assigning existing namespaces to resource groups](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-namespace-resource-list"},{"document_id":"ibmcld_05628-12554-14474","score":0.0285714286,"text":"\nFor bare metal flavors, specify dedicated.\n\n--public-vlan <public_vlan_id>\n: If you already have a public VLAN set up in your IBM Cloud infrastructure account for that zone, enter the ID of the public VLAN that you retrieved earlier. If you don't have a public VLAN in your account, don't specify this option. IBM Cloud Kubernetes Service automatically creates a public VLAN for you. Private VLAN routers always begin with bcr (back-end router) and public VLAN routers always begin with fcr (front-end router). When you create a cluster and specify the public and private VLANs, the number and letter combination after those prefixes must match.\n\n--private-vlan <private_vlan_id>\n: If you already have a private VLAN set up in your IBM Cloud infrastructure account for that zone, enter the ID of the private VLAN that you retrieved earlier. If you don't have a private VLAN in your account, don't specify this option. IBM Cloud Kubernetes Service automatically creates a private VLAN for you. Private VLAN routers always begin with bcr (back-end router) and public VLAN routers always begin with fcr (front-end router). When you create a cluster and specify the public and private VLANs, the number and letter combination after those prefixes must match.\n\n--private-only\n: Create the cluster with private VLANs only. If you include this option, don't include the --public-vlan option.\n\n--name <name>\n: Specify a name for your cluster. The name must start with a letter, can contain letters, numbers, periods (.), and hyphen (-), and must be 35 characters or fewer. Use a name that is unique across regions. The cluster name and the region in which the cluster is deployed form the fully qualified domain name for the Ingress subdomain. To ensure that the Ingress subdomain is unique within a region, the cluster name might be truncated and appended with a random value within the Ingress domain name.\n\n--workers <number>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03966-3327-5475","score":0.0327868852,"text":"\n* Org admins: When you join a consortium that is hosted by an ordering service, you provide the signing certificates of identities that will become the administrators for your organization. You can use these identities to create or edit channels.\n* Peer or orderer admins: IBM Blockchain Platform nodes are deployed with the signing certificates of component administrators identities inside of them. These certificates allow the admins to operate the component from a remote client or by using the console.\n* Applications: Your applications need to sign their transactions before submitting them to be validated by the network. You need to create identities you can use to sign transactions from your client applications.\n\n\n\nYou can use the console to create these identities by using the [registration process](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-register). After you register your admin identities, you need to issue each identity a signing certificate and private key, provide the signing certificate to your organization MSP definition, and add the identity to your console wallet. You can complete these steps for one admin identity when you [create your organization MSP](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizationsconsole-organizations-create-msp). You can use separate identities as org admins or node admins, or you can use one identity to do both tasks. The [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) uses one identity to be an admin for each organization created in the tutorial.\n\n\n\n\n\n Associating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_03893-74275-75877","score":0.0322580645,"text":"\nConfigure an HSM client image[See Build a Docker image](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-hsm-build-docker).\n3. Configure the node to use HSM. From the APIs or the console, when you deploy a peer, CA, or ordering node, you can select the advanced option to use an HSM. See [Configure the node to use the HSM](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-cfg-hsm-node).\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* The Kubernetes CLI is required to configure the HSM. If you are using a Kubernetes cluster on IBM Cloud see [Getting started with IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) or [Installing the OpenShift CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-cli).\n* You need access to a container registry, such as Docker or the [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-started).\n\n\n\n\n\n\n\n Build a Docker image \n\nConfigure HSM on your blockchain network by publishing an HSM client image to a container registry, as described below.\n\nBuild an HSM client image\n\nNext we build a Docker file that contains the HSM client image. These instructions assume that you have successfully configured your HSM appliance and HSM client. Use these steps to generate an image that is consumable by the IBM Blockchain Platform operator.\n\n\n\n* Step one: Modify the HSM client configuration.\n* Step two: Build the HSM client image.\n* Step three: Push the Docker image to your container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_16281-0-376","score":0.0317460317,"text":"\n\n\n\n\n\n\n  Integrating with a custom client app \n\nIBM Cloud\n\nIf the available integration channels do not meet your needs, you can build your own client application as the interface between the assistant and your customers.\n\nFor more information, see [Building a custom client using the API](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-custom-app"},{"document_id":"ibmcld_02998-8791-9815","score":0.03125,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03982-9793-12132","score":0.0307692308,"text":"\nBecause an MSP is the representation of an organization in the network, you select the MSP definition when you deploy your nodes (identifying the organization the node belongs to), are joined to the consortium (by an ordering service admin), create a channel, join a channel, edit a channel, or perform any action where you have to specify the organization that is performing the action.\n\n\n\n\n\n Downloading a connection profile \n\nAfter you create an organization MSP definition and create peers with that organization MSP definition, you can download a connection profile that can be used by a client application to connect to your network via one or more gateway peers. The gateway peers are the peers that are specified in the connection profile, and they are used to perform service discovery to find all of the endorsing peers in the network that will endorse transactions.\n\nClick the Organization MSP tile for the organization that your client application interacts with. Click Create connection profile to open a side panel where you can build and download your connection profile.\n\n![Create connection profile panel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/create-connx-profile.png)\n\nIf you plan to use the client application to register and enroll users with the organization CA, you need to include the Certificate Authority in the connection profile definition.\n\nSelect the peers to include in the connection profile definition. When a peer is not available to process requests from a client application, service discovery ensures that the request is automatically sent to a different peer. Therefore, to accommodate for peer downtime during a maintenance cycle for example, it is recommended that you select more than one peer for redundancy. In addition to peers created by using the console or APIs, imported peers that have been imported into the console are eligible to be selected as well.\n\nThe list of channels that the selected peers have joined is also provided for your information. If a channel is missing from the list, it is likely because the peer joined to it is currently unavailable.\n\nYou can then download the connection profile to your local file system and use it with your client application to generate certificates and invoke smart contracts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizations"},{"document_id":"ibmcld_05070-7-1814","score":0.0303030303,"text":"\nUsing Node.js \n\nThe IBM Cloud\u00ae Object Storage SDK for Node.js provides modern capabilities that make the most of IBM Cloud Object Storage.\n\n\n\n Installing the SDK \n\n[Node.js](https:\/\/cloud.ibm.com\/docs\/node?topic=node-getting-started) is an excellent way to build [web applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-mean-stack), and customize your instance of Object Storage for your end users. The preferred way to install the Object Storage SDK for Node.js is to use the [npm](https:\/\/www.npmjs.com) package manager for Node.js. Type the following command into a command line:\n\nnpm install ibm-cos-sdk\n\nTo download the SDK directly, the source code is hosted on [GitHub](https:\/\/github.com\/IBM\/ibm-cos-sdk-js).\n\nMore detail on individual methods and classes can be found in [the API documentation for the SDK](https:\/\/ibm.github.io\/ibm-cos-sdk-js\/).\n\n\n\n\n\n Getting Started \n\n\n\n Minimum requirements \n\nTo run the SDK, you need Node 4.x+.\n\n\n\n\n\n Creating a client and sourcing credentials \n\nTo connect to COS, a client is created and configured by providing credential information (API Key, Service Instance ID, and IBM Authentication Endpoint). These values can also be automatically sourced from a credentials file or from environment variables.\n\nAfter generating a [Service Credential](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials), the resulting JSON document can be saved to \/.bluemix\/cos_credentials. The SDK will automatically source credentials from this file unless other credentials are explicitly set during client creation. If the cos_credentials file contains HMAC keys the client authenticates with a signature, otherwise the client uses the provided API key to authenticate with a bearer token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_02680-7025-8620","score":0.0298507463,"text":"\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Integrate Kotlin to your Java project with these steps:\n\n\n\n* Add the Kotlin Gradle plug-in to the Module level build.gradle\n\ndependencies {\nclasspath \"com.android.tools.build:gradle:4.1.1\"\nclasspath \"org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version\"\n}\n* Add kotlin-android plugin to the App level build.gradle\n\nplugins {\nid 'com.android.application'\nid 'kotlin-android'\n}\n\n\n\n4. Initialize the SDK.\n\nAppConfiguration appConfiguration = AppConfiguration.getInstance();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_03916-19063-21128","score":0.0294117647,"text":"\nIf you manually built your organization MSP with certificates from an external CA, the connection profile will not include any information in the \"certificateAuthorities\": section.\n\n\n\n\n\n Service discovery \n\nService discovery allows your applications to dynamically find the peer and ordering endpoints of your network. If you do not use service discovery, you need to manually add the endpoint information of peer and ordering nodes on your channel to your connection profile or your application. You would need to edit your connection profile or update your application each time a node is added or removed from your network.\n\nBefore you can take advantage of the [Service Discovery](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/discovery-overview.html) feature of Hyperledger Fabric, you must configure anchor peers on the channel. Service discovery allows your application to learn which peers on the channel outside your organization need to endorse a transaction. Without service discovery, you will need to get the endpoint information of these peers out of band from other organizations and add them to your connection profile. For more information, see [Configuring anchor peers](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-governibp-console-govern-channels-anchor-peers).\n\nLater in this topic, we use the connection profile to build a Fabric gateway that is configured for [service discovery](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-sd-cfg).\n\n\n\n\n\n Enrolling by using the SDK \n\nOnce the network operator provides the enroll ID and secret of the application identity and the network connection profile, an application developer can use the Fabric SDKs or the Fabric CA client to generate client-side certificates. You can use the following steps to enroll an application identity by using the [Fabric SDK for Node.js](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/index.html).\n\n\n\n1. Save the connection profile to your local system and rename it connection.json.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_02998-7662-9256","score":0.0289855072,"text":"\n[An ending node was added to the dialog also.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs. Let's see how well it works.\n\n\n\n1. Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/try-it.png) icon to open the Try it out pane. There's that reassuring welcome message.\n2. In the text field, type Hello and press Enter. The output indicates that the General_Greetings intent was recognized, and the appropriate response (Good day to you.) is displayed.\n3. Try the following input:\n\n\n\n* bye\n* howdy\n* see ya\n* good morning\n* sayonara\n\n\n\n\n\nWatson can recognize your intents even when your input doesn't exactly match the examples that you included. The dialog uses intents to identify the purpose of the user's input regardless of the precise wording used, and then responds in the way you specify.\n\n\n\n\n\n Result of building a dialog \n\nThat's it. You created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03916-39203-41294","score":0.0285714286,"text":"\nSuccessfully enrolled client \"user1\" and imported it into the wallet\n\nYou can find the wallet that was created in the identity folder of the magnetocorp directory.\n\n\n\n\n\n Step four: Use the connection profile to build a Fabric gateway \n\nThe Hyperledger Fabric [Transaction Flow](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/txflow.html) spans multiple components, with the client applications playing a unique role. Your application needs to connect to the peers that need to endorse the transaction and needs to connect to the ordering service that will order the transaction and add it into a block. You can provide the endpoints of these nodes to your application by using your connection profile to construct a Fabric gateway. The gateway then conducts the low-level interactions with your Fabric network. To learn more, visit the [Fabric gateway](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/developapps\/gateway.html) topic in the Fabric documentation.\n\nYou have already downloaded your connection profile and used it to connect to your organization's Certificate Authority. Now we use the connection profile to build a gateway.\n\nOpen the file issue.js in a text editor. Before you edit the file, notice that it imports the FileSystemWallet and Gateway classes from fabric-network library.\n\nconst { FileSystemWallet, Gateway } = require('fabric-network')\n\nYou will need to import the path class to build the gateway from the connection profile you downloaded from your console. Add the following line to the file to import the path class:\n\nconst path = require('path');\n\nThe Gateway class is used to construct a gateway that you will use to submit your transaction.\n\nconst gateway = new Gateway()\n\nThe FileSystemWallet class is used to load the wallet you created in the previous step. Edit the following line if you changed the location of the wallet on your file system.\n\nconst wallet = new FileSystemWallet('..\/identity\/user\/isabella\/wallet');\n\nAfter you import your wallet, use the following code to pass your connection profile and wallet to the new gateway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3433743194}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05891-109363-111311","score":0.0163934426,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\nkubectl drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5. Make your worker node available for pod scheduling.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_02953-3805-5544","score":0.0163934426,"text":"\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_04489-110010-111892","score":0.0161290323,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\nkubectl drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10203-2544-4340","score":0.0161290323,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10290-107432-109320","score":0.0158730159,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\noc adm drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10359-14691-16707","score":0.0158730159,"text":"\nThe source IP address of client requests is preserved by default in version 2.0 NLBs.\n\nWhen a client request to your app is sent to your cluster, a load balancer service pod receives the request. If no app pod exists on the same worker node as the load balancer service pod, the NLB forwards the request to a different worker node. The source IP address of the package is changed to the public IP address of the worker node where the load balancer service pod runs.\n\nTo preserve the original source IP address of the client request, you can [enable source IP](https:\/\/kubernetes.io\/docs\/tasks\/access-application-cluster\/create-external-load-balancer\/preserving-the-client-source-ip) for load balancer services. The TCP connection continues all the way to the app pods so that the app can see the actual source IP address of the initiator. Preserving the client\u2019s IP is useful, for example, when app servers have to apply security and access-control policies.\n\nAfter you enable the source IP, load balancer service pods must forward requests to app pods that are deployed to the same worker node only. Typically, load balancer service pods are also deployed to the worker nodes that the app pods are deployed to. However, some situations exist where the load balancer pods and app pods might not be scheduled onto the same worker node:\n\n\n\n* You have edge nodes that are tainted so that only load balancer service pods can deploy to them. App pods are not permitted to deploy to those nodes.\n* Your cluster is connected to multiple public or private VLANs, and your app pods might deploy to worker nodes that are connected only to one VLAN. Load balancer service pods might not deploy to those worker nodes because the NLB IP address is connected to a different VLAN than the worker nodes.\n\n\n\nTo force your app to deploy to specific worker nodes where load balancer service pods can also deploy to, you must add affinity rules and tolerations to your app deployment.\n\n\n\n Adding edge node affinity rules and tolerations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer"},{"document_id":"ibmcld_10290-111044-112870","score":0.015625,"text":"\nDuring the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_05967-15142-16962","score":0.015625,"text":"\nIf no app pod exists on the same worker node as the load balancer service pod, the NLB forwards the request to a different worker node. The source IP address of the package is changed to the public IP address of the worker node where the load balancer service pod runs.\n\nTo preserve the original source IP address of the client request, you can [enable source IP](https:\/\/kubernetes.io\/docs\/tasks\/access-application-cluster\/create-external-load-balancer\/preserving-the-client-source-ip) for load balancer services. The TCP connection continues all the way to the app pods so that the app can see the actual source IP address of the initiator. Preserving the client\u2019s IP is useful, for example, when app servers have to apply security and access-control policies.\n\nAfter you enable the source IP, load balancer service pods must forward requests to app pods that are deployed to the same worker node only. Typically, load balancer service pods are also deployed to the worker nodes that the app pods are deployed to. However, some situations exist where the load balancer pods and app pods might not be scheduled onto the same worker node:\n\n\n\n* You have edge nodes that are tainted so that only load balancer service pods can deploy to them. App pods are not permitted to deploy to those nodes.\n* Your cluster is connected to multiple public or private VLANs, and your app pods might deploy to worker nodes that are connected only to one VLAN. Load balancer service pods might not deploy to those worker nodes because the NLB IP address is connected to a different VLAN than the worker nodes.\n\n\n\nTo force your app to deploy to specific worker nodes where load balancer service pods can also deploy to, you must add affinity rules and tolerations to your app deployment.\n\n\n\n Adding edge node affinity rules and tolerations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer"},{"document_id":"ibmcld_05891-113289-115164","score":0.0153846154,"text":"\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.\n\n\n\nibmcloud ks worker reload --cluster CLUSTER --worker WORKER_ID [--skip-master-healthcheck] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_03891-5842-7878","score":0.0153846154,"text":"\nFor the purpose of this tutorial, it is assumed that a user has followed the [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-network) in their console and has created a peer, ordering service, and an application channel. Subsequent to this, a separate user, with a separate console, wishes to add a node to that ordering service, which is called Ordering Service.\n\nAs part of describing the process for creating a new node from a separate console, we will refer to \"Console 1\" and \"Console 2\". Console 1 is the originating console; it's where the ordering service was originally created. Console 2 is where a user is attempting to create a new node for this ordering service using a different organization in a different console.\n\nUnless you have already created new nodes for this ordering service, do not reuse an existing CA and MSP.\n\nThe process of creating a CA, registering identities, and creating an MSP is identical to the process described in [Creating your ordering service organization CA](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network-create-orderer-ca) from the Build a network tutorial. However, use the following values:\n\n\n\n Task: Create a CA and register users \n\n\n\nTable 1. Create a CA and register users\n\n Field Description Enroll ID Secret Type \n\n Create CA Ordering Service2 CA admin adminpw \n Register users Ordering Service2 admin OS2admin OS2adminpw admin \n Ordering Service node identity OS2 OS2pw orderer \n\n\n\nIf you are using a separate console, it is possible to specify exactly the same values for these fields as was specified in the Build a network tutorial. Only the mspid from the fields below must be different than osmsp, as two different MSPs cannot have the same ID in the same console (the MSP you create here will be exported to the other console in a future step). However, we have given different values in this tutorial in case users are running this tutorial inside the same console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-orderer"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06279-70523-72321","score":0.0163934426,"text":"\nTo delete a persistent VPC load balancer, delete the Kubernetes LoadBalancer service definition that the VPC load balancer is associated with.\n\n\n\n\n\n Moving a VPC load balancer from one cluster to another \n\n[Persistent VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaasvpc_lb_persist) can be detached from one VPC cluster and then attached to another. The new cluster must be within the same VPC as the original cluster.\n\n\n\n Detaching a VPC load balancer from a cluster \n\nVPC load balancers are linked to the Kubernetes LoadBalancer service definition that they were created with. To detach a persistent VPC load balancer from a cluster, you must break the link with the LoadBalancer service by [renaming the VPC load balancer](https:\/\/cloud.ibm.com\/docs\/vpc-infrastructure-cli-plugin?topic=vpc-infrastructure-cli-plugin-vpc-referenceload-balancer-update), or by removing the service.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-lb-name annotation from the original LoadBalancer service definition. You can also detach a persistent VPC load balancer from a cluster by [deleting the cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove).\n\nIf you remove the annotation, the original LoadBalancer service reverts and creates a non-persistent VPC load balancer in the original cluster. This non-persistent VPC load balancer follows the kube-<cluster_ID>-<kubernetes_lb_service_UID> naming convention.\n\n\n\n\n\n Attaching a VPC load balancer to a cluster \n\nAfter a persistent VPC load balancer is detached from a cluster, you can attach to a different cluster by creating a new Kubernetes LoadBalancer service definition that references the VPC load balancer, or by updating an existing Kubernetes LoadBalancer service that exists on the new cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas"},{"document_id":"ibmcld_16628-0-1541","score":0.0163934426,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_10041-7462-8947","score":0.0161290323,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_13206-2553-4129","score":0.0161290323,"text":"\nIBM Cloud VPC concepts and the networking constructs are explained in the [VPC pages of the IBM Cloud\u2122 Docs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). More information about planning and deploying bare metal servers on VPC can be found in the [Bare metal server section of IBM Cloud VPC pages](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n\n\n\n Objectives \n\n\n\n* Understand the Virtual Private Cloud infrastructure used for VMware vSphere deployment.\n* Create a IBM Cloud VPC, subnets and bare metal server instances for a vSphere deployment.\n* Manually deploy vCenter and create a compute cluster.\n* Create shared storage for your compute cluster either by using vSAN or VPC file share (NFS).\n* Use IBM Cloud VPC networking for your VMware Virtual Machines.\n\n\n\nThe following diagram presents an overview of the base deployment in IBM Cloud VPC. The deployment is based on IBM Cloud\u00ae Bare Metal Servers for Virtual Private Cloud and uses [subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpc) to host the servers' network interfaces and [access control lists and security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc) to secure the network access. VMware vSAN with local ESXi host embedded SSDs or IBM Cloud VPC file share are the storage options for datastores to be used for VMware Virtual Machines. IBM Cloud VPC subnets can also be used to host network interfaces of VMware Virtual machines. Alternatively NSX-T can be used for Virtual Machines, but this is not mandatory.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware"},{"document_id":"ibmcld_05567-7444-8929","score":0.0158730159,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_11164-6586-7646","score":0.0158730159,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_10686-70394-71984","score":0.015625,"text":"\n[Persistent VPC load balancers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaasvpc_lb_persist) can be detached from one VPC cluster and then attached to another. The new cluster must be within the same VPC as the original cluster.\n\n\n\n Detaching a VPC load balancer from a cluster \n\nVPC load balancers are linked to the Kubernetes LoadBalancer service definition that they were created with. To detach a persistent VPC load balancer from a cluster, you must break the link with the LoadBalancer service by [renaming the VPC load balancer](https:\/\/cloud.ibm.com\/docs\/vpc-infrastructure-cli-plugin?topic=vpc-infrastructure-cli-plugin-vpc-referenceload-balancer-update), or by removing the service.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-lb-name annotation from the original LoadBalancer service definition. You can also detach a persistent VPC load balancer from a cluster by [deleting the cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove).\n\nIf you remove the annotation, the original LoadBalancer service reverts and creates a non-persistent VPC load balancer in the original cluster. This non-persistent VPC load balancer follows the kube-<cluster_ID>-<kubernetes_lb_service_UID> naming convention.\n\n\n\n\n\n Attaching a VPC load balancer to a cluster \n\nAfter a persistent VPC load balancer is detached from a cluster, you can attach to a different cluster by creating a new Kubernetes LoadBalancer service definition that references the VPC load balancer, or by updating an existing Kubernetes LoadBalancer service that exists on the new cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"},{"document_id":"ibmcld_13206-1130-3047","score":0.015625,"text":"\n[IBM Cloud Bare Metal Servers for Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-bare-metal-servers) environment provide a new option to deploy VMware on IBM Cloud. Currently the IBM Cloud VPC environment provides only the automated vSphere Hypervisor (ESXi) Operating System image deployment to Intel Bare Metals on VPC. Therefore, you need to manually install and configure the required VMware components, such as ESXi hosts, vCenter, vSAN or NSX-T components.\n\nThis tutorial walks you through creating your own IBM Cloud VPC with multiple subnets as required to support vSphere networking and the provisioning of IBM Cloud Bare Metal Servers for Virtual Private Cloud (BMS) for a basic VMware vSphere deployment. After the IBM Cloud VPC and Bare Metal Servers for VPC have been provisioned, the tutorial covers a manual deployment of the vCenter, creating VMware compute cluster with vSAN or NFS shared storage options. The tutorial also covers optional features, such as using IBM Cloud VPC network for VMware Virtual Machine networking.\n\nThis tutorial assumes a working knowledge of VMware vSphere Hypervisor and vCenter Server 7.0 as well as IBM Cloud zones, regions, prefixes, subnets and security groups that build the base IBM Cloud VPC networking and are used to support the vSphere deployment. More information about VMware products can be found in [VMware Docs](https:\/\/docs.vmware.com). IBM Cloud VPC concepts and the networking constructs are explained in the [VPC pages of the IBM Cloud\u2122 Docs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). More information about planning and deploying bare metal servers on VPC can be found in the [Bare metal server section of IBM Cloud VPC pages](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n\n\n\n Objectives \n\n\n\n* Understand the Virtual Private Cloud infrastructure used for VMware vSphere deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware"},{"document_id":"ibmcld_06282-17354-19397","score":0.0153846154,"text":"\nWhen you create your VPC cluster, you can also attach additional security groups alongside, or instead of, the default VPC security groups. The security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_11554-13102-14857","score":0.0153846154,"text":"\nDNS records](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/images\/sap-terraform-ha-dns.png)\n\nFigure 6. DNS records\n\n\n\n\n\n\n\n 2. Highly available system for SAP HANA database \n\nZoom\n\n![Figure 7. SAP HA for HANA DB instances cluster nodes Primary (Active) and Secondary (Passive)](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/images\/sap-ha-hana-vpc-single-zone.svg)\n\nFigure 2. SAP HA for HANA DB instances cluster nodes Primary (Active) and Secondary (Passive)\n\nAt the most basic level, a standard HA HANA cluster in an active-passive configuration has two nodes: one is the primary node and the other is the standby node. This simply means that the primary node is actively serving the active SAP instances (PAS and AAS), while the standby node is waiting to jump in if there is a failure.\n\nThe cluster is set with a virtual hostname IP (hostname is mapped to the FQDN of the HANA ALB through DNS, which is the same as explained previously for SAP ASCS and ERS instances). App instances (PAS and AAS), these are the details to be used on the SAP profiles to call that particular component. The cluster assigns that virtual IP to the active node and uses a heartbeat monitor to confirm the availability of the components. If the primary node stops responding, it triggers the automatic failover mechanism that calls the standby node to step up to become the primary node. The ALB detects the change, redirects the traffic to the new active node, and assigns the virtual IP to it, restoring the component availability. After the failed node is fixed, it comes online as a standby node.\n\n\n\n Synchronous on disk (sync) HANA database replication mechanism supported by SAP","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10041-8604-10172","score":0.0327868852,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-8586-10154","score":0.0322580645,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-9785-11475","score":0.0317460317,"text":"\ncontainers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v2\/disablePrivateServiceEndpoint Disable a private cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/disablePublicServiceEndpoint Disable a public cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/enableKMS Enable a key management service (KMS) for a cluster containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v2\/enablePrivateServiceEndpoint Enable the private cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/enablePublicServiceEndpoint Enable the public cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/enablePullSecret Create image pull secret to IBM Cloud Container Registry in the default Kubernetes namespace. containers-kubernetes.cluster.operate containers-kubernetes.cluster.update \n POST\/v2\/refreshMaster Refresh the Kubernetes master. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/updateMaster Update the version of the Kubernetes cluster master node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-9767-11457","score":0.03125,"text":"\ncontainers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v2\/disablePrivateServiceEndpoint Disable a private cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/disablePublicServiceEndpoint Disable a public cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/enableKMS Enable a key management service (KMS) for a cluster containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v2\/enablePrivateServiceEndpoint Enable the private cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/enablePublicServiceEndpoint Enable the public cloud service endpoint for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/enablePullSecret Create image pull secret to IBM Cloud Container Registry in the default Kubernetes namespace. containers-kubernetes.cluster.operate containers-kubernetes.cluster.update \n POST\/v2\/refreshMaster Refresh the Kubernetes master. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/updateMaster Update the version of the Kubernetes cluster master node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_11889-0-903","score":0.0307692308,"text":"\n\n\n\n\n\n\n  Setting up cluster groups \n\nThe cluster group specifies all clusters that you want to include in the deployment of your Kubernetes resources. The clusters can run in your Satellite location or in IBM Cloud.\n\nIf you want to use the console to create Satellite configurations, you can create cluster groups as part of the configuration creation process. If you want to use the CLI to create Satellite configurations, you must create a cluster group first. Follow these steps to create a cluster group with the CLI:\n\n\n\n1.  List the clusters that are registered with the Satellite Config component and note their ID.\n\nibmcloud sat cluster ls\n2.  Add the cluster to your cluster group.\n\nibmcloud sat group attach --cluster <cluster_ID> --group <cluster_group_name>\n3.  Verify that your cluster is successfully added to your cluster group.\n\nibmcloud sat group get --group <cluster_group_name>\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig-groups"},{"document_id":"ibmcld_06282-18946-20824","score":0.0303030303,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-19050-20928","score":0.0298507463,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_10689-19663-21541","score":0.0294117647,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-group"},{"document_id":"ibmcld_10041-16414-17914","score":0.0289855072,"text":"\nGET\/v2\/alb\/getAlbImages List supported Ingress controller images. containers-kubernetes.cluster.read alb-image.list \n GET\/v2\/alb\/getClusterAlbs List all ALBs in a cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v2\/alb\/getMigrationStatus Get the status of the Ingress migration process. containers-kubernetes.cluster.read cluster-alb-migration-status.get \n POST\/v1\/alb\/albs Enable an existing ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.enable \n POST\/v1\/alb\/albsecrets Import an ALB secret from Secrets Manager to a cluster. containers-kubernetes.cluster.create cluster-ingress-secret.create \n POST\/v1\/alb\/clusters\/{idOrName}\/zone\/{zoneId} Create a public or private ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/cleanupMigration Clean up any Ingress resources and configmaps that are no longer needed after an Ingress migration. containers-kubernetes.cluster.create cluster-alb-migration.cleanup \n POST\/v2\/alb\/startMigration Start a migration of your IBM Cloud Ingress ConfigMap and Ingress resources to the Kubernetes Ingress format. containers-kubernetes.cluster.create cluster-alb-migration.start \n POST\/v2\/alb\/updateAlb Update ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb.update \n POST\/v2\/alb\/vpc\/createAlb Create a public or private ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/vpc\/disableAlb Disable an ALB in a VPC cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-16394-17894","score":0.0285714286,"text":"\nGET\/v2\/alb\/getAlbImages List supported Ingress controller images. containers-kubernetes.cluster.read alb-image.list \n GET\/v2\/alb\/getClusterAlbs List all ALBs in a cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v2\/alb\/getMigrationStatus Get the status of the Ingress migration process. containers-kubernetes.cluster.read cluster-alb-migration-status.get \n POST\/v1\/alb\/albs Enable an existing ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.enable \n POST\/v1\/alb\/albsecrets Import an ALB secret from Secrets Manager to a cluster. containers-kubernetes.cluster.create cluster-ingress-secret.create \n POST\/v1\/alb\/clusters\/{idOrName}\/zone\/{zoneId} Create a public or private ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/cleanupMigration Clean up any Ingress resources and configmaps that are no longer needed after an Ingress migration. containers-kubernetes.cluster.create cluster-alb-migration.cleanup \n POST\/v2\/alb\/startMigration Start a migration of your IBM Cloud Ingress ConfigMap and Ingress resources to the Kubernetes Ingress format. containers-kubernetes.cluster.create cluster-alb-migration.start \n POST\/v2\/alb\/updateAlb Update ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb.update \n POST\/v2\/alb\/vpc\/createAlb Create a public or private ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/vpc\/disableAlb Disable an ALB in a VPC cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-593375-595353","score":0.0327868852,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-593333-595311","score":0.0322580645,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11997-5537-6386","score":0.0317460317,"text":"\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.\n* See [understanding blueprint templates and configuration](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-templates) to dig into how to define cloud environments using blueprint templates and inputs of latest version.\n* [Beta code for Schematics Blueprints](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-beta-limitations) to provide your feedback and understand beta limitations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro"},{"document_id":"ibmcld_12581-17606-19704","score":0.03125,"text":"\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom"},{"document_id":"ibmcld_08921-1291-2538","score":0.0307692308,"text":"\n\"name\": \"Schematic Dev Workspace\",\n\u00a0 \"type\": [\n\u00a0\u00a0\u00a0 \"terraform_v0.13.7\"\n\u00a0 ],\n\u00a0 \"location\": \"us-south\",\n\u00a0 \"description\": \"Schematic Dev Workspace\",\n\u00a0 \"tags\": [],\n\u00a0 \"template_repo\": {\n\u00a0\u00a0\u00a0 \"url\": \"<GitHub repo URL>\",\n\u00a0\u00a0\u00a0 \"githubtoken\": \"<github-token>\"\n\u00a0 }\n\n\n\n Example Python request for schematics_variables_update.py file \n\nThe following Python example request is for the example file, schematics_variables_update.py.\n\nimport logging, os, json\n\nlogging.basicConfig()\nlogging.root.setLevel(logging.NOTSET)\nlogging.basicConfig(level=logging.NOTSET)\n\nfrom schematics_env_class import HPCCEnvironmentValues\n\nlogging.info(\"Schematic Variable Update Started\")\n\nif __name__ == '__main__':\n\n\u00a0\u00a0\u00a0 json_files = os.path.join(os.path.abspath(\".\"), \"config.json\")\n\n\u00a0\u00a0\u00a0 with open(json_files, \"r\") as file:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 config_data = json.load(file)\n\n\u00a0\u00a0\u00a0 api_key = config_data[\"template_data\"][\"variablestore\"][\"value\"]\n\n\u00a0\u00a0\u00a0 schematic_obj = HPCCEnvironmentValues(api_key)\n\n\u00a0\u00a0\u00a0 workspace_response = schematic_obj.schematics_service.get_workspace(w_id=\"<workspace id>\").get_result()\n\u00a0\u00a0\u00a0 schematic_obj.update_variables(w_id=\"<workspace id>\",\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 t_id=workspace_response[\"template_data\"][\"id\"],\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 variablestore=config_data[\"template_data\"][\"variablestore\"]\n\u00a0\u00a0\u00a0 )","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-update-variables"},{"document_id":"ibmcld_12008-4112-6332","score":0.0303030303,"text":"\nCorrect the Terraform config error at source and push a new release to its Git source repository.\n\nIf explicit version of the blueprint modules is used on specific branches. The blueprint template requires updating in its Git repository to specify the new release tag or branch for the module statement.\n\n\n\n* Update the blueprint module statements to specify the new module version.\n* Push the new release of the blueprint template to its Git source repository. With an updated release tag for the template if needed.\n\n\n\nFor modules, when no Git release is specified on the blueprint module statements and relaxed module version are used. No update to the blueprint template is needed. The current change to the module repository is pulled automatically by Schematics.\n\nRun the ibmcloud schematics blueprint update command to refresh the blueprint configuration that is stored by Schematics with the update to the blueprint template. With latest release, Schematics identifies the updated module Git repository and run the Pull-Latest to update any modules with the modified Terraform configurations.\n\nibmcloud schematics blueprint update -id <blueprint_ID>\u00a0\n\nIf explicit version is used with release tags for each blueprint template release, the blueprint configuration must be updated in Schematics with the new release tag.\n\nibmcloud schematics blueprint update --id <blueprint_ID> --bp-git-release x.y.z\u00a0\u00a0\n\nFinally, run the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and to complete all operations against all modules.\n\nibmcloud schematics blueprint apply -id <blueprint_ID>\u00a0\n\n\n\n\n\n Blueprint apply failure due to Terraform timeouts or transient failures \n\n What\u2019s happening \n\nWhen you run the blueprint apply command, it fails with message that the install of module fails.\n\n Why it\u2019s happening \n\nAnalysis of the logs indicates that the modules Terraform apply operation that is timed out or a transient failure occurs.\n\n How to fix it \n\nNo user action must be necessary to recover and the apply operation can be retried.\n\nRun the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and complete all operations against all modules.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-apply-fails"},{"document_id":"ibmcld_08295-130293-131214","score":0.0298507463,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"},{"document_id":"ibmcld_12258-139533-140454","score":0.0294117647,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference&interface=cli"},{"document_id":"ibmcld_04516-139667-140633","score":0.0289855072,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace. Initial support for files up to 4MB in size.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-schematics-cli-reference"},{"document_id":"ibmcld_08331-131395-132711","score":0.0285714286,"text":"\ntemplate_data[0].variablestore[v].use_default Optional Set the use_default parameter to true to override the default .tfvars parameter. By default, this parameter is set to false. \n github_source_repo_url Optional Enter the link to your GitHub repository. The link can point to the master branch, a different branch, or a subdirectory. \n\n\n\n\n\n\n\n Example for variable store \n\n\"variablestore\": [\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-schematics-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10116-16035-17814","score":0.0327868852,"text":"\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-8826-10757","score":0.0322580645,"text":"\nReview each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-3176-5101","score":0.0317460317,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https:\/\/cloud.ibm.com\/), from the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_11408-13151-14243","score":0.03125,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_05666-4707-6582","score":0.0307692308,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for IBM Cloud Kubernetes Service clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-10237-12114","score":0.0303030303,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for Red Hat OpenShift on IBM Cloud clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_11408-11687-13539","score":0.0298507463,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_07578-909255-911116","score":0.0294117647,"text":"\nIf you are using the IBM Cloud CLI or API you must also create an instance group manager. For more information, see [Setting up auto scale with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupsetting-up-auto-scale-with-the-cli).\n* How much am I charged for using auto scale?\n\nAuto scale for VPC is free, but you are charged for the resources that you consume. For example, you are charged for virtual server instances that are created in the instance group.\n* How does auto scaling work?\n\nYou set scaling policies that define your desired average utilization for metrics like CPU, memory, and network usage. The policies that you define determine when virtual server instances are added or removed from your instance group.\n\nAuto scale uses the following computation to determine how many instances are running at any given time:\n\n\u03a3(Current average utilization of each instance)\/target utilization = membership count\n\nFor more information about how it works, see [Auto Scale for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupauto-scale-vpc).\n* What permissions do I need for using auto scale?\n\nYou can check the required permissions for actions on instance templates, instance groups, instance group managers, memberships, and policies in the [Required permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls). For more information about using IBM Cloud Identity and Access Management (IAM) to assign users access, see [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources).\n* Can I set multiple scaling policies?\n\nYou can set scaling policies for these metrics: CPU utilization (%), RAM utilization (%), Network in (Mbps), Network out (Mbps).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-909132-910993","score":0.0289855072,"text":"\nIf you are using the IBM Cloud CLI or API you must also create an instance group manager. For more information, see [Setting up auto scale with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupsetting-up-auto-scale-with-the-cli).\n* How much am I charged for using auto scale?\n\nAuto scale for VPC is free, but you are charged for the resources that you consume. For example, you are charged for virtual server instances that are created in the instance group.\n* How does auto scaling work?\n\nYou set scaling policies that define your desired average utilization for metrics like CPU, memory, and network usage. The policies that you define determine when virtual server instances are added or removed from your instance group.\n\nAuto scale uses the following computation to determine how many instances are running at any given time:\n\n\u03a3(Current average utilization of each instance)\/target utilization = membership count\n\nFor more information about how it works, see [Auto Scale for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupauto-scale-vpc).\n* What permissions do I need for using auto scale?\n\nYou can check the required permissions for actions on instance templates, instance groups, instance group managers, memberships, and policies in the [Required permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls). For more information about using IBM Cloud Identity and Access Management (IAM) to assign users access, see [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources).\n* Can I set multiple scaling policies?\n\nYou can set scaling policies for these metrics: CPU utilization (%), RAM utilization (%), Network in (Mbps), Network out (Mbps).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15276-7-1903","score":0.0285714286,"text":"\nFAQs for auto scale \n\n\n\n What elements do I need to create to set up auto scaling? \n\nIf you are using IBM Cloud console, you need to create an instance template, an instance group, and if you choose the dynamic scaling method, you must create scaling policies. For more information, see [Setting up auto scale with the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupsetting-up-autoscale-overview). If you are using the IBM Cloud CLI or API you must also create an instance group manager. For more information, see [Setting up auto scale with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupsetting-up-auto-scale-with-the-cli).\n\n\n\n\n\n How much am I charged for using auto scale? \n\nAuto scale for VPC is free, but you are charged for the resources that you consume. For example, you are charged for virtual server instances that are created in the instance group.\n\n\n\n\n\n How does auto scaling work? \n\nYou set scaling policies that define your desired average utilization for metrics like CPU, memory, and network usage. The policies that you define determine when virtual server instances are added or removed from your instance group.\n\nAuto scale uses the following computation to determine how many instances are running at any given time:\n\n\u03a3(Current average utilization of each instance)\/target utilization = membership count\n\nFor more information about how it works, see [Auto Scale for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupauto-scale-vpc).\n\n\n\n\n\n What permissions do I need for using auto scale? \n\nYou can check the required permissions for actions on instance templates, instance groups, instance group managers, memberships, and policies in the [Required permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-faqs-auto-scale"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03994-15948-17676","score":0.0325224749,"text":"\nIf you do not want to use the default File Storage that is pre-selected for you when you provision a Kubernetes cluster in IBM Cloud, you can provision storage of your choice. See this topic on [Persistent storage considerations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-storage) to learn more.\n* If you decide to include IBM Cloud multi-zone support in your Kubernetes cluster on IBM Cloud, you must provision your own storage. See [Using Multizone (MZR) clusters with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-mzr) for more details.\n* You can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance will be limited by throughput, storage and functionality. IBM Cloud will delete your cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster. If you choose a paid Kubernetes cluster instead of the limited free cluster, you will incur charges for the Kubernetes service to your IBM Cloud account.\n* Kubernetes clusters that are configured with private VLANs are not supported.\n\n\n\n\n\n\n\n License and pricing \n\nIBM Blockchain Platform for IBM Cloud introduces a new hourly pricing model based on virtual processor core (VPC) usage. The simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_04031-6179-7910","score":0.0163934426,"text":"\n[Elements of pricing](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/elements-of-pricing.svg)\n\nFigure 1. Elements of pricing\n\n\n\n* IBM Blockchain Platform: Based on a flat rate of $0.29 USD\/VPC-hour. This fee represents the charge for your blockchain component VPC allocation in your Kubernetes cluster.\n* IBM Cloud Kubernetes Service: While you can link your IBM Blockchain Platform service instance to either an IBM Cloud Kubernetes service cluster or an OpenShift cluster, this pricing model is based on the usage of an IBM Cloud Kubernetes service cluster. The IBM Cloud Kubernetes service uses a tiered pricing model that is visible in IBM Cloud when you provision your paid cluster. This includes the charges for your compute, that is, CPU and memory. IBM Cloud Kubernetes Services are priced on a tiered model that is based on the number of hours of usage per month. Therefore, when you examine pricing plans, consider that 24x7 usage is equivalent to 720 hours per month. Refer to the table on the [Kubernetes Service Catalog page](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about) for more details on cluster pricing. Customers who are interested in pricing OpenShift clusters can review [Red Hat OpenShift on IBM Cloud Pricing](https:\/\/www.ibm.com\/cloud\/openshift\/pricing).\n* Storage: Choose the storage plan that works for your needs. See [Understanding Kubernetes storage basics](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptskube_concepts) to learn more about your storage class options and how much they [cost](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing). The IBM Blockchain Platform nodes use the default storage class for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-10086-11557","score":0.0161290323,"text":"\nCPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr ) \n Hourly cost: IBM Cloud Kubernetes cluster $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) \n Hourly cost: Storage $0.06 USD <br>340GB <br>[Bronze](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>2 IOPS\/GB $0.09 USD <br>420GB <br>[Silver](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>4 IOPS\/GB \n Total hourly cost $0.71 USD $1.19 USD \n\n\n\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_07578-882118-884014","score":0.0158730159,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14546-2844-4906","score":0.0158730159,"text":"\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.\n\n\n\n\n\n\n\n VMware Shared on-demand billing plan \n\nVMware Shared on-demand virtual data center resources are allocated as needed. Pricing is hourly based on the resource usage in the virtual data center. The following metrics are part of this plan.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 2. VMware Shared Solutions On-demand billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_BASE_COST Monthly Virtual data center price, which includes the edge gateway with five IP addresses. \n TOTAL_VCPU_HOURS Hourly The peak vCPU usage over the period of an hour. \n TOTAL_RAM_GB_HOURS Hourly The peak memory usage over the period of an hour. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of an hour. This value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_16727-881995-883891","score":0.015625,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13995-0-1665","score":0.015625,"text":"\n\n\n\n\n\n\n  Dedicated host pricing \n\nPricing for dedicated hosts is offered in an hourly and monthly model.\n\nDedicated host pricing is inclusive of all vCPU, RAM, local storage, and uplink port speed components as instances are provisioned onto dedicated hosts. For more information about pricing, see the [Virtual servers pricing and configuration tool](https:\/\/www.ibm.com\/cloud\/virtual-servers\/calculator\/).\n\nWith dedicated hosts, extra local storage disks are available on first, second, third, fourth, and fifth disks. Extra capacity up to 400 GB on each secondary disk is also available.\n\nHourly instances can be provisioned on hourly and monthly hosts. Monthly instances can be provisioned on only monthly hosts.\n\n\n\nTable 1. Dedicated host configurations\n\n Host configuration  vCPU  RAM (GB)  Local storage (TB SSD) \n\n 56x242x1.2          56    242       1.2                    \n 56x484x1.2          56    484       1.2                    \n\n\n\nPricing varies by region.\n\nSAN (network attached), premium OSs, and add-ons are charged hourly or monthly, by the instance, depending on the instance provisioned on the dedicated host. Pricing for these components is consistent with the existing offering on public instances and dedicated instances.\n\nFor example, a dedicated instance that is provisioned on a dedicated host with the following configuration isn't charged by the instance. vCPU, RAM, local storage, and uplink port speeds are included in dedicated host charges.\n\n\n\n*  8 vCPU\n*  16 GB RAM\n*  100 GB Local SSD first disk\n*  400 GB Local SSD second disk\n*  400 GB Local SSD third disk\n*  1 Gbps public and private network uplinks (dedicated host)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-dedicated-virtual-server-pricing"},{"document_id":"ibmcld_07578-966486-968340","score":0.0153846154,"text":"\nSnapshots have their own lifecycle, independent of the Block Storage for VPC volume. You can separately manage the source volume. However, when you take a snapshot, you must wait for the snapshot creation process to complete before you detach or delete the volume.\n* How am I charged for usage?\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary. Deleting snapshots reduces cost, so the fewer snapshots you retain the lower the cost becomes.\n\nPricing for snapshots is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\nWhen you use the [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) feature, your existing regional plan is adjusted. Billing for fast restore is based on instance hours. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14007-0-1917","score":0.0153846154,"text":"\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"},{"document_id":"ibmcld_16727-966362-968216","score":0.0151515152,"text":"\nSnapshots have their own lifecycle, independent of the Block Storage for VPC volume. You can separately manage the source volume. However, when you take a snapshot, you must wait for the snapshot creation process to complete before you detach or delete the volume.\n* How am I charged for usage?\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary. Deleting snapshots reduces cost, so the fewer snapshots you retain the lower the cost becomes.\n\nPricing for snapshots is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\nWhen you use the [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) feature, your existing regional plan is adjusted. Billing for fast restore is based on instance hours. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.2900757977}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09120-94597-96242","score":0.0327868852,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-95785-97389","score":0.0322580645,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_04488-93746-95375","score":0.0317460317,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-22025-23534","score":0.03125,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-29325-30645","score":0.0307692308,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-30080-31503","score":0.0303030303,"text":"\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09055-69659-70937","score":0.0298507463,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08987-28071-29358","score":0.0294117647,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_04488-28730-30034","score":0.0289855072,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09087-21484-22833","score":0.0285714286,"text":"\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15994-2940-5003","score":0.031778058,"text":"\nYou can't delete a block storage volume by name or ID.\n\n Why it\u2019s happening \n\nThe volume name and ID are not accepted.\n\n How to fix it \n\nVerify that the volume name or identifier is correct and that the volume is not attached to a virtual server instance. Also, verify that the volume is not in a pending state.\n\n\n\n\n\n Expandable volume remains in an updating state when an attempt is made to delete an instance \n\n What\u2019s happening \n\nWhen you attempt to delete a virtual server instance with an attached volume that is being resized, the volume remains in an updating state and can't be deleted.\n\n Why it\u2019s happening \n\nA volume is being resized and you tried to delete the instance that the volume is attached to, either manually or by auto-delete. The status of the volume remains updating and the volume isn't deleted with the instance.\n\n How to fix it \n\nA volume must be in an available state for operations such as attach, detach, delete. When you are expanding a volume, wait for the volume resize to complete before you perform any operations. If you try to delete a volume that's resizing, the volume remains in an updating state and is not deleted with the instance. To delete the volume, reattach the volume to a different instance, and make sure that the resizing is complete (volume status becomes available), and then delete the volume.\n\n\n\n\n\n Removing IAM authorization from the storage service to the KMS causes root key deregistration failure \n\n What\u2019s happening \n\nThe root keys in the Key management service (KMS) instance remain registered to the deleted block storage volume or image resources.\n\n Why it\u2019s happening \n\nIf you remove IAM authorization from Cloud Block Storage to the KMS before you delete all BYOK volumes or images, the root key fails to unregister from the resource.\n\n How to fix it \n\nAs best practice, delete all storage or image resources before you remove IAM authorization. If you already removed authorization, you must restore the IAM authorization between Cloud Block Storage (source service) and your KMS (target service).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-block-storage"},{"document_id":"ibmcld_07578-1212442-1214450","score":0.031024531,"text":"\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_08695-7-1852","score":0.0308349146,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_09088-10880-12721","score":0.0308349146,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_16727-1215075-1217083","score":0.0305503731,"text":"\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1211120-1213024","score":0.0303657695,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":0.0299107143,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08435-4-1684","score":0.0163934426,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_15994-4553-5739","score":0.0153846154,"text":"\nWhy it\u2019s happening \n\nIf you remove IAM authorization from Cloud Block Storage to the KMS before you delete all BYOK volumes or images, the root key fails to unregister from the resource.\n\n How to fix it \n\nAs best practice, delete all storage or image resources before you remove IAM authorization. If you already removed authorization, you must restore the IAM authorization between Cloud Block Storage (source service) and your KMS (target service). For more information, see [Using authorizations to grant access between services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) to establish IAM service-to-service authorizations in the UI, CLI, or API.\n\n\n\n\n\n Resolving volume resize issues while a snapshot is taken \n\n What\u2019s happening \n\nIf you take a snapshot of a volume and resize the source volume while the snapshot is being created, you get an error.\n\n Why it\u2019s happening \n\nWhile the snapshot is in a pending state, a volume resize error displays with the message \"The resize validation failed.\" The correct message says, \"volume is locked.\"\n\n How to fix it \n\nWait until the snapshot is created and it is in an available state before you resize the source volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-block-storage"},{"document_id":"ibmcld_08435-1255-3053","score":0.0151515152,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0980392858}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-3634-5079","score":0.0327868852,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-6973-8664","score":0.0320020481,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":0.0320020481,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":0.015625,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_05007-3201-4787","score":0.015625,"text":"\nThis could be a specific date in the future, or a period of time after new objects are written.\n\n\n\n\n\n NoncurrentVersionExpiration \n\nThe number of days after which non-current versions of objects are automatically deleted.\n\n\n\n\n\n Prefix \n\nAn optional string that will be matched to the prefix of the object name in the bucket. A rule with a prefix will only apply to the objects that match. You can use multiple rules for different expiration actions for different prefixes within the same bucket. For example, within the same lifecycle configuration, one rule could delete all objects that begin with logs\/ after 30 days, and a second rule could delete objects that begin with video\/ after 365 days.\n\n\n\n\n\n Status \n\nA rule can either be enabled or disabled. A rule is active only when enabled.\n\n\n\n\n\n\n\n Sample lifecycle configurations \n\nThis configuration expires any new objects after 30 days.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>delete-after-30-days<\/ID>\n<Filter \/>\n<Status>Enabled<\/Status>\n<Expiration>\n<Days>30<\/Days>\n<\/Expiration>\n<\/Rule>\n<\/LifecycleConfiguration>\n\nThis configuration deletes any objects with the prefix foo\/ on June 1, 2020.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>delete-on-a-date<\/ID>\n<Filter>\n<Prefix>foo\/<\/Prefix>\n<\/Filter>\n<Status>Enabled<\/Status>\n<Expiration>\n<Date>2020-06-01T00:00:00.000Z<\/Date>\n<\/Expiration>\n<\/Rule>\n<\/LifecycleConfiguration>\n\nThis configuration expires any non-current versions of objects after 100 days.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>DeleteAfterBecomingNonCurrent<\/ID>\n<Filter\/>\n<Status>Enabled<\/Status>\n<NoncurrentVersionExpiration>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry"},{"document_id":"ibmcld_14887-7-2470","score":0.0153846154,"text":"\nUnderstanding cloud maintenance operations \n\n\n\n Types of maintenance operations that affect your virtual server instances \n\n\n\n Host and dedicated host maintenance \n\nIBM Cloud\u00ae performs periodic maintenance on the server hosts and dedicated hosts that run virtual servers. This maintenance upgrades the software on the underlying hypervisor, update the firmware on the systems, or other security and performance updates. In general, users don't experience any issues during these upgrades. Modifications that require host maintenance are applied with no or little impact to running services in most cases. Scenarios can occur where the user is involved during maintenance operations, which are discussed in the [Possible impacts to virtual server instances during maintenance operations](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-cloud-maintenancemaintenance-impacts) section.\n\nMost updates are done transparently to the host and the virtual servers that run on those hosts do not see any disruption. Nondisruptive changes can occur multiple times per week or even daily if necessary, all without impacting the user experience.\n\n\n\n\n\n Data center maintenance \n\nIBM Cloud\u00ae also performs periodic data center maintenance upgrades. Users don't generally experience any issues during data center maintenance. Examples of this maintenance can be updates to the network, power infrastructure, or server hardware in a data center. Most maintenance is performed without impact to the user\u2019s workloads. Some infrequent scenarios can occur where the user might need to be involved during those operations, which are discussed in the following section.\n\n\n\n\n\n\n\n Possible impacts to virtual server instances during maintenance operations \n\nSome changes can require a secure live migration of a virtual server to update the hypervisor or host. These changes can be a firmware update, an event where the hypervisor kernel cannot be live patched, or load balancing. The regular live migration process is nondisruptive and use of dedicated hosts and virtual servers is not interrupted.\n\nWhen nondisruptive live migration occurs, the virtual server experiences a brief pause of around 10 seconds, and in some cases up to 30 seconds. You are not notified in advance of nondisruptive migration. The virtual server instance is not restarted as part of this process.\n\nIn cases where a disruptive migration is required, you are notified 30 days in advance of the scheduled migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-cloud-maintenance"},{"document_id":"ibmcld_08211-1158-3123","score":0.0153846154,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_09061-6176-7874","score":0.0151515152,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_04939-57496-59284","score":0.0151515152,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_10859-0-1629","score":0.0149253731,"text":"\n\n\n\n\n\n\n  Action terminates after one minute \n\n  What\u2019s happening \n\nYou are invoking an action that returns after one min with an http code 202 and the result is only showing the activation ID.\n\n  Why it\u2019s happening \n\nWhen invoking an action, there are two modes possible: blocking or non-blocking. The default for regular action invocations is non-blocking and for web actions, it is blocking. Blocking invocations use a request-response style and wait for the activation result to be available. The wait period is the lesser of 60 seconds or the action's timeout limit. At the end of the wait period (for example, after 60 sec), all invocations switch to non-blocking and instead of the result, these actions return the activation ID.\n\nThe following example shows possible output.\n\n{\n\"activationId\": \"27eca80056d54f93aca80056d5cf93b9\"\n}\n\nIf an invocation of a web action reaches the end of wait period, the response shows both the activation ID and the transaction ID as well as an indication that the request is returned, but the action continues to run.\n\nThe following example shows possible output.\n\n{\n\"activationId\": \"d13cfd3ce4b14f7cbcfd3ce4b11f7cce\",\n\"code\": \"42c15dc7f450df1e9a01104de158d489\",\n\"error\": \"Response not yet ready.\"\n}\n\n  How to fix it \n\nWith the activation ID, you can poll for the completion of the action and the result. For more information, see [CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_activation).\n\nFor more information about blocking actions, see [Testing blocking actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-testtest-block).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-ts_action_terminated"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.804809975,"ndcg_cut_10":0.804809975}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08211-2628-3483","score":0.0327868852,"text":"\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08211-1158-3123","score":0.0322580645,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_12570-2467-4288","score":0.0305788982,"text":"\nibmcloud catalog entry-visibility ID [--global]\n\n\n\n Command options \n\n--global\n: Operate in global scope\n\n\n\n\n\n Examples \n\nGet visibility of resource j402-dnf1i in global scope:\n\nibmcloud catalog entry-visibility 'j402-dnf1i' --global\n\n\n\n\n\n\n\n ibmcloud catalog entry-visibility-set \n\nUpdate the visibility of an existing catalog entry(catalog admin of an account only):\n\nibmcloud catalog entry-visibility-set ID [--includes-add LIST] [--includes-remove LIST] [--excludes-add LIST] [--excludes-remove LIST] [--owner ID or Email] [--restrict] [--unrestrict] [-c PARAMETERS_AS_JSON] [--global]\n\n\n\n Command options \n\n--includes-add\n: Adding an account (or list of comma-separated accounts) to the includes list, granting visibility to the entry. Email or Account GUIDs are acceptable.\n\n--includes-remove\n: Removing an account (or list of comma-separated accounts) from the includes list, revoking visibility to the entry. Email or Account GUIDs are acceptable.\n\n--excludes-add\n: Adding an account (or list of comma-separated accounts) to the excludes list. Email or Account GUIDs are acceptable.\n\n--excludes-remove\n: Removing an account (or list of comma-separated accounts) from the excludes list, revoking visibility to the entry. If the account was set by global admins, the account admins can't remove the account. Email or Account GUIDs are acceptable.\n\n--owner\n: Changing the owner of an object. Email or Account GUIDs are acceptable.\n\n--restrict\n: Changing the restriction of the visibility object to 'Private'.\n\n--unrestrict\n: Changing the restriction of the visibility object to 'Public'.\n\n-c\n: Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration parameters, see documentation for the particular catalog entry.\n\n--global","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_catalog"},{"document_id":"ibmcld_14388-5667-7422","score":0.0303657695,"text":"\nHowever, by default, vSphere HA reserves 50% of CPU and RAM for failover on vCenter Server instances that were initially deployed with two ESXi servers. For this example, the following configuration is available:\n\n50% of 2 * 16 cores * 2.1 GHz = 33.6 GHz available\n\nOther workloads are also present on the ESXi servers, for example, VMware vCenter Server, VMware NSX\u00ae Controller\u2122, and VMware NSX Edge\u2122. Because these resources are used, the third requirement cannot be satisfied because 33.6 GHz of CPU and 32 GB RAM are needed for the two BIG-IP VMs.\n\nIn this case, the F5 BIG-IP installation might fail, unless at least one ESXi server is added to the environment and vSphere HA failover reservations are updated to ensure that enough resources are available for two BIG-IP VE VMs. If more resources are needed to run the F5 BIG-IP service, you can add more ESXi servers before you install F5 BIG-IP.\n\n\n\n\n\n Considerations when you delete F5 BIG-IP \n\nReview the following considerations before you delete the service:\n\n\n\n* Before you delete the F5 BIG-IP service, ensure that the existing BIG-IP VE configuration is removed correctly. Specifically, network traffic must be routed around BIG-IP VE instead of through BIG-IP VE. Otherwise, the existing data traffic from your environment might be impacted.\n* If you installed the F5 BIG-IP service before VMware Solutions v4.0 and then deleted that service, you must manually remove the DNS entries. For more information, see [Manually removing the DNS entries](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_deletingservicesvc_deletingservices-DNS-entries).\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Ordering F5 BIG-IP](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_ordering)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_considerations"},{"document_id":"ibmcld_13104-7-2031","score":0.0301177536,"text":"\nRetrieving information about a virtual server \n\nAfter you create a virtual server instance by using the Hyper Protect Virtual Servers service, you can view detailed information about your new instance.\n\nThe Ubuntu servers are preconfigured in such a way that the passwords expire after 90 days. After the user password expires, you have 30 days to change your password. If you don't change your password within the 30 days, your account becomes inactive and it is no longer possible to log in with SSH even if you are using SSH-keys. For more information, see [Protecting a virtual server](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-protect_vs).\n\n\n\n Retrieving information in the UI \n\n\n\n1. To select the Hyper Protect Virtual Servers resource, either:\n\n\n\n* Go to the [Resource list](https:\/\/cloud.ibm.com\/resources), then look for your virtual server instance under the Services entry in the Name column.\n* From the IBM Cloud dashboard or the IBM Cloud Navigation Menu, select View all within the Resource summary area to open the Resource list. The column Location displays the data center where your instance was created. Use the filter to search for virtual server instances in certain regions or data centers. See also Figure 2 from [Provisioning a virtual server](https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-provision).\n\n\n\n2. Click your virtual server instance to open the Hyper Protect Virtual Servers dashboard.\n\n\n\nIn this dashboard:\n\n\n\n* The Locate map shows you in which region your instance was created.\n* You can find the public IP address, which you use to connect to the virtual server.\n\n\n\nYou must use the internal IP address when you connect to a virtual server from another virtual server, which is in the same virtual LAN (VLAN). VLANs span across all data centers within their region.\n\nYou must also work with the internal IP addresses, when you connect to other IBM Cloud Cloud services that are located within the same data center.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-retrieve-info-vs"},{"document_id":"ibmcld_14401-9252-11053","score":0.015625,"text":"\nSince other workloads exist on the ESXi servers, for example, vCenter Server, VMware NSX\u00ae Controller, or VMware NSX Edge, by using these resources, the third requirement is not met. The reason is because 33.6 GHz of CPU and 24 GB RAM for the two FortiGate VMs are needed.\n\nIn this case, the FortiGate Virtual Appliance installation might fail, unless at least one ESXi server is added to the environment. Also, the vSphere HA failover reservations must be updated to ensure that enough resources are available for two FortiGate VMs.\n\nIf more resources are needed to run the FortiGate Virtual Appliance service, you can add more ESXi servers before you install the service.\n\n\n\n\n\n Considerations when you delete FortiGate Virtual Appliance \n\nReview the following considerations before you delete the service:\n\n\n\n* Before you delete the FortiGate Virtual Appliance service, ensure that the configuration of the existing FortiGate Virtual Appliances is deleted correctly. Specifically, network traffic must be routed around FortiGate Virtual Appliances instead of through FortiGate Virtual Appliances. Otherwise, the existing data traffic within your environment might be impacted.\n* If you installed the FortiGate Virtual Appliance service before VMware Solutions v4.0, and you then delete that service, you must manually remove the DNS entries. For more information, see [Manually removing the DNS entries](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_deletingservicesvc_deletingservices-DNS-entries).\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Ordering FortiGate Virtual Appliance](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortinetvm_ordering)\n* [Managing FortiGate Virtual Appliance](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managingfortinetvm)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortinetvm_considerations"},{"document_id":"ibmcld_00324-15719-17878","score":0.0153846154,"text":"\nThat content is then cached for the TTL duration specified for the content. If a user request is received after the TTL has expired, the Edge server reaches out to the origin host to fetch the content. If the origin server cannot be reached for some reason (for instance, the origin host is down, or there is a network issue), the Edge server serves the expired (stale) content to the request. This feature is supported by Akamai and cannot be turned off.\n\n\n\n\n\n Support for multiple origins with distinct paths \n\nIn certain cases, you might want to deliver certain content from a different origin server. For example, you might want certain photos or videos that are served from different origin servers. IBM Cloud CDN provides the option to set up multiple origin servers with multiple paths. This allows flexibility with regards to how and where the data is stored.\n\nThe path that is specified for the origin server must be unique regarding the CDN. The origin server itself does not need to be unique.\n\n\n\n\n\n Time to Live (TTL) \n\nTime to Live indicates the amount of time (in seconds) the Edge server retains the cached content for that particular file or directory path. When a CDN is first created, a global TTL is created for path \/* with a default time of 3600 seconds. The minimum value for TTL is 0 seconds, and the maximum value is 2147483647 seconds. For each entry, the TTL path must be unique for the CDN. If multiple paths match a given content, the most recently configured path match applies to that content. For example, consider two TTLs, \/example\/file created first with a time to live value of 3000 seconds and \/example\/* is created later, with a value of 4000 seconds. Although \/example\/file is more specific, \/example\/ was created most recently, so the TTL for \/example\/file is 4000 seconds. After creation, TTL entries can be edited for path, time, or both. TTL entries can also be deleted.\n\n\n\n\n\n Token authentication \n\nToken authentication is the process of generating tokens, associating them with an authenticated user session, and validating the request by using these tokens to prevent unauthorized sharing of links to your content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_14622-7-2169","score":0.0153846154,"text":"\nDeleting services from vCenter Server instances \n\nYou can delete the services that were provisioned for your VMware vCenter Server\u00ae instances when you no longer need these services.\n\n\n\n Before you delete services from vCenter Server instances \n\n\n\n* Deleting services from vCenter Server instances with VMware vSphere\u00ae 6.5 is not supported.\n* You are billed until the end of the IBM Cloud\u00ae infrastructure billing cycle for the deleted services.\n\n\n\n\n\n\n\n Procedure to delete services from vCenter Server instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > vCenter Server from the left navigation pane.\n2. In the vCenter Server table, click the instance for which you want to delete services.\n3. Click the Services tab.\n4. On the Services page, locate the service instance that you want to delete, click the vertical overflow menu next to the Status column, and then click Delete service.\n5. In the Remove service window, review the considerations or warnings if there are any and select I Understand. Click Delete.\n\n\n\n\n\n\n\n Results after you delete services from vCenter Server instances \n\nAfter your request to delete a service is accepted, the service status is changed to Removing.\n\nWhen the service deletion is completed successfully, you are notified by email, and the service is deleted from the Services page of the instance.\n\nYou are billed until the end of the IBM Cloud infrastructure billing cycle for the deleted services.\n\n\n\n\n\n Manually removing the DNS entries for specific services \n\nFor specific services, if you installed the service in a VMware Solutions release earlier than V4.0 and you delete that service, you must manually remove the DNS entries.\n\nAfter you delete the service, unused DNS entries remain in Active Directory\u2122. These entries do not cause any problems. However, in the future, they might create conflicts with reverse lookups. It is recommended that you remove the entries as soon as possible.\n\nThe following table shows the services that are affected. The table also shows the pattern for hostnames for various service offerings. The actual hostname might differ from the pattern in various ways.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_deletingservices"},{"document_id":"ibmcld_00589-15623-17497","score":0.0151515152,"text":"\nEnsure that the IBM Cloudant instance has IAM authentication that is enabled. If the instance is deployed in a Cloud Foundry org and space, migrate it to a Resource Group by using the [Resource Groups FAQ](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-ibm-cloud-resource-groups).\n2. Update your application to use IAM authentication instead of IBM Cloudant legacy authentication.\n3. Generate [new service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials) as needed.\n4. Open a new IBM Cloud support case that requests the removal of IBM Cloudant legacy credentials for your instance. Include the username of the instance as shown in the service credentials. For more information, see [Locating your service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-your-service-credentials).\n5. After support replies that the legacy credentials were removed, any service credentials that were created before removal contain legacy username and password details that no longer work. It is recommended to remove any of these service credential entries.\n\n\n\n\n\n\n\n Making requests to instances by using IAM credentials \n\nNow, the following section describes how to use IBM Cloudant with service instances through IAM authentication. It uses the details from the [Service credential JSON examples for each option](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantservice-credential-json-examples-for-each-option-ai).\n\nIBM Cloud IAM requires that an IAM API key is exchanged for a time-limited access token before you make a request to a resource or service. The access token is then included in the Authorization HTTP header to the service. When the access token expires, the consuming application must handle getting a new one from the IAM token service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_08217-1687-3909","score":0.0151515152,"text":"\nWhen you click the 'Inactive' server in Name field, an error message is displayed to indicate that provisioning has failed.\n\n What\u2019s happening \n\nYou try to create more than five virtual servers within a short period in one data center without any existing virtual server instances.\n\n Why it\u2019s happening \n\nThe number of virtual servers per data center is limited to five. Creating more than five virtual servers almost all at the same time in one data center leads to the status 'Inactive' (provisioning failed) for the sixth and all subsequent instances.\n\n How to fix it \n\nYou can either provision more than five virtual servers in different data centers. Or you can provision more than five instances by using different IBM Cloud accounts.\n\n\n\n\n\n Generating a new virtual server fails because of exhausted resources \n\nYou can only create a limited number of virtual server instances in each data center.\n\n What\u2019s happening \n\nWhen you provision a new virtual server, you get an error message because the resources (for example, memory) are exhausted.\n\n Why it\u2019s happening \n\nThe resources for the selected data center are exhausted.\n\n How to fix it \n\nRetry the action and select a different data center.\n\n\n\n\n\n Can't connect to free virtual server anymore \n\nI can't connect to a server (for example, via SSH), which is in the free plan although it's visible in the IBM Cloud resource list.\n\n What\u2019s happening \n\nYou can't connect to a server in the free plan anymore. The server is still visible in the resource list, but the dashboard shows an error message. The message indicates that the server has expired. When a server expires, the server and all data that is stored on the server are deleted.\n\n Why it\u2019s happening \n\nAll virtual servers in free plans are deleted after 30 days.\n\n How to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09061-4-1966","score":0.0163934426,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08671-117491-118751","score":0.0163934426,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-routine-maintenance)\n* [How do I get support for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-hpcs-support)\n\n\n\n\n\n\n\n Troubleshooting key management service \n\n[Why am I not authorized to make key management service API request?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-authenticate-apitroubleshoot-unable-to-authenticate-api)\n\n[Why am I receiving a CKR_IBM_WK_NOT_INITIALIZED error when I use CLI or API?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-error-CLI-APItroubleshoot-error-CLI-API)\n\n[Why can't I create a standard key after I load another master key?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-standard-keystroubleshoot-unable-to-create-standard-keys)\n\n[Why can't I create or import keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-keystroubleshoot-unable-to-create-keys)\n\n[Why can't I delete an initialized service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-instancetroubleshoot-delete-instance)\n\n[Why can't I delete keys?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_09120-94597-96242","score":0.0161290323,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08671-120101-121577","score":0.0161290323,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-key-smart-cardstroubleshoot-master-key-rotation-key-smart-cards)\n\n[Why do I fail to load the new master key during the master key rotation process?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotationtroubleshoot-master-key-rotation)\n\n\n\n\n\n Troubleshooting smart cards and the Management Utilities \n\n[Why am I not authorized when I start the Trusted Key Entry application?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unauthorized-token-tke-applicationtroubleshoot-unauthorized-token-tke-application)\n\n[Why am I receiving a blocked PIN on EP11 smart card error?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-block-smart-cardtroubleshoot-block-smart-card)\n\n[Why am I receiving a no smart card readers found error when I use the Management Utilities?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-no-smart-cardtroubleshoot-no-smart-card)\n\n\n\n\n\n Troubleshooting Trusted Key Entry \n\n[Why am I not authorized when running TKE CLI plug-in commands?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unauthorized-tokentroubleshoot-unauthorized-token)\n\n[Why can't I change signature thresholds?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-change-signature-thresholdstroubleshoot-unable-to-change-signature-thresholds)\n\n[Why can't I list crypto units?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08988-95785-97389","score":0.0158730159,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_08671-118434-119667","score":0.0158730159,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-keystroubleshoot-unable-to-create-keys)\n\n[Why can't I delete an initialized service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-instancetroubleshoot-delete-instance)\n\n[Why can't I delete keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keystroubleshoot-unable-to-delete-keys)\n\n[Why can't I perform any actions by using the IBM Cloud console?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-ui-session-timeouttroubleshoot-ui-session-timeout)\n\n[Why can't I rotate root keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-rotate-root-keystroubleshoot-unable-to-rotate-root-keys)\n\n[Why can't I view or list keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-keys-apitroubleshoot-unable-to-list-keys-api)\n\n[Why can't I view or list specific keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-specific-keystroubleshoot-unable-to-list-specific-keys)\n\n\n\n\n\n Troubleshooting master key rotation \n\n[Why can't I rotate master keys by using key part files?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_04488-93746-95375","score":0.015625,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_08671-119258-120594","score":0.015625,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-keys-apitroubleshoot-unable-to-list-keys-api)\n\n[Why can't I view or list specific keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-specific-keystroubleshoot-unable-to-list-specific-keys)\n\n\n\n\n\n Troubleshooting master key rotation \n\n[Why can't I rotate master keys by using key part files?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-key-part-filestroubleshoot-master-key-rotation-key-part-files)\n\n[Why can't I rotate master keys by using recovery crypto units?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-recovery-crypto-unitstroubleshoot-master-key-rotation-recovery-crypto-units)\n\n[Why can't I rotate master keys by using smart cards?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-key-smart-cardstroubleshoot-master-key-rotation-key-smart-cards)\n\n[Why do I fail to load the new master key during the master key rotation process?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotationtroubleshoot-master-key-rotation)\n\n\n\n\n\n Troubleshooting smart cards and the Management Utilities \n\n[Why am I not authorized when I start the Trusted Key Entry application?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_01019-7-2103","score":0.0153846154,"text":"\nDeleting a database \n\nWhen a service instance is deleted, the database that it provides is also removed. This will delete any online data and logs as well as database backups. The data will not be recoverable after this action.\n\n\n\n How is the data deleted \n\nAll data is encrypted at rest to ensure data is protected at all times using encryption keys stored in a key management service called Key Protect. When access to those keys is removed, the data is crypto-shredded and cannot be recovered. When the service instance is deleted, the block storage that is used for the database is wiped to ensure that all of the data is erased. Any data objects in cloud object storage are also deleted and not recoverable.\n\n\n\n\n\n When is the data deleted \n\n\n\n\n\n Using your own encryption keys to delete data \n\nYou can use your own encryption keys to delete data. This is called crypto-shredding. After the key is deleted, your data is unrecoverable and unreadable by anyone.\n\nKey Protect allows you to initiate a force delete of a key that is in use by various IBM Cloud\u00ae services, including your Db2 on Cloud service instances. Deleting a key that is in use on your deployment locks the disks containing your data when the key is requested again. You can have this occur right away by contacting IBM Support or by deleting your service instance. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete.\n\nIf you delete a deployment that is protected with your Key Protect key, the deployment remains registered against the key for the duration of the soft-deletion period (up to 9 days). If you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_07578-74047-75977","score":0.0153846154,"text":"\nYou can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* Why don't I see the Analytics page?\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n* Why am I unable to view the API details, API key, or service credentials?\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1211120-1213024","score":0.0327868852,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":0.0322580645,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08695-7-1852","score":0.0317460317,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_09088-9397-11338","score":0.03125,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_09192-5368-7014","score":0.0307692308,"text":"\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening \n\nThis key is actively protecting one or more cloud resources, such as a IBM Cloud\u00ae Object Storage bucket or a Cloud Databases deployment.\n\n How to fix it \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. Before you delete a key, [review which resources are encrypted by this key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nYou can get the current list of resources associated with your key by first [synchronizing the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-sync-associated-resources), which might take up to 4 hours. Then, proceed to [viewing associations between root keys and encrypted IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\nAfter using Sync, associations between the key and other resources will be current and up to date. If there are no associations after using Sync, the key can be deleted normally.\n\nIf the associations are still there after Sync:\n\n\n\n* You can use the Key Protect API to [force deletion on the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete).\n* You can delete the resources associated with the key, and then delete the key normally.\n\n\n\n\n\n\n\n Getting help and support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_16059-9270-11112","score":0.0303030303,"text":"\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"},{"document_id":"ibmcld_16045-9337-11274","score":0.0298507463,"text":"\nVolume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_09192-4150-5583","score":0.0294117647,"text":"\nIf the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys \n\nWhen you use the Key Protect user interface or REST API, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou're assigned a Manager access policy for the Key Protect instance. You try to delete a key, but the action fails with the following error message.\n\nConflict: Key could not be deleted. Status: 409, Correlation ID: 160cc463-71d1-4b30-a5f2-d3f7e9f2b75e\n\nYou also try to delete the key by using the Key Protect API, but you receive the following error message.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key could not be deleted. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_07578-1209748-1211682","score":0.0289855072,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1212381-1214315","score":0.0285714286,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01034-3831-4923","score":0.0327868852,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_06341-2428-3641","score":0.0322580645,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":0.0317460317,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":0.03125,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":0.0307692308,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":0.0303030303,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_09559-3849-5260","score":0.0298507463,"text":"\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you must [force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-hpcs"},{"document_id":"ibmcld_01041-3464-4855","score":0.0294117647,"text":"\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-management-services"},{"document_id":"ibmcld_09562-3760-5490","score":0.0289855072,"text":"\nWhen you rotate a key, the process initiates a syncing KMS state task, and your deployment is reencrypted with the new key. The task is displayed on the Tasks page on your deployment's Overview and the associated Key Protect and Cloud Databases events are sent to Activity Tracker.\n\nFor more information, see [Rotating manually or automatically](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-rotationcompare-key-rotation-options).\n\n\n\n\n\n Deleting the Deployment \n\nIf you delete a deployment that is protected with a Key Protect key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). To delete the key in the soft-deletion period, [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. To determine when you can delete the key, check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"},{"document_id":"ibmcld_06381-1376-2975","score":0.0285714286,"text":"\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}],"retriever_scores":{"recall_1":0.1666666667,"recall_3":0.5,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8539316502,"ndcg_cut_10":0.7618870796}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06116-15519-16206","score":0.0163934426,"text":"\nFor more information, see the [PX-Backup documentation](https:\/\/backup.docs.portworx.com\/use-px-backup\/backup-restore\/create-backup\/perform-backup\/).\n\nRestore any backup that you created to another cluster: You can restore an entire namespace, your apps, or your data to any cluster that you added to the PX-Backup service. Use this PX-Backup capability if you want to migrate apps and data from one cluster to another. For more information, see the [PX-Backup documentation](https:\/\/backup.docs.portworx.com\/use-px-backup\/backup-restore\/restore-backup\/).\n\n\n\n Upgrading PX-Backup \n\nFollow the Portworx documentation to [upgrade PX-backup](https:\/\/backup.docs.portworx.com\/use-px-backup\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_backup"},{"document_id":"ibmcld_06341-2428-3641","score":0.0163934426,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_10557-15527-16214","score":0.0161290323,"text":"\nFor more information, see the [PX-Backup documentation](https:\/\/backup.docs.portworx.com\/use-px-backup\/backup-restore\/create-backup\/perform-backup\/).\n\nRestore any backup that you created to another cluster: You can restore an entire namespace, your apps, or your data to any cluster that you added to the PX-Backup service. Use this PX-Backup capability if you want to migrate apps and data from one cluster to another. For more information, see the [PX-Backup documentation](https:\/\/backup.docs.portworx.com\/use-px-backup\/backup-restore\/restore-backup\/).\n\n\n\n Upgrading PX-Backup \n\nFollow the Portworx documentation to [upgrade PX-backup](https:\/\/backup.docs.portworx.com\/use-px-backup\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_backup"},{"document_id":"ibmcld_06499-2416-3629","score":0.0161290323,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_14953-27407-29603","score":0.0158730159,"text":"\nContact your IBM Sales representative if you are interested in getting access.\n\n\n\nTable 24. Actions that generate events for file storage resources\n\n Resource Action Description \n\n shares is.share.share.create File share was created \n shares is.share.share.read One or more file shares were retrieved \n shares is.share.share.update File share was updated \n shares is.share.share.delete File share was deleted \n shares is.share.share.split Replication relationship is removed between two file shares \n shares is.share.share.failover Replication relationship is reversed between two file shares \n shares is.share.share.schedule.modification The replication schedule was modified. \n share mount targets is.share.mount-target.create Mount target for a file share was created \n share mount targets is.share.mount-target.read One mount target for a file share was retrieved \n share mount targets is.share.mount-target.list List of all mount targets for a file share was retrieved \n share mount targets is.share.mount-target.update Mount target for a file share was modified \n share mount targets is.share.mount-target.delete Mount target for a file share was deleted \n\n\n\n\n\n\n\n Backup service events \n\nThe following table lists the actions that are related to the VPC Backup service resources and the generation of events.\n\n\n\nTable 25. Actions that generate events for VPC Backup service resources\n\n Resource Action Description \n\n backup-policy is.backup-policy.backup-policy.create Backup policy was created \n backup-policy is.backup-policy.backup-policy.update Backup policy was updated \n backup-policy is.backup-policy.backup-policy.delete Backup policy was deleted \n backup-policy is.backup-policy.backup-policy.list One or more backup policies were retrieved \n backup-policy is.backup-policy.backup-policy.read Backup policy was retrieved \n backup-policy is.backup-policy.backup-plan.create Backup plan was created \n backup-policy is.backup-policy.backup-plan.delete Backup plan was deleted \n backup-policy is.backup-policy.backup-plan.read One or more backup plans were retrieved \n backup-policy is.backup-policy.backup-job.read One or more backup jobs were retrieved \n\n\n\n\n\n\n\n\n\n Supported locations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-at-events"},{"document_id":"ibmcld_06443-2410-3623","score":0.0158730159,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_09549-4-1855","score":0.015625,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Managing Cloud Databases backups \n\nBackups for Cloud Databases deployments are accessible from the Backups tab of your deployment's dashboard. Here is some additional general information about backups:\n\n\n\n* One backup is taken every day.\n* Backups are available for 30 days.\n* Backups cannot be deleted.\n* If you delete your deployment, its backups are deleted automatically.\n* Daily backup scheduling is not configurable.\n* Backups are restorable to other regions, except for eu-de and par-01, which can restore backups only between each other. For example, par-01 backups can be restored to eu-de, and vice versa.\n* Backup storage is encrypted. To manage the encryption keys, see [Key Protect integration](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-key-protectbyok-for-backups). Otherwise, backups are encrypted with a key that is automatically generated for your deployment.\n* Backups are restorable across accounts, but only through the API and only if the user that is running the restore has access to both the source and destination accounts.\n* Cloud Databases backups are not downloadable. If you need a local backup, use the appropriate software. For example, [pg_dump](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) is an effective tool for managing PostgreSQL backups.\n* IBM Cloud\u00ae Databases for DataStax does not support reenablement. After a deployment is disabled, that deployment must be restored from a backup.\n\n\n\nFor information on taking an on-demand backup, see [Taking an on-demand backup](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=cliondemand-backup).\n\n\n\n Backups in the UI \n\nThe backup types have their respective tabs, either On-demand or Automatic. Each backup is listed with its type and when the backup was taken.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-dashboard-backups"},{"document_id":"ibmcld_06627-2422-3635","score":0.015625,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06339-4-1855","score":0.0153846154,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Managing Cloud Databases backups \n\nBackups for Cloud Databases deployments are accessible from the Backups tab of your deployment's dashboard. Here is some additional general information about backups:\n\n\n\n* One backup is taken every day.\n* Backups are available for 30 days.\n* Backups cannot be deleted.\n* If you delete your deployment, its backups are deleted automatically.\n* Daily backup scheduling is not configurable.\n* Backups are restorable to other regions, except for eu-de and par-01, which can restore backups only between each other. For example, par-01 backups can be restored to eu-de, and vice versa.\n* Backup storage is encrypted. To manage the encryption keys, see [Key Protect integration](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-key-protectbyok-for-backups). Otherwise, backups are encrypted with a key that is automatically generated for your deployment.\n* Backups are restorable across accounts, but only through the API and only if the user that is running the restore has access to both the source and destination accounts.\n* Cloud Databases backups are not downloadable. If you need a local backup, use the appropriate software. For example, [pg_dump](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) is an effective tool for managing PostgreSQL backups.\n* IBM Cloud\u00ae Databases for DataStax does not support reenablement. After a deployment is disabled, that deployment must be restored from a backup.\n\n\n\nFor information on taking an on-demand backup, see [Taking an on-demand backup](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=cliondemand-backup).\n\n\n\n Backups in the UI \n\nThe backup types have their respective tabs, either On-demand or Automatic. Each backup is listed with its type and when the backup was taken.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-dashboard-backups"},{"document_id":"ibmcld_06696-2412-3625","score":0.0153846154,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12584-10119-11773","score":0.0163934426,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery, see the [IBM Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Customers can help meet disaster recovery objectives by deploying their project in a development or test environment before they deploy to production. <br>\\nThe customer does not have to take other actions to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM Cloud is available globally and load balanced from a single URL. It is highly available and continues to run even if your resources are unavailable. For more information about high availability, see the [IBM service level objectives](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slo) and the [sample application architecture](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery). N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures"},{"document_id":"ibmcld_08435-3634-5079","score":0.0163934426,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_11164-6586-7646","score":0.0161290323,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_08435-8253-9823","score":0.0161290323,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_06123-7-1983","score":0.0158730159,"text":"\nSetting up disaster recovery with Portworx \n\nYou can configure disaster recovery for your data that you store in your Kubernetes clusters by using Portworx. When one of your clusters becomes unavailable, Portworx automatically fails over to another cluster so that you can still access your data.\n\nDisaster recovery with Portworx requires at least two Kubernetes clusters where Portworx is installed and configured for disaster recovery. One of the two clusters is considered the active cluster where your data is primarily stored. All data is then replicated to the standby cluster. If your active cluster becomes unavailable, Portworx automatically fails over to the standby cluster and makes the standby cluster the new active cluster so that data can continue to be accessed.\n\nIf you installed Portworx in one of your clusters without the Portworx disaster recovery plan, you must re-install Portworx with the disaster recovery plan so that you can include this cluster in your disaster recovery configuration.\n\nDepending on your cluster setup, Portworx offers the following two disaster recovery configurations:\n\n\n\n* [Metro DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/1-metro-dr-nodes-are-in-the-metro-area-network-man): Your Kubernetes clusters are in the same metro location, such as both clusters are deployed in one or multiple zones of the us-south region. All clusters are configured to use the same Portworx cluster and share the same Portworx key-value store. Data is automatically replicated between the clusters because the Portworx storage layer is shared. RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Kubernetes clusters are deployed in different regions, such as us-south and us-east.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_recovery"},{"document_id":"ibmcld_08435-6973-8664","score":0.0158730159,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_00471-3725-5071","score":0.015625,"text":"\nIf you intend to store sensitive information in an IBM Cloudant database, you must use client-side encryption to render data unreadable to IBM Cloudant operators. For example, for PCI DSS compliance, you must encrypt the Primary Account Number (PAN) before sending a document that contains it to the database. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes the following tasks:\n\n\n\n* Provide dependencies on disaster recovery sites.\n* Provision disaster recovery environments.\n* Back up data and configuration.\n* Replicate data and configuration to the disaster recovery environment.\n* Fail over disaster events.\n\n\n\n\n\nTable 4. Responsibilities for disaster recovery\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n HA\/DR (cross-region) Customer is responsible for creating more IBM Cloudant instances in separate regions and configuring replications to achieve the cross-region HA\/DR architecture they want. See [Configuring IBM Cloudant for cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-configuring-ibm-cloudant-for-cross-region-disaster-recovery) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-responsibilities"},{"document_id":"ibmcld_08435-4752-6201","score":0.015625,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_10564-7-2011","score":0.0153846154,"text":"\nSetting up disaster recovery with Portworx \n\nYou can configure disaster recovery for your data that you store in your Red Hat OpenShift clusters by using Portworx. When one of your clusters becomes unavailable, Portworx automatically fails over to another cluster so that you can still access your data.\n\nDisaster recovery with Portworx requires at least two Red Hat OpenShift clusters where Portworx is installed and configured for disaster recovery. One of the two clusters is considered the active cluster where your data is primarily stored. All data is then replicated to the standby cluster. If your active cluster becomes unavailable, Portworx automatically fails over to the standby cluster and makes the standby cluster the new active cluster so that data can continue to be accessed.\n\nIf you installed Portworx in one of your clusters without the Portworx disaster recovery plan, you must re-install Portworx with the disaster recovery plan so that you can include this cluster in your disaster recovery configuration.\n\nDepending on your cluster setup, Portworx offers the following two disaster recovery configurations:\n\n\n\n* [Metro DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/1-metro-dr-nodes-are-in-the-metro-area-network-man): Your Red Hat OpenShift clusters are in the same metro location, such as both clusters are deployed in one or multiple zones of the us-south region. All clusters are configured to use the same Portworx cluster and share the same Portworx key-value store. Data is automatically replicated between the clusters because the Portworx storage layer is shared. RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Red Hat OpenShift clusters are deployed in different regions, such as us-south and us-east.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_recovery"},{"document_id":"ibmcld_09061-6176-7874","score":0.0153846154,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04621-58586-59933","score":0.0327868852,"text":"\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1\n: The SDK for Node.js buildpack v3.25.1 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.16.0, 8.11.4, 8.15.0, 10.10.0 and 10.15.0. The default is latest 6.x, so it is currently 6.16.0. The versions 6.15.0, 8.14.0 and 10.14.0 that were included in the last buildpack had a regression. The regressions has been fixed in 6.16.0, 8.15.0 and 10.15.0 which are now included instead.\n\n\n\n\n\n 7 January 2019 \n\nUpdated Node.js buildpack v3.25\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_04621-57662-58966","score":0.0322580645,"text":"\n* Update Node.js version to 6.17.0\n\n\n\n\n\n\n\n 18 March 2019 \n\nUpdated Node.js buildpack v3.26\n: The SDK for Node.js buildpack v3.26 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.16.0, 6.17.0, 8.15.0, 8.15.1, 10.15.0 and 10.15.3. The default is latest 6.x, so it is currently 6.17.0.\n\n\n\n\n\n 1 March 2019 \n\nUpdated Liberty buildpack v3.29-20190223-2128\n: The default Liberty runtime GA version is the [18.0.0.4](https:\/\/openliberty.io\/blog\/2018\/12\/14\/microprofile21-18004.html) release.\n\n\n\n* The alternate Liberty runtime GA version [19.0.0.2](https:\/\/openliberty.io\/blog\/2019\/03\/01\/sharding-keys-jdbc43-19002.html) was added.\n* The Cloudant client libraries were updated to 2.14.0.\n\n\n\n\n\n\n\n 1 February 2019 \n\nUpdated Liberty buildpack v3.28-20190127-1723\n: The default Liberty runtime GA version is the [18.0.0.4](https:\/\/openliberty.io\/blog\/2018\/12\/14\/microprofile21-18004.html) release.\n\n\n\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_05598-32183-33356","score":0.0317460317,"text":"\nGateway-enabled cluster controller 1348 1444 Updated image for [CVE-2021-36159](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-36159). \n GPU device plug-in and installer 82ee77b a9461a8 Updated to use Go version 1.16.6. \n IBM Calico extension 747 763 Updated to use Go version 1.16.6. Updated UBI to the latest 8.4-205 version to resolve CVEs. \n IBM Cloud Controller Manager v1.19.13-1 v1.19.14-1 Updated to support the Kubernetes 1.19.14 release and to use Go version 1.15.15. \n IBM Cloud File Storage for Classic plug-in and monitor 395 398 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n Key Management Service provider v2.3.6 v2.3.7 Updated to use Go version 1.15.15. Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs. \n Kubernetes v1.19.13 v1.19.14 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.19.14). \n Kubernetes Dashboard metrics scraper v1.0.6 v1.0.7 See the [Kubernetes Dashboard metrics scraper release notes](https:\/\/github.com\/kubernetes-sigs\/dashboard-metrics-scraper\/releases\/tag\/v1.0.7).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_16034-7-1778","score":0.03125,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_04621-59443-60826","score":0.0307692308,"text":"\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.\n\n\n\n* The default Liberty runtime version was updated to the [18.0.0.4](https:\/\/openliberty.io\/blog\/2018\/12\/14\/microprofile21-18004.html) release.\n* The monthly Liberty runtime version was updated to the 2018.11.0.0 release.\n* The IBM JRE version was updated to 8 SR5 FP26.\n\n\n\n\n\n\n\n 12 December 2018 \n\nUpdated ASP.NET Core buildpack v2.1-20181205-1536\n: This release includes version 2.2.0 of the dotnet-core Cloud Foundry buildpack.\n\n\n\n* Add support for .NET ASP.NET Core 2.1.2\n* Add support for .NET ASP.NET Core 2.1.4\n* Add support for .NET ASP.NET Core 2.1.5\n* Add support for .NET Runtime 1.0.11\n* Add support for .NET Runtime 1.0.12\n* Add support for .NET Runtime 1.1.9\n* Add support for .NET Runtime 1.1.10\n* Add support for .NET Runtime 2.0.7\n* Add support for .NET Runtime 2.0.9\n* Add support for .NET Runtime 2.1.2\n* Add support for .NET Runtime 2.1.5\n* Add support for .NET SDK 1.0.4","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_00861-221488-222586","score":0.0303030303,"text":"\nJVM: 11.0.10 (Eclipse OpenJ9 openj9-0.24.0)\nOS: Linux 5.10.47-linuxkit amd64\n\n oc version\nClient Version: 4.8.11\n\n zip\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\n\n unzip\nUnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n\n git --version\ngit version 2.17.1\n\n curl\ncurl 7.58.0 (x86_64-pc-linux-gnu) libcurl\/7.58.0 OpenSSL\/1.1.1 zlib\/1.2.11 libidn2\/2.0.4 libpsl\/0.19.1 (+libidn2\/2.0.4) nghttp2\/1.30.0 librtmp\/2.3\n\n wget\nGNU Wget 1.19.4 built on linux-gnu.\n\n openssl version\nOpenSSL 1.1.1 11 Sep 2018\n\n make\nGNU Make 4.1\n\n docker\nClient: Docker Engine - Community\nVersion: 19.03.9\nAPI version: 1.40\nGo version: go1.13.10\nGit commit: 9d988398e7\nBuilt: Fri May 15 00:22:47 2020\nOS\/Arch: linux\/amd64\nExperimental: false\n\n dc --version\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.14 \n\nTo view the contents of version 2.14, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-222303-223263","score":0.0298507463,"text":"\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.14 \n\nTo view the contents of version 2.14, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n yq4 --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.12.1\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.5\", GitCommit:\"6b1d87acf3c8253c123756b9e61dac642678305f\", GitTreeState:\"clean\", BuildDate:\"2021-03-18T01:10:43Z\", GoVersion:\"go1.15.8\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.9.0 c8bb937807d405d92be91f06ce2629e6202ac7a9\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.17.0\", GitCommit:\"a690bad98af45b015bd3da1a41f6218b1a451dbe\", GitTreeState:\"clean\"}\n\n helm3 version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_10402-64992-66123","score":0.0294117647,"text":"\nUpdated universal base image (UBI) to the latest 8.4-205 version to resolve CVEs. \n IBM Cloud Block Storage for Classic plug-in and driver v2.0.8 v2.0.9 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n IBM Cloud Controller Manager v1.19.13-1 v1.19.14-1 Updated to support the Kubernetes 1.19.14 release and to use Go version 1.15.15. \n IBM Cloud File Storage for Classic plug-in and monitor 395 398 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n Key Management Service provider v2.3.6 v2.3.7 Updated to use Go version 1.15.15. Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs. \n Load balancer and load balancer monitor for IBM Cloud Provider 1328 1510 Updated image for [CVE-2020-27780](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-27780). \n Red Hat OpenShift 4.6.38 4.6.42 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.6\/release_notes\/ocp-4-6-release-notes.htmlocp-4-6-42).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_46"},{"document_id":"ibmcld_05598-104511-105297","score":0.0289855072,"text":"\nIn addition, the Kubernetes DNS autoscaler configuration was updated to include worker nodes that can't be scheduled in scaling calculations. \n Kubernetes NodeLocal DNS cache 1.15.13 1.15.14 See the [Kubernetes NodeLocal DNS cache release notes](https:\/\/github.com\/kubernetes\/dns\/releases\/tag\/1.15.14). \n Load balancer and load balancer monitor for IBM Cloud Provider 223 234 Updated to use Go version 1.15.2. \n Operator Lifecycle Manager Catalog v1.6.1 v1.14.0 See the [Operator Lifecycle Manager Catalog release notes](https:\/\/github.com\/operator-framework\/operator-registry\/releases\/tag\/v1.14.0). \n Operator Lifecycle Manager 0.14.1-IKS-1 0.16.1 See the [Operator Lifecycle Manager release notes](https:\/\/github.com\/operator-framework\/operator-lifecycle-manager\/releases\/tag\/0.16.1).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_05525-43196-44354","score":0.0285714286,"text":"\nOpenVPN server 2.4.6-r3-IKS-115 2.4.6-r3-IKS-121 Updated images for [CVE-2019-1547](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2019-1547) and [CVE-2019-1563](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2019-1563). \n Kubernetes v1.14.6 v1.14.7 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.14.7). \n Ubuntu 18.04 kernel and packages 4.15.0-62-generic 4.15.0-64-generic Updated worker node images with kernel and package updates for [CVE-2019-15031](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-15031), [CVE-2019-15030](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-15030), and [CVE-2019-14835](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-14835). \n Ubuntu 16.04 kernel and packages 4.4.0-161-generic 4.4.0-164-generic Updated worker node images with kernel and package updates for [CVE-2019-14835](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-14835). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.14.6_1533, released 16 September 2019 \n\nThe following table shows the changes that are in the worker node fix pack 1.14.6_1533.\n\n\n\nTable 1. Changes since version 1.14.6_1532\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-114_changelog"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16261-10613-12744","score":0.0163934426,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16034-7-1778","score":0.0163934426,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16360-1493-3354","score":0.0161290323,"text":"\nAll phrases corresponding to an intent are created as example phrases for the new action. This can provide a helpful starting point when you are ready to start building actions in the new experience.\n\n\n\n1. Download the intents that you want to migrate to actions from the classic Watson Assistant experience. For more information, see [Downloading intents](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download). The format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nwhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions\nIs it raining?,weather_conditions\nWhat's the temperature?,weather_conditions\nWhere is your nearest location?,find_location\nDo you have a store in Raleigh?,find_location\n2. From the main actions page, click the Upload icon ![Upload icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/upload.svg).\n3. Select the intents file that you downloaded.\n\nThe file is validated and uploaded, and the system trains itself on the new data.\n\nThe intents in column 2 are created as new actions, and the phrases in column 1 are created as example phrases for the corresponding action. For example, if you upload the example from step 1, two new actions are created for the weather_conditions and find_location intents. The underscores (_) in the intent names are replaced with spaces, for example, the weather_conditions intent becomes the weather conditions action.\n\nIn this example, the weather_conditions action will have three example phrases: Tell me the current weather conditions., Is it raining?, and What's the temperature?. The find_location action will have two example phrases: Where is your nearest location? and Do you have a store in Raleigh?.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-upload-download-actions"},{"document_id":"ibmcld_00861-47234-48299","score":0.0161290323,"text":"\nOS name: \"linux\", version: \"5.15.49-linuxkit\", arch: \"amd64\", family: \"unix\"\n\n gradle -version\n\nWelcome to Gradle 7.6!\n\nHere are the highlights of this release:\n- Added support for Java 19.\n- Introduced --rerun flag for individual task rerun.\n- Improved dependency block for test suites to be strongly typed.\n- Added a pluggable system for Java toolchains provisioning.\n\nFor more details see https:\/\/docs.gradle.org\/7.6\/release-notes.html\n\n------------------------------------------------------------\nGradle 7.6\n------------------------------------------------------------\n\nBuild time: 2022-11-25 13:35:10 UTC\nRevision: daece9dbc5b79370cc8e4fd6fe4b2cd400e150a8\n\nKotlin: 1.7.10\nGroovy: 3.0.13\nAnt: Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM: 17.0.5 (Eclipse OpenJ9 openj9-0.35.0)\nOS: Linux 5.15.49-linuxkit amd64\n\n oc version\nClient Version: 4.12.0\nKustomize Version: v4.5.7\n\n zip\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\n\n unzip\nUnZip 6.00 of 20 April 2009, by Info-ZIP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_09906-1621-3194","score":0.0158730159,"text":"\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"url\": \"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"url\":\"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_16034-2811-4611","score":0.0158730159,"text":"\n* Updated load-balancer-create and load-balancer-update commands to support load balancer private DNS service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.8.0 \n\nVersion 6.8.0 was released on 2023-03-15.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated vpc-routing-table-route-create and vpc-routing-table-route-update commands to support route priority feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.7.2 \n\nVersion 6.7.2 was released on 2023-03-13.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed instances list command to show the floating IP.\n* Fixed instance-volume-attachment-add command optional field issue.\n\n\n\n\n\n\n\n\n\n v6.7.0 \n\nVersion 6.7.0 was released on 2023-03-07.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated load-balancer-listener-create, and load-balancer-listener-update commands to support load balancer idle connection timeout.\n* Updated volumes command to support attachment-state, encryption, operating-system-family, operating-system-architecture and zone filters.\n* Updated instance-create command to support instance creation from existing boot volume.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.6.0 \n\nVersion 6.6.0 was released on 2023-02-15.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_06414-1051-2499","score":0.015625,"text":"\nThe pg_dump command has many options and it is recommended that you [consult the official documentation](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) and [command reference](https:\/\/www.postgresql.org\/docs\/9.6\/static\/app-pgdump.html) for a fuller view of its capabilities.\n\n\n\n\n\n Restoring pg_dump's output \n\nThe resulting output of pg_dump can then be uploaded into a new Databases for EnterpriseDB deployment. As the output is SQL, it can simply be sent to the database through the psql command. We recommend that imports be performed with the admin user.\n\nSee the [Connecting with psql](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-connecting-psql) for details on how to connect as admin by using psql. To connect with the psql command, you need the admin user's connection string and the TLS certificate. The certificate needs to be decoded from the base64 and stored as an arbitrary local file. To import the previously created dump.sql into a database deployment named example-psql, the psql command can be called with -f dump.sql as a parameter. The parameter tells psql to read and run the SQL statements in the file. The command looks something like:\n\nPGPASSWORD=yourpasswordhere PGSSLROOTCERT=cert.crt psql 'host=c7798cf6-e5d2-4513-b17f-3d3fa67d8291.8f7bfd8f3faa4218aec56e069eb46187.databases.appdomain.cloud port=32484 dbname=ibmclouddb user=admin sslmode=verify-full' -f dump.sql","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-migrating"},{"document_id":"ibmcld_00861-61030-62048","score":0.015625,"text":"\nmvn -version\nApache Maven 3.8.6 (84538c9988a25aec085021c365c560670ad80f63)\nMaven home: \/opt\/IBM\/maven\nJava version: 17.0.5, vendor: IBM Corporation, runtime: \/usr\/local\/jdk17\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"5.15.49-linuxkit\", arch: \"amd64\", family: \"unix\"\n\n gradle -version\n\nWelcome to Gradle 7.6!\n\nHere are the highlights of this release:\n- Added support for Java 19.\n- Introduced --rerun flag for individual task rerun.\n- Improved dependency block for test suites to be strongly typed.\n- Added a pluggable system for Java toolchains provisioning.\n\nFor more details see https:\/\/docs.gradle.org\/7.6\/release-notes.html\n\n------------------------------------------------------------\nGradle 7.6\n------------------------------------------------------------\n\nBuild time: 2022-11-25 13:35:10 UTC\nRevision: daece9dbc5b79370cc8e4fd6fe4b2cd400e150a8\n\nKotlin: 1.7.10\nGroovy: 3.0.13\nAnt: Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM: 17.0.5 (Eclipse OpenJ9 openj9-0.35.0)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_06644-1022-2468","score":0.0153846154,"text":"\nThe pg_dump command has many options and it is recommended that you [consult the official documentation](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) and [command reference](https:\/\/www.postgresql.org\/docs\/9.6\/static\/app-pgdump.html) for a fuller view of its capabilities.\n\n\n\n\n\n Restoring pg_dump's output \n\nThe resulting output of pg_dump can then be uploaded into a new Databases for PostgreSQL deployment. As the output is SQL, it can simply be sent to the database through the psql command. We recommend that imports be performed with the admin user.\n\nSee the [Connecting with psql](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-connecting-psql) for details on how to connect as admin by using psql. To connect with the psql command, you need the admin user's connection string and the TLS certificate. The certificate needs to be decoded from the base64 and stored as an arbitrary local file. To import the previously created dump.sql into a database deployment named example-psql, the psql command can be called with -f dump.sql as a parameter. The parameter tells psql to read and execute the SQL statements in the file. The command looks something like:\n\nPGPASSWORD=yourpasswordhere PGSSLROOTCERT=cert.crt psql 'host=c7798cf6-e5d2-4513-b17f-3d3fa67d8291.8f7bfd8f3faa4218aec56e069eb46187.databases.appdomain.cloud port=32484 dbname=ibmclouddb user=admin sslmode=verify-full' -f dump.sql","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-migrating"},{"document_id":"ibmcld_00861-176821-177830","score":0.0153846154,"text":"\nApache Maven 3.8.6 (84538c9988a25aec085021c365c560670ad80f63)\nMaven home: \/opt\/IBM\/maven\nJava version: 11.0.11, vendor: AdoptOpenJDK, runtime: \/usr\/local\/openjdk-11\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"5.15.49-linuxkit\", arch: \"amd64\", family: \"unix\"\n\n gradle -version\n\nWelcome to Gradle 7.6!\n\nHere are the highlights of this release:\n- Added support for Java 19.\n- Introduced --rerun flag for individual task rerun.\n- Improved dependency block for test suites to be strongly typed.\n- Added a pluggable system for Java toolchains provisioning.\n\nFor more details see https:\/\/docs.gradle.org\/7.6\/release-notes.html\n\n------------------------------------------------------------\nGradle 7.6\n------------------------------------------------------------\n\nBuild time: 2022-11-25 13:35:10 UTC\nRevision: daece9dbc5b79370cc8e4fd6fe4b2cd400e150a8\n\nKotlin: 1.7.10\nGroovy: 3.0.13\nAnt: Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM: 11.0.11 (Eclipse OpenJ9 openj9-0.26.0)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15545-195860-197138","score":0.0163934426,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":0.0161290323,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-195756-197034","score":0.0158730159,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-195812-197090","score":0.015625,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_15646-26617-28366","score":0.0153846154,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":0.0151515152,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-6657-8493","score":0.0149253731,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15545-194867-196144","score":0.0147058824,"text":"\nIf this property is not provided, the root key from source volume is used.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in the ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-update \n\nUpdate an image.\n\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-194919-196196","score":0.0144927536,"text":"\nIf this property is not provided, the root key from source volume is used.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in the ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-update \n\nUpdate an image.\n\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-194763-196040","score":0.0142857143,"text":"\nIf this property is not provided, the root key from source volume is used.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in the ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-update \n\nUpdate an image.\n\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-5434-7003","score":0.0327868852,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":0.0322580645,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":0.0317460317,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_16601-1150-2518","score":0.03125,"text":"\n* [Salesforce SDK](https:\/\/github.com\/watson-developer-cloud\/salesforce-sdk)\n* [Swift SDK](https:\/\/github.com\/watson-developer-cloud\/swift-sdk)\n* [Unity SDK](https:\/\/github.com\/watson-developer-cloud\/unity-sdk)\n\n\n\n\n\n\n\n SDK updates and deprecation \n\nThe supported Watson SDKs are updated according to the following guidelines.\n\n\n\n Semantic versioning \n\nSupported Watson SDKs adhere to semantic versioning with releases labeled as {major}.{minor}.{patch}.\n\n\n\n\n\n Release frequency \n\nSDKs are released independently and might not update on the same schedule.\n\n\n\n* The current releases of the Watson SDKs are updated on a 2- to 6-week schedule. These releases are either minor updates or patches that do not include breaking changes. You can update to any version of the SDK with the same major version number.\n* Major updates that might include breaking changes are released approximately every 6 months.\n\n\n\n\n\n\n\n Deprecated release \n\nWhen a major version is released, support continues on the previous major release for 12 months in a deprecation period. The deprecated release might be updated with bug fixes, but no new features will be added and documentation might not be available.\n\n\n\n\n\n Obsolete release \n\nAfter the 12-month deprecation period, a release is obsolete. The release might be functional but is unsupported and not updated. Update to the current release.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-using-sdks"},{"document_id":"ibmcld_15647-27849-29558","score":0.0307692308,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-27823-29559","score":0.0303030303,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15507-8094-9618","score":0.0298507463,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15175-10224-11754","score":0.0294117647,"text":"\necc68c2f-96a1-4862-bc86-14f47e5d9ed8 aa-1-bx-boot-1617035447000\nCreated 2021-05-20T09:43:16+08:00\nVisibility private\nFile size(GB) -\nEncryption none\nResource group f22cf48f-8836-4527-9131-1d7c73ba85e9\n\n\n\n\n\n\n\n Schedule custom image lifecycle status changes by using the CLI \n\nWhen you import a custom image by using the command-line interface (CLI), you can also schedule the lifecycle status changes of the IBM Cloud VPC custom image at the same time by using options of the ibmcloud is image-create command.\n\nSpecify the name of the custom image to be created by using the IMAGE_NAME variable and the source by using the --source-volume option to indicate that the source is an existing boot volume.\n\nTo schedule the deprecate-at or obsolete-at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates and times, the deprecate-at date must be after the obsolete-at date and time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifv"},{"document_id":"ibmcld_15507-6657-8493","score":0.0289855072,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-29196-30599","score":0.0142857143,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2857142857,"recall_5":0.2857142857,"recall_10":0.4285714286,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.3835663674,"ndcg_cut_10":0.3936118448}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":0.0327868852,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_03166-23681-24372","score":0.0322580645,"text":"\nFor Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU) \n\n\n\nFor more information about how the web chat widget tracks MAUs, see [Billing](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03798-0-2240","score":0.0317460317,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_03107-4-1607","score":0.03125,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Managing your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16252-7-1601","score":0.0307692308,"text":"\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_16365-15662-16934","score":0.0303030303,"text":"\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03704-1531-3564","score":0.0298507463,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":0.0294117647,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":0.0289855072,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02597-3131-5174","score":0.0285714286,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03709-0-1479","score":0.0327868852,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03704-7496-9340","score":0.0322580645,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1048947-1050776","score":0.0317460317,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1048818-1050647","score":0.03125,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03732-0-1673","score":0.0307692308,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03711-0-822","score":0.0303030303,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cant-create-service-feature-code"},{"document_id":"ibmcld_03704-8977-10890","score":0.0298507463,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":0.0294117647,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":0.0289855072,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03699-7-2091","score":0.0285714286,"text":"\nApplying promo codes \n\nPromotions are limited-time credits toward your IBM Cloud\u00ae account and services that you can get by applying promo codes. Each promo code can be used one time and is valid only for a certain amount of time. Promo codes are provided on a limited basis by IBM Cloud sales to customers with billable accounts.\n\nPromo codes are typically based on short phrases, like PROMO200. If you have an alphanumeric code, such as a1b2c3def456, it's a different type of code that is referred to as a feature code. You can apply these codes on the Manage > Account > Account settings page or when you register for a new account. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\nPromotions are one type of credit for your account. For example, if you have a Pay-As-You-Go or Subscription account, you can use promo codes for limited-time credits toward your account and IBM Cloud products. Promo codes are different from feature codes that provide access to Trial accounts, or subscriptions that add credits as discounts to your account.\n\n\n\n Types of available promotion credits \n\nBoth one-time credit promotions and recurring dollar credit promotions are available for all IBM Cloud products.\n\n\n\n1. One-time credit promotion\n\n\n\n* Credit promotions can be used only one time, for a set time period, and you can't remove them after you apply them. Credit promotions use the following format: $X off for Y days.\n\n\n\n2. Recurring dollar credit promotion\n\n\n\n* Recurring dollar credits are offered for a set time period. For example, you can have a promotion of $100 USD value that is recurring every 30 days for 6 months. Recurring dollar credit promotions use the following format: $X every Y months, repeats Z times.\n* Promo credit expires at the end of the committed term. Any credit that isn't used doesn't roll over to the next term.\n\nWith a recurring credit, if the amount of credit that is allocated to a client is not used within the allocated time, the credit expires.\n\n\n\n\n\n\n\n\n\n Applying promo codes to your account","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-1710-3705","score":0.0322664585,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":0.0315136476,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":0.0314980159,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":0.0303030303,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03704-3030-4892","score":0.0296312555,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":0.0289915966,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03794-0-812","score":0.0163934426,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_03713-3269-5168","score":0.0161290323,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":0.015625,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03799-0-731","score":0.0153846154,"text":"\n\n\n\n\n\n\n  Why can't I update my billing address? \n\nYou can't update the billing address for a credit card in the IBM Cloud console. You must contact support to update the billing address on an existing credit card.\n\n  What\u2019s happening \n\nWhen you try update your payment details, you can't update the billing address for the credit card.\n\n  Why it\u2019s happening \n\nOn the [Payment methods page](https:\/\/cloud.ibm.com\/billing\/payments), you can't edit the billing address in the IBM Cloud Console.\n\n  How to fix it \n\nTo update the billing address for a credit card, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Depending on your level of support, you can chat with a support agent or open a case.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-update-billing-address"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.9493885685}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":0.0327868852,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":0.0322580645,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":0.0317460317,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":0.03125,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":0.0307692308,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":0.0303030303,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03713-7896-8949","score":0.0298507463,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03793-7-1857","score":0.029198636,"text":"\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https:\/\/cloud.ibm.com\/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm"},{"document_id":"ibmcld_07578-1068305-1070191","score":0.0285714286,"text":"\nYou can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqscancelaccount).\n\n\n\nManaging your account, resources, and access\n\n\n\n* How do I create an IBM Cloud account?\n\nYou can create an account by [registering](https:\/\/cloud.ibm.com\/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n* How is my credit card authorized?\n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03794-0-812","score":0.0147058824,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03735-7-1918","score":0.0315449578,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_07578-806120-808288","score":0.0313188158,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":0.0308349146,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01623-6277-8255","score":0.0301587302,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_12539-0-2074","score":0.0161290323,"text":"\n\n\n\n\n\n\n  Estimating architecture costs in a project \n\nCost estimation is available for deployable architectures in the IBM Cloud catalog. Depending on the deployable architecture, a starting cost is estimated based on the available data. This estimate is meant to be a starting point to help you determine how much your account could be charged for deploying an architecture. This estimated amount is subject to change as the architecture is customized within a project, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n  Viewing the starting cost for your deployable architecture \n\nDepending on the deployable architecture that you select from the catalog, there is an estimated starting cost.\n\nTo view the estimated starting cost, complete the following steps:\n\n\n\n1.  Go to the catalog details page for the deployable architecture.\n2.  Next, click the Starting at amount for additional details about the cost summary.\n\n\n\nAfter you add the deployable architecture to your project, you can configure the input values. By doing so, you can tailor the architecture to match your needs. Adjusting the configuration input might adjust the estimated cost.\n\n\n\n1.  Go to the Projects page, and select a project.\n2.  Go to Configurations, and select a configuration of the deployable architecture.\n3.  Enter the input values to configure the deployable architecture, and click Save. For more information about configuring and deploying, see [Configuring and deploying a deployable architecture](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-config-project).\n4.  After saving, the validation checks are run and a new cost estimate is computed. This might take a few minutes. After the validation is complete, you can view the estimated cost for the configured architecture on the validation modal in the Cost estimate successful section.\n\n\n\nThis estimated amount is subject to change as the architecture is customized and deployed, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-cost-estimate-project"},{"document_id":"ibmcld_04260-0-1777","score":0.0158730159,"text":"\n\n\n\n\n\n\n  Using the Pricing calculator to estimate your monthly cost per user per month \n\nThe pricing information for your system resources is shown on the side of the provisioining window and shows all of your equipment and physical resource costs. To view the cost estimates for your organization on a per user basis, use the pricing calculator. You can get estimates for different configurations before you begin provisioning. The pricing calculator is on the DaaS estimate tab on the main Citrix-DaaS product page.\n\n\n\n  What the pricing calculator does \n\nThe pricing calculator looks at several factors to estimate your cost and savings with different Citrix-DaaS configurations:\n\n\n\n1.  The geographic area and region where your resources are located.\n2.  The number of users that use your system.\n3.  The operating system that your system uses.\n4.  The boot volume size on your system.\n5.  The profile settings for your system, including the image to use, CPU, RAM, etc.\n\n\n\nThe calculator takes the inputs and creates a per user estimate for your configuration.\n\n\n\n\n\n  Calculating cost per user for your system \n\nTo calculate the cost per users for your Citrix-DaaS configuration:\n\n\n\n1.  From the Citrix-DaaS product page, select the DaaS estimate tab. The pricing calculator is shown.\n2.  Enter the geographic, user, OS, and boot volume information for your system.\n3.  Verify that the profile settings listed match your system or match the system that you are estimating. If they do not match, select Change Profile to enter the correct profile information.\n\n\n\nThe calculator shows you the cost estimate per user for your system.\n\nIf you want to see estimates for different profiles, or different numbers of users, modify the specific fields to see new estimates.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-daas?topic=citrix-daas-pricing-calculator-monthly-cost"},{"document_id":"ibmcld_03735-1425-3233","score":0.015625,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_07578-807740-809746","score":0.015625,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_15160-8509-10437","score":0.0153846154,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-planbackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.\n\n\n\nThe cost estimate summary shows how the costs are calculated and breaks down the storage cost, providing a monthly estimate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_16727-807613-809619","score":0.0153846154,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8065735964}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12746-0-1760","score":0.0327868852,"text":"\n\n\n\n\n\n\n  How does Security and Compliance Center calculate pricing? \n\nPricing for IBM Cloud\u00ae Security and Compliance Center is based on the number of evaluations performed. An evaluation is the check of one assessment against one resource.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate from either the [provisioning](https:\/\/cloud.ibm.com\/security-compliance\/catalog) or [plan page](https:\/\/cloud.ibm.com\/security-compliance\/plan).\n\n\n\n  Plan types \n\nThe service offers two pricing plans.\n\nTrial\n:   To try out the service, you can enroll in a Trial period where you have access the full capabilities of the Posture Management component for 30 days at no charge. You can create profiles, set up credentials, and configure your account to evaluate your resources, among other things. Each account can have 1 instance of the trial service for the lifetime of the account.\n\nStandard\n:   With a Standard plan, you are able to access the full capabilities of the service without limitations. However, you are charged per evaluation.\n\n\n\n\n\n  When am I charged? \n\nYou are charged if an evaluation produces a result of pass or fail. You are not charged for the evaluation if the check cannot be performed or is not applicable. Each scan that is run provides you with the number of billable evaluations in the results UI.\n\n\n\n\n\n  How do I stop getting charged for Security and Compliance Center? \n\nYou are charged when an evaluation takes place. If you no longer want to be charged for a specific evaluation, stop the scan or scans that you do not want to be charged for from running by deleting your attachment. This does not remove your historical results, but it does stop future scans from being run.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-scc-pricing"},{"document_id":"ibmcld_02775-4830-5961","score":0.0322580645,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_08474-1435-3113","score":0.0317460317,"text":"\nOperational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n 22 internal keystores $3795 (5x0+15x225+2x210) \n 15 external keystores $980 (1x0+14x70) \n Unified Key Orchestrator connection $3600 (30x24x5.00) \n Total charge $11442.2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing"},{"document_id":"ibmcld_07578-1183252-1185036","score":0.03125,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1185885-1187669","score":0.0307692308,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08671-108191-109525","score":0.0303030303,"text":"\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs-uko)\n* [Is there a free trial for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-free-trial)\n\n\n\n[FAQs: Provisioning and operations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-provisioning-operations)\n\n\n\n* [Are there any prerequisites for using Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-hpcs-prerequisites)\n* [How to initialize Hyper Protect Crypto Services service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-how-to-initialize)\n* [Can I initialize my service instance through the TKE CLI plug-in by using a proxy?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-tke-proxy)\n* [Are there any recommendations on how to set up smart cards?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08474-7-1664","score":0.0298507463,"text":"\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing"},{"document_id":"ibmcld_03794-0-812","score":0.0294117647,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_08671-107301-108547","score":0.0289855072,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-do-with-hpcs)\n* [How do I know whether Hyper Protect Crypto Services is right for my company?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-choose-hs-crypto)\n* [How does Hyper Protect Crypto Services work?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-how-hpcs-work)\n* [What crypto card does Hyper Protect Crypto Services use?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-crypto-card)\n* [Which IBM regions are Hyper Protect Crypto Services available in?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-hpcs-regions)\n* [I have workloads in a data center where Hyper Protect Crypto Services is not available. Can I still subscribe to this service?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-data-center)\n\n\n\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_02775-3372-5498","score":0.0285714286,"text":"\nYou incur an extra charge when you enable them. For example, if you obtain 10,000 access tokens, then you turn on password policy management and obtain 10,000 more. You would pay for 20,000 authentication events and 10,000 advanced security events. If you disable all the advanced features, your account reverts to the original-cost policy.\n\n\n\nTable 1. Description of the benefits that are gained with advanced authentication events\n\n Feature Benefit \n\n Multi-factor authentication With [MFA for Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-mfacd-mfa), you can confirm a user\u2019s identity by requiring them to enter a one time passcode that is sent to their email or SMS after they enter their email and password. \n Runtime authentication activity tracking By integrating Activity Tracker with App ID, you can track different types of authentication events at run time. For example, a password reset request, authentication failures, or a user logout. For more information, see [Viewing runtime events](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-eventsat-monitor-runtime). \n Password policy management As an account owner, you can enforce more secure passwords for Cloud Directory by configuring a set of rules that user passwords must conform to. Examples include, the number of attempted sign-ins before lockout, expiration times, minimum time span between password updates, or the number of times that a password can't be repeated. For a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-4932-7001","score":0.0327868852,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-5228-7163","score":0.0320020481,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-1672-3956","score":0.0320020481,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_05666-7-2151","score":0.0310096154,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_03578-7-2257","score":0.0307765152,"text":"\nAbout bandwidth metering \n\nTo reduce your overall bandwidth costs, it's important to consider your bandwidth metering options. You can purchase and manage bandwidth metering for classic in two ways, through metering on individual devices, or through collective-metering when you add a device to a bandwidth pool.\n\nAll inbound and outbound bandwidth inside the IBM Cloud Classic infrastructure is unlimited and cost-free for your servers' use. Public egress bandwidth is charged on a tiered basis, with a set allocation for each month of your servers' use.\n\nBandwidth usage is measured as egress traffic on a device's public interfaces.\n\nBandwidth allocations are reserved for all public egress network usage. Devices with individual bandwidth metering and pool-based metering are all measured unless the device is ordered on the private network only.\n\nBandwidth allocation is a threshold where usage below the threshold is free or included, while usage in excess of the threshold is billed as a bandwidth overage. Bandwidth overages are billed individually per server or device, unless they participate in a bandwidth pool.\n\nDevices added to a bandwidth pool contribute both their bandwidth allocation and bandwidth usage to form aggregated totals for the pool. If the pool usage exceeds the total pool allocation, the account owner is billed a consolidated pool overage fee.\n\n\n\n About device bandwidth \n\nYou can manage each device's bandwidth allocation. When you provision certain devices, you can select the amount of bandwidth that you want to allocate to that device. For each device, you pay for a fixed amount of bandwidth allocation during a billing cycle, and receive a notification when the device is at risk of overage for the billing cycle. For more information, see [Adding Bare Metal Server bandwidth](https:\/\/cloud.ibm.com\/docs\/bandwidth-services?topic=bandwidth-services-adding-bare-metal-server-bandwidth) and [Adding virtual server instance bandwidth](https:\/\/cloud.ibm.com\/docs\/bandwidth-services?topic=bandwidth-services-adding-virtual-server-insance-bandwidth).\n\nWhen the bandwidth usage on a device reaches 85% of its total allocation, the account owner receives notifications.\n\nIBM charges for some firewall bandwidth metering.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bandwidth-metering?topic=bandwidth-metering-about-bandwidth-metering"},{"document_id":"ibmcld_10116-7-2157","score":0.0305361305,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10116-1581-3594","score":0.0298507463,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-1575-3588","score":0.0294117647,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_03776-3313-5682","score":0.0289855072,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12837-8834-10242","score":0.0142857143,"text":"\nBlock tier (up to) The total amount that is charged is established by an up to quantity that doesn't vary within the block If Q is <=Q1, T=T1<br><br>If Q1 < Q <=Q2, T=T2<br><br>If Q2 < Q <=Q3, T=T3 Q1=1000, T1=$0<br><br>Q2=2500, T2=2500<br><br>Q3=10000, T3=$4500<br><br>T=$4500 \n\n\n\nBlock tier pricing is not currently supported. If your product migrated from the resource management console, and you used block tier pricing, it is still honored. However, you can't add any new block tier pricing plans at this time.\n\n\n\n\n\n Metrics for metering models \n\nIf you created your service with Partner Center, you can choose from the following metrics and default metering models:\n\n\n\nTable 9. Partner Center metering model metrics\n\n Type Metric \n\n dailyproration_max Active User \n standard-add API call \n dailyproration_max Authorized User \n standard_add Gigabyte hour \n standard_add Gigabyte month \n monthlyproration Instance \n standard_add Terabyte hour \n standard_add Terabyte month \n dailyproration_max User \n standard_add Virtual Server \n standard_add Virtual Server Hour \n standard_add Virtual Processor Core \n\n\n\nThird-party providers that migrated from the resource management console to Partner Center can manage their metering models with Partner Center. Any information that you added or edited for pricing plans and metering models by using the resource management console can be updated in Partner Center.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02665-3418-5653","score":0.0325224749,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_12815-5234-7392","score":0.0322664585,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_03776-5228-7163","score":0.0320020481,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_08067-0-1736","score":0.0307765152,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_07578-506456-508701","score":0.0296703297,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-508107-510221","score":0.015625,"text":"\nIf the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs\/faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https:\/\/cloud.ibm.com\/docs\/faqsfaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs\/faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict cost.\n* Can you give some example pricing scenarios?\n\n\n\n Pricing Scenario 1: Mobile App with Feature Flags \n\nAssume you have a mobile app and you want feature flags and targeted segments to roll out features incrementally to different sets of users. Your historical metrics show 200,000 users but only about 50% are active in a month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-508049-510175","score":0.0153846154,"text":"\nIf the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs?tab=faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https:\/\/cloud.ibm.com\/docs?tab=faqsfaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs?tab=faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict cost.\n* Can you give some example pricing scenarios?\n\n\n\n Pricing Scenario 1: Mobile App with Feature Flags \n\nAssume you have a mobile app and you want feature flags and targeted segments to roll out features incrementally to different sets of users. Your historical metrics show 200,000 users but only about 50% are active in a month.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-506398-508643","score":0.0151515152,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00536-0-2049","score":0.0149253731,"text":"\n\n\n\n\n\n\n  Pricing FAQ \n\nIBM Cloudant pricing is based on the provisioned throughput capacity that you set for your instance, and the amount of data storage you use.\n\nWith IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, you can increase or decrease your provisioned throughput capacity as needed, and pay pro-rated hourly. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second.\n\nFor more information, see [IBM Cloudant Pricing](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing).\n\n\n\n  Can I change my capacity setting? \n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n\n\n\n\n\n  How do I know I exceeded the capacity limit that I set? \n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n\n\n\n\n\n  Where can I see my usage data? \n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-pricing"},{"document_id":"ibmcld_02665-5090-7240","score":0.0149253731,"text":"\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usagefaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usagefaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10214-19770-20862","score":0.0163934426,"text":"\nSatellite: See the [IBM Cloud Satellite documentation](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-faqsstandards).\n\n\n\n\n\n Can I use IBM Cloud and other services with my cluster? \n\nYou can add IBM Cloud platform and infrastructure services as well as services from third-party vendors to your Red Hat OpenShift on IBM Cloud cluster to enable automation, improve security, or enhance your monitoring and logging capabilities in the cluster.\n\nFor a list of supported services, see [Integrating services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrationssupported_integrations).\n\n\n\n\n\n Does IBM support third-party and open source tools that I use with my cluster? \n\nSee the [IBM Open Source and Third Party policy](https:\/\/www.ibm.com\/support\/pages\/node\/737271).\n\n\n\n\n\n What am I charged for? Can I estimate and control costs in my cluster? \n\nSee [Managing costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs).\n\n\n\n\n\n Can I downgrade my cluster to a previous version? \n\nNo, you cannot downgrade your cluster to a previous version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_12561-5237-7143","score":0.0163934426,"text":"\nIf you want to view usage for a specific account group or account, find the name or ID by running the ibmcloud enterprise command.\n\nFor example, the following command displays all account groups in an enterprise.\n\nibmcloud enterprise account-groups --recursive\n3. View usage by running the ibmcloud billing command as shown in the following examples.\n\n\n\n* View usage for the entire enterprise for the current month.\n\nibmcloud billing enterprise-usage\n* View usage for the Development account group for July 2019.\n\nibmcloud billing enterprise-usage --account-group Development --month 2019-07\n* View the usage for the account groups and accounts that are directly under the enterprise.\n\nibmcloud billing enterprise-usage --children\n\n\n\n\n\nBy default, the commands output the usage report for the current month in the following format. Most costs are listed as billable costs. Non-billable costs are listed only in rare cases, such as for the month when you add a trial account to the enterprise.\n\nName Type Billable Cost Non-billable Cost Currency Month\nExample Corp account 123.45 0 USD 2019-07\nDevelopment account_group 234.56 0 USD 2019-07\nMarketing account_group 345.67 0 USD 2019-07\nSales account_group 456.78 0 USD 2019-07\n\nYou can output the report in JSON format by specifying the --output JSON option.\n\n\n\n\n\n Viewing enterprise usage by using the API \n\nYou can get usage reports from an enterprise and its accounts by calling the [Enterprise Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports). You can base the query in your API call on an enterprise, an account group, or an account and specify whether to view the entity or its children.\n\nThe following examples show queries that you can use to get different usage reports. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_05777-20604-22088","score":0.0161290323,"text":"\n* International Organization for Standardization (ISO 27001, ISO 27017, ISO 27018)\n* Payment Card Industry Data Security Standard (PCI DSS)\n\n\n\nVPC infrastructure: IBM Cloud Kubernetes Service implements controls commensurate with the following security standards:\n\n\n\n* EU-US Privacy Shield and Swiss-US Privacy Shield Framework\n* Health Insurance Portability and Accountability Act (HIPAA)\n* International Standard on Assurance Engagements 3402 (ISAE 3402), Assurance Reports on Controls at a Service Organization\n\n\n\n\n\n\n\n Can I use IBM Cloud and other services with my cluster? \n\nYou can add IBM Cloud platform and infrastructure services as well as services from third-party vendors to your IBM Cloud Kubernetes Service cluster to enable automation, improve security, or enhance your monitoring and logging capabilities in the cluster.\n\nFor a list of supported services, see [Integrating services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrationssupported_integrations).\n\n\n\n\n\n Does IBM support third-party and open source tools that I use with my cluster? \n\nSee the [IBM Open Source and Third Party policy](https:\/\/www.ibm.com\/support\/pages\/node\/737271).\n\n\n\n\n\n What am I charged for? Can I estimate and control costs in my cluster? \n\nSee [Managing costs for your clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs).\n\n\n\n\n\n Can I downgrade my cluster to a previous version? \n\nNo, you cannot downgrade your cluster to a previous version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_03776-3313-5682","score":0.0161290323,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_08056-3796-5774","score":0.0158730159,"text":"\nTo upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https:\/\/cloud.ibm.com\/user\/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n\n\n\n\n How am I charged for support? \n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\n\n\n\n\n How can I upgrade my support plan? \n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\n\n\n\n\n Why can't I see my support cases? \n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-get-supportfaq"},{"document_id":"ibmcld_03776-1678-3763","score":0.0158730159,"text":"\nIf you use tags to organize your resources such as by team or cost center, you can sort your instance report by the tags to identify the associated usage.\n\nSetting spending limits is another helpful way to keep an eye on usage in your account. You can set notifications for total account, runtime, container, and service spending. When you reach a percentage of the spending limit that you set, you are notified immediately by email.\n\nTo view your current balance, manage your payment method, or make a one-time payment, go to the Payments page. You can download your latest invoice with all discounts and charges here or from the Invoices page.\n\nNow that you've walked through the common billing options and how to delegate billing administrator capabilities, track usage, and pay your bill, you're ready to start deciding what is best for your account. As always, if you need more information, check out the documentation for IBM Cloud billing and usage.\n\n\n\n\n\n How does billing work in IBM Cloud? \n\nIBM Cloud has two billable account types, Pay-As-You-Go and Subscription accounts. With a billable account, you can use IBM Cloud resources and services that incur costs. The account type that you choose impacts how you're billed for your resource usage.\n\nWhen you have a Pay-As-You-Go account, you're billed monthly for your resource usage. You pay only for what you use, with no long-term contracts. As your resource usage changes, so does your invoice, similar to a utility bill. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads.\n\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_07578-1033424-1035350","score":0.015625,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_09887-7-2096","score":0.015625,"text":"\nQueue manager sizes \n\nLearn about the characteristics of IBM queue managers available to deploy on IBM Cloud.\n\n\n\n Lite queue managers \n\nTo give you a taste of MQ as a managed service, the IBM MQ on Cloud service offers a Lite queue manager. If you do not currently have a Lite queue manager deployed, you can create one by following the [creating a queue manager](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_create_qm) guide.\n\nNote:\n\n\n\n* You can deploy up to two Lite queue managers per Lite service instance\n* You can delete an existing Lite queue manager and deploy a new one at any time\n* Lite queue managers will automatically be deleted after 30 days of inactivity but you are welcome to deploy a new one\n* A Lite queue manager is considered active if you have sent a message (using a non-SYSTEM queue), or have logged in to the service instance via the IBM Cloud user interface\n* You will never be charged for a Lite queue manager\n* Whilst all billable queue managers have regular backups taken, please note that backups of Lite queue managers are not taken and therefore user configuration is non-recoverable\n\n\n\n\n\n\n\n Billable queue managers \n\nThe IBM MQ on Cloud service offers the following billable queue manager sizes:\n\n\n\n* Extra Small: Appropriate for very light or occasional workloads with modest throughput requirements\n* Small: Appropriate for light workloads such as supporting an individual department or application\n* Medium: Appropriate for shared use by a number of light to moderate workload applications\n* Large: Appropriate for heavy throughput scenarios where transaction performance is critical\n\n\n\nA billable queue manager is charged based on the number of Virtual Processor Core (VPC) hours that it is active - for example, a Large size queue manager is charged at four times (4x) the rate of a Small size queue manager. The hourly cost is dependent on your local currency and can be seen in the Pricing Plan at the bottom of the [MQ service catalog page](https:\/\/cloud.ibm.com\/catalog\/services\/mq), where you can select your country or region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-qm_sizes"},{"document_id":"ibmcld_16727-1033295-1035221","score":0.0153846154,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03749-8477-10695","score":0.0153846154,"text":"\nFor more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03765-5710-7263","score":0.0327868852,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_07578-1044428-1046278","score":0.0322580645,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":0.0317460317,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-3030-4892","score":0.03125,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03765-4100-6125","score":0.0307692308,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars \n\nDue to current banking regulations, recurring credit card transactions might be unsuccessful for India-based customers with accounts that are billed in US Dollars. You can use one of the following methods to make a payment:\n\n\n\n* [Make a one-time payment](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagemakepayment)\n* Request to migrate your account to be billed in India Rupees. To make a request, provide a credit card that is billed in India Rupees on the [Payment Method](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. Specify that India Rupees are in the Payment Currency section. Additional information might be requested through a Support case during the migration process.\n\n\n\n\n\n\n\n Making a one-time payment \n\nYou can use a credit card to make a one-time payment at any time for any amount, whether it's for the full balance or a partial sum. The details that you enter for the one-time payment aren't recorded for future use, and aren't populated with a default amount.\n\nTo make a one-time payment, in the IBM Cloud console, go to Manage > Billing and usage, and select Payments. Click Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03713-6236-8279","score":0.0303030303,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03765-2725-4571","score":0.0298507463,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03776-5228-7163","score":0.0294117647,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03793-7-1857","score":0.0289855072,"text":"\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https:\/\/cloud.ibm.com\/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm"},{"document_id":"ibmcld_03704-4411-6289","score":0.0285714286,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03771-7-2029","score":0.0327868852,"text":"\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http:\/\/ibm.com\/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03771-1594-3365","score":0.0322580645,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03764-2220-3440","score":0.0317460317,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_07578-1065299-1067188","score":0.03125,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1066874-1068548","score":0.0307692308,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03795-7-1690","score":0.0303030303,"text":"\nWhy can't I view the invoices for my Pay-As-You-Go or Subscription account in the console? \n\nInvoices that are managed outside of the console can not be viewed by going to Manage > Billing and Usage > Invoices in the IBM Cloud console.\n\n What\u2019s happening \n\nAs a Pay-As-You-Go or Subscription account owner, you might not be able to view your invoices from the Invoices page in the IBM Cloud console.\n\nWhen you try to view your invoices, one of the following messages is displayed:\n\nYour invoices are managed through IBM.com.\n\nThis account is invoiced on a separate billing platform.\n\n Why it\u2019s happening \n\nIf you have a Pay-As-You-Go account that is billed in a currency other than US dollars or a Subscription account, you view your invoices on the [IBM Invoices](https:\/\/www.ibm.com\/support\/customer\/invoices\/) website, which is linked from the Invoices page in the console.\n\n How to fix it \n\nIf you're visiting the Invoices website for the first time, sign up with your IBMid and complete your profile. Then, add access to your account with your IBM customer number.\n\n\n\n1. Go to [IBM Invoices](https:\/\/www.ibm.com\/support\/customer\/invoices\/), and select your region.\n2. Log in with the same IBMid and password that you use to log in to IBM Cloud.\n3. Complete your profile on the Invoices website.\n4. From the Invoices website, go to the Accesses tab. Add access to your account and provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option or contact the [eCustomer Care team](https:\/\/www-112.ibm.com\/software\/howtobuy\/passportadvantage\/paocustomer\/docs\/en_US\/ecare.html) for help.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice"},{"document_id":"ibmcld_07578-1064084-1065746","score":0.0296312555,"text":"\nFor more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-1062822-1064465","score":0.0296312555,"text":"\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03764-7-1642","score":0.0289855072,"text":"\nFAQs for invoices \n\nReview the following FAQs to find helpful information about invoices. To find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Where can I access my invoice? \n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n\n\n\n\n\n Why does my usage not match my invoice? \n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I manage my invoices? \n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_16727-1068047-1069909","score":0.0285714286,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.787702057,"ndcg_cut_10":0.787702057}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03786-7-2105","score":0.0320184426,"text":"\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https:\/\/cloud.ibm.com\/billing\/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https:\/\/www.ibm.com\/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_12597-0-804","score":0.0315136476,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03786-1684-3421","score":0.031024531,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03704-8977-10890","score":0.0308861962,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03785-7-2010","score":0.0305503731,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_07578-1050413-1052321","score":0.0304147465,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1068047-1069909","score":0.0300904977,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1065299-1067188","score":0.0296442688,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03710-0-838","score":0.0292110874,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_16727-1050284-1052192","score":0.0158730159,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3010299957}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07191-7-2252","score":0.0327868852,"text":"\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07178-6197-7974","score":0.0322580645,"text":"\n[Example query structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/query_structure2.png)\n\nOperators that evaluate a field (<= , >=, <, >) require a number or date as the value. Using quotations around a value always makes it a string. Therefore score>=0.5 is a valid query and score>=\"0.5\" is not. See [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators) for a complete list of operators.\n\nConsiderations:\n\n\n\n* Not sure when to query on an entity, concept, or keyword? See [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).\n\n\n\nAfter you click Run query and open the JSON tab, query highlighting is turned on, by default. The setting adds a highlight field to your query results. Within the highlight field, the words that match your query are wrapped in HTML <em> (emphasis) tags. For more information, see the [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight).\n\n\n\n\n\n\n\n Building combined queries \n\nYou can combine query parameters together to build more targeted queries. For example, you can use the both the filter and query parameters together. For more information about filtering vs. querying, see [Differences between the filter and query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfiltervquery).\n\n\n\n\n\n How to structure an aggregation \n\nAggregations return a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see [Aggregations](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_02590-7911-9371","score":0.0317460317,"text":"\nTo prevent [dangerous client bugs and backward-compatibility hazards](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-robustnesssanitation-and-validation), unrecognized query parameters SHOULD and invalid parameter values MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Case insensitivity \n\nQuery parameter names SHOULD NOT be case-normalized to support case insensitivity; a parameter that does not match the case of a defined parameter but otherwise matches its name SHOULD be treated as any other extraneous input\n\n[4].\n\nHowever, parameter name case normalization MAY be supported for backward compatibility with existing clients.\n\n\n\n\n\n Parameter duplication \n\nRequests that provide a query string with duplicate single-value\n\n[5]query parameters of the same name and differing values[6] MUST result in a 400 status and appropriate error response model. For backward compatibility with existing clients, query strings containing duplicate query parameters of the same name and with the same value MAY be supported [7].\n\nIf a service supports parameter name [case insensitivity](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uriscase-insensitivity), parameter names MUST be normalized prior to validating uniqueness.\n\nSupport for array input in query parameters SHOULD use comma-separated values within a single parameter (for example, foo=1,2,3) instead of duplicated\n\n[8]parameters ( foo=1&foo=2&foo=3).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uris"},{"document_id":"ibmcld_07191-1691-3739","score":0.03125,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_13406-1732-4088","score":0.0307692308,"text":"\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_07098-7-2215","score":0.0303030303,"text":"\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataquery). For an overview of query concepts, see the [Query overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07067-26099-28206","score":0.0298507463,"text":"\nIf false, ranks the passages from all of the documents by passage quality regardless of the document quality and returns them in a separate passages field in the response.\n* When passages are returned for a query, you can also enable answer finding. When true, answer objects are returned as part of each passage in the query results. When find_answers and per_document are both set to true, the document search results and the passage search results within each document are reordered by using the answer confidences. The goal of this reordering is to place the best answer as the first answer of the first passage of the first document. Similarly, if the find_answers parameter is set to true and per_document parameter is set to false, then the passage search results are reordered in decreasing order of the highest confidence answer for each document and passage.\n* Both v1 and v2 support custom stop words. However, there are a few differences in how custom stop words are used:\n\n\n\n* There is no default custom stop words list for Japanese collections in v2.\n* When you define custom stop words in v1, your stop words list replaces the existing stop words list. In v2, your list augments the default list. You cannot replace the list, which means you cannot remove stop words that are part of the default list in v2.\n\n\n\n\n\n\n\n Update how your application handles query results \n\nThe way that your application shows query results might need to be updated due to the following differences between the query results document syntax between the v1 and v2 queries:\n\n\n\n* At the entity enrichment level, the following information is not supported in v2:\n\n\n\n* Disambiguation\n* Emotion\n* Sentiment\n\n\n\nThe Part of Speech enrichment is applied automatically to documents in most project types in v2, but the index fields that are generated by the enrichment are not displayed in the JSON representation of the document.\n\nZoom\n\n![Difference in entities data structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/compare-result-syntax.png)\n\nFigure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_13446-15041-17074","score":0.0294117647,"text":"\nAvailability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Generally available or beta for next-generation models that support low latency. For more information, see [Supported next-generation language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ngmodels-ng-supported). \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n max_alternatives \n\nAn optional integer that specifies the maximum number of alternative hypotheses that the service returns. By default, the service returns a single final hypothesis. For more information, see [Maximum alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metadatamax-alternatives).\n\n\n\nTable 17. The max_alternatives parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n model \n\nAn optional model that specifies the language in which the audio is spoken and the rate at which it was sampled: broadband\/multimedia or narrowband\/telephony. By default, en-US_BroadbandModel is used. For more information, see [Using a model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-use).\n\n\n\nTable 18. The model parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n processing_metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_03285-5746-7932","score":0.0289855072,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":0.0285714286,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3692678015}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-1284-2889","score":0.0325224749,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-7-1700","score":0.0322664585,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-7-1568","score":0.0314980159,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10833-0-1231","score":0.0310096154,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_10852-48513-49624","score":0.0305361305,"text":"\n* [Reading an object with the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_arch)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_13429-163247-165127","score":0.0300768883,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13455-26115-26611","score":0.0296312555,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13741-1529-3393","score":0.029198636,"text":"\nSynthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's \/v1\/synthesize method. The two versions of the method offer generally equivalent functionality. You pass the text that is to be synthesized as a query parameter with the GET method and as the body of the request with the POST method.\n* [The WebSocket interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket) provides a \/v1\/synthesize method. You pass the text that is to be synthesized over an established WebSocket connection.\n\n\n\nWith both the HTTP and WebSocket interfaces, you specify the language and voice that are to be used, and the format for the audio that is to be returned.\n\n\n\n* For an overview of the features that are available for speech synthesis, see [Using speech synthesis features](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-featuresfeatures-synthesis).\n* For detailed descriptions and examples of the speech synthesis methods, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of text with a single request:\n\n\n\n* The HTTP GET \/v1\/synthesize method accepts a maximum of 8 KB of input, which includes the input text and the URL and headers.\n* The HTTP POST \/v1\/synthesize method accepts a maximum of 8 KB for the URL and headers, and a maximum of 5 KB for the input text that is sent in the body of the request.\n* The WebSocket \/v1\/synthesize method accepts a maximum of 5 KB of input text.\n\n\n\nThese limits include all characters of the input, including whitespace.\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-features"},{"document_id":"ibmcld_13384-7-1898","score":0.0161290323,"text":"\nUsing a custom language model for speech recognition \n\nOnce you create and train your custom language model, you can use it in speech recognition requests by using the language_customization_id query parameter. By default, no custom language model is used with a request. You can create multiple custom language models for the same or different domains. But you can specify only one custom language model at a time for a speech recognition request. You must issue the request with credentials for the instance of the service that owns the custom model.\n\nA custom model can be used only with the base model for which it is created. If your custom model is based on a model other than the default, you must also specify that base model with the model query parameter. For more information, see [Using the default model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-usemodels-use-default).\n\nFor information about telling the service how much weight to give to words from a custom model, see [Using customization weight](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageUseweight). For examples that use a grammar with a custom language model, see [Using a grammar for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse).\n\n\n\n Examples of using a custom language model \n\nThe following examples show the use of a custom language model with each speech recognition interface. In this case, the custom model that is used is based on the next-generation model en-US_Telephony.\n\n\n\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), use the \/v1\/recognize method. The specified custom model is used for all requests that are sent over the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageUse"},{"document_id":"ibmcld_03285-5746-7932","score":0.0144927536,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.5249810332}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-1284-2889","score":0.0327868852,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-7-1700","score":0.0322580645,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-7-1568","score":0.0317460317,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10833-0-1231","score":0.03125,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_10852-48513-49624","score":0.0307692308,"text":"\n* [Reading an object with the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_arch)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_13429-163247-165127","score":0.0303030303,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13455-26115-26611","score":0.0298507463,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13741-1529-3393","score":0.0294117647,"text":"\nSynthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's \/v1\/synthesize method. The two versions of the method offer generally equivalent functionality. You pass the text that is to be synthesized as a query parameter with the GET method and as the body of the request with the POST method.\n* [The WebSocket interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket) provides a \/v1\/synthesize method. You pass the text that is to be synthesized over an established WebSocket connection.\n\n\n\nWith both the HTTP and WebSocket interfaces, you specify the language and voice that are to be used, and the format for the audio that is to be returned.\n\n\n\n* For an overview of the features that are available for speech synthesis, see [Using speech synthesis features](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-featuresfeatures-synthesis).\n* For detailed descriptions and examples of the speech synthesis methods, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of text with a single request:\n\n\n\n* The HTTP GET \/v1\/synthesize method accepts a maximum of 8 KB of input, which includes the input text and the URL and headers.\n* The HTTP POST \/v1\/synthesize method accepts a maximum of 8 KB for the URL and headers, and a maximum of 5 KB for the input text that is sent in the body of the request.\n* The WebSocket \/v1\/synthesize method accepts a maximum of 5 KB of input text.\n\n\n\nThese limits include all characters of the input, including whitespace.\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-features"},{"document_id":"ibmcld_13455-1311-2796","score":0.0289855072,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-5746-7932","score":0.0285714286,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.4414924137,"ndcg_cut_10":0.4414924137}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09902-1273-2070","score":0.0163934426,"text":"\n* Example parameters.json file:\n\n{\n\"url\": \"www.url.example\",\n\"features\": {\n\"entities\": {\n\"model\": \"your-model-id-here\"\n},\n\"relations\": {\n\"model\": \"your-model-id-here\"\n}\n}\n}\n* Example curl request:\n\ncurl --user \"apikey\":\"{apikey}\" \"{url}\/v1\/analyze?version={date}\" --request POST --header \"Content-Type: application\/json\" --data @parameters.json\n\n\n\n\n\n\n\n Deleting custom entities and relations models \n\nTo delete an entities or relations model from your service instance, use the Delete model method. Replace {url} and {apikey} with your service URL and API key, and replace {model_id} with the model ID of the model you want to delete.\n\n\n\n* The following example undeploys an entities or relations model.\n\ncurl --user \"apikey\":\"{apikey}\" \"{url}\/v1\/models\/{model_id}?version={date}\"\n--request DELETE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entities-and-relations"},{"document_id":"ibmcld_03037-2895-4808","score":0.0163934426,"text":"\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics \n\nUser metrics allow you to see, for example, the number of unique users who have engaged with your assistant, or the average number of conversations per user over a given time interval on the [Overview page](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview). User metrics are enabled by using a unique User ID parameter.\n\nTo specify the User ID for a message sent using the \/message API, include the user_id property in your global [context](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2message), as in this example:\n\n\"context\": {\n\"global\": {\n\"system\": {\n\"user_id\": \"{UserID}\"\n}\n}\n}\n\nIf your application is still using the older [v1 runtime API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1?curl=message), the context format is different:\n\n\"context\" : {\n\"metadata\" : {\n\"user_id\": \"{UserID}\"\n}\n}\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_09902-7-1469","score":0.0161290323,"text":"\nCreating custom entities and relations models \n\nThe Natural Language Understanding Free plan limits the size and performance of your custom model. To test a custom model to its full extent, use it with the Natural Language Understanding Standard plan.\n\n\n\n1. [Get started with Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutintro).\n2. Create a custom model.\n\n\n\n1. To create a custom entities and relations model, see [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro)\n2. You can also create a custom entities model with a rule-based model. See [Creating a rule-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutrule_intro) for details.\n\n\n\n3. [Deploy your model to Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlwks_manlu)\n4. To use your model, specify the model that you deployed in the [entities](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understandingentities) or [relations](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understandingrelations) options of your API request:\n\n\n\n* Example parameters.json file:\n\n{\n\"url\": \"www.url.example\",\n\"features\": {\n\"entities\": {\n\"model\": \"your-model-id-here\"\n},\n\"relations\": {\n\"model\": \"your-model-id-here\"\n}\n}\n}\n* Example curl request:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entities-and-relations"},{"document_id":"ibmcld_07390-54955-56227","score":0.0161290323,"text":"\nIf not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nUpdate location 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-location-update f1aba936b94213e5b8dca0c0dbf1f9cc 9a234ede-c2b6-4c39-bc27-d39ec139ecdb --subnet crn:v1:bluemix:public:is:us-south-1:a\/01652b251c3ae2787110a995d8db0135::subnet:0716-b49ef064-0f89-4fb1-8212-135b12568f04 --enabled true -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-location-delete \n\nDelete custom resolver location for a service instance.\n\nibmcloud dns custom-resolver-location-delete RESOLVER_ID LOCATION_ID [-i, --instance INSTANCE] [-f, --force]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\nLOCATION_ID\n: The ID of custom resolver location.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n---f, --force\n: Delete custom resolver location without prompting for confirmation.\n\n\n\n\n\n Examples \n\nDelete location 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"},{"document_id":"ibmcld_13182-11477-13252","score":0.0158730159,"text":"\nIn this example template, the creation is fully controlled though Terraform variables - you do not need to change the actual Terraform template, for example if you need more networks or virtual machines. An example terraform.tfvars-example file is provided and example values are provided with explanations.\n\nBefore you begin, copy the example terraform.tfvars-example to terraform.tfvars, for example:\n\ncp terraform.tfvars-example terraform.tfvars\n\nYou can use it as such, add more networks, more virtual machines and customize NAT or firewall rules and so on based on your needs.\n\n\n\n1. Set the following common variable to access your instance and virtual data center.\n\n Note. Variable values to access your Director instance. Use the Director portal\n to figure our your values here.\n\nvmwaas_url = \"put-your-director-url-here\" for example \"https:\/\/abcxyz.us-south.vmware.cloud.ibm.com\/api\"\nvmwaas_org = \"put-your-org-id-here\"\nvmwaas_vdc_name = \"put-your-vdc-name-here\"\n\nvmwaas_user = \"put-your-username-here\"\nvmwaas_password = \"put-your-password-here\"\nvmwaas_api_token = \"\" Note. This will be supported in the near future.\n\nFor these variables, you could alternatively create environment variables named TF_VAR_ for vmwaas_user and vmwaas_password rather than defining them in terraform.tfvars as shown through the vmwaas.sh script. In this case, comment these lines out in your terraform.tfvars.\n\nIf you change the authentication method, the provider block in the code needs to changed to use a different authentication method. Currently only username and password method is supported in IBM Cloud\u00ae for VMware as a Service - single tenant instance.\n2. Set a common name prefix to identify and separate your virtual data center networks, virtual machines and so on.\n\n Note.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-as-a-service-tf"},{"document_id":"ibmcld_04345-54935-56207","score":0.0158730159,"text":"\nIf not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nUpdate location 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-location-update f1aba936b94213e5b8dca0c0dbf1f9cc 9a234ede-c2b6-4c39-bc27-d39ec139ecdb --subnet crn:v1:bluemix:public:is:us-south-1:a\/01652b251c3ae2787110a995d8db0135::subnet:0716-b49ef064-0f89-4fb1-8212-135b12568f04 --enabled true -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-location-delete \n\nDelete custom resolver location for a service instance.\n\nibmcloud dns custom-resolver-location-delete RESOLVER_ID LOCATION_ID [-i, --instance INSTANCE] [-f, --force]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\nLOCATION_ID\n: The ID of custom resolver location.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n---f, --force\n: Delete custom resolver location without prompting for confirmation.\n\n\n\n\n\n Examples \n\nDelete location 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"},{"document_id":"ibmcld_16276-5813-8052","score":0.015625,"text":"\nIf you expect customers to typically make a request about a specific type of claim, such as auto, home, or medical, you might not want to ask another question about what type. They might say I need to file an auto claim or I want to make a home claim.\n\nAlthough you still need a step that collects the answer about the type of claim, you might not want or need to ask that explicit question, especially if your assistant is used with the phone integration. Instead, you can create a step with the claim options, but set it to never ask.\n\nThis table shows how you might set up the steps. The last step is a catch-all in case the customer doesn't mention the claim type initially.\n\n\n\nExample using the never ask response setting\n\n Step Conditions Assistant says Customer response Customer response setting And then \n\n 1 None What kind of claim? Options: Automobile, Homeowner, Medical Never ask Continue to the next step \n 2 Step 1 is Automobile None Click here to file an automobile claim Skip (default) End the action \n 3 Step 1 is Homeowner None Click here to file a homeowner claim Skip (default) End the action \n 4 Step 1 is Medical None Click here to file a medical claim Skip (default) End the action \n 5 Step 1 is not defined (no claim type) None Click here to file an insurance claim Skip (default) End the action \n\n\n\n\n\n\n\n\n\n\n\n Customer response types \n\nThe configuration information that you must provide varies by response type.\n\n\n\n Options \n\nAn options response presents customers with a list of choices to select from. How these options are presented depends upon how your customers connect to the assistant. In the web chat integration, the options are shown as clickable buttons (for 4 or fewer options) or as a drop-down list (for more than 4 options).\n\nThere are two ways to create the list:\n\n\n\n* Enter a list of options and synonyms\n* Generate a dynamic list from a variable\n\n\n\n\n\n Entering a list of options and synonyms \n\nEnter each choice in the Option fields. You can click Add synonyms to enter variations of an option value that customers might type. You can enter multiple synonyms in a comma-separated list.\n\nFor example, you might define the following options and synonyms:\n\n\n\nOptions example\n\n Option value Synonyms","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-info"},{"document_id":"ibmcld_07390-50922-52362","score":0.015625,"text":"\nibmcloud dns custom-resolver-update RESOLVER_ID [--name NAME] [--enabled true|false] [--description DESCRIPTION] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\n-n, --name\n: The name of the custom resolver.\n\n-d, --description\n: The descriptive text of the custom resolver.\n\n--enabled\n: Whether to enable the custom resolver.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nUpdate a custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-update f1aba936b94213e5b8dca0c0dbf1f9cc --name \"example\" --enabled true -description \"demo\" -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver \n\nGet a custom resolver details for a service instance.\n\nibmcloud dns custom-resolver RESOLVER_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nGet a custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver f1aba936b94213e5b8dca0c0dbf1f9cc -i \"dns-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"},{"document_id":"ibmcld_13880-16435-16974","score":0.0153846154,"text":"\n* Use social identity providers.\n* Add a date picker to the statistics page to filter displayed data.\n* Use a custom login page for App ID.\n\n\n\n\n\n\n\n Related Content \n\nHere are links to additional information on the topics covered in this tutorial. The app itself is available in this [GitHub repository](https:\/\/github.com\/IBM-Cloud\/github-traffic-stats).\n\nDocumentation:\n\n\n\n* [App ID documentation](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-getting-started)\n* [Db2 on Cloud](https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-about)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-serverless-github-traffic-analytics"},{"document_id":"ibmcld_04345-50902-52342","score":0.0153846154,"text":"\nibmcloud dns custom-resolver-update RESOLVER_ID [--name NAME] [--enabled true|false] [--description DESCRIPTION] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\n-n, --name\n: The name of the custom resolver.\n\n-d, --description\n: The descriptive text of the custom resolver.\n\n--enabled\n: Whether to enable the custom resolver.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nUpdate a custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-update f1aba936b94213e5b8dca0c0dbf1f9cc --name \"example\" --enabled true -description \"demo\" -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver \n\nGet a custom resolver details for a service instance.\n\nibmcloud dns custom-resolver RESOLVER_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nGet a custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver f1aba936b94213e5b8dca0c0dbf1f9cc -i \"dns-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":0.0327868852,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03179-4-1759","score":0.0317460317,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16280-3111-5196","score":0.0310096154,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_16291-1353-3298","score":0.0308349146,"text":"\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_03158-4-2042","score":0.0305361305,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nBy adding the phone integration to your assistant, you can make your assistant available to customers over the phone.\n\nWhen you add the phone integration to your assistant, you can automatically generate a working phone number that is automatically connected to your assistant. Or, if you prefer, you can connect the assistant to your existing infrastructure by configuring an existing Session Initiation Protocol (SIP) trunk.\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX). If you choose to generate a free phone number for your assistant, a SIP trunk is automatically provisioned from IntelePeer. You can also choose to use an existing SIP trunk from a provider such as IntelePeer, Genesys, or Twilio.\n\nGenerating a free phone number is available only with new phone integrations. If you have an existing phone integration and you want to switch to a free phone number, you must delete the existing integration and create a new one.\n\nWhen your customer makes a phone call using the telephone number connected to your assistant, the phone integration answers. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service. The audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16297-7-1893","score":0.0289915966,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_16287-2974-4988","score":0.0161290323,"text":"\nChoose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are integrating with a contact center, follow the instructions to configure the contact center. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Select contact center page, select the tile of the connect center you would like to use.\n2. On the Connect to contact center page, enter the required information. There is a Test Connection button on the page to validate the connection. Click Next.\n\n\n\n6. If you are using an existing phone number, follow the instructions to configure the SIP trunk. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n\n\n\n7. On the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16287-7-2037","score":0.015625,"text":"\nIntegrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nAdding the phone integration to your assistant makes your assistant available to customers over the phone.\n\nIf an end user asks to speak to a person, the phone integration can transfer the call to an agent. Supported live agent and contact center integrations:\n\n\n\n* Genesys\n* Twilio Flex\n* NICE CXone\n* Bring your own\n\n\n\nThere are several ways to add the phone integration to your assistant:\n\n\n\n* You can generate a free phone number that is automatically provisioned from IntelePeer. This is available only with new phone integrations. If you have an existing phone integration, you must delete it and create a new one to switch to a free phone number.\n* You can connect to a contact center with live agents. For more information about setting up the integration, see [Integrating with phone and NICE CXone contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone).\n* You can use and connect an existing number by configuring a Session Initiation Protocol (SIP) trunk from a provider such as Genesys, IntelePeer, or Twilio.\n\n\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03158-2940-4987","score":0.0151515152,"text":"\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03165-4477-6547","score":0.0149253731,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-6287-8401","score":0.0327868852,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03165-4477-6547","score":0.0322580645,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16288-1733-3996","score":0.0317460317,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03216-18448-20174","score":0.03125,"text":"\ndtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json"},{"document_id":"ibmcld_16321-7-1807","score":0.0307692308,"text":"\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16337-10301-11908","score":0.0303030303,"text":"\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n{\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}\n},\n\"channels\":\n{\n\"channel\": \"voice_telephony\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n end_session \n\nSends a command to the channel ending the session. This response type instructs the phone integration to hang up the call.\n\n\n\n Integration channel support \n\n\n\n Phone SMS \n\n ![Yes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/checkmark-icon.svg) \n\n\n\n\n\n* The SMS integration supports ending a session by using the terminateSession action command.\n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_16321-1374-3426","score":0.0298507463,"text":"\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:\n\n\n\n* [Define a sequence of phone commands](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sequence)\n\n\n\nYou can also perform the following phone-specific actions:\n\n\n\n* [Inject custom values into CDR log events](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-cdr-custom-data)\n* [Access phone integration context variables from your action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-access-context-variables)\n\n\n\nFor reference information about response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\n Adding phone-specific responses to your assistant \n\nTo initiate a voice-specific interaction from a an action step, add a response within the generic array using the appropriate response type. For more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-assistant-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from an action step, you can dynamically change the Speech to Text configuration during a conversation.\n\nBy default, any Speech to Text configuration changes you make persist for the remainder of the conversation, or until you update them again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03179-4-1759","score":0.0294117647,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16337-9125-10721","score":0.0289855072,"text":"\nName Type Description Required? \n\n response_type string date Y \n\n\n\n\n\n\n\n Example \n\nThis example sends a text response asking the user to specify a date, and then shows an interactive date picker.\n\n{\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"What day will you be checking in?\"\n},\n{\n\"response_type\": \"date\"\n}\n]\n}\n\n\n\n\n\n\n\n dtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Integration channel support \n\n\n\n Phone \n\n ![Yes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=phone-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_03285-1272-3273","score":0.0285714286,"text":"\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same dialog node or step. For more information, see [Defining a sequence of phone actions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sequence).\n\nFor reference information about phone-specific repsonse types and related context variables, see [Phone context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context).\n\n\n\n Adding phone-specific responses to your dialog or actions \n\nTo initiate a voice-specific interaction from a dialog node or a step in an action, add a response within the output.generic array using the appropriate response type.\n\nAlthough many response types can be specified using the Watson Assistant user interface, phone-specific response types must currently be added using the JSON editor.\n\nFor more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from a dialog node or action step, you can dynamically change the Speech to Text configuration during a conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.9197207891,"ndcg_cut_5":0.9197207891,"ndcg_cut_10":0.9197207891}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03165-4477-6547","score":0.0327868852,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16290-4708-6492","score":0.0315136476,"text":"\n[Genesys simulate call](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/phone-genesys-simulate-call.png)\n16. Go to Phone Management and click Create new. Specify the following information:\n\n\n\n* In the Phone Name field, specify a descriptive name.\n* In the Base Settings field, select WebRTCPhone.\n* In the Site field, select the site you want to use.\n* In the Person field, select yourself.\n\n\n\n17. In the Watson Assistant user interface, [create a new phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phonedeploy-phone-setup). Specify the following information:\n\n\n\n* When prompted, select Use an existing phone number with an external provider.\n* Specify the phone number you assigned in the Genesys Number Plans setting. This is not necessarily a real phone number; it is just the identifier you assigned.\n* Complete the phone integration setup process. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone).\n* After the phone integration is set up, go to the SIP trunk tab and uncheck the Don't place callers on hold while transferring to a live agent option.\n\n\n\n18. In the Genesys Cloud console, click the circle in the upper left corner. Select Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to a live agent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys"},{"document_id":"ibmcld_03367-4-2117","score":0.031024531,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Phone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by your dialog or actions \n\n\n\nVoice context variables set by the dialog or actions\n\n Name Type Description Default \n\n final_utterance_timeout_count Number The time (in milliseconds) that the phone integration waits to receive a final utterance from the Speech to Text service. The timeout occurs if the phone integration does not receive a final utterance within the specified time limit, even if hypotheses continue to be generated. When the timeout occurs, the phone integration sends Watson Assistant a text update that includes the word vgwFinalUtteranceTimeout to indicate that no final utterance was received. N\/A \n post_response_timeout_count Number The time (in milliseconds) to wait for a new utterance after the response is played back to the caller. When this timeout occurs, the phone integration channel sends a text message to the assistant that includes the word vgwPostResponseTimeout and sets the context variable input.integrations.voice_telephony.post_response_timeout_occurred to true. 7000 \n turn_settings.timeout_count Number The time (in milliseconds) to wait for a response from Watson Assistant. If this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_03179-4-1759","score":0.0305503731,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_03179-1292-3261","score":0.0296703297,"text":"\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account and follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:\n\n\n\n* Phone Number: Specify the Twilio phone number that you created earlier.\n\nConsider provisioning more than one phone number and going through the process of getting permission for the numbers in parallel. If your number was used by a different business previously (because Twilio assigned you a number that was used before, for example), WhatsApp will reject it.\n* Are you working with an ISV: No\n* Twilio Account SID: From the Twilio site, click the home icon to go to your project dashboard to find the SID.\n* Facebook Business Manager ID: Add the ID for the account that you created in the previous step.\n\n\n\n4. Click Request Now.\n\n\n\nGive WhatsApp time to evaluate and approve your request. It can take up to 7 days for your request to be approved.\n\n\n\n\n\n Set up the integration \n\nTo set up the integration, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16287-7751-9832","score":0.0296442688,"text":"\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images\/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16297-7-1893","score":0.0296312555,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_03161-5817-7635","score":0.0161290323,"text":"\n* In the Person field, select yourself.\n\n\n\n17. In the Watson Assistant user interface, create a new phone integration. Specify the following information:\n\n\n\n* When prompted, select Use an existing phone number with an external provider.\n* Specify the phone number you assigned in the Genesys Number Plans setting. (Remember, this is not necessarily a real phone number; it is just the identifier you assigned.)\n* Complete the phone integration setup process. (For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone).)\n* After the phone integration is setup, go to the SIP trunk tab and uncheck the Don't place callers on hold while transferring to a live agent option.\n\n\n\n18. In the Genesys Cloud console, click the circle in the upper left corner. Select Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.!\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to an agent \n\nNow that your Genesys Cloud environment can connect to Watson Assistant, you can set up the ability for your assistant to transfer calls back to your human agents. To do so, follow these steps:\n\n\n\n1. In the Genesys Cloud console, go to DID Numbers -> DID Ranges and create a new range. Specify the following information:\n\n\n\n* In the DID Start and DID End fields, specify a phone number. (Once again, you do not need to use a real phone number; you can just make up an identifier for your Genesys environment, such as 1-888-888-1234.)\n\n\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys"},{"document_id":"ibmcld_16288-3499-5184","score":0.0158730159,"text":"\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.\n\nThe SIP INVITE request can include metadata about the call in headers that can be extracted and sent to your assistant using context variables. For example, many companies use Interactive Voice Response (IVR) systems that pass information about an incoming call by using SIP headers. If you want to make use of any of these headers, list the header names here.\n\nThe specified headers, if present in the request, are stored in the context variable sip_custom_invite_headers, along with other related metadata that is automatically extracted from the SIP INVITE. This variable is an array in which each key\/value pair represents a header from the request, as in this example:\n\n{\n\"input\": {\n\"text\": \"\",\n...\n},\n\"context\" : {\n\"global\" : {...},\n\"skills\" : {...},\n\"integrations\" : {\n\"voice_telephony\": {\n\"private\":{\n\"user_phone_number\":\"+18594213456\",\n},\n\"sip_call_id\": \"Aob2-2743-5678-1234\",\n\"assistant_phone_number\":\"+18882346789\",\n\"sip_custom_invite_headers\": {\n\"X-customer-name\": \"my_name\",\n\"X-account-number\": \"12345\"\n}\n}\n}\n}\n}\nShow more\n\nYou can then reference these headers in your assistant. For example, you might check the header value in a step condition to determine the next step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-23545-25765","score":0.015625,"text":"\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2184074368}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07839-0-1665","score":0.0327868852,"text":"\n\n\n\n\n\n\n  PS-7 - Third-party Personnel Security \n\n\n\n  Control requirements \n\nThe organization:\n\nPS-7 (a)\n:   Establishes personnel security requirements including security roles and responsibilities for third-party providers;\n\nPS-7 (b)\n:   Requires third-party providers to comply with personnel security policies and procedures established by the organization;\n\nPS-7 (c)\n:   Documents personnel security requirements;\n\nPS-7 (d)\n:   Requires third-party providers to notify [Assignment: organization-defined personnel or roles] of any personnel transfers or terminations of third-party personnel who possess organizational credentials and\/or badges, or who have information system privileges within [IBM Assignment: same day]; and\n\nPS-7 (e)\n:   Monitors provider compliance.\n\n\n\n\n\n  NIST supplemental guidance \n\nThird-party providers include, for example, service bureaus, contractors, and other organizations providing information system development, information technology services, outsourced applications, and network and security management. Organizations explicitly include personnel security requirements in acquisition-related documents. Third-party providers may have personnel working at organizational facilities with credentials, badges, or information system privileges issued by organizations. Notifications of third-party personnel changes ensure appropriate termination of privileges and credentials. Organizations define the transfers and terminations deemed reportable by security-related characteristics that include, for example, functions, roles, and nature of credentials\/privileges associated with individuals transferred or terminated.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ps-7"},{"document_id":"ibmcld_14618-10735-13151","score":0.0322580645,"text":"\n* The client is responsible for providing in\u2013depth documentation at the time of a failure and responding timely to IBM Support when further clarification is needed.\n* Clients are also responsible for following the guidelines in this document to grant consent to proactive support.\n* By declining consent or failing to abide by the guidelines provided, the client assumes the responsibility of possible lag in problem resolution that is caused by communication delays between the client and support team.\n* The client must be prepared to perform more technical troubleshooting that would otherwise be done by IBM Support. IBM provides appropriate documentation and assistance where necessary.\n\n\n\n\n\n\n\n Security measures \n\n\n\n* Management of Cloud Service - Client is responsible for managing administration, operation, maintenance, and security of the applications, including underlying middleware.\n* Service Integrity and Availability - IBM forwards to the Client all network intrusion notifications detected for this Cloud Service. It is the Client\u2019s responsibility to ascertain the impact of each notification that is reported. Client is notified of hardware failures. Monitoring and responding to OS or software failures is the responsibility of the Client, engaging IBM support as required.\n* Activity Logging - Client is responsible for activity logging of OS\/System and Database\/Applications, as needed.\n* Encryption - Client is responsible for configuring and managing all encryption (for both data at rest and in transit), as needed.\n* Business Continuity and Disaster Recovery - Client is responsible for configuring and managing all business continuity and disaster recovery processes, as needed.\n\n\n\n\n\n\n\n Third-party services \n\n\n\n* Third-Party software or code is included or bundled with some of our IBM offerings. This code is included for your convenience but is not considered part of the IBM program.\n* These non\u2013IBM programs are licensed directly by their providers. Client agrees to use the non\u2013IBM programs under the provider\u2019s terms and conditions. These terms are provided in the IBM licensing agreement that accompanies the IBM offering at time of purchase.\n* IBM does testing to ensure that the third-party products work with IBM programs and that they function correctly.\n* IBM Support diagnoses client problems by using the knowledge of how our IBM offerings work with the Third-Party software.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_compl_info"},{"document_id":"ibmcld_16321-19290-20983","score":0.0317460317,"text":"\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_14636-9913-12364","score":0.03125,"text":"\n* The client is responsible for providing in\u2013depth documentation at the time of a failure and responding timely to IBM Support when further clarification is needed.\n* Clients are also responsible for following the guidelines set forth in this document to grant consent to proactive support.\n* By declining consent or failing to abide by the guidelines provided, the client assumes the responsibility of possible lag in problem resolution, which might be caused by communication delays between the client and support team.\n* The client should be prepared to perform more technical troubleshooting that would otherwise be done by IBM Support. IBM will provide appropriate documentation and assistance where necessary.\n\n\n\n\n\n\n\n Security measures \n\n\n\n* Management of Cloud Service - Client is responsible for managing administration, operation, maintenance, and security of the applications, including underlying middleware.\n* Service Integrity and Availability - IBM will forward to the Client all network intrusion notifications detected for this Cloud Service. It is the Client\u2019s responsibility to ascertain the impact of each notification that is reported. Client will be notified of hardware failures. Monitoring and responding to OS or software failures is the responsibility of the Client, engaging IBM support as required.\n* Activity Logging - Client is responsible for activity logging of OS\/System and Database\/Applications, as needed.\n* Encryption - Client is responsible for configuring and managing all encryption (for both data at rest and in transit), as needed.\n* Business Continuity and Disaster Recovery - Client is responsible for configuring and managing all business continuity and disaster recovery processes, as needed.\n\n\n\n\n\n\n\n Third-party services \n\n\n\n* Third-Party software or code is included or bundled with some of our IBM offerings. This code is included for your convenience but is not considered part of the IBM program.\n* These non\u2013IBM programs are licensed directly by their providers. Client agrees to use the non\u2013IBM programs under the provider\u2019s terms and conditions. These terms are provided in the IBM licensing agreement that accompanies the IBM offering at time of purchase.\n* IBM does testing to ensure that the third-party products work with IBM programs and that they function correctly.\n* IBM Support will diagnose client's problems by using the knowledge of how IBM offerings work with the Third-Party software.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_hybrid_compl_info"},{"document_id":"ibmcld_16288-10521-12298","score":0.0307692308,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16250-5445-7809","score":0.0303030303,"text":"\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03158-17978-19852","score":0.0298507463,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. Click Customer success as the case type.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03312-5487-7760","score":0.0294117647,"text":"\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16288-7-2218","score":0.0289855072,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_10769-4829-6342","score":0.0285714286,"text":"\nThe feed action sets up a ruleT -> pollMyService.\n\n\n\nThis procedure implements a polling-based trigger entirely by using Cloud Functions actions, without any need for a separate service.\n\n\n\n\n\n Implementing feeds by using connections \n\nThe previous two architectural choices are simple and easy to implement. However, if you want a high-performance feed, you can use persistent connections and long-polling or similar techniques.\n\nSince Cloud Functions actions must be short-running, an action cannot maintain a persistent connection to a third party. Instead, you can stand up a separate service, called provider services, outside of Cloud Functions that run all the time. A provider service can maintain connections to third-party event sources that support long polling or other connection-based notifications.\n\nThe provider service has a REST API that allows the Cloud Functions feed action to control the feed. The provider service acts as a proxy between the event provider and Cloud Functions. When it receives events from the third party, it sends them on to Cloud Functions by firing a trigger.\n\nThe IBM Cloudant changes feed is the canonical example as it stands up a cloudanttrigger service, which mediates between IBM Cloudant notifications over a persistent connection, and Cloud Functions triggers.\n\nThe alarm feed is implemented with a similar pattern.\n\nThe connection-based architecture is the highest performance option, but operations are more labor-intensive than polling and hook architectures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_custom"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.4217734095}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":0.0327868852,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":0.0322580645,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":0.0317460317,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":0.03125,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":0.0307692308,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":0.0303030303,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":0.0298507463,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":0.0294117647,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-545406-546780","score":0.0289855072,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06160-10037-11653","score":0.0285714286,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05762-7-1980","score":0.0320184426,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes"},{"document_id":"ibmcld_10197-7-2062","score":0.0312805474,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For Red Hat Openshift clusters, check the Red Hat OpenShift on IBM Cloud component.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"},{"document_id":"ibmcld_10534-140407-141645","score":0.0305503731,"text":"\n[Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateupdate)\n\n\n\n* [Updating the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster)\n\n\n\n* [About updating the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster-about)\n* [Steps to update the cluster master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster-steps)\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs)\n* [Updating classic worker nodes in the CLI with a configmap](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-configmap)\n* [Updating classic worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_up_console)\n\n\n\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_prereqs)\n* [Updating VPC worker nodes in the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10394-7-1848","score":0.0301587302,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_05713-143677-145052","score":0.029877369,"text":"\n* [About updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster-about)\n* [Steps to update the cluster master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster-steps)\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs)\n* [Updating classic worker nodes in the CLI with a configmap](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-configmap)\n* [Updating classic worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_up_console)\n\n\n\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_prereqs)\n* [Updating VPC worker nodes in the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_cli)\n* [Updating VPC worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_ui)\n\n\n\n* [Updating flavors (machine types)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type)\n* [Updating cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatecomponents)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_06209-6757-8643","score":0.0163934426,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_16729-103029-104898","score":0.0161290323,"text":"\n* 30 minutes\n* 2023-02-21\n\n\n\n[Using Calico network policies to control traffic on Classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-policy_tutorial)Using Calico network policies to control traffic on Classic clusters\n\nLearn how to use Calico policies to allow network traffic from and to certain IP addresses.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 60 minutes\n* 2023-07-07\n\n\n\n[Updating Classic worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic)Updating Classic worker nodes that use OpenShift Data Foundation\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10642-6354-8294","score":0.0158730159,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10534-264143-265453","score":0.0153846154,"text":"\n* [Version 4.13 parameters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-classic-params-413)\n* [Version 4.10, 4.11, and 4.12 parameters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-classic-params-410)\n* [Version 4.9 parameters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-classic-params-48)\n\n\n\n* [Limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-limitations-classic)\n\n\n\n[Updating Classic worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicopenshift-storage-update-classic)\n\n\n\n* [Update the cluster master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicupdate-cluster-master-classic)\n* [Determine which worker nodes you want to update](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicdetermine-worker-nodes-classic)\n* [Scale down OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicscale-down-odf-classic)\n* [Cordon and drain the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classiccordon-drain-worker-node-classic)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10642-18947-20676","score":0.0151515152,"text":"\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_updateportworx_vpc_up).\n\nIf you have OpenShift Data Foundation deployed in your cluster, follow the steps to [update VPC worker nodes with OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.350148302}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":0.0325224749,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-7-1827","score":0.0313188158,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10642-6354-8294","score":0.0312576313,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-6757-8643","score":0.0308349146,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_13900-26892-28337","score":0.0158730159,"text":"\nVRVDR-56228 7.5 DLA-2773-1 CVE-2021-22946, CVE-2021-22947: Debian DLA-2773-1 : curl - LTS security update \n VRVDR-56221 6.5 DLA-2771-1 CVE-2018-5729, CVE-2018-5730, CVE-2018-20217, CVE-2021-37750: Debian DLA-2771-1 : krb5 - LTS security update \n VRVDR-56210 7.4 DLA-2766-1 CVE-2021-3712: Debian DLA-2766-1 : openssl - LTS security update \n\n\n\n\n\n\n\n\n\n 1912q \n\n\n\n Issues Resolved \n\n\n\nIssues resolved for 1912q\n\n Issue Number Priority Summary \n\n VRVDR-55753 Major Multicast: eliminate or hide FAL counter logs \n VRVDR-55749 Major Swapped in SFP doesn't pick up configured MTU \n VRVDR-55569 Major MRIBv6 FIB: Peek error Resource temporarily unavailable \n VRVDR-55011 Major Can't log into a SIAD with read-only SSD \n VRVDR-54591 Blocker TACACS authentications fails when TACACS accounting has a large backlog \n VRVDR-53135 Major \"protocols multicast ip log-warning\" doesn't log any warnings \n VRVDR-53114 Major TACACS+ session accounting may still use hostname instead of IP address \n VRVDR-53099 Major TACACS+ starts only when service is restarted manually \n VRVDR-53085 Major Multicast IPv4 and IPv6 is mutually exclusive on SIAD \n VRVDR-52997 Major tacplusd get_tty_login_addr() may overflow buffer \n VRVDR-52912 Critical service-user creation fails due to moved SSSD databases \n VRVDR-52855 Critical Creating service users fails \n VRVDR-52842 Major sssd pipes should not be shared with user sandboxes \n VRVDR-52730 Major sssd should not run as root","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-ciena-vyatta-5600-vrouter-software-patches"},{"document_id":"ibmcld_16601-1150-2518","score":0.015625,"text":"\n* [Salesforce SDK](https:\/\/github.com\/watson-developer-cloud\/salesforce-sdk)\n* [Swift SDK](https:\/\/github.com\/watson-developer-cloud\/swift-sdk)\n* [Unity SDK](https:\/\/github.com\/watson-developer-cloud\/unity-sdk)\n\n\n\n\n\n\n\n SDK updates and deprecation \n\nThe supported Watson SDKs are updated according to the following guidelines.\n\n\n\n Semantic versioning \n\nSupported Watson SDKs adhere to semantic versioning with releases labeled as {major}.{minor}.{patch}.\n\n\n\n\n\n Release frequency \n\nSDKs are released independently and might not update on the same schedule.\n\n\n\n* The current releases of the Watson SDKs are updated on a 2- to 6-week schedule. These releases are either minor updates or patches that do not include breaking changes. You can update to any version of the SDK with the same major version number.\n* Major updates that might include breaking changes are released approximately every 6 months.\n\n\n\n\n\n\n\n Deprecated release \n\nWhen a major version is released, support continues on the previous major release for 12 months in a deprecation period. The deprecated release might be updated with bug fixes, but no new features will be added and documentation might not be available.\n\n\n\n\n\n Obsolete release \n\nAfter the 12-month deprecation period, a release is obsolete. The release might be functional but is unsupported and not updated. Update to the current release.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-using-sdks"},{"document_id":"ibmcld_06209-8154-10055","score":0.015625,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-19911-21816","score":0.0153846154,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_13900-2674-4204","score":0.0151515152,"text":"\nYou should also validate that your firewall policies allow VRRP and that your VRRP configurations -- such as preempt false, priority (253 on the default backup and 254 on the default primary) and advertise-interval (the default is 1) -- are all set to the same value for each VIF. This is required in order to have a stable VRRP cluster.\n\n\n\nIssues resolved for 2012p\n\n Issue Number Priority Summary \n\n VRVDR-60094 Major VRRP doesn't function properly if multiple vrrp-instances have same vrrp-sync-group configured \n VRVDR-60065 Major Memory leaks in DPDK and dataplane \n VRVDR-60041 Major Upgrading from 1912t to 2012n, segfault took place (dp\/mastercsync) \n VRVDR-60008 Major PAM account management error: Permission denied \n VRVDR-59602 Major VRRP transitions from MASTER to BACKUP when new VIF interface is created \n VRVDR-59174 Major IPsec fails to start after upgrade to 2012m and VRRP failover \n VRVDR-59062 Major IPsec failing on reboot after upgrade from 1912 to 2012m \n VRVDR-55060 Critical ribd coredump in zv_exp_l_string \n VRVDR-54588 Major Values returned for vyatta-system-v1\/system\/cpu-history\/cpu-data do not conform to YANG model \n\n\n\n\n\n\n\n Security Vulnerabilities Resolved \n\n\n\nSecurity vulnerabilities resolved for 2012p\n\n Issue Number CVSS score Advisory Summary \n\n VRVDR-60496 5.5 DSA-5378-1 CVE-2022-23824, CVE-2022-42331, CVE-2022-42332, CVE-2022-42333, CVE-2022-42334: Debian DSA-5378-1 : xen - security update \n VRVDR-60489 N\/A DLA-3367-1 Debian DLA-3367-1 : libdatetime-timezone-perl - LTS security update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-ciena-vyatta-5600-vrouter-software-patches"},{"document_id":"ibmcld_10290-113594-115347","score":0.0151515152,"text":"\nibmcloud oc worker reload --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker replace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a worker node and replace it with a new worker node in the same worker pool.\n\nThe replacement worker node is created in the same zone and has the same flavor as the old worker node, but might be assigned new public or private IP addresses. You might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates. To see the changes from one major, minor, or patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation. Remember that your worker nodes can be only up to two versions behind the master version (n-2).\n\nWhen you replace a worker node, keep in mind the following considerations.\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16471-73103-74976","score":0.0327868852,"text":"\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16471-71623-73502","score":0.0322580645,"text":"\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_04826-44093-45752","score":0.0317460317,"text":"\n* Flag: --body FILE_PATH\n\n\n\n* Optional: The REGION where the bucket is present. If this flag is not provided, the program uses the default option that is specified in config.\n\n\n\n* Flag: --region REGION\n\n\n\n* Optional: Output FORMAT can be only json or text.\n\n\n\n* Flag: --output FORMAT\n\n\n\n\n\n\n\n\n\n\n\n Upload a part copy \n\n\n\n* Action: Upload a part by copying data from an existing object.\n* Usage:ibmcloud cos part-upload-copy --bucket BUCKET_NAME --key KEY --upload-id ID --part-number NUMBER --copy-source SOURCE [--copy-source-if-match ETAG] [--copy-source-if-modified-since TIMESTAMP] [--copy-source-if-none-match ETAG] [--copy-source-if-unmodified-since TIMESTAMP] [--copy-source-range value] [--region REGION] [--output FORMAT]\n\n\n\n* Note that you must save each uploaded file part's number and ETag (which the CLI will print for you) for each part into a JSON file. Refer to the \"Multipart Upload Guide\" for more information.\n\n\n\n* Parameters to provide:\n\n\n\n* The name of the bucket.\n\n\n\n* Flag: --bucket BUCKET_NAME\n\n\n\n* The KEY of the object.\n\n\n\n* Flag: --key KEY\n\n\n\n* Upload ID identifying the multipart upload.\n\n\n\n* Flag: --upload-id ID\n\n\n\n* Part NUMBER of part being uploaded. This is a positive integer between 1 and 10,000.\n\n\n\n* Flag: --part-number PART_NUMBER\n\n\n\n* (SOURCE) The name of the source bucket and key name of the source object, which is separated by a slash (\/). Must be URL-encoded.\n\n\n\n* Flag: --copy-source SOURCE\n\n\n\n* Optional: Copies the object if its entity tag (Etag) matches the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-match ETAG\n\n\n\n* Optional: Copies the object if it has been modified since the specified time (TIMESTAMP).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage-cli-plugin?topic=cloud-object-storage-cli-plugin-ic-cos-cli"},{"document_id":"ibmcld_04457-43925-45584","score":0.03125,"text":"\n* Flag: --body FILE_PATH\n\n\n\n* Optional: The REGION where the bucket is present. If this flag is not provided, the program uses the default option that is specified in config.\n\n\n\n* Flag: --region REGION\n\n\n\n* Optional: Output FORMAT can be only json or text.\n\n\n\n* Flag: --output FORMAT\n\n\n\n\n\n\n\n\n\n\n\n Upload a part copy \n\n\n\n* Action: Upload a part by copying data from an existing object.\n* Usage:ibmcloud cos part-upload-copy --bucket BUCKET_NAME --key KEY --upload-id ID --part-number NUMBER --copy-source SOURCE [--copy-source-if-match ETAG] [--copy-source-if-modified-since TIMESTAMP] [--copy-source-if-none-match ETAG] [--copy-source-if-unmodified-since TIMESTAMP] [--copy-source-range value] [--region REGION] [--output FORMAT]\n\n\n\n* Note that you must save each uploaded file part's number and ETag (which the CLI will print for you) for each part into a JSON file. Refer to the \"Multipart Upload Guide\" for more information.\n\n\n\n* Parameters to provide:\n\n\n\n* The name of the bucket.\n\n\n\n* Flag: --bucket BUCKET_NAME\n\n\n\n* The KEY of the object.\n\n\n\n* Flag: --key KEY\n\n\n\n* Upload ID identifying the multipart upload.\n\n\n\n* Flag: --upload-id ID\n\n\n\n* Part NUMBER of part being uploaded. This is a positive integer between 1 and 10,000.\n\n\n\n* Flag: --part-number PART_NUMBER\n\n\n\n* (SOURCE) The name of the source bucket and key name of the source object, which is separated by a slash (\/). Must be URL-encoded.\n\n\n\n* Flag: --copy-source SOURCE\n\n\n\n* Optional: Copies the object if its entity tag (Etag) matches the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-match ETAG\n\n\n\n* Optional: Copies the object if it has been modified since the specified time (TIMESTAMP).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ic-cos-cli"},{"document_id":"ibmcld_04981-44060-45719","score":0.0307692308,"text":"\n* Flag: --body FILE_PATH\n\n\n\n* Optional: The REGION where the bucket is present. If this flag is not provided, the program uses the default option that is specified in config.\n\n\n\n* Flag: --region REGION\n\n\n\n* Optional: Output FORMAT can be only json or text.\n\n\n\n* Flag: --output FORMAT\n\n\n\n\n\n\n\n\n\n\n\n Upload a part copy \n\n\n\n* Action: Upload a part by copying data from an existing object.\n* Usage:ibmcloud cos part-upload-copy --bucket BUCKET_NAME --key KEY --upload-id ID --part-number NUMBER --copy-source SOURCE [--copy-source-if-match ETAG] [--copy-source-if-modified-since TIMESTAMP] [--copy-source-if-none-match ETAG] [--copy-source-if-unmodified-since TIMESTAMP] [--copy-source-range value] [--region REGION] [--output FORMAT]\n\n\n\n* Note that you must save each uploaded file part's number and ETag (which the CLI will print for you) for each part into a JSON file. Refer to the \"Multipart Upload Guide\" for more information.\n\n\n\n* Parameters to provide:\n\n\n\n* The name of the bucket.\n\n\n\n* Flag: --bucket BUCKET_NAME\n\n\n\n* The KEY of the object.\n\n\n\n* Flag: --key KEY\n\n\n\n* Upload ID identifying the multipart upload.\n\n\n\n* Flag: --upload-id ID\n\n\n\n* Part NUMBER of part being uploaded. This is a positive integer between 1 and 10,000.\n\n\n\n* Flag: --part-number PART_NUMBER\n\n\n\n* (SOURCE) The name of the source bucket and key name of the source object, which is separated by a slash (\/). Must be URL-encoded.\n\n\n\n* Flag: --copy-source SOURCE\n\n\n\n* Optional: Copies the object if its entity tag (Etag) matches the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-match ETAG\n\n\n\n* Optional: Copies the object if it has been modified since the specified time (TIMESTAMP).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli"},{"document_id":"ibmcld_16471-74601-76664","score":0.0303030303,"text":"\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation \n SCONJ subordinating conjunction \n SYM symbol \n VERB verb \n X other \n\n\n\n\n\n\n\n Examples \n\nExample 1: Using a part of speech tag directly in an extract statement\n\nThe view EnglishNoun extracts English nouns (singular or mass) or proper nouns (singular).\n\ncreate view EnglishNoun\nas extract parts_of_speech 'NOUN' and 'PROPN'\nwith language 'en' on D.text\nas noun from Document D;\n\n\n\n\n\n\n\n Sequence patterns \n\nUse the pattern extraction specification to perform pattern matching across an input document and other spans extracted from the input document.\n\n\n\n Syntax \n\nThe general syntax of a sequence pattern is to first specify the pattern to be matched in the text, and then to specify what is to be returned by the extractor. The final part of the sequence pattern specifies what is the input to the pattern; it might be a column from a previously defined view, or it might be the entire document text.\n\npattern <pattern specification> [return clause] [with inline_match on <viewname.colname>]\n\n\n\n\n\n Description \n\n\n\n* <pattern specification>\n\nA <pattern specification> is composed of multiple Atoms. An individual Atom can be a column from an already-defined view, a fixed string, or a regular expression. You can specify your Atoms to be optional and repeating, and specify token gaps between Atoms.\n\nThe pattern specification is part of a larger AQL statement, which includes an extract clause.\n\nHere is a simple example of how to create a view that contains three adjacent matches from earlier defined views. In this example, the entire combination is returned, which is what group 0 refers to:\n\ncreate view Money as\nextract pattern <C.match> <N.match> <Q.match>\nreturn group 0 as match","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_04996-1622-3532","score":0.0298507463,"text":"\nInvalidBucketName The specified bucket is not valid. 400 Bad Request \n InvalidBucketState The request is not valid with the current state of the bucket. 409 Conflict \n InvalidDigest The Content-MD5 that you specified is not valid. 400 Bad Request \n InvalidLocationConstraint The specified location constraint is not valid. For more information about regions, see How to Select a Region for Your Buckets. 400 Bad Request \n InvalidObjectState The operation is not valid for the current state of the object. 403 Forbidden \n InvalidPart One or more of the specified parts might not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag. 400 Bad Request \n InvalidPartOrder The list of parts was not in ascending order. Parts list must specified in order by part number. 400 Bad Request \n InvalidRange The requested range cannot be satisfied. 416 Requested Range Not Satisfiable \n InvalidRequest Please use AWS4-HMAC-SHA256. 400 Bad Request \n InvalidSecurity The provided security credentials are not valid. 403 Forbidden \n InvalidURI Mightn't parse the specified URI. 400 Bad Request \n KeyTooLong Your key is too long. 400 Bad Request \n MalformedPOSTRequest The body of your POST request is not well-formed multipart\/form-data. 400 Bad Request \n MalformedXML The XML you provided was not well-formed or did not validate against our published schema. 400 Bad Request \n MaxMessageLengthExceeded Your request was too large. 400 Bad Request \n MaxPostPreDataLengthExceededError Your POST request fields preceding the upload file were too large. 400 Bad Request \n MetadataTooLarge Your metadata headers exceed the maximum allowed metadata size. 400 Bad Request \n MethodNotAllowed The specified method is not allowed against this resource. 405 Method Not Allowed \n MissingContentLength You must provide the Content-Length HTTP header. 411 Length Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-common"},{"document_id":"ibmcld_06885-7-1959","score":0.0294117647,"text":"\nPart 2: Set up a Continuous Integration (CI) toolchain \n\nThis tutorial is part 2 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 2 of this tutorial series, you use the toolchain template for continuous integration (CI) with security and compliance-related best practices in DevSecOps. It is preconfigured for continuous deployment with inventory integration, change management with Git Repos and Issue Tracking, evidence collection, and deployment to IBM Cloud Kubernetes Service.\n\n\n\n Before you begin \n\nBefore you begin part 2 of this tutorial series, ensure that you complete the following prerequisites:\n\n\n\n1. Complete [Part 1: Set up prerequisites](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cd-devsecops).\n2. View the [Getting started with DevSecOps in IBM Cloud - Part 1](https:\/\/video.ibm.com\/embed\/recorded\/130714354) video.\n3. Start the [IBM Cloud console](https:\/\/cloud.ibm.com\/). The console is the starting point of this tutorial.\n\n\n\n\n\n\n\n Continuous Integration (CI) toolchain introduction \n\nThe CI toolchain implements the following best practices:\n\n\n\n* Runs a static code scanner on the application repositories to detect secrets in the application source code and vulnerable packages that are used as application dependencies\n* Builds a container image on every Git commit, setting a tag based on build number, timestamp, and commit ID for traceability\n* Tests the Dockerfile before the image is created\n* Stores the built image in a private image registry\n* Automatically configures access permissions for target cluster deployment by using API tokens that can be revoked\n* Scans the container image for security vulnerabilities\n* Adds a Docker signature upon successful completion\n* Inserts the built image tag into the deployment manifest automatically","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-ci-toolchain"},{"document_id":"ibmcld_07140-11001-12762","score":0.0289855072,"text":"\n* \"{field_name}\" - The name of the field to be created.\n\n\n\nField names defined in your configuration must meet the restrictions defined in [Field Name Requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configreffield_reqs).\n\n\n\n* \"css_selector\" : stringrequired - a CSS selector expression that defines the area of content to be stored in a field.\n* \"type\" : stringrequired - The type of field to be created, can be string, date For detailed information, see [Using CSS selectors to extract fields](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceusing-css).\n\n\n\n\n\n\n\n\n\n Segment \n\nThe segment object is a set of configuration options that split ingested documents into one or more segments based on the identified HTML headings (h1, h2).\n\n\"segment\": {\n\"enabled\": true,\n\"selector_tags\": [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]\n}\n\n\n\n* \"enabled\": boolean - required - must be set to true to enable document segmentation.\n* \"selector_tags\": array - required - a comma separated array of HMTL h tags on which to split documents.\n\n\n\nAs an overview, when document segmentation is enabled the following cannot be specified:\n\n\n\n* json_normalizations cannot be specified as part of the configuration.\n* normalizations cannot be specified as part of the configuration.\n* The extracted_fields option of the html conversion cannot be specified as part of the configuration.\n\n\n\nFor detailed information, see [Performing segmentation](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceperforming-segmentation).\n\n\n\n\n\n JSON \n\nYou can perform pre-enrichment normalization of the ingested JSON by defining operation objects in the json_normalizations array.\n\n\"json_normalizations\": [\n{\n\"operation\": \"remove\",\n\"source_field\": \"header\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_07551-18310-20079","score":0.0285714286,"text":"\nAfter the device is subscribed to a particular tag, the device can receive notifications that are sent for that tag.\n\nAdd the following code snippet to your iOS mobile application to subscribe to a list of tags.\n\n\/\/ Subscribe to the given tag\nenPush.subscribeToTags(tagName: \"<tag_name>\") { response, statusCode, error in\n\/.....\/\n});\n\n\n\n\n\n Retrieve subscribed tags \n\nThe retrieveSubscriptionsWithCompletionHandler API returns the list of tags to which the device is subscribed. Use the following code snippets in the mobile application to get the subscription list.\n\n\/\/ Get a list of tags that to which the device is subscribed.\nenPush.retrieveSubscriptionsWithCompletionHandler { response, statusCode, error in\n\/.....\/\n}\n\n\n\n\n\n Unsubscribe from tags \n\nThe unsubscribeFromTags API removes the device subscription from the list tags. Use the following code snippets to allow your devices to get unsubscribe from a tag.\n\n\/\/ unsubscibe from the given tag ,that to which the device is subscribed.\nenPush.unsubscribeFromTags(tagName: \"<tag_name>\") { response, statusCode, error in\n\/.....\/\n}\n\n\n\n\n\n Receiving push notifications on iOS devices \n\nTo receive push notifications on iOS devices, add the following Swift method to the appDelegate.swift of your application:\n\nfunc application(_ application: UIApplication, didReceiveRemoteNotification userInfo: [AnyHashable : Any], fetchCompletionHandler completionHandler: @escaping (UIBackgroundFetchResult) -> Void) {\n\n\/\/UserInfo dictionary will contain data sent from the server\n}\n\n\n\n\n\n\n\n Notification options \n\nThe following notification options are supported.\n\n\n\n Interactive notifications \n\n\n\n1. To enable interactive push notifications, the notification action parameters must be passed in as part of the notification object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02882-5559-7278","score":0.0163934426,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon.\n\n\n\n* To create a peer node that is checked next if the condition for the existing node is not met, select Add node below.\n* To create a peer node that is checked before the condition for the existing node is checked, select Add node above.\n* To create a child node to the selected node, select Add child node. A child node is processed after its parent node.\n* To copy the current node, select Duplicate.\n\n\n\nFor more information about the order in which dialog nodes are processed, see [Dialog overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n10. Test the dialog as you build it.\n\nSee [Testing your dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-build-test) for more information.\n\n\n\n\n\n\n\n Conditions \n\nA node condition determines whether that node is used in the conversation. Response conditions determine which response to return to a user.\n\n\n\n* [Condition artifacts](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-condition-artifacts)\n* [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-special-conditions)\n* [Condition syntax details](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-condition-syntax)\n\n\n\nFor tips on performing more advanced actions in conditions, see [Condition usage tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tipsdialog-tips-condition-usage).\n\n\n\n Condition artifacts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_06160-11142-12906","score":0.0163934426,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_12890-1796-4070","score":0.0161290323,"text":"\nA database can demonstrate only two of these three attributes for both theoretical and practical reasons. A database prioritizing consistency and availability is simple: a single node stores a single copy of your data. But this model is difficult to scale as you must upgrade the node to get more performance, rather than use extra nodes. And, even a minor system failure can shut down a single-node system, while any message loss means significant data loss. To endure, the system must become more sophisticated.\n\n\n\n Tradeoffs in partition tolerance \n\nA database that prioritizes consistency and partition tolerance commonly employs a primary-secondary setup, where one node of the many in the system is elected leader. Only the leader approves data writes, while all secondary nodes replicate data from the leader to handle reads. If the leader loses connection to the network, or can't communicate with many of the system's nodes, the remainder elects a new leader. This election process differs between systems, and might be a source of [significant problems](https:\/\/aphyr.com\/posts\/284-call-me-maybe-mongodb).\n\nIBM Cloudant prioritizes availability and partition tolerance by employing a primary-primary setup, such that every node can accept both writes and reads to its portion of your data. Multiple nodes include copies of each portion of your data. Each node copies data with other nodes. If a node becomes inaccessible, others can serve in its place while the network heals. This way, the system returns your data in a timely manner despite arbitrary node failure, and maintains [eventual consistency](https:\/\/en.wikipedia.org\/wiki\/Eventual_consistency). The tradeoff in deprioritizing absolute consistency is that it takes time for all nodes to see the same data. As a result, some responses might include old data while the new data propagates through the system.\n\n\n\n\n\n Changing the approach \n\nMaintaining one consistent view of data is logical and easy to understand because a relational database does this work for you. The expectation is that web-based services that interact with database systems behave in this way. But that expectation doesn't mean that they do work this way. Consistency isn't a given, and it takes a little work to change the approach.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-cap-theorem"},{"document_id":"ibmcld_10596-11475-13230","score":0.0161290323,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_14508-7-1988","score":0.0158730159,"text":"\nVMware Aria Operations Manager design \n\nThe VMware Aria\u00ae Operations\u2122 Manager (formerly known as VMware vRealize\u00ae Operations Manager\u2122) Analytics Cluster contains the nodes that analyze and store data from the monitored components. In this deployment, four nodes are deployed and two VMware NSX\u00ae Load Balancers. This size allows monitoring of up to 30,000 VMs and 9,000,000 metrics to be collected.\n\nThe 4-node analytics cluster consists of the following components:\n\n\n\n* Primary node \u2013 The primary node is the initial node in a VMware Aria Operations cluster. In a large environment, this node manages all the other nodes.\n* Primary node replica \u2013 This node enables high availability of the primary node.\n* Data nodes \u2013 The data node enables scale out of VMware Aria Operations in larger environments, two are deployed in this design.\n\n\n\nAdditionally, the design uses Remote Collector nodes, which act as a proxy or relay server to collect data only and forward collected data to the primary and data nodes. Data nodes and Remote Collectors can be added to scale up depending on environment size. The placement of VMware Aria Operations components onto VLANs or VXLANs is shown in the following diagram.\n\nZoom\n\n![Operations Manager network diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/opsmgmt-vropsnw.svg)\n\nFigure 1. Operations Manager networking\n\n\n\n* Primary node, primary node replica, and data nodes are deployed on the tools subnet by using IBM Cloud\u00ae Portable IP addresses. This deployment facilitate communication to all components that are addressed out of the IBM Cloud RFC1918 address space. These components include vSphere hosts, vCenter, Platform Services Controller (PSC), NSX Manager, and NSX Controllers\u2122. An NSX Load Balancer is used along with a VIP for HA.\n* Customer workloads use IP addressing from the BYOIP address space so this design uses Remote Collectors that are hosted in a VXLAN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrops"},{"document_id":"ibmcld_06160-12611-14167","score":0.0158730159,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06348-7-2266","score":0.015625,"text":"\nHigh-Availability \n\nIBM Cloud\u00ae Databases for Elasticsearch is a managed cloud database service that is fully integrated into the IBM Cloud environment. The database, storage, and supporting infrastructure all run in IBM Cloud.\n\nDatabases for Elasticsearch provides replication, fail-over, and high-availability features to protect your databases and data from infrastructure maintenance, upgrades, and failures. Deployments contain a cluster with three nodes where all three are data nodes and any node can be the primary node. Elasticsearch clusters work on a quorum system, if one data member becomes unreachable, your cluster continues to operate normally. If more nodes go down and the cluster can't maintain a quorum, it becomes read-only to protect your data. The cluster resumes normal operations when the nodes are recovered or new nodes are added.\n\nWhen you add an index to Elasticsearch, it splits the data into shards and spreads those shards across the nodes in the cluster. The sharded configuration allows for Elasticsearch to run concurrent operations on your data across all the nodes. Concerning high-availability, not all shards contain a complete copy of all the data in the index. To enforce that multiple complete copies of the data are spread across the cluster in a node failure, you should ensure that when you create an index you set the replica count to at least 1. Setting the replica count to 0 can cause data loss.\n\nIf you [add nodes to your cluster](https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-horizontal-scaling), Elasticsearch automatically rebalances the shards and replicas of your indexes across the newly added node or nodes. Adding nodes can provide more stability in a multi-node failure, since you can lose more nodes and maintain a quorum. More nodes also improves performance.\n\n\n\n Staying Production Ready \n\nTo keep your IBM Cloud\u00ae Databases for Elasticsearch database up and running, do not drop the icd-auth index. This index stores your database, as well as all user accounts and is critical to operational integrity.\n\n\n\n\n\n Application-level High-Availability \n\nApplications that communicate over networks and cloud services are subject to transient connection failures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-high-availability"},{"document_id":"ibmcld_10596-5350-7330","score":0.015625,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_02900-1669-3428","score":0.0153846154,"text":"\n* [Customizing digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-enable-digressions)\n* [Digression usage tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digress-tips)\n* [Disabling digressions into a root node](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-disable-digressions)\n* [Digression tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digression-tutorial)\n* [Design considerations](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digression-design-considerations)\n\n\n\n\n\n Before you begin \n\nAs you test your overall dialog, decide when and where it makes sense to allow digressions and returns from digressions to occur. The following digression controls are applied to the nodes automatically. Only take action if you want to change this default behavior.\n\n\n\n* Every root node in your dialog is configured to allow digressions to target them by default. Child nodes cannot be the target of a digression.\n* Nodes with slots are configured to prevent digressions away. All other nodes are configured to allow digressions away. However, the conversation cannot digress away from a node under the following circumstances:\n\n\n\n* If any of the child nodes of the current node contain the anything_else or true condition\n\n\n\nThese conditions are special in that they always evaluate to true. Because of their known behavior, they are often used in dialogs to force a parent node to evaluate a specific child node in succession. To prevent breaking existing dialog flow logic, digression are not allowed in this case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_06160-5357-7356","score":0.0153846154,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06320-2897-4555","score":0.0327868852,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-1330-3318","score":0.0322580645,"text":"\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https:\/\/docs.datastax.com\/en\/devapp\/doc\/devapp\/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-4083-5561","score":0.0317460317,"text":"\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration. For more information, see [DSBULK documentation](https:\/\/docs.datastax.com\/en\/dsbulk\/doc\/dsbulk\/reference\/dsbulkCmd.html).\n\n\n\n\n\n\n\n Resource configurations \n\n\n\n* The recommended configuration for a node is:\n\n\n\n* 16 CPUs\n* 32 GB to 64 GB RAM\n* 16 K disk IOPS (16 k IOPS == 1.6 TB disk)\n\n\n\n\n\n\n\n\n\n\n\n Next steps \n\nDetailed information on CQL, the Cassandra Query Language, can be found by consulting [CQL for DSE Documentation](https:\/\/docs.datastax.com\/en\/dse\/6.0\/cql\/).\n\nLooking to administer your deployment? Consult DataStax's documentation on using the [stand-alone CQLSH client](https:\/\/docs.datastax.com\/en\/astra\/docs\/connecting-to-databases-using-standalone-cqlsh.html).\n\nYou can manage your deployment with [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli), the [Cloud Databases CLI plug-in](https:\/\/cloud.ibm.com\/docs\/databases-cli-plugin?topic=databases-cli-plugin-cdb-reference), or by using the [Cloud Databases API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05891-109363-111311","score":0.0327868852,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\nkubectl drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5. Make your worker node available for pod scheduling.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-110010-111892","score":0.0322580645,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\nkubectl drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10290-107432-109320","score":0.0317460317,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\noc adm drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10290-111044-112870","score":0.03125,"text":"\nDuring the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_05891-113289-115164","score":0.0307692308,"text":"\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.\n\n\n\nibmcloud ks worker reload --cluster CLUSTER --worker WORKER_ID [--skip-master-healthcheck] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-113908-115783","score":0.0303030303,"text":"\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.\n\n\n\nibmcloud ks worker reload --cluster CLUSTER --worker WORKER_ID [--skip-master-healthcheck] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_06209-21345-23408","score":0.0298507463,"text":"\nThis type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node. However, the replacement worker node is assigned a new private IP address, and loses any custom labels or taints that you applied to the old worker node (worker pool labels and taints are still applied to the replacement worker node).\n\nWhat if I replace multiple worker nodes at the same time?\n: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n\nWhat if a replacement worker node is not created?\n: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-off).\n\n\n\n Prerequisites","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10290-114867-116840","score":0.0294117647,"text":"\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n* Node-level customizations are not preserved: Any custom labels or taints that you applied at the individual worker node level are not applied to the replacement worker node. Instead, apply [labels](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) or [taints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliworker_pool_taint) at the worker pool level so that the replacement worker node gets these attributes.\n* Automatic rebalancing: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-off).\n\n\n\nBefore you begin, make sure that your cluster has enough other worker nodes so that your pods can be rescheduled and continue to run.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to replace.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Replace the worker node. As part of the replace process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10044-0-1900","score":0.0289855072,"text":"\n\n\n\n\n\n\n  Why doesn't replacing a worker node create a worker node? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you [replace a worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) or [update a VPC worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node), a worker node is not automatically added back to your cluster.\n\n  Why it\u2019s happening \n\nBy default, your worker pools are set to automatically rebalance when you replace a worker node. However, you might have disabled automatic rebalancing by manually removing a worker node, such as in the following scenario.\n\n\n\n1.  You have a worker pool that automatically rebalances by default.\n2.  You have a troublesome worker node in the worker pool that you removed individually, such as with the ibmcloud oc worker rm command.\n3.  Now, automatic rebalancing is disabled for your worker pool, and is not reset unless you try to rebalance or resize the worker pool.\n4.  You try to replace a worker node with the ibmcloud oc worker replace command or update a VPC worker node with the ibmcloud oc worker replace --update command. The worker node is removed, but another worker node is not added back to your worker pool.\n\n\n\nYou might also have issued the remove command shortly after the replace command. If the remove command is processed before the replace command, the worker pool automatic rebalancing is still disabled, so your worker node is not replaced.\n\n  How to fix it \n\nTo enable automatic rebalancing, [rebalance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_rebalance) or [resize](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) your worker pool. Now, when you replace a worker node, another worker node is created for you.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-off"},{"document_id":"ibmcld_05575-0-1906","score":0.0285714286,"text":"\n\n\n\n\n\n\n  Why doesn't replacing a worker node create a worker node? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you [replace a worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clicli_worker_replace) or [update a VPC worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node), a worker node is not automatically added back to your cluster.\n\n  Why it\u2019s happening \n\nBy default, your worker pools are set to automatically rebalance when you replace a worker node. However, you might have disabled automatic rebalancing by manually removing a worker node, such as in the following scenario.\n\n\n\n1.  You have a worker pool that automatically rebalances by default.\n2.  You have a troublesome worker node in the worker pool that you removed individually, such as with the ibmcloud ks worker rm command.\n3.  Now, automatic rebalancing is disabled for your worker pool, and is not reset unless you try to rebalance or resize the worker pool.\n4.  You try to replace a worker node with the ibmcloud ks worker replace command or update a VPC worker node with the ibmcloud ks worker replace --update command. The worker node is removed, but another worker node is not added back to your worker pool.\n\n\n\nYou might also have issued the remove command shortly after the replace command. If the remove command is processed before the replace command, the worker pool automatic rebalancing is still disabled, so your worker node is not replaced.\n\n  How to fix it \n\nTo enable automatic rebalancing, [rebalance](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_rebalance) or [resize](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) your worker pool. Now, when you replace a worker node, another worker node is created for you.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-off"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08867-20399-21926","score":0.0320184426,"text":"\n+-------------------------------------------+\nSubscription Name: 30 Day Self-Supported Red Hat OpenShift Container Platform, 2-Core Evaluation\nProvides: Red Hat Ansible Engine\nRed Hat Software Collections (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise Infrastructure\nRed Hat JBoss Core Services\nRed Hat Enterprise Linux Fast Data path\nRed Hat OpenShift Container Platform for Power\nJBoss Enterprise Application Platform\n:\nRed Hat OpenShift Container Platform Client Tools for Power\nRed Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise JBoss EAP add-on\nRed Hat OpenShift Container Platform\nRed Hat Gluster Storage Management Console (for RHEL Server)\nRed Hat OpenShift Enterprise JBoss A-MQ add-on\nRed Hat Enterprise Linux for Power, little endian Beta\nRed Hat OpenShift Enterprise Client Tools\n:\nRed Hat OpenShift Enterprise Application Node\n:\nRed Hat OpenShift Service Mesh\n:\nRed Hat OpenShift Enterprise JBoss FUSE add-on\nSKU: SER0419\nContract: 123456789\nPool ID: 1a2345bcd6789098765abcde43219bc3\nProvides Management: Yes\nAvailable: 10\nSuggested: 1\nService Level: Self-Support\nService Type: L1-L3\nSubscription Type: Stackable\nStarts: 12\/03\/2018\nEnds: 01\/02\/2019\nSystem Type: Physical\n7. Exit the secure shell to return to your OpenShift installation directory inside your container.\n\nexit\n\nExample output:\n\nlogout\nConnection to 169.47.XXX.XX closed.\n\/go\/bin\/terraform-ibm-openshift \n\n\n\n2. Finish setting up and registering the nodes with the Red Hat Network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"},{"document_id":"ibmcld_14491-1340-3282","score":0.0310544054,"text":"\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"},{"document_id":"ibmcld_14492-10142-11408","score":0.0310096154,"text":"\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [VMware Solutions and Red Hat OpenShift overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro)\n* [Red Hat OpenShift Container Platform 4.7 documentation](https:\/\/docs.openshift.com\/container-platform\/4.7\/welcome\/index.html)\n* [Red Hat OpenShift Container Platform 4.7 release notes](https:\/\/docs.openshift.com\/container-platform\/4.7\/release_notes\/ocp-4-7-release-notes.html)\n* [What's new in Red Hat OpenShift](https:\/\/www.openshift.com\/learn\/whats-new)\n* [Succeeding with Red Hat OpenShift and VMware\u2019s Software-Defined Datacenter (SDDC)](https:\/\/blog.openshift.com\/red-hat-openshift-and-vmware-better-together\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10422-1393-2886","score":0.0303030303,"text":"\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.10\/release_notes\/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https:\/\/github.com\/kubernetes\/kubernetes\/tree\/master\/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_10422-7-1877","score":0.0301587302,"text":"\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_14497-11060-12784","score":0.0294117647,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_13144-9759-11433","score":0.0163934426,"text":"\nThe Pods, Builds, Services and Routes are visible.\n\nZoom\n\n![App Details](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution55-openshift-microservices\/ocp45-topo-app-details.png)\n\nApp Details\n\n\n\n* Pods: Your Node.js application containers\n* Builds: The auto-generated build that created a Docker image from your Node.js source code, deployed it to the Red Hat OpenShift container registry, and kicked off your deployment config\n* Services: Tells Red Hat OpenShift how to access your Pods by grouping them together as a service and defining the port to listen to\n* Routes: Exposes your services to the outside world using the LoadBalancer provided by the IBM Cloud network\n\n\n\n3. Click on View Logs next to your completed Build. This shows you the process that Red Hat OpenShift took to install the dependencies for your Node.js application and build\/push a Docker image. The last entry should looks like this:\n\nSuccessfully pushed image-registry.openshift-image-registry.svc:5000\/example-health\/patient-health-frontend@sha256:f9385e010144f36353a74d16b6af10a028c12d005ab4fc0b1437137f6bd9e20a\nPush successful\n4. Click back to the Topology and select your app again.\n5. Click on the URL under Routes to visit your application. Enter any string for username and password, for instance test:test because the app is running in demonstration mode.\n\n\n\nThe Node.js app has been deployed to Red Hat OpenShift Container Platform. To recap:\n\n\n\n* The \"Example Health\" Node.js application was deployed directly from GitHub into your cluster.\n* The application was examined in the Red Hat OpenShift on IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_10462-8619-10498","score":0.0161290323,"text":"\nIf you created other priority classes in your cluster, you can check to make sure that they don't set a globalDefault by running oc describe priorityclass <name>. \n description Optional: Tell users why to use this priority class. Enclose the string in quotations (\"\"). \n\n\n\n4. Create the priority class in your cluster.\n\noc apply -f filepath\/priorityclass.yaml\n5. Verify that the priority class is created.\n\noc get priorityclasses\n\n\n\nGreat! You created a priority class. Let your team know about the priority class and which priority class, if any, that they must use for their pod deployments.\n\n\n\n\n\n Assigning priority to your pods \n\nAssign a priority class to your pod spec to set the pod's priority within your Red Hat OpenShift on IBM Cloud cluster.\n\nBefore you begin:\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Ensure that you have the [Writer or Manager IBM Cloud IAM service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) in the namespace that you want to deploy the pods to.\n* [Understand how priority scheduling works](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_prioritypriority_scheduling), as priority can preempt existing pods and affect how your cluster's resources are consumed.\n\n\n\nComplete the following steps to check the importance of other deployed pods so that you can choose the correct priority class for your pods in relation to what already is deployed.\n\n\n\n1. View the priority classes that other pods in the namespace use.\n\noc get pods -n <namespace> -o custom-columns=NAME:.metadata.name,PRIORITY:.spec.priorityClassName\n2. Get the details of the priority class and note the value number. Pods with higher numbers are prioritized before pods with lower numbers. Repeat this step for each priority class that you want to review.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_priority"},{"document_id":"ibmcld_11768-7-2036","score":0.0158730159,"text":"\nUpdating Satellite location control plane hosts \n\nIBM provides version updates for your hosts that are assigned to the Satellite location control plane. The version updates include OpenShift Container Platform, the operating system, and security patches. You choose when to apply the host version updates by detaching the hosts from your location, reloading the host machine in the infrastructure provider, and reattaching and reassigning the host to the Satellite location control plane.\n\n\n\n Considerations before you update control plane hosts \n\nReview the following considerations before you update your Satellite location control plane hosts.\n\nHow can I tell if a version update is available?\n: Version updates for hosts become available as the Red Hat OpenShift on IBM Cloud team packages new versions for worker nodes. Typically, worker node version updates are released every two weeks.\n: You might check for a version update to meet your required security cadence, such as updates on a monthly or bi-monthly basis. To review available version updates, see the [Version change log for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nDoes updating the hosts impact the cluster masters that run in the Satellite location control plane?\n: Yes. Because the cluster masters run in your Satellite location control plane, make sure that you have enough extra hosts in your control plane before you update any hosts. To attach extra hosts, see [Attaching capacity to your Satellite location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts).\n\nDo the hosts in my Satellite-enabled IBM Cloud services have to run the same version as my Satellite location control plane?\n: No, the hosts that are assigned to the Satellite location control plane do not have to run the same version as the hosts that are assigned to Satellite-enabled IBM Cloud services that run in the location. However, all hosts in the location must run a supported version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-location"},{"document_id":"ibmcld_10702-7-1940","score":0.0153846154,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13629-7578-9236","score":0.0163934426,"text":"\nYou must specify the sampling rate with this audio format. For example, specify audio\/l16;rate=16000 for audio that is sampled at 16 kHz.\n\nYou can optionally specify the endianness for the audio by using the endianness parameter. Endianness indicates how bytes of data are ordered by the underlying computer architecture:\n\n\n\n* Big-endian (endianness=big-endian) orders data by most-significant bit.\n* Little-endian (endianness=little-endian) orders data by least-significant bit.\n\n\n\nFor example, specify audio\/l16;rate=16000;endianness=big-endian to obtain audio that is sampled at 16 kHz and returned in big-endian order. If you omit the endianness, the default is little-endian. (Specifying the endianness is an issue only for the audio\/l16 format, which does not include a header. Endianness is not a concern for the other formats.)\n\nFor more information, see\n\n\n\n* IETF [Request for Comment (RFC) 2586](https:\/\/tools.ietf.org\/html\/rfc2586)\n* [Pulse-code modulation](https:\/\/wikipedia.org\/wiki\/Pulse-code_modulation)\n* [Endianness](https:\/\/wikipedia.org\/wiki\/Endianness)\n\n\n\n\n\n\n\n audio\/mp3 and audio\/mpeg formats \n\nMP3 or Motion Picture Experts Group (MPEG) is a lossy data compression format (MP3 and MPEG refer to the same format). You can optionally specify a sampling rate other than the default 22,050 Hz.\n\nFor more information, see [MP3](https:\/\/wikipedia.org\/wiki\/MP3).\n\n\n\n\n\n audio\/mulaw format \n\n8-bit mu-law (or u-law) audio is a single-channel, lossy audio format that is encoded by using 8-bit mu-law data. You must specify the sampling rate with this audio format. For example, specify audio\/mulaw;rate=16000 for audio that is sampled at 16 kHz.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formats"},{"document_id":"ibmcld_14913-0-1238","score":0.0163934426,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_15268-3594-5206","score":0.0161290323,"text":"\nIf you determine that disabling Hyper-Threading Technology is right for your configuration, you can use one of the following methods to disable it on your guest virtual machines (VMs) in IBM Cloud.\n\n\n\n\n\n Checking Hyper-Threading Technology status and changing it in my guest VM: Basics \n\nWhen a virtual machine is up and running, you can check the Hyper-Threading Technology status by using the lscpu command on Linux operating systems. You see output similar to the following:\n\nArchitecture: x86_64\nCPU op-mode(s): 32-bit, 64-bit\nByte Order: Little Endian\nCPU(s): 8\nOn-line CPU(s) list: 0-7\nThread(s) per core: 2\nCore(s) per socket: 4\n...\n\nIn this example, notice that the Thread(s) per core displays 2, indicating that Hyper-Threading Technology is enabled. The VM has 4 physical cores and 8 virtual CPUs. Modern versions of the Linux kernel allow users to disable Hyper-Threading Technology on a per core basis. You can run some cores with Hyper-Threading Technology enabled and other cores with Hyper-Threading Technology disabled. To see this on a per core basis, you can use the command lscpu --extended. You see output similar to the following:\n\nCPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE\n0 0 0 0 0:0:0:0 yes\n1 0 0 0 1:1:0:0 yes\n2 0 0 1 2:2:1:0 yes\n3 0 0 1 3:3:1:0 yes\n4 0 0 2 4:4:2:0 yes\n5 0 0 2 5:5:2:0 yes\n6 0 0 3 6:6:3:0 yes\n7 0 0 3 7:7:3:0 yes\n\nThe preceding example output shows that each core has 2 CPUs and both CPUs are online. Core 0 has siblings: CPU 0 and CPU 1. To get the sibling list, you can find the data in thread_sibling_list in the devices file system as shown in the following example:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-disabling-hyper-threading"},{"document_id":"ibmcld_16030-7-2126","score":0.0161290323,"text":"\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"},{"document_id":"ibmcld_02718-3198-5373","score":0.0158730159,"text":"\nSo this first one might have [Writing] current location, and [Writing] zip code.\n\nAttributes, this allows users who are either currently in the location or have already stipulated that they live nearby to view this feature, but before we do that we want to test the feature out on our own employees. [Writing] So we would have segment Bof our testers because we want them to be our employees the attribute might be [Writing] email ID.\n\nNow we can effectively test our feature in production by {Draw] flipping this toggle on. So now this feature is on for our testers, and say maybe something went wrong so we're actually going to flip it off fix it, and then we'll turn it back on for segment B.\n\nOnce we're satisfied that everything is working well. Then we can flip this on for our [Draw] segment A.\n\nNow all this is done without a deployment because our feature is already in production. All we're doing is making it visible or not visible to certain users.\n\nOnce it is in production. [Draw] We can actually add a little bit of automation to this\n\nwith our testers, we did it manually, we flipped it on and off manually, but with feature flags we can actually add a time element. So let's say we only want this to be viewable for [Writing] three weeks,\n\ntwo weeks before grand opening, one week after grand opening of our new shop. This will be flipped on and then automatically turned off or not visible for this segment of users after three weeks.\n\nOkay, so now we're getting really good at using feature flags so our [Draw] feature flags are potentially starting to stack up we might have a couple apps and a couple websites with a couple different types of features that are flagged.\n\nSo we've got maybe [Writing] app one here, [Writing] app two, and say a [Writing] web page.\n\nWith a feature flagging service we can actually group these in collections so that we're a little bit more organized with which feature flags are tied to, which apps are web pages.\n\nSo now today we've learned about returning feature flags on and off without deployment testing directly in production, and then segmenting those features based on the user attributes.\n\nThank you for watching.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_16026-0-358","score":0.0158730159,"text":"\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vnf-limitations"},{"document_id":"ibmcld_02718-4890-5645","score":0.015625,"text":"\nSo we've got maybe [Writing] app one here, [Writing] app two, and say a [Writing] web page.\n\nWith a feature flagging service we can actually group these in collections so that we're a little bit more organized with which feature flags are tied to, which apps are web pages.\n\nSo now today we've learned about returning feature flags on and off without deployment testing directly in production, and then segmenting those features based on the user attributes.\n\nThank you for watching. If you have questions, please drop us a line below. If you want to see more videos like this in the future, please like and subscribe. And don't forget, you can grow your skills and earn badges with IBM CloudLabs, which are free browser-based interactive kubernetes labs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_07953-7-2429","score":0.015625,"text":"\nEnsuring isolation between Satellite management functions and workload functions \n\nA key aspect of the IBM Cloud Framework for Financial Services is to separate user workloads from system management functions and isolate security functions from nonsecurity functions. The network infrastructure of the Satellite location can be used to provide physical and logical separation between the Satellite management control plane and your workloads.\n\nNetwork flow rule design should follow the IBM Cloud Framework for Financial Services's [information flow guidelines](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection) by using a \"deny by default\" approach.\n\n\n\n Before you begin \n\n\n\n1. Complete the work for [account setup and management](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-account-setup).\n2. Complete [Satellite location setup](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n\n\n\n\n\n\n\n Identify network areas for control plane hosts and workload hosts \n\n\n\n1. Place control plane hosts into a separate network segment. Control plane hosts support various management and security-related components of the Satellite location. To facilitate effective network flow restrictions within the Satellite location, it is recommended to place control plane hosts into a separate network segment (whether physical or virtual) that can enable clear identification of source or destination of the network flows related to control plane functionality. The control plane hosts can be deployed to different physical locations, but the address space they are assigned to should provide an easy way to identify this group of hosts (for example, CIDR blocks).\n2. Designate a separate network segment for each group of Satellite hosts assigned to Red Hat OpenShift on IBM Cloud workload clusters. Satellite hosts that are assigned to Red Hat OpenShift on IBM Cloud workload clusters (workload hosts) should use their own network segments that would enable network flow control and monitoring between workload hosts, control plane, and other components outside of the Satellite location. It is recommended to designate a separate network segment (virtual subnet, VLAN, or a similar entity) for each group of Satellite hosts assigned to the same workload cluster.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"},{"document_id":"ibmcld_11109-3562-5832","score":0.0153846154,"text":"\n: It is run by moving the production to the DR site. From the network perspective, this is equivalent to the real emergency. The entire production networks must be routed to the DR site, while the replication network flow is reversed (from DR site to on premises) to bring the update back to the on premises, which now works as the DR site.\n\nIn the cloud, the network for testing is provisioned as part of the DR cloud resources and is often subject to limitations as mentioned before. If the DR is implemented on the same cloud, it would be easier to configure a network to simulate or switch the production environment.\n\n\n\n\n\n Failover (or emergency) \n\nThe entire production networks must be routed to the DR site, while the replication network flow is reversed from DR site to on premises to bring the update back to the on premises, and suspended until the emergency is over at on-premises site.\n\nDuring the emergency, the network functions (routing and security) are also transferred from on premises to the DR site, and if the primary is physical on premises, it might need to be virtualized to adapt to the target requirements. A precheck and maintenance of this physical-to-virtual network function is a key success factor during the emergency, and it has the same importance as the data replicator or the server reprovisioning technique.\n\nFor this network, also apply all the considerations described previously for cloud to DR cloud.\n\n\n\n\n\n Fallback \n\nFallback presents the same challenges as the DR simulation by switch-over seen before, as you keep having the production running at the DR site, while intercepting and sending updates back to the fallback site. The quantity of data that flows back to the fallback sites depends on the emergency that happened.\n\nFor short-term emergencies where the original site is unavailable for a period of time, but servers and storage remain intact, a delta-resynch might fit the need to bring the operation back to on premises.\n\nFor other emergencies, that have forced a change to the site, server, or storage in the original on premises, it might require a full resynchronization of data, so the fallback will happen tidily at the most convenient time after the sync point has been achieved.\n\n\n\n\n\n Cloud networking (LAN)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-networking-aspects"},{"document_id":"ibmcld_16030-4758-6868","score":0.0153846154,"text":"\nInter-subnet, inter-zone data flows - For these flows, the implicit router function removes the VNI and forwards the packet in the VPC's MPLS VPN for transit across the cloud backbone. At the destination zone, the implicit router function tags the data packet with the appropriate VNI. Then, the packet is forwarded to the destination hypervisor, where the VNI is stripped off again so that the data packet can be forwarded to the destination virtual server instance.\n\nExtra-vpc service data flows - Packets that are destined for IaaS or IBM Cloud Service Endpoint (CSE) services use the VPC's implicit router function. They also use a network address translation (NAT) function. The translation function replaces the virtual server instance address with an IPv4 address that identifies the VPC to the IaaS or CSE service that is requested.\n\nExtra-vpc internet data flows - Packets that are destined for the internet are the most complex. In addition to using the VPC's implicit router function, each of these flows also rely on one of the implicit router's two network address translation (NAT) functions.\n\n\n\n* An explicit one-to-many NAT through a public gateway function that serves all subnets that are connected to it.\n* One-to-one NAT assigned to individual virtual server instances.\n\n\n\nAfter NAT translation, the implicit router forwards these internet-destined packets to the internet, by using the cloud backbone.\n\n\n\n\n\n Life cycle of external IP addresses that are associated with public gateway functions \n\nAs both external IP addresses and PGWs are bound to an availability zone. A public gateway function can have only a single external IP. This external IP has the following lifecycle:\n\n\n\n* The external IP is allocated when the public gateway is created.\n* The external IP is released when the public gateway is deleted.\n\n\n\n\n\n\n\n Classic access \n\nThe [classic access](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) feature for VPC is accomplished by reusing the VRF identifier from the IBM Cloud\u00ae classic infrastructure account as the VRF identifier for VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.6508205186}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":0.0327868852,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":0.0322580645,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_10852-44214-45420","score":0.0317460317,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_13429-166159-168045","score":0.03125,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_10852-43319-44485","score":0.0307692308,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":0.0303030303,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-2884-4620","score":0.0298507463,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":0.0294117647,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12330-7-2140","score":0.0289855072,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_02772-1628-3402","score":0.0285714286,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8175295904}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":0.0327868852,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":0.0320020481,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":0.0315136476,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":0.0314980159,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":0.0307765152,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":0.0305361305,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12530-4747-5873","score":0.0149253731,"text":"\nThe evidence is reported to the IBM Cloud Security and Compliance Center, and included in an automated change rquest document.\n\nTwo types of issues are reported from your CI and CC pipelines: incident issues and nonincident issues. Incident issues can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts, and nonincident issues do not arise from vulnerabilities, but rather represent a deviation from the compliance posture, for example, unit test failures and branch protection check failures. For more information about managing issues, see [Processing incident and nonincident issues](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-issue-processing) and [Managing incident issues](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-incident-issues)\n\nCompliance evidence creates the trail that auditors look for during a compliance audit. One of the goals of DevSecOps is automated evidence generation and storage in auditable change requests and durable evidence lockers. For more information, see [Evidence](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-evidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-compliant-software-development"},{"document_id":"ibmcld_10852-44214-45420","score":0.0149253731,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_06872-7-2017","score":0.0147058824,"text":"\nProcessing incident and nonincident issues \n\nThe following types of issues are supported:\n\n\n\n* Incident issues, which can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts.\n* Nonincident issues, which do not arise from vulnerabilities, but rather represent a deviation from the compliance posture. For example, unit test failures and branch protection check failures.\n\n\n\n\n\n Adding default assignees to issues \n\nYou can define multiple default assignees for the issue by using the incident-assignees pipeline parameter. The incident-assignees parameter can be used only with GitHub accounts and GitLab Premium accounts. For more information about the incident-assignees parameter, see [Assigning issues to users](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-issue-processingassign-issues).\n\nYou can also set a default issue assignee for the pipeline with the incident-assignee pipeline parameter, however this parameter is deprecated and will be removed with the v1 evidence (legacy) collection.\n\n\n\n\n\n Filtering issues \n\nYou can filter and search for issues by using default and custom labels. The following default labels are assigned to the issues upon creation or update:\n\n\n\n* The [scan type](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-incident-issuesdue-date-supported-tools) that is used for the issue processing is added to the incident issue as a tool label (for example, tool:cra, tool:va, tool:sonarqube).\n* A severity label is also assigned to issues. The severity categories are defined based on the scan results and can be one of the following: severity:critical, severity:high, severity:medium, severity:low, severity:informational.\n* The has-exempt is a VA tool-specific label that is assigned to the issue if it is exempted based on the scan result. If the exempt status is not included in the scan result, you can exempt the issue manually by assigning the exempt label and adding a link to the source of the exempt issue ticket in a comment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-issue-processing"},{"document_id":"ibmcld_12332-1034-2510","score":0.0147058824,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.932521092}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":0.0327868852,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":0.0320020481,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":0.0314980159,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":0.0312805474,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":0.0310096154,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":0.0305361305,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":0.0296312555,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10852-44214-45420","score":0.0149253731,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_09663-15216-17504","score":0.0147058824,"text":"\n* Apply the patch to the secondary replica in the primary MZR i.e. the SQL server in AZ2, if applicable:\n\n\n\n* Using SSMS, change the failover mode from Automatic to Manual to ensures that no automatic failover happens while the patches are installed.\n* Using SSMS, suspend data movement for the secondary replica databases so that the primary replica does not send any transaction block to the specific secondary replica.\n* Via RDP to the server hosting the secondary replica, apply the CU.\n* Restart the server.\n* Once the secondary replica comes online, connect to it using SSMS and perform the following validation:\n\n\n\n* Verify SQL Services are online.\n* SQL Server version validation.\n* Review SQL Server error logs for any errors, warnings.\n* It is also recommended to perform a database consistency checker (DBCC CHECKDB) after applying the patches.\n* Using SSMS, resume data movement to the secondary replica database and wait for the availability group dashboard to show healthy.\n\n\n\n\n\n* Apply the patch to the secondary replica in the recovery MZR, if applicable:\n\n\n\n* Using SSMS, suspend data movement for the secondary replica databases so that the primary replica does not send any transaction block to the specific secondary replica.\n* Via RDP to the server hosting the secondary replica, apply the CU.\n* Restart the server.\n* Once the secondary replica comes online, connect to it using SSMS and perform the following validation:\n* Verify SQL Services are online.\n* SQL Server version validation.\n* Review SQL Server error logs for any errors, warnings.\n* It is also recommended to perform a database consistency checker (DBCC CHECKDB) after applying the patches.\n* Using SSMS, resume data movement to the secondary replica database and wait for the availability group dashboard to show healthy.\n\n\n\n* Apply the patch to the primary replica:\n\n\n\n* Using SSMS, perform a manual failover from the primary replica to the secondary replica in the primary MZR. After the failover, the primary replica changes its state to a secondary replica.\n* Using SSMS, suspend data movement for the secondary replica databases so that the primary replica does not send any transaction block to the specific secondary replica.\n* Via RDP to the server hosting the secondary replica, apply the CU.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-mssql-ops"},{"document_id":"ibmcld_16149-10569-12386","score":0.0144927536,"text":"\nFor more information on this issue, see [(SRX) IPSec comes UP when SRX-A is the Initiator, but fails when SRX-A becomes the responder](https:\/\/kb.juniper.net\/InfoCenter\/index?page=content&id=KB22239) in the Juniper Knowledge Base. Consult [vpn (Security)](https:\/\/www.juniper.net\/documentation\/en_US\/junos\/topics\/reference\/configuration-statement\/security-edit-vpn.html) for more details on these settings.\n\n\n\n\n\n Correcting warning 1177 \n\nOne or more security zone policy rules with the dynamic-application any configuration was detected. If the vSRX is not installed with the Content Security Bundle (CSB) license and application signature database, then this configuration might cause traffic disruption due to changes in newer vSRX releases, such as 19.4R2-S3.\n\nFor example, the following security policy configuration contains the dynamic-application any label:\n\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL match dynamic-application any\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL match source-address SL8\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL match destination-address SL8\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL then permit\n\nIf you are using a similar configuration, it is recommended that you either install the CSB license and the application signature database or remove the dynamic-application any rule.\n\n\n\n\n\n Correcting warning 1179 \n\nThe vSRX version running on the Gateway is not certified on IBM Cloud and is unsupported. Operations such as OS Reload and Rebuild Cluster will overwrite the current unsupported vSRX version with the version currently listed on the Gateway Details page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-correcting-readiness-errors"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-7-1743","score":0.0327868852,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":0.0322580645,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":0.0317460317,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":0.03125,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":0.0307692308,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":0.0303030303,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-1342-3184","score":0.0298507463,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":0.0294117647,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_16351-1788-3771","score":0.0144927536,"text":"\nTo see your new greeting in action, click Preview. In the Preview pane, you should see your customized greeting appear.\n\n\n\n![Preview of customized greeting](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/greeting-preview.png)\n\n\n\n\n\n Adding a mandatory welcome flow \n\nApart from how it is initiated, the Greet customer action is just like any other action. If you need to start each conversation with more than just a standard greeting, you can configure your Greet customer action with more steps and customer responses, just as you would with any other action. For example, instead of just saying hello, your Greet customer action might start by asking for the user's account number. For more information about editing actions, see [Overview: Editing actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview).\n\nYou can also use the Greet customer action to initialize variables for use throughout the conversation. For example, you might want to initialize tracking variables at the beginning of the conversation, or store the user's name so you can personalize the assistant's interactions. In general, you can set variables in the Greet customer action just as you can with any other action. (For more information about setting variables, see [Managing information during the conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-info).)\n\nKeep in mind that you should not rely on the Greet customer action to initialize required variables unless you are certain it will always be triggered at the beginning of each conversation. For more information, see [When the greeting action is triggered](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-start-conversationgreeting-triggered).\n\n\n\n\n\n When the greeting action is triggered \n\nDepending on how you publish your assistant, the Greet customer action might not be triggered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-start-conversation"},{"document_id":"ibmcld_11130-7621-10352","score":0.0144927536,"text":"\nThey are single-tenant and data plane products. They are accessed locally in customer accounts, data plane hosted on virtual resources in the customer's account, control plane security owned by IBM, and data plane security owned by the customer. IBM Cloud products of this type include IBM Cloud Kubernetes Service on classic infrastructure and Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae on classic infrastructure.\n\n\n\nTable 3. Shared responsibilities for self-managed products\n\n Resource Incident and Operations Management Change Management Identity and Access Management Security and Regulation Compliance Disaster Recovery \n\n Data Customer Customer Customer Customer Customer \n Application Customer Customer Customer Customer Customer \n Service instance Shared Shared Shared Shared Shared \n Operating system Shared Shared Shared Shared Shared \n Virtual and bare metal servers Shared Shared Shared Shared Shared \n Virtual storage Shared Shared Shared Shared Shared \n Virtual network Shared Shared Shared Shared Shared \n Hypervisor IBM IBM IBM IBM IBM \n Physical servers and memory IBM IBM IBM IBM IBM \n Physical storage IBM IBM IBM IBM IBM \n Physical network and devices IBM IBM IBM IBM IBM \n Facilities and data centers IBM IBM IBM IBM IBM \n\n\n\nFor areas marked as shared responsibilities, the customer is responsible for all the configurations, and IBM is responsible for all underlying management. For disaster recovery, the customer is responsible for creating resources in a secondary region and managing the application and data disaster recovery.\n\n\n\n\n\n Software packages \n\nSoftware packages are deployed by IBM as single tenant instances, and they are accessed locally in the customer account. The software instance is hosted on resources in the customer's accounts. The software deployment control plane security is owned by IBM, and the software instance security is owned by the customer.\n\nA generic software deployment control plane manages the lifecycle of deployed software package instances. At a minimum, it manages the deployment, upgrade, and delete actions. As the packages become smarter, the generic control plane might also manage the start, stop, migration, scaling, monitoring, backup, and restore tasks.\n\nYou can find a list of software in the IBM Cloud catalog on the Software tab.\n\n\n\nTable 4. Shared responsiblities for software packages\n\n Resource Incident and Operations Management Change Management Identity and Access Management Security and Regulation Compliance Disaster Recovery \n\n Data Customer Customer Customer Customer Customer \n Application Customer Customer Customer Customer Customer \n Software packages Shared Shared Customer Customer Shared \n Operating system Shared Shared Customer Customer Shared","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-shared-responsibilities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4981892575,"ndcg_cut_10":0.6546154995}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":0.0325224749,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":0.0320184426,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-7-1743","score":0.031024531,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-44214-45420","score":0.0308349146,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-43319-44485","score":0.030798389,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-15747-17355","score":0.0303099885,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_12332-1034-2510","score":0.0301177536,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-7-1802","score":0.029877369,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":0.0298573975,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_06968-8289-10541","score":0.0142857143,"text":"\nThe following table shows examples of how some words are stemmed versus lemmatized.\n\n\n\nStemmer versus Lemmatizer comparison\n\n Surface form Lemmatized form Stemmed form \n\n running run run \n ran run ran \n instructor instructor instruct \n instruction instruction instruct \n\n\n\nAs you can see from the examples, the lemmatizer captures the word meanings better than the stemmer. Both running and ran are recognized as different forms of the same root verb run. And the difference in meaning between the two nouns instructor and instruction is preserved. However, if the data contains misspellings such as instructer and instructoin, the normalized form that is generated by stemming (instruct) will return better matches.\n\nDiscovery normalizes words when it ingests and stores data in the index and at run time when it analyzes queries that are submitted by users. The same normalization method is used for both operations, even though one operation occurs at the collection-level and the other occurs at the project-level. When a query is submitted, it is federated to each collection within the project, where the query is normalized based on that collection's configuration. Collections that are configured to use the stemmer normalize the query by using stemming. The collections that are not, normalize the query by using lemmatization.\n\nTo enable the stemmer instead of the lemmatizer when you create the collection, expand More processing options, and then set the Use stemming instead of lemmatization when indexing switcher to On.\n\nIf you configure Discovery to use the stemmer, consider also designing the queries that extract information from the collection to allow for character differences during matching. For more information, see the [String variation operator](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsvariation).\n\nFor more information about the languages for which the stemmer is supported, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\n\n\n\n\n Collection limits \n\nThe number of collections that you can create per project differs by project type.\n\n\n\nCollections per project limits\n\n Project type Collections per project \n\n Document Retrieval 5","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.9134015925}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":0.0327868852,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":0.0322580645,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":0.0317460317,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":0.03125,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":0.0307692308,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":0.0303030303,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":0.0298507463,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":0.0294117647,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_07971-2155-4528","score":0.0289855072,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01533-4-2366","score":0.0285714286,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":0.0320184426,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_07578-365833-367834","score":0.031778058,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01535-4585-6962","score":0.0315136476,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_16727-365807-367808","score":0.0312805474,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-6329-8623","score":0.030798389,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01415-6473-8616","score":0.030798389,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01535-6381-8675","score":0.0303308824,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":0.029198636,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_01494-97628-98949","score":0.0151515152,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01533-4-2366","score":0.0144927536,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0980392858}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-7-2257","score":0.0327868852,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":0.0322580645,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":0.0317460317,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":0.03125,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":0.0307692308,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":0.0303030303,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":0.0298507463,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-6329-8623","score":0.0294117647,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":0.0289855072,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-8109-9900","score":0.0142857143,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.8318724637}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01329-58331-60199","score":0.0327868852,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01442-1679-3832","score":0.0322580645,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":0.0317460317,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01441-7-2257","score":0.03125,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":0.0307692308,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-10805-12534","score":0.0303030303,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-10857-12586","score":0.0298507463,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-367408-369576","score":0.0294117647,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-367382-369550","score":0.0289855072,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04340-56606-58228","score":0.0285714286,"text":"\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":0.0325224749,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":0.0325224749,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-7-2257","score":0.0314980159,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01329-58331-60199","score":0.0312576313,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01442-7-2257","score":0.0310096154,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-10805-12534","score":0.0289855072,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-10857-12586","score":0.0285714286,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":0.0151515152,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_04340-56606-58228","score":0.0151515152,"text":"\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01535-4-2366","score":0.0149253731,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":0.0327868852,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":0.0322580645,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":0.0317460317,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":0.03125,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":0.0307692308,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":0.0303030303,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":0.0298507463,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_07971-2155-4528","score":0.0294117647,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01533-3131-4993","score":0.0144927536,"text":"\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe Security status column in the Images tab of the Container Registry dashboard displays the number of issues that are associated with each image. To find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_00882-2700-4149","score":0.0144927536,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16410-14917-17357","score":0.0327868852,"text":"\nAnnotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static. As your project evolves, you'll likely discover instances of mentions and relationships that are not accurately captured in the guidelines. And you'll likely discover inconsistencies between multiple human annotators who interpret the guidelines in different ways. By updating the guidelines as situations arise, you can help improve the accuracy and consistency of annotations over time.\n\nBefore documents can be considered ground truth, any conflicts between how different human annotators annotated the same documents must be resolved. A key way to resolve the conflicts is by discussing what caused the confusion, thus helping human annotators learn from their mistakes. Improving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area. For example, if you add an entity type, review the guidelines for annotating relation types and specify how the new entity type can relate to other entity types.\n\n\n\n\n\n Annotation guidelines example \n\nMost annotation guidelines will need a lot of detail and examples to ensure that human annotators consistently annotate text.\n\nThe example presented here is a simple guideline that was created for a small domain that contains traffic incident reports.\n\n\n\n Task Goals \n\n\n\n* As project members, become familiar with the iterative process of manual annotation and machine learning model refinement.\n* Annotate documents in the automotive domain with the ground truth editor and use the annotations to train a machine learning model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16417-10079-12145","score":0.0322580645,"text":"\nWhen you find instances of disagreement, you must decide how to resolve the conflict, either by selecting the correct annotation from those applied by the human annotators or by selecting a different annotation to apply.\n\nA document is available for adjudication when at least one of the following conditions is true:\n\n\n\n* The project manager approves two or more annotation sets in a task at the same time, and the same document exists in at least two of the annotation sets (an overlapping document).\n* The project manager approves another annotation set before documents in the previously approved annotation sets are adjudicated. If you adjudicate a document that overlaps between annotation set A and annotation set B, promote the annotations to ground truth, and then approve another annotation set, C, that has the same document, the annotations in the newly approved document are promoted automatically to ground truth because conflicts no longer exist. Be aware that the annotations promoted in annotation set C override the ground truth established when the overlapping documents in annotation sets A and B were adjudicated. If you approve annotation set C before you promote the annotations in annotation set A and B, the overlapping documents in set C can be checked for conflicts and adjudicated.\n\n\n\nThe amount of time that you spend adjudicating might lessen over time if you take time to improve the annotation guidelines. By providing examples and clarifying areas that caused confusion, you can help human annotators learn from their mistakes and prevent future conflicts.\n\nHere are a few examples of various ways that human annotators disagree:\n\n\n\n* Mentions\n\n\n\n* Annotator_1 places a mention on a span of text; Annotator_2 does not.\n* Annotator_1's index begins or ends before or after Annotator_2's (there is a partial overlap or subrange of text).\n* Annotator_1 assigns an entity type that is different from the entity type that Annotator_2 assigned.\n\n\n\n* Relations\n\n\n\n* Annotator_1 creates a relation between two mentions; Annotator_2 does not.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-10078-12144","score":0.0317460317,"text":"\nWhen you find instances of disagreement, you must decide how to resolve the conflict, either by selecting the correct annotation from those applied by the human annotators or by selecting a different annotation to apply.\n\nA document is available for adjudication when at least one of the following conditions is true:\n\n\n\n* The project manager approves two or more annotation sets in a task at the same time, and the same document exists in at least two of the annotation sets (an overlapping document).\n* The project manager approves another annotation set before documents in the previously approved annotation sets are adjudicated. If you adjudicate a document that overlaps between annotation set A and annotation set B, promote the annotations to ground truth, and then approve another annotation set, C, that has the same document, the annotations in the newly approved document are promoted automatically to ground truth because conflicts no longer exist. Be aware that the annotations promoted in annotation set C override the ground truth established when the overlapping documents in annotation sets A and B were adjudicated. If you approve annotation set C before you promote the annotations in annotation set A and B, the overlapping documents in set C can be checked for conflicts and adjudicated.\n\n\n\nThe amount of time that you spend adjudicating might lessen over time if you take time to improve the annotation guidelines. By providing examples and clarifying areas that caused confusion, you can help human annotators learn from their mistakes and prevent future conflicts.\n\nHere are a few examples of various ways that human annotators disagree:\n\n\n\n* Mentions\n\n\n\n* Annotator_1 places a mention on a span of text; Annotator_2 does not.\n* Annotator_1's index begins or ends before or after Annotator_2's (there is a partial overlap or subrange of text).\n* Annotator_1 assigns an entity type that is different from the entity type that Annotator_2 assigned.\n\n\n\n* Relations\n\n\n\n* Annotator_1 creates a relation between two mentions; Annotator_2 does not.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16468-16607-18718","score":0.03125,"text":"\nImproving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area. For example, if you add an entity type, review the guidelines for annotating relation types and specify how the new entity type can relate to other entity types.\n\n\n\n\n\n Annotation guidelines example \n\nMost annotation guidelines will need a lot of detail and examples to ensure that human annotators consistently annotate text.\n\nThe example presented here is a simple guideline that was created for a small domain that contains traffic incident reports.\n\n\n\n Task Goals \n\n\n\n* As project members, become familiar with the iterative process of manual annotation and machine learning model refinement.\n* Annotate documents in the automotive domain with the ground truth editor and use the annotations to train a machine learning model. Annotate the entity types, relation types, and coreference the entities as needed.\n\n\n\n\n\n\n\n Guideline Notations \n\n\n\n* Square brackets [ ] indicate the extent to be annotated when less than the entire quoted text is annotated.\n\nInclude negations as appropriate, for example [no injuries]ACCIDENT_OUTCOME. The type system is not using entity class to represent negation.\n\n\n\n\n\n\n\n Entity Types \n\nThe type system does not use entity sub-types or roles, nor mention types or classes.\n\n\n\n Entity types Guidelines Examples \n\n ACCIDENT_OUTCOME A consequence of an accident. Applies to both humans (e.g., death) and cars (e.g., dented). Can include \"towed\" and \"air bag deployment\" as indicators of severity of damage, and \"transported to hospital\" (but not funeral home) as indicators of severity of injury. Can include negation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16417-3559-5683","score":0.0305361305,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16468-14825-17168","score":0.0303099885,"text":"\nTo connect the ground truth editor and adjudication tool to your annotation guidelines:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. select the Settings > Annotation Guidelines tab.\n3. Specify the URL to where your guidelines are hosted.\n4. Click Save. The system connects the ground truth editor and adjudication tool to your annotation guidelines. Depending on the access permissions granted to users when you created the guidelines, human annotators and workspace administrators might be able to update the guidelines after opening them, for example, to add clarifications and examples.\n\n\n\n\n\n\n\n Annotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static. As your project evolves, you'll likely discover instances of mentions and relationships that are not accurately captured in the guidelines. And you'll likely discover inconsistencies between multiple human annotators who interpret the guidelines in different ways. By updating the guidelines as situations arise, you can help improve the accuracy and consistency of annotations over time.\n\nBefore documents can be considered ground truth, any conflicts between how different human annotators annotated the same documents must be resolved. A key way to resolve the conflicts is by discussing what caused the confusion, thus helping human annotators learn from their mistakes. Improving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16481-3559-5682","score":0.0300768883,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16242-7-2224","score":0.0147058824,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16456-13093-15345","score":0.0147058824,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16456-21212-23338","score":0.0144927536,"text":"\nMove through the document and click each mention that means the same thing and is labeled by the same entity type. For example, click each occurrence of IBM, International Business Machines, and IBM Corp., assuming all these mentions have the entity type ORGANIZATION.\n2. Double-click the last mention that you want to add to the chain. A coreference chain is created in the side panel. The name of the chain matches the first mention that you selected.\n3. To highlight all mentions in a chain to review them in context, hover over the name of the chain in the side pane.\n\n\n\n8. The Single Mention List displays terms in the document that have been annotated, but have not been added to a chain. If you notice a mention in the list that belongs in a chain, you can add it to the chain from here.\n\n\n\n1. From the Single Mention List in the side panel, click the mention.\n2. From the drop-down list below the mention description, choose the number that represents the chain that you want to add the mention to.\n3. Click Merge to add the mention to the chain, and then click OK.\n\n\n\nThe mention is removed from the Single Mention List and the number of the chain that it now belongs to is displayed below the mention in the document.\n9. You can undo your work by using the following methods:\n\n\n\n* To remove a coreference chain that you just added, press Ctrl+Z to undo the action.\n* To remove a coreference chain later, from the Coreference Chains side panel, click the X next to the chain that you want to remove.\n* To remove a single mention from the chain, click the coreference ID to open a window that displays a list of the mentions in the chain, and then click the X next to the mention that you want to remove.\n\n\n\n10. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01377-13470-15034","score":0.0327868852,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-13496-15060","score":0.0322580645,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01530-1294-3025","score":0.0317460317,"text":"\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinviamuserinv).\n\nIf you want users to create clusters in IBM Cloud Kubernetes Service, ensure that you assign the IBM Cloud Container Registry Administrator role to those users, and don't assign a resource group. For more information, see [Preparing to create clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusterscluster_prepare).\n\n\n\nTo create policies for IBM Cloud Container Registry, the service name field must be container-registry.\n\nIf you want to access resources, you must assign roles to users or service IDs. If you want to grant access to everything, don't specify a resource type or a resource. If you want to grant access to a specific namespace, specify the resource type as namespace and use the namespace name as the resource.\n\n\n\n* To create a policy for users, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n* To create a policy for service IDs, run the ibmcloud iam service-policy-create command or use the IBM Cloud console to bind roles to your service IDs. To create policies, you must have the Administrator role. You automatically have the Administrator role on your own account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user"},{"document_id":"ibmcld_01494-31513-33000","score":0.03125,"text":"\n* [Enforce security in your cluster](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_enforce_security)\n* [Resolve vulnerabilities in your image](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_resolve_vulnerabilities)\n\n\n\n* [Deploying to nondefault Kubernetes namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_deploy_nondefault_namespaces)\n\n\n\n\n\n\n\n Granting access to Container Registry resources tutorial \n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access_prereq)\n* [Authorize a user to configure the registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessconfigure_registry)\n* [Authorize a user to access specific namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessaccess_resources)\n* [Create a service ID and grant access to a resource](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessservice_id)\n* [Cleaning up your account](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessclean_up)\n\n\n\n\n\n\n\n Solution tutorials \n\n[Moving a VM based app to Kubernetes](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-vm-to-containers-and-kubernetesvm-to-containers-and-kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_16729-71418-73421","score":0.0307692308,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_01530-7-1855","score":0.0303030303,"text":"\nDefining IAM access policies for Container Registry \n\nAs an administrator, you can define IBM Cloud\u00ae Identity and Access Management (IAM) access policies to create different levels of access for different users in IBM Cloud\u00ae Container Registry. For example, you can authorize some users to view quotas and other users to set quotas.\n\nYou must define IAM\n\naccess policiesfor every user that works with IBM Cloud Container Registry. The scope of an IAM access policy is based on the user's role or roles that determine the actions that they are allowed to do. Some roles are predefined, but custom roles can be defined.\n\nTo find out more about IAM access policies, see [IBM Cloud IAM roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nYou can assign Container Registry namespaces to a [resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs) and scope access policies to that group, see [Planning namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_setup_cli_namespace_plan). However, you can still define access policies that are scoped to individual Container Registry namespaces or to all namespaces that are owned by the account.\n\n\n\n Creating policies \n\nBefore you begin, complete the following tasks:\n\n\n\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinviamuserinv).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user"},{"document_id":"ibmcld_01377-4-1879","score":0.0298507463,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-4-1879","score":0.0294117647,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01388-7-1807","score":0.0289855072,"text":"\nGranting access to Container Registry resources tutorial \n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser).\n\nFor more information about how to use IAM to manage access to your resources, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Before you begin \n\nBefore you begin, you must complete the following tasks:\n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n* Ensure that you have access to two [IBM Cloud accounts](https:\/\/cloud.ibm.com\/login) that you can use for this tutorial, one for User A and one for User B, each must use a unique email address. You work in your own account, User A, and invite another user, User B, to use your account. You can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01388-10517-12258","score":0.0285714286,"text":"\nList the policies for User B by running the following command.\n\nibmcloud iam user-policies <user.b@example.com>\n\nFind the policies that you created and note the Policy IDs.\n3. Delete the policies that you created by running the following command, where <Policy_ID> is the Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 3: Create a service ID and grant access to a resource \n\nConfigure a service ID and grant it access to your IBM Cloud Container Registry namespace.\n\n\n\n1. Set up a service ID with access to IBM Cloud Container Registry and create an\n\nAPI keyfor it.\n\n\n\n1. Log in to User A's account by running the following command.\n\nibmcloud login\n2. Create a service ID named cr-roles-tutorial with the description \"Created during the access control tutorial for Container Registry\" by running the following command.\n\nibmcloud iam service-id-create cr-roles-tutorial --description \"Created during the access control tutorial for Container Registry\"\n3. Create a service policy for the service ID that grants the Reader role on namespace_a by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_a --roles Reader\n4. Create a second service policy that grants the Writer role on namespace_b by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_b --roles Writer\n5. Create an API key for the service ID by running the following command.\n\nibmcloud iam service-api-key-create cr-roles-tutorial-apikey cr-roles-tutorial\n\n\n\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04025-17033-18743","score":0.0163934426,"text":"\nIn order for a CA, peer, or ordering node to be able to communicate with the HSM client image you need to create a Kubernetes secret named hsmcrypto that contains the keys and configuration files for the HSM that you are using. When the console deploys a node that is configured with HSM, it uses this secret to access the HSM client image keys and configuration files.\n\nThe Kubernetes secret needs to be created in the IBM Blockchain Platform service instance namespace that is visible on the console Support page. If you are using the IBM Cloud HSM, the command would be:\n\n$ kubectl create secret generic hsmcrypto -n <NAMESPACE> --from-file=Chrystoki.conf --from-file=cert.pem --from-file=key.pem --from-file=server.pem\n\nReplace <NAMESPACE> with the name of your service instance namespace or OpenShift project If you are not using IBM Cloud HSM, you need to replace the values of the --from-file parameters with the set of certificates and configuration files that are required for your HSM client image.\n\nWhen successful, the output looks similar to:\n\nsecret\/hsmcrypto created\n\nTo verify the contents of the secret, run the command:\n\nkubectl get secret -n <namespace> hsmcrypto -o yaml\n\nYou should see results similar to:\n\napiVersion: v1\ndata:\nChrystoki.conf: \"\"\ncafile.pem: \"\"\ncert.pem: \"\"\nkey.pem: \"\"\nkind: Secret\nmetadata:\nname: hsmcrypto\nnamespace: <NAMESPACE>\n\n\n\n\n\n Step five: Create the HSM configmap \n\nBecause the console needs to know the configuration settings to use for your HSM, you need to create a Kubernetes [configmap](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/configmap\/) to store these values. The configMap settings depend on whether you configured a daemon for your HSM or not.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-hsm-gemalto"},{"document_id":"ibmcld_06155-0-1193","score":0.0163934426,"text":"\n\n\n\n\n\n\n  Why does binding a service to a cluster result in a same name error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nWhen you run ibmcloud ks cluster service bind --cluster <cluster_name> --namespace <namespace> --service <service_instance_name>, you see the following message.\n\nMultiple services with the same name were found.\nRun 'ibmcloud service list' to view available Bluemix service instances...\n\n  Why it\u2019s happening \n\nMultiple service instances might have the same name in different regions.\n\n  How to fix it \n\nUse the service GUID instead of the service instance name in the ibmcloud ks cluster service bind command.\n\n\n\n1.  [Log in to the IBM Cloud region that includes the service instance to bind.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zonesbluemix_regions)\n2.  Get the GUID for the service instance.\n\nibmcloud service show <service_instance_name> --guid\n\nExample output\n\nInvoking 'cf service <service_instance_name> --guid'...\n<service_instance_GUID>\n3.  Bind the service to the cluster again.\n\nibmcloud ks cluster service bind --cluster <cluster_name> --namespace <namespace> --service <service_instance_GUID>\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-app-svc-bind-name"},{"document_id":"ibmcld_10852-36156-37516","score":0.0161290323,"text":"\n* [How do I set IAM policies so that others can work with my namespace?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_namespace_policies)\n* [How do I set IAM policies so that others can create namespaces in my account?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_namespace_create)\n* [How do I know which access policies have set for me?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_set_policies_me)\n* [Platform management roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_platform_roles)\n* [Service-specific roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice_specific_roles)\n* [Setting access policies for a service ID](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice-id-set-policy)\n\n\n\n* [Setting access policies for a service ID in the console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice-id-set-ui)\n* [Setting an access policy for your Cloud Functions service ID through the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamcli-set)\n\n\n\n\n\n\n\n\n\n Integrating serverless apps \n\n[Binding IBM Cloud services to Cloud Functions entities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-servicesservices)\n\n\n\n* [Binding a service to an action or package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-servicesservices_bind)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10773-5740-7643","score":0.0161290323,"text":"\nYou can set an access policy for a service ID by using the IAM console.\n\n\n\n1. Open the [IAM Service ID page](https:\/\/cloud.ibm.com\/iam\/serviceids).\n2. In the Service IDs list, select your Cloud Functions namespace.\n3. On the Manage page, click Access policies, then click Assign access.\n4. Next, select an Access Type. You can choose from the following options.\n\n\n\n* Assign access within a resource group: Use this option to grant your Cloud Functions service ID access to a resource group.\n* Assign access to resources: Use this option to grant your Cloud Functions service ID access to a specific resource, like an instance of IBM Cloud Object Storage.\n* Assign access to account management services: Use this option to grant your Cloud Functions service ID access to account management services such as billing, user management, and more.\n\n\n\n\n\n\n\n\n\n Setting an access policy for your Cloud Functions service ID through the CLI \n\nSet an access policy for a service ID by using the CLI.\n\nCopy the following command. Replace <namespace_service_ID> with the name of your Cloud Functions namespace. Replace <IAM_role1,IAM_role2> with the IAM roles you want to assign to your namespace. Replace <other_service_name> with the name of the IBM service you want Cloud Functions to work with. Replace <other_service_GUID> with the GUID of the IBM service instance.\n\nibmcloud iam service-policy-create <namespace_service_ID> --roles <IAM_role1,IAM_role2> --service-name <other_service_name> --service-instance <other_service_GUID>\n\n\n\nTable 1. Understanding the command components\n\n Option Description \n\n <namespace_service_ID> The service ID for the namespace. To see all service IDs, run ibmcloud iam service-ids. \n <IAM_role> The type of IAM service access role that the action must have to use the target service. To see the supported roles for the other service, run ibmcloud iam roles --service SERVICE_NAME.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iam"},{"document_id":"ibmcld_03977-17614-19173","score":0.0158730159,"text":"\n![How to find peer fabric version](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/peerversion.png)\n\nFigure 1.How to find peer fabric version\n\n\n\n Hyperledger Fabric v2.x peer image \n\n![version 2.x](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/2-x_Pill.png) While the terms \"smart contract\" and \"chaincode\" are often used interchangeably, \"smart contracts\" refers to the business logic that governs transactions and access to its data, while \"chaincode\" refers to the larger infrastructure of packages and other code that encompasses a smart contract.\n\nIf your peer is based on the Hyperledger Fabric v2.x image, you can run the following set of kubectl commands to view the smart contract logs.\n\nFind your cluster namespace\n\nIf you don't already know it, you need to find your Kubernetes cluster namespace. From the console, open any CA node and click the Info and Usage icon. View the value of the API URL. For example: https:\/\/nf85a2a-soorg10524.ibpv2-cluster.us-south.containers.appdomain.cloud:7054. The namespace is the first part of the URL beginning with the letter n and followed by a random string of six alphanumeric characters. So in the example above the value of the namespace is nf85a2a.\n\nFind the smart contract pod\n\nNext, get a list of all of the smart contract pods running in your cluster:\n\nkubectl get po -n <NAMESPACE> | grep chaincode-execution | cut -d\" \" -f1 | xargs -I {} kubectl get po {} -n <NAMESPACE> --show-labels","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-manage-console"},{"document_id":"ibmcld_05647-11842-13275","score":0.0158730159,"text":"\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: tcp-services\nnamespace: kube-system\ndata:\n9000: \"<namespace>\/<service>:8080\"\n2. Create the ConfigMap in the kube-system namespace.\n\nkubectl apply -f tcp-services.yaml -n kube-system\n3. Specify the tcp-services ConfigMap as a field in the [ibm-ingress-deploy-config ConfigMap](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationscomm-customize-deploy).\n\n\"tcpServicesConfig\":\"kube-system\/tcp-services\"\n4. [Modify each ALB service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationscomm-customize-deploy) to add the ports.\n\n\n\n\n\n\n\n Setting a maximum number of upstream keepalive requests \n\nTo set the maximum number of requests that can be served through one keepalive connection, use the following Kubernetes ibm-k8s-controller-config ConfigMap [field](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/configmap\/upstream-keepalive-requests).\n\nupstream-keepalive-requests: 32\n\n\n\n\n\n Setting the maximum upstream keepalive timeout \n\nTo set the maximum time that a keepalive connection stays open between the ALB proxy server and your app's upstream server, use the following Kubernetes ibm-k8s-controller-config configmap [field](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/configmap\/upstream-keepalive-timeout).\n\nupstream-keepalive-timeout: 32\n\n\n\n\n\n Customizing the ALB deployment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotations"},{"document_id":"ibmcld_10773-1311-3056","score":0.015625,"text":"\nFor more information about Platform and Service level access roles, see [Platform management roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_platform_roles) and [Service-specific roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice_specific_roles).\n\nWant to learn more about IAM key concepts? Check out [the IAM overview](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverview) or the [Best practices for assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setup).\n\n\n\n\n\n How do I set IAM policies so that others can create namespaces in my account? \n\nTo allow other users to manage Cloud Functions namespaces, including creating new namespaces, you must set the following access policies for those users.\n\n\n\n* The user's Platform role must be set to Administrator. This policy applies to all resources of Cloud Functions.\n* The user's Service role must be set to Manager. This policy applies to all resources of Cloud Functions.\n\n\n\n\n\n\n\n How do I know which access policies have set for me? \n\nYou can see which access policies have been set for you in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog) console.\n\n\n\n1. From the console, click Manage > Access (IAM) > Users. Or, navigate to https:\/\/cloud.ibm.com\/iam\/users.\n2. Click your name in the user table.\n3. Click the Access policies tab to see your access policies.\n\n\n\n\n\n\n\n Platform management roles \n\nThe following table details the actions that are mapped to platform management roles. Platform management roles enable users to perform tasks on service resources at the platform level. For example, assign user access for the service, create or delete service IDs, create instances, and bind instances to applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iam"},{"document_id":"ibmcld_10727-14691-16478","score":0.015625,"text":"\nThese properties allow actions to programmatically work with assets through the REST API or set an internal alarm when the action is about to use up its allotted time budget.\n\n\n\nEnvironment variables for actions.\n\n Property Description \n\n __OW_ACTION_NAME The fully qualified name of the running action. \n __OW_ACTIVATION_ID The activation ID for this running action instance. \n __OW_API_HOST The API host for the deployment that is running this action. \n __OW_API_KEY The API key for the subject that is invoking the action. This variable is only provided for classic CF-based namespaces. \n __OW_DEADLINE The approximate time, in epoch milliseconds, when this action consumes its entire duration quota. \n __OW_IAM_API_URL The service endpoint used for IAM operations, such as getting a token from API key. This variable is only available for IAM-enabled namespaces. \n __OW_IAM_NAMESPACE_API_KEY The API key for IAM-enabled namespaces. See [Setting access policies](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespacesnamespace-access) for usage. \n __OW_NAMESPACE The namespace ID (GUID). For classic CF-based namespaces, this ID is constructed from org and space names. \n __OW_NAMESPACE_CRN The namespace cloud resource name [CRN](https:\/\/cloud.ibm.com\/docs\/account?topic=account-crn). The CRN is only available for IAM-enabled namespaces. \n __OW_TRANSACTION_ID The transaction ID for the running action instance. If the action is running as part of a sequence, then the transaction ID is the same for the sequence and all its actions. If this ID is used as part of a user log line, then the [logs](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-logslogs_console) can be filtered for a specific transaction. \n\n\n\n\n\n Incorporating action environment variables in your app","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions"},{"document_id":"ibmcld_06029-8866-10776","score":0.0153846154,"text":"\nIf you created other priority classes in your cluster, you can check to make sure that they don't set a globalDefault by running kubectl describe priorityclass <name>. \n description Optional: Tell users why to use this priority class. Enclose the string in quotations (\"\"). \n\n\n\n4. Create the priority class in your cluster.\n\nkubectl apply -f filepath\/priorityclass.yaml\n5. Verify that the priority class is created.\n\nkubectl get priorityclasses\n\n\n\nGreat! You created a priority class. Let your team know about the priority class and which priority class, if any, that they must use for their pod deployments.\n\n\n\n\n\n Assigning priority to your pods \n\nAssign a priority class to your pod spec to set the pod's priority within your IBM Cloud Kubernetes Service cluster.\n\nBefore you begin:\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* Ensure that you have the [Writer or Manager IBM Cloud IAM service access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) in the namespace that you want to deploy the pods to.\n* [Understand how priority scheduling works](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod_prioritypriority_scheduling), as priority can preempt existing pods and affect how your cluster's resources are consumed.\n\n\n\nComplete the following steps to check the importance of other deployed pods so that you can choose the correct priority class for your pods in relation to what already is deployed.\n\n\n\n1. View the priority classes that other pods in the namespace use.\n\nkubectl get pods -n <namespace> -o custom-columns=NAME:.metadata.name,PRIORITY:.spec.priorityClassName\n2. Get the details of the priority class and note the value number. Pods with higher numbers are prioritized before pods with lower numbers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod_priority"},{"document_id":"ibmcld_06090-18009-19560","score":0.0153846154,"text":"\nConfigure your app to read the environment variable and to parse the JSON content to retrieve the information that you need to access your service.\n\nExample code in Python:\n\nif os.environ.get('BINDING'):\ncredentials = json.loads(os.environ.get('BINDING'))\n8. Optional: As a precaution, add error handling to your app in case that the BINDING environment variable is not set properly.\n\nExample code in Java:\n\nif (System.getenv(\"BINDING\") == null) {\nthrow new RuntimeException(\"Environment variable 'SECRET' is not set!\");\n}\n\nExample code in Node.js:\n\nif (!process.env.BINDING) {\nconsole.error('ENVIRONMENT variable \"BINDING\" is not set!');\nprocess.exit(1);\n}\n\n\n\n\n\n\n\n\n\n Removing a service from a cluster \n\nIf you don't want to use an IBM Cloud service that you bound to your cluster, you can manually remove the Kubernetes secret and the pods that access the secret from your cluster.\n\n\n\n1. List the services that are bound to your cluster and note the name of your service and the namespace that the service is bound to.\n\nibmcloud ks cluster service ls --cluster\n\nExample output\n\nOK\nService Instance GUID Key Namespace\nmyservice 12345ab1-1234-1abc-a12b-12abc12a12ab kube-a1a12abcd12a123abc1a12ab1a1234ab7.abcdefg0p1abcd123lgg.default default\n2. List the Kubernetes secrets in the namespace that your service is bound to and look for the secret with a name that follows the binding-<service_name> format.\n\nkubectl get secrets -n <namespace> | grep Opaque\n\nExample output\n\nbinding-myservice Opaque 1 3d23h\n3. Retrieve all the pods that access the secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-binding"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00512-1696-3972","score":0.0327868852,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00513-7-2197","score":0.0322580645,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00512-7-2158","score":0.0317460317,"text":"\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00576-7385-9302","score":0.03125,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-20968-23077","score":0.0307692308,"text":"\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00589-25445-26913","score":0.0303030303,"text":"\nGET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_disk_size\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_info\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design_docs cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.any-document.read \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n COPY \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n POST\/DELETE \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.design-document.write \n GET\/HEAD \/$DATABASE\/_security cloudantnosqldb.database-security.read \n PUT \/$DATABASE\/_security cloudantnosqldb.database-security.write \n GET\/HEAD \/$DATABASE\/_shards cloudantnosqldb.database-shards.read \n COPY (Depends on write document type.) \/$DATABASE\/$DOCUMENT_ID cloudantnosqldb.any-document.read + cloudantnosqldb.design-document.write either or both cloudantnosqldb.local-document.write either or both cloudantnosqldb.data-document.write","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_00612-7-2163","score":0.0298507463,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_06633-1299-3259","score":0.0294117647,"text":"\nYou can extend high-availability further by adding [PostgreSQL members](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-horizontal-scaling) to the instance, for greater in-region redundancy, or by provisioning [read-only replicas](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-read-only-replicas) for cross-regional failover or read offloading.\n\nDatabases for PostgreSQL is designed and built to provide a robust, resilient, and performant Database as a Service offering. Review the PostgreSQL documentation on [replication techniques](https:\/\/www.postgresql.org\/docs\/current\/wal-async-commit.html) to understand the constraints and tradeoffs that are associated with the asynchronous replication strategy that is deployed by default with Databases for PostgreSQL.\n\nIn scenarios where a database becomes critically unhealthy, such as a server crash on the leader, Databases for PostgreSQL attempts a failover. This auto failover capability is capped at 16 MB of data lag from leader to follower (a few rows of data once accounting for more PostgreSQL data overhead) and is not performed if the lag threshold is exceeded. If the potential for 16 MB of data loss is intolerable for the application, horizontally scale your Databases for PostgreSQL instance to three members and configure Databases for PostgreSQL to use a synchronous replication strategy on a per user or per database basis.\n\n\n\n Synchronous replication \n\nBy default, streaming replication is asynchronous. If the primary server crashes, some transactions that were committed might not have been replicated to the standby server, causing data loss. Cloud Databases ensures that data loss is kept to a minimum substantial data loss; however, synchronous replication offers the ability to confirm that all changes were made by a transaction have been transferred to a synchronous member, ensuring consistency across a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-high-availability"},{"document_id":"ibmcld_00550-7-2005","score":0.0289855072,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_09521-7-2114","score":0.0285714286,"text":"\nLimitations & Exclusions \n\nMaximo Application Suite SaaS is implemented using a defined set of technologies and operates within a security profile designed to ensure our client's data is secure and the applications operate efficiently and effectively. As a result of the decisions made regarding technologies and to meet the high security standards, there are differences between what is available using the Managed Services and what a client could do if they hosted and operated the Suite themselves.\n\nThe following items are not included or allowed in the Maximo Application Suite SaaS offering:\n\n\n\n Databases \n\nThe following are database limitations of the MAS-SaaS offering:\n\n\n\n* Only IBM DB2 Warehouse is supported. Oracle and SQLServer are not supported. Conversion services are available.\n* If converting from Oracle to DB2, Oracle compatibility mode is not supported.\n* Customers are not allowed direct access to MAS-SaaS database(s). If direct database access is needed, customer should look into the [MAS-Dedicated](https:\/\/cloud.ibm.com\/docs\/mas-ms) offering.\n* DB2 Text Search is not supported.\n* Running SQL statements (update\/insert\/delete) directly on the database is not allowed and IBM SRE team will not be able to execute those statements for you. DBC scripts are not allowed. Customers should carry out these changes using the Maximo UI via [Automation Scripts](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) or the [Maximo Integration Framework](https:\/\/www.ibm.com\/docs\/en\/maximo-ora-con\/8.1.0?topic=architecture-maximo-integration-framework-overview).\n\n\n\n\n\n\n\n Java Extensions \n\nJava extensions are not supported. Maximo Manage [Automation Scripting](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) capability should instead be used. Existing Maximo customers who have Java extensions will need to migrate \/ convert these functions into automation scripts within the application.\n\n\n\n\n\n 3rd Party Applications \n\nMaximo Application Suite SaaS will not host or support 3rd party applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-limitations-exclusions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07028-8585-10420","score":0.0320184426,"text":"\nTo add an advanced rule model, complete the following steps:\n\n\n\n1. Create the model and export the ZIP file that contains the model resources.\n\nFor more information about how to export the model, see the instructions for your model source:\n\n\n\n* [Knowledge Studio for IBM Cloud Pak\u00ae for Data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-advanced-rules-model)\n* [Knowledge Studio for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-create-advanced-rules-model)\n* [Open source NLP Editor](https:\/\/github.com\/CODAIT\/nlp-editor)\n\n\n\n2. From the Teach domain concepts section of the Improvement tools panel, choose Advanced rules model.\n3. Click Upload.\n4. Specify a name for the model, and then choose the language that was used to define the model.\n5. Specify a name for the result field, which is the field in the index where the output of this enrichment will be stored.\n6. Click Upload to browse for the ZIP file that you exported earlier.\n7. Click Create.\n8. Choose the collection and field where you want to apply the enrichments from the model, and then click Apply.\n\n\n\n\n\n\n\n Output format for advanced rules \n\nKnowledge Studio uses the Annotation Query Language (AQL) to define the rules in an advanced rules model. Each model is defined by one or more views. Each view is a relational data structure that contains multiple data records. Each record is composed of values in columns that are defined by the view\u2019s schema. To facilitate representing these models, which are custom and therefore have various schemas, a uniform JSON output schema is used.\n\n\n\n* Each JSON object represents an Annotation Query Language (AQL) view.\n* The name-and-value pairs in the JSON objects represent the names and values of the attributes in the view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-ml"},{"document_id":"ibmcld_00519-12531-14412","score":0.0320184426,"text":"\nIn particular, you must not use functions that generate random numbers or return the current time.\n\n\n\n\n\n\n\n Filter functions \n\nDesign documents with options.partitioned set to true can't contain a filters field.\n\nFilter functions are design documents that filter the [changes feed](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasesget-changes). They work by applying tests to each of the objects included in the changes feed.\n\nIf any of the function tests fail, the object is \"removed\" or \"filtered\" from the feed. If the function returns a true result when applied to a change, the change remains in the feed. In other words, filter functions \"remove\" or \"ignore\" changes that you don't want to monitor.\n\nFilter functions can also be used to modify a [replication task](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationfiltered-replication-adv-repl).\n\nFilter functions require two arguments: doc and [req](https:\/\/docs.couchdb.org\/en\/stable\/json-structure.htmlrequest-object).\n\nThe doc argument represents the document that is tested for filtering.\n\nThe req argument includes more information about the request. With this argument, you can create filter functions that are more dynamic because they're based on multiple factors such as query parameters or the user context.\n\nFor example, you could control aspects of the filter function tests by using dynamic values that are provided as part of the HTTP request. However, in many filter function use cases, only the doc parameter is used.\n\nSee the following example design document that includes a filter function:\n\n{\n\"_id\":\"_design\/example_design_doc\",\n\"filters\": {\n\"example_filter\": \"function (doc, req) { ... }\"\n}\n}\n\nSee the following example of a filter function:\n\nfunction(doc, req){\n\/\/ we need only mail documents\nif (doc.type != 'mail'){\nreturn false;\n}\n\/\/ we're interested only in new ones","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-documents"},{"document_id":"ibmcld_13493-1220-3010","score":0.0312805474,"text":"\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_00472-19526-21520","score":0.0161290323,"text":"\nIt differs from using \"fieldname:value\" in the q parameter only in that the values aren't analyzed. [Faceting](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-searchfaceting) must be enabled for this parameter to function. No JSON A JSON array that includes two elements: the field name and the value. Yes \n group_field Field by which to group search matches. Yes String A string that includes the name of a string field. Fields that include other data such as numbers, objects, or arrays can't be used. No \n group_limit Maximum group count. This field can be used only if group_field is specified. Yes Numeric No \n group_sort This field defines the order of the groups in a search that uses group_field. The default sort order is relevance. Yes JSON This field can have the same values as the sort field, so single fields and arrays of fields are supported. No \n highlight_fields Specifies which fields to highlight. If specified, the result object includes a highlights field with an entry for each specified field. Yes Array of strings Yes \n highlight_pre_tag A string that is inserted before the highlighted word in the highlights output. Yes, defaults to <em> String Yes \n highlight_post_tag A string that is inserted after the highlighted word in the highlights output. Yes, defaults to <\/em> String Yes \n highlight_number Number of fragments that are returned in highlights. If the search term exceeds the fragment size, then the entire search term is returned. Yes, defaults to 1 Numeric Yes \n highlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_13493-7-1679","score":0.0158730159,"text":"\nRunning a query \n\nWatch the following video to learn more about Data Engine and how you can get started to run a basic query.\n\nIn SQL, the term query is just another way of saying SELECT statement. To run a query:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter a SELECT statement.\n\n\n\n* After the FROM keyword, specify one or more [unique resource identifiers](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique) (URIs). Each URI can be thought of as a table. It specifies one or more input objects; each input object can be thought of as a table partition. You must have at least 'Reader' access to the buckets that contain the input objects.\n* If the format of the input objects is CSV, and no special options are required, it is not necessary to specify a STORED AS clause. However, if the format is JSON, ORC, Parquet, or AVRO, after the FROM clause, specify STORED AS JSON, STORED AS ORC, STORED AS PARQUET, or STORED AS AVRO.\n* If text formats, such as JSON and CSV, are compressed with either gzip or bzip2 and have the extensions .gz and .bz, they automatically get recognized as compressed files. However, do not use these kinds of compressed files due to performance reasons.\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_00546-1171-2777","score":0.0158730159,"text":"\n\"products\",\n)\n\ndatabaseInformation, response, err := service.GetDatabaseInformation(getDatabaseInformationOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(databaseInformation, \"\", \" \")\nfmt.Println(string(b))\n\nconst { CloudantV1 } = require('@ibm-cloud\/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.getDatabaseInformation({db: 'products'}).then(response => {\nconsole.log(response.result);\n});\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nThe elements of the returned structure are shown in the following table:\n\n\n\nTable 1. Database details\n\n Field Description \n\n compact_running Set to true if the database compaction routine is operating on this database. \n db_name The name of the database. \n disk_format_version The version of the physical format that is used for the data that is stored on disk. \n disk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-database-details"},{"document_id":"ibmcld_07163-5129-7116","score":0.0153846154,"text":"\nWe recommend that you apply both available ratings to your results: Relevant and Not relevant. Only rating the Relevant documents does not provide the data needed. If you plan to score your documents, using both the Discovery tooling and the API, or if you plan to begin with the API and move to the tooling, use the 0 and 10 relevancy scores.\n* A random sample of documents that are not explicitly given a relevance rating is assigned a relevance score of 0. It is not mandatory to apply a relevance score of 0 when you train your documents, but if you apply a relevance score of 0 to certain documents, relevancy training marks those documents as non-relevant examples, instead of treating them as a random sample of results from the query.\n* The training queries must include some term overlap between the query and the desired answer so it can be retrieved by the Discovery service's initial search, which is broad in scope.\n\n\n\nWatson uses training data to learn patterns and to generalize, not to memorize individual training queries. The service, therefore, might not always reproduce identical relevance results for any given training query.\n\nTraining cannot exceed the following maximum requirements:\n\n\n\n* You cannot exceed 40 trained collections per environment.\n* Within a single collection, you are limited to 10,000 training queries, with a maximum of 100 examples per query.\n\n\n\n\n\n\n\n Adding a query to the training-data set \n\nUse the POST \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data method to add a query to a collection's set of training data. The query is specified as a JSON object in the following format:\n\n{\n\"query_id\": \"string\",\n\"natural_language_query\": \"string\",\n\"filter\": \"string\",\n\"examples\": [\n{\n\"document_id\": \"string\",\n\"cross_reference\": \"string\",\n\"relevance\": 0\n}\n]\n}\n\nThe values in this object are as follows:\n\n\n\n* query_id: A unique ID for the query. If you do not specify this field, the service automatically generates an ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_00580-4796-6846","score":0.0153846154,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_13498-31178-32892","score":0.0151515152,"text":"\nRelations can be joined by using several types of joins that are described in detail in section [joinType](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencejoinType).\n\nApart from the join type, the following two different types of joins exist:\n\n\n\n* Joins that specify a join condition by using a booleanExpression or a USING clause.\n* NATURAL joins that make an implicit guess on which columns to use for joining relations. Use natural joins carefully.\n\n\n\n\n\n\n\n relationPrimary \n\n\n\n\n\n externalTableSpec \n\nAn external table specification represents an URI for an object that is stored on Cloud Object Storage combined with a specification of the object type. Valid values for object type identifier are AVRO, CSV, JSON, ORC, PARQUET, and TEXT.\n\nIf the file format is CSV, with the optional FIELDS TERMINATED BY clause you can specify a field separator other than the default , (comma). The following example shows a query for parsing a CSV with | (vertical bar) as the delimiter:\n\nSELECT \nFROM cos:\/\/us-geo\/sql\/BlackFriday.csv\nSTORED AS CSV FIELDS TERMINATED BY '|'\nLIMIT 3\n\nAll single Unicode characters are allowed as delimiters.\n\nBy default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify the option NOHEADER in the STORED AS CSV clause. In this case, the names _C0, _C1, ... are used for the input columns. For more information, see [COS URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceCOSURI).\n\nBy default, if the format of the input data is JSON, each line must contain a separate, self-contained, and valid JSON object, also called newline-delimited JSON.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_00472-21040-23007","score":0.0149253731,"text":"\nhighlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes \n limit Limit the number of the returned documents to the specified number. For a grouped search, this parameter limits the number of documents per group. Yes Numeric The limit value can be any positive integer number up to and including 200. Yes \n q Abbreviation for query. Runs a Lucene query. No String or Number Yes \n query Runs a Lucene query. No String or Number Yes \n ranges This field defines ranges for faceted, numeric search fields. The value is a JSON object where the fields names are faceted numeric search fields, and the values of the fields are JSON objects. The field names of the JSON objects are names for ranges. The values are strings that describe the range, for example \"[0 TO 10]\". Yes JSON The value must be an object with fields that have objects as their values. These objects must have strings with ranges as their field values. No \n sort Specifies the sort order of the results. In a grouped search (when group_field is used), this parameter specifies the sort order within a group. The default sort order is relevance. Yes JSON A JSON string of the form \"fieldname<type>\" or -fieldname<type> for descending order. The fieldname is the name of a String or Number field, and type is either a number, a string, or a JSON array of strings. The type part is optional, and defaults to number. Some examples are \"foo\", \"-foo\", \"bar<string>\", \"-foo<number>\", and [\"-foo<number>\",\"bar<string>\"]. String fields that are used for sorting must not be analyzed fields.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16423-3286-5408","score":0.0325224749,"text":"\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_06968-15099-17180","score":0.0320184426,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_07117-1664-3943","score":0.0320020481,"text":"\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot-ingestion"},{"document_id":"ibmcld_00510-5537-7566","score":0.0158730159,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_07232-1707-3805","score":0.015625,"text":"\nIf you crawl Box or Salesforce, a list of available resources is presented when you configure a source, using the Discovery tooling.\n* If you are using the Discovery tooling, you can configure a collection with a single data source.\n* Crawling a data source uses resources, namely API calls, of the data source. The number of API calls depends on the number of documents that need to be crawled. You must obtain an appropriate level of service license, for example Enterprise, for the data source. For information about the appropriate service level license that you need, contact the source system administrator.\n* Discovery source crawls do not delete documents that are stored in a collection, but you can manually delete them using the API. When a source is re-crawled, new documents are added, updated documents are modified to the current version, and deleted documents remain as the version last stored.\n* Discovery can only ingest the following file types, and it ignores all other document types:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* IBM Watson\u2122 Discovery supports crawling JSON and HTML documents, but you cannot edit these documents using the SDU editor. To change the configuration of HTML and JSON documents, you must use the API. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).\n\n** Individual image files, such as PNG, TIFF, and JPG, are scanned, and any text is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned, and any text is extracted.\n\nView the following table to see the objects that a data source can crawl and which data sources support crawling new and modified documents during a refresh:\n\n\n\nTable 1. Data sources that support crawling new and modified documents during refresh and objects that can be crawled\n\n Data source Crawls new and modified documents during refresh? Compatible objects that can be crawled \n\n Box (Application level access) No Files, folders","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources"},{"document_id":"ibmcld_16358-7447-9162","score":0.0153846154,"text":"\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_00579-7-1988","score":0.0153846154,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_03054-7324-9318","score":0.0151515152,"text":"\nSelect the language of the files that you are adding to this collection.\n\nFor information about the languages supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nIf you are uploading a PDF document and want to extract party, nature, and category information from it, then expand the Advanced section and click Use the Default Contract Configuration with this collection.\n\n\n\n2. Click Next.\n3. Click Select documents to upload documents.\n\nSupported file types include PDF, HTML, JSON, Word, Excel, PowerPoint, PNG, TIFF, JPG, GIF, TXT, CSV, ZIP, GZIP, and TAR\n\nNo ongoing synchronization of uploaded documents is available. If you want to pick up changes that are made to a document, upload a later version of the document.\n\n\n\n\n\n2. Wait for the collection to be fully ingested.\n\nYour collection is added to a project that is created for you automatically. The project is a conversational search project with a name like Untitled Project 3; its sole purpose is to store your data collection.\n3. Find the project name in the page breadcrumb after your collection is created. Make a note of the project name in case you want to return to the collection from the Discovery application later.\n4. 1.5.0 only: If you want to add another collection to the project, click Manage collections, and then click New collection to add another collection.\n5. When the project contains all of the data collections that you want to use, click Back to Watson Assistant to finish creating the search skill.\n6. Select the project you just created from the list of projects, and then click Configure.\n\n\n\n\n\n Data collection creation example \n\nFor example, you might have a JSON file like this one:\n\n{\n\"Title\": \"About\",\n\"Shortdesc\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"Topics\": \"overview\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_00580-7-1957","score":0.0151515152,"text":"\nLearning Center \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Learning Center offers a video series to help you learn to use IBM Cloudant. The videos start with the basics of using IBM Cloudant. Then the videos walk you through document structure, the API, indexing and querying, and include an Under the Hood topic that highlights the architecture that powers the service.\n\nYou can use the [playlist](https:\/\/www.youtube.com\/embed\/playlist?list=PLzpeuWUENMK3F93hGaS4ezGmlX4Bipt4S) to go through the courses, or navigate directly to the topic of your choosing.\n\n\n\n Introduction to IBM Cloudant video \n\nLearn about the IBM Cloudant 17-part video series that provides an overview of the IBM Cloudant database-as-a-service.\n\n\n\n* Introduction to IBM Cloudant video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 1 - What is IBM Cloudant?\n\nIBM Cloudant is a database, run as a service in the IBM Cloud\u00ae. Its job is to store your application's data securely and make it possible for you to retrieve it quickly and efficiently. IBM Cloudant's key features are shown in the following list:\n\nDatabase\n: Stores and retrieves data. More specifically, it is a JSON document store. JSON comes from JavaScript and represents simple objects in a universal file format.\n\nDocument\n: The unit of storage in IBM Cloudant. Documents are added, updated, and deleted in their entirety.\n\nHTTP API\n: Any IBM Cloudant operation can be achieved by using HTTPS. HTTP is the protocol that powers the World Wide Web and IBM Cloudant is a database that is built for the web. Most databases are hidden in a private network, inaccessible but to a handful of machines. The IBM Cloudant service sits (mainly) on the public internet where it can be accessed by anyone with an internet connection (and permission to do so).\n\nIBM Cloudant wasn't written entirely by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_07224-7-1998","score":0.0149253731,"text":"\nSmart Document Understanding \n\nSmart Document Understanding (SDU) trains IBM Watson\u2122 Discovery to extract custom fields in your documents. Customizing how your documents are indexed into Discovery improves the answers that your application returns.\n\nWith SDU, you annotate fields within your documents to train custom conversion models. As you annotate, Watson is learning and starts to predict annotations. SDU models can be exported and used on other collections.\n\nThis documentation applies to Discovery service instances that you create with a Lite or an Advanced plan, or that you created with a Premium plan before 16 July 2020. For more information about features in Premium plan instances created on or after 16 July 2020, and in Plus (including Plus Trial) plan instances, see [these docs](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields).\n\n\n\n Supported document types and browsers \n\nSupported document types for Smart Document Understanding:\n\n\n\n* Lite plans: PDF, Word, PowerPoint, Excel, JSON*, HTML*\n* Advanced plans: PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML*\n\n\n\n* JSON and HTML documents are supported by IBM Watson\u2122 Discovery, but can not be edited using the SDU editor. To change the configuration of HTML and JSON docs, you need to use the API. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).\n\n** Individual image files (PNG, TIFF, JPG) are scanned and the text (if any) is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text, if any, is extracted.\n\n\n\n\n\n Using the Smart Document Understanding editor \n\nThe SDU editor is only available for collections that contain supported document types and do not have the Element Classification enrichment applied. If you do not want to use the SDU editor, you can set up your configuration using the API, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1268470-1270517","score":0.0163934426,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00510-5537-7566","score":0.0163934426,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_16727-1271119-1273166","score":0.0161290323,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00558-23465-25360","score":0.0161290323,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_06968-18330-20453","score":0.0158730159,"text":"\nPlus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.\n\nA maximum of 1,000 fields can be added to the index.\n\nYou cannot assign the data type, such as Date or String, of a field. The data type is detected automatically and assigned to the field during document ingestion. The assignment is based on the data type that is detected from the first document that is indexed. Ingestion errors can occur in subsequent documents if a different data type is detected for the value in the same field. Therefore, if your documents have a mix of data types in a single field, first ingest the document that has a value with the most flexible data type, such as String, in the field.\n\nWhen you crawl a website or upload an HTML file, the HTML content is added to the collection and indexed in an html field.\n\nThe following table shows the maximum size limit for fields per document.\n\n\n\nMaximum field sizes\n\n Field type Maximum allowed size per document \n\n html field 5 MB \n Sum of all other fields 1 MB \n\n\n\nIf the maximum size of the fields in the document exceeds the allowed limits, they are treated as follows:\n\n\n\n* For a document with an oversized html field, all of the fields in the document are indexed except the html field.\n\nFor IBM Cloud Pak for Data version 4.0 and earlier, the entire document is not indexed.\n* For a document with oversized non-HTML fields, the document is not indexed.\n\n\n\nIf you are uploading a Microsoft Excel file and a message is displayed that indicates that the non-HTML field size limit is exceeded, consider converting the XLS file into a CSV file. When you upload a comma-separated value (CSV) file, each row is indexed as a separate document. As a result, no field size limits are exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_12904-23555-25450","score":0.0158730159,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01234-7-2066","score":0.015625,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_00581-0-1268","score":0.015625,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_11911-14530-16183","score":0.0153846154,"text":"\nUser Name username Secret The username to connect to the storage device. true N\/A \n User Password password Secret The password to connect to the storage device. true N\/A \n Limit Volume Size limitVolumeSize Config The maximum volume size (in Gibibytes) that can be requested and the qtree parent volume size. true 50Gi \n Limit AggregateUsage limitAggregateUsage Config Provisioning fails if usage is above this percentage. true 80% \n\n\n\n\n\n\n\n 22.10 parameter reference \n\n\n\nTable 3. 22.10 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N\/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N\/A \n SVM svm Config The name of the SVM. true N\/A \n User Name username Secret The username to connect to the storage device. true N\/A \n User Password password Secret The password to connect to the storage device. true N\/A \n Limit Volume Size limitVolumeSize Config The maximum volume size (in Gibibytes) that can be requested and the qtree parent volume size. true 50Gi \n Limit AggregateUsage limitAggregateUsage Config Provisioning fails if usage is above this percentage. true 80% \n\n\n\n\n\n\n\n\n\n Storage class reference for NetApp ONTAP-SAN \n\nBefore you deploy apps that use the sat-netapp storage classes, review the following notes.\n\nBy default, the sat-netapp-file-gold storage class doesn't include any QoS limits (unlimited IOPS).\n\nTo use the sat-netapp-file-silver and sat-netapp-file-bronze storage classes, you must create corresponding silver and bronze QoS policy groups on the storage controller and define the QoS limits.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-netapp-ontap-san"},{"document_id":"ibmcld_00510-7123-9213","score":0.0153846154,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07033-12111-13895","score":0.0163934426,"text":"\nIf bulk labeling is enabled, a notification is displayed to show the number of occurrences of the term that were found and labeled in the current document.\n5. If you want to label occurrences of the term in all of the documents in the collection, click Apply to all documents.\n\nWhen you enable this option, occurrences of the term are labeled in all of the documents in the collection, including documents that you already reviewed and marked complete.\n\nZoom\n\n![Shows the notification that asks whether to apply bulk labeling to all documents.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/ee-bulk-label-all-docs.png)\n\nFigure 5. Bulk labeling configuration\n\nYou are asked to confirm the action because it cannot be undone. If you don't want to have to confirm the action every time you choose to apply bulk labeling to all documents, select Do not ask for confirmation again. Click Run.\n\nZoom\n\n![Shows the bulk labeling confirmation dialog box.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/ee-bulk-label-confirmation.png)\n\nFigure 6. Bulk labeling configuration confirmation\n\nFor more information, see [Labeling examples in bulk](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractorentity-extractor-bulk-label).\n6. Scroll through the document to label every valid example of every entity type that you want your extractor to recognize.\n\nThe machine learning model learns as much from the terms that you don't label as the terms that you do.\n\nIf you miss labeling a valid example, the model learns that when the term is used in that context, it is not a valid mention of the entity type. In some cases, an omission is appropriate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractor"},{"document_id":"ibmcld_01234-7-2066","score":0.0163934426,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_07001-7-2183","score":0.0161290323,"text":"\nSalesforce \n\nCrawl documents that are stored in a Salesforce data source.\n\nIBM Cloud\n\nIBM Cloud only\n\nThis information applies only to managed deployments. For more information about connecting to Salesforce from an installed deployment, see [Salesforce](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-salesforce-cp4d).\n\n\n\n What documents are crawled \n\nDuring the initial crawl of the content, documents from all of the objects that can be accessed from the URL that you specify are crawled and added to your collection. Knowledge Articles are crawled only if their version is published and their languages is en-us.\n\nDuring subsequent scheduled recrawls, only new and modified documents are crawled and any changes are reflected in your collection. Documents that are deleted from the external data source are not deleted from the collection.\n\nAll Discovery data source connectors are read-only. Regardless of the permissions that are granted to the crawl account, Discovery never writes, updates, or deletes any content in the original data source.\n\nDiscovery can crawl the following objects:\n\n\n\n* Any default and custom objects that you have access to\n* Accounts\n* Contacts\n* Cases\n* Contracts\n* Knowledge articles\n* Attachments\n\n\n\n\n\n\n\n Data source requirements \n\nIn addition to the [data source requirements](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-sourcespublic-requirements) for all managed deployments, your Salesforce data source must meet the following requirements:\n\n\n\n* The instance that you plan to connect to must be part of an Enterprise plan or higher.\n* You must obtain any required service licenses for the data source that you want to connect to. For more information about licenses, contact the system administrator of the data source.\n\n\n\n\n\n\n\n What you need before you begin \n\nYou must have the following information ready. If you don't know it, ask your Salesforce administrator to provide the information or consult the [Salesforce developer documentation](https:\/\/developer.salesforce.com\/docs\/).\n\nUsername\n: The username of an account that has access to the Salesforce site. For example, jdoe@example.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-salesforce-cloud"},{"document_id":"ibmcld_07578-1268470-1270517","score":0.0161290323,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00629-5827-8148","score":0.0158730159,"text":"\nEventually, the database copies complete their replication so that all the changes to a document are present in each copy.\n\nThis \"eventual consistency\" model has two characteristics that affect a list of changes:\n\n\n\n1. A change that affects a document almost certainly takes place at different times in different copies of the database.\n2. The order in which changes affect documents might differ between different copies of the database, depending on when and from where the replication took place.\n\n\n\nA consequence of the first characteristic is that, when you ask for a list of changes, it is meaningless to ask for a list of changes after a specific point in time. The reason is that the list of changes might be supplied by a different database copy, which resulted in document updates at different times. However, it is meaningful to ask for a list of changes after a specific change, which is specified by using a sequence identifier.\n\nAn extra consequence of the first characteristic is that it might be necessary to \"look back\" at preceding changes to agree on the list of changes. In other words, to get a list of changes, you start from the most recent change that the database copies agree on. The point of agreement between database copies is identified within IBM Cloudant by using the [checkpoint](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guidecheckpoints) mechanism that enables replication between database copies to be synchronized.\n\nFinally, when you look at a list of changes, they might be presented in a different order in subsequent requests. The order depends on how documents were changed between different database copies. In other words, an initial list of changes might report changes A, B, then C in that order. But a subsequent list of changes might report changes C, A, then B in that order. All the changes are listed, but in a different order. This difference is because the sequence of changes that are received during replication might vary between two different copies of the database.\n\n\n\n What does \"eventual consistency\" mean for the list of changes? \n\nWhen you request a list of changes, the response you get might vary depending on which database copy supplies the list.\n\nThe since option obtains a list of changes after a specific update sequence identifier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_16727-1271119-1273166","score":0.0158730159,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16358-20798-22437","score":0.015625,"text":"\n[Shows another preview of the assistant where the test question is answered](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-answer2.png)\n\nFigure 20. Web chat returns a detailed answer\n5. Optionally ask the assistant other questions.\n\nIf the assistant doesn't know the answer, reword the question to include \u201cin Watson Discovery\u201d to make it clearer that you are asking about how something works in Discovery specifically.\n\n\n\nCongratulations! You successfully created an assistant that can answer questions about Discovery by retrieving information from the product documentation by way of the NeuralSeek service.\n\n\n\n Summary \n\nIn this tutorial, you created a Watson Discovery Document Retrieval project with uploaded PDF files that contain the Discovery product documentation. Separately, you created a Watson Assistant virtual assistant with a single action that can recognize user questions about Discovery. You added a custom extension to your assistant that connects to a third-party service called NeuralSeek that gets the correct answer from Discovery and rewords the response. Finally, you tested your virtual assistant by asking a question and getting an accurate and well-written response.\n\n\n\n\n\n Next steps \n\nThe assistant that you created is available from the draft environment. Next, you can publish your assistant to a production environment and deploy it. You can deploy the assistant in various ways. For more information, see [Overview: Previewing and publishing](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_16208-7528-9399","score":0.015625,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/b293a157aaf26e34a94525b64f55b4e73b099b09\/icons\/icon_hamburger.svg) > Classic Infrastructure > Devices > your virtual server instance. Select the Storage tab, and authorize your block and file storage if not listed there.\n\n\n\n\n\n\n\n Limitations \n\nReview the following storage migration limitations:\n\n\n\n* All migrations are limited to a volume size of 2 TB only.\n* You can choose only four volumes while provisioning a virtual server instance. Only four attached volumes, in addition to your boot volume, can be migrated. If you have more than four volumes in your classic instance, see [Volume attachment limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits) for details and use the Content Data Migrator in the VPC+ tool to migrate the additional volumes.\n* Up to four primary partitions or three primary with two logical on the fourth partition can be migrated.\n* Migration of block volumes and partitions without file systems is not yet supported.\n* A maximum of 10 IOPS\/Gb mapping will be done on virtual server instances for VPC.\n* Migration of storage attached to Windows is not yet supported.\n\n\n\nAll three storage types can be migrated if your use case satisfies these limitations.\n\n\n\n\n\n Storage migration use cases \n\nConsider the following uses cases for storage migration:\n\n\n\n1. Classic virtual server instance has portable storage that is attached with Linux file systems. This is migrated as-is to VPC.\n2. Classic virtual server instance has network file storage:\n\n\n\n* An equivalent Linux file system (ext4) is created in VPC and then the contents are copied over.\n* VPC does not yet support NAS storage. Your storage will be on the Linux file system on your VPC instance, and it cannot be shared.\n\n\n\n3. Classic virtual server has network block storage (iSCSI devices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/wanclouds-vpc-plus?topic=wanclouds-vpc-plus-migration-considerations"},{"document_id":"ibmcld_03249-4-1889","score":0.0153846154,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Gathering information with slots \n\nAdd slots to a dialog node to gather multiple pieces of information from a user within that node. Slots collect information at the user's pace. Details that a user provides up front are saved, and your assistant asks only for the missing details it needs to fulfill the request.\n\n\n\n Why add slots? \n\nUse slots to get the information you need before you can respond accurately to the user. For example, if users ask about operating hours, but the hours differ by store location, you could ask a follow-up question about which store location they plan to visit before you answer. You can then add response conditions that take the provided location information into account.\n\n![Asks for location information before answering the question, When do you open?.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/op-hours.png)\n\nSlots can help you to collect multiple pieces of information that you need to complete a complex task for a user, such as making a dinner reservation.\n\n![Shows four slots that prompt for the information needed to make a dinner reservation.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/reservation.png)\n\nThe user might provide values for mutliple slots at once. For example, the input might include the information, There will be 6 of us dining at 7 PM. This one input contains two of the missing required values: the number of guests and time of the reservation. Your assistant recognizes and stores both of them, each one in its corresponding slot. It then displays the prompt that is associated with the next empty slot.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_15081-2595-4569","score":0.0153846154,"text":"\nBlock Storage for VPC offers block-level volumes that are attached to an instance as a boot volume when the instance is created or attached as secondary data volumes. You can configure up to 300 Block Storage for VPC volumes per account in a region. You can request to increase this quota by [opening support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit) and specifying in which zone you need more volumes.\n\nYou can attach only one boot volume to a virtual server instance at a time, but you can attach up to 12 Block Storage for VPC data volumes to a single instance. For other limitations, see [Volume attachment limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits).\n\n\n\n Boot volumes \n\nWhen you create an instance from a stock image, a 100 GB, 3,000 IOPS general-purpose boot volume is created and attached to the instance by default. When you create an instance from a custom image, you can specify a boot volume capacity of 10 GB to 250 GB, depending what the image requires. This capacity can be any size between the minimum size that is supported for the selected image and the maximum supported image size. If the custom image is smaller than 10 GB, the boot volume capacity is rounded up to 10 GB. After the boot volume is created, you can expand the boot volume size to the maximum supported size, which is 250 GB.\n\nYou cannot create an image from a boot volume that is encrypted with customer-managed keys and is not 100 GB. Such an operation is not supported.\n\nBy default, boot volumes are encrypted by IBM-managed encryption. Optionally, you can use your own root keys (CRKs) by choosing customer-managed encryption during instance creation (see [Customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption)).\n\nBy default, boot volumes are deleted when you delete an instance. You can toggle this setting on or off in the instance details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13144-25047-26967","score":0.0163934426,"text":"\nserviceClass: cloudantnosqldb\nplan: standard\n6. Click Create to create a IBM Cloudant database instance. Your context should be Operators > Installed Operators > IBM Cloud Operator in the Administrator perspective with Project: example-health in the Service panel.\n7. Click on the service just created, <your-initials>-cloudant-service and over time the state field will change from provisioning to Online meaning it is good to go.\n8. Create a Binding resource and a Secret resource for the cloudant Service resource just created. Navigate back to Operators > Installed Operators > IBM Cloud Operator > Binding tab. Open the Binding tab, click Create Binding and select YAML View. Create a cloudant-binding associated with the serviceName <your-initials>-cloudant-service, (this is the the name provided for the Service created earlier).\n\napiVersion: ibmcloud.ibm.com\/v1\nkind: Binding\nmetadata:\nname: cloudant-binding\nnamespace: example-health\nspec:\nserviceName: <your-initials>-cloudant-service\n9. Optionally dig a little deeper to understand the relationship between the Red Hat OpenShift resources: Service, service Binding, binding Secret and the IBM Cloud resources: Service, service Instance and the instance's Service credentials. Using the cloud shell:\n\nibmcloud resource service-instances --service-name cloudantnosqldb\n\nYOURINITIALS=<your-initials>\n\nibmcloud resource service-instance $YOURINITIALS-cloudant-service\n\nibmcloud resource service-keys --instance-name $YOURINITIALS-cloudant-service --output json\n\nOutput looks something like this:\n\nyouyou@cloudshell:$ ibmcloud resource service-instances --service-name cloudantnosqldb\nRetrieving instances with type service_instance in all resource groups in all locations under ..\nOK\nName Location State Type\n<your-initials>-cloudant-service us-south active service_instance\nyouyou@cloudshell:$ ibmcloud resource service-instance <your-initials>-cloudant-service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_00445-2996-3911","score":0.0163934426,"text":"\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,\n\"database\": \"shards\/00000000-3fffffff\/acceptly\/acceptly_my_chances_logs_live.1321035717\",\n\"design_document\": \"_design\/MyChancesLogCohortReport\",\n\"started_on\": 1363273094,\n\"total_changes\": 26389\n},\n{\n\"user\": \"username\",\n\"updated_on\": 1371118433,\n\"type\": \"search_indexer\",\n\"total_changes\": 5466,\n\"node\": \"dbcore@db7.meritage.cloudant.net\",\n\"pid\": \"<0.29569.7037>\",\n\"changes_done\": 4611,\n\"database\": \"shards\/40000000-7fffffff\/username\/database_name\",\n\"design_document\": \"_design\/lucene\",\n\"index\": \"search1\",\n\"started_on\": 1371118426\n},\n{\n\"view\": 1,\n\"user\": \"acceptly\",\n\"updated_on\": 1363273504,\n\"type\": \"view_compaction\",\n\"total_changes\": 26095,\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.21218.4070>\",\n\"changes_done\": 20000,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks"},{"document_id":"ibmcld_03406-27177-29118","score":0.0161290323,"text":"\n`has_skipped_slots` I look forward to helping you with your next reservation. Have a good day. \n\n\n\nThe has_skipped_slots condition checks the properties of the slots node to see if any of the slots were skipped. The exit handler skips all remaining slots to go directly to the node response. So, when the has_skipped_slots property is present, you know the exit intent was triggered, and the dialog can display an alternate response.\n\nIf you configure more than one slot to skip other slots, or configure another node-level event handler to skip slots, then you must use a different approach to check whether the #exit intent was triggered. See [Handling requests to exit a process](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slotsdialog-slots-node-level-handler) for an alternate way to do so.\n9. You want your assistant to check for the has_skipped_slots property before it displays the standard node-level response. Move the has_skipped_slots conditional response up so it gets processed before the original conditional response or it will never be triggered. To do so, click the response you just added, use the up arrow to move it up, and then click Save.\n10. Test this change by using the following script in the \"Try it out\" pane.\n\n\n\nScript details\n\n Speaker Utterance \n\n You i want to make a reservation \n Watson I can make a reservation for you. Just tell me the day and time of the reservation, and how many people it is for. \n You it's for 5 people \n Watson Ok. The reservation is for 5 guests. What day would you like to come in? \n You Nevermind \n Watson Ok, we'll stop there. No reservation will be made. I look forward to helping you with your next reservation. Have a good day. \n\n\n\n\n\n\n\n\n\n Step 8: Apply a valid value if the user fails to provide one after several attempts \n\nIn some cases, a user might not understand what you are asking for. They might respond again and again with the wrong types of values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots-complex"},{"document_id":"ibmcld_00445-2359-3178","score":0.0161290323,"text":"\n\"checkpointed_source_seq\": \"403-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTRyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmIymg5TXDqSHIBkUj1YUxyaJkNcmvJYgCRDA5AC6tuflZhGrPsgGg9ANAJtzMkCAPFSStc\",\n\"changes_pending\": 134,\n\"pid\": \"<0.1781.4101>\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"docs_written\": 0,\n\"missing_revisions_found\": 0,\n\"replication_id\": \"d0cdbfee50a80fd43e83a9f62ea650ad+continuous\",\n\"revisions_checked\": 0,\n\"source\": \"https:\/\/repl:@tsm.cloudant.com\/tsm-admin\/\",\n\"source_seq\": \"537-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTUyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmI9mg4jXDqSHIBkUj1WTTityWMBkgwNQAqob39WYhextkE0HoBoBNo4MQsAFuVLVQ\",\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks"},{"document_id":"ibmcld_03072-26912-28861","score":0.0158730159,"text":"\n`has_skipped_slots` I look forward to helping you with your next reservation. Have a good day. \n\n\n\nThe has_skipped_slots condition checks the properties of the slots node to see if any of the slots were skipped. The exit handler skips all remaining slots to go directly to the node response. So, when the has_skipped_slots property is present, you know the exit intent was triggered, and the dialog can display an alternate response.\n\nIf you configure more than one slot to skip other slots, or configure another node-level event handler to skip slots, then you must use a different approach to check whether the #exit intent was triggered. See [Handling requests to exit a process](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-node-level-handler) for an alternate way to do so.\n9. You want your assistant to check for the has_skipped_slots property before it displays the standard node-level response. Move the has_skipped_slots conditional response up so it gets processed before the original conditional response or it will never be triggered. To do so, click the response you just added, use the up arrow to move it up, and then click Save.\n10. Test this change by using the following script in the Try it out pane.\n\n\n\nScript details\n\n Speaker Utterance \n\n You i want to make a reservation \n Watson I can make a reservation for you. Just tell me the day and time of the reservation, and how many people it is for. \n You it's for 5 people \n Watson Ok. The reservation is for 5 guests. What day would you like to come in? \n You Nevermind \n Watson Ok, we'll stop there. No reservation will be made. I look forward to helping you with your next reservation. Have a good day. \n\n\n\n\n\n\n\n\n\n Step 8: Apply a valid value if the user fails to provide one after several attempts \n\nIn some cases, a user might not understand what you are asking for. They might respond again and again with the wrong types of values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots-complex"},{"document_id":"ibmcld_04108-0-1506","score":0.0158730159,"text":"\n\n\n\n\n\n\n  Accessing your Cloudant database through CIS \n\nFollow these steps to access your Cloudant database through IBM Cloud\u00ae Internet Services (CIS).\n\n\n\n  Before you begin \n\nThese instructions assume you have already added a domain to CIS as outlined in the [Getting started](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedgetting-started) page.\n\n\n\n\n\n  Step 1: Add your CIS domain to the Cross-Origin Resource Sharing (CORS) \n\n\n\n*  Navigate to your Cloudant database and open the Account > CORS page.\n*  Add your CIS domain to the origin domains input field. For example, https:\/\/cloudant.test.foo.com.\n\n\n\n\n\n\n\n  Step 2. Configure CIS to point to your Cloudant database \n\n\n\n*  Navigate to the CIS dashboard and create a load balancer or DNS record that points to your Cloudant database hostname. For example, https:\/\/cloudant.test.foo.com -> 111-222-333-444-555-test.cloudant.com.\n*  Enable proxy for the DNS record or load balancer.\n\n\n\n\n\n\n\n  Step 3. Create a page rule to set the Host Header Override \n\n\n\n*  In the CIS dashboard, navigate to Performance > Page rules.\n*  Create a page rule for the URL you want, for example, https:\/\/cloudant.test.foo.com\/.\n*  Select the Rule Behavior setting Host Header Override.\n*  Set as the Cloudant database hostname, for example, 111-222-333-444-555-test.cloudant.com.\n\n\n\nTo learn more about Cloudant, see the [Cloudant documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantgetting-started-with-cloudant).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-access-cloudant-through-cis"},{"document_id":"ibmcld_00626-3414-5513","score":0.015625,"text":"\nThe _replicator database is a special database within your account, where you can PUT or POST replication documents to specify the replications you want.\n\nBefore you start a replication, you must create the _replicator database. To create a database, send a PUT request to:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/_replicator\n\nFor more information, see [Databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases).\n\nTo cancel a replication, you DELETE the replication document. The fields that are supplied in the replication document are described in the [Create or modify a replication operation](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) description under Request information.\n\nAll design documents and _local documents that are added to the \/_replicator database are ignored.\n\n\n\n\n\n Important notes \n\n\n\n* A new and more powerful [replication scheduler](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationthe-replication-scheduler) changes the previous behavior of the IBM Cloudant replication mechanisms. Ensure that your applications are updated.\n* Replications can severely impact the performance of an IBM Cloudant instance. Performance testing helps you understand the impact on your environment under an increasing number of concurrent replications.\n* [Continuous replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicontinuous-replication) can result in many internal calls. Requiring many calls might affect the costs for multi-tenant users of IBM Cloudant systems. By default, continuous replication is not enabled.\n* The target database must exist. It is not automatically created if it does not exist. Add \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-api"},{"document_id":"ibmcld_00614-11599-12675","score":0.015625,"text":"\n{\n\"start\": 1436194475,\n\"end\": 1436194775,\n\"target_responses\": [\n{\n\"target\": \"myclustername Documents per second through map functions\",\n\"datapoints\":\n\n0.0,\n1436194480\n],\n\n0.5,\n1436194495\n],\n\n0.4000000000005457,\n1436194510\n],\n...\n\n0.0,\n1436194765\n]\n]\n}\n]\n}\nShow more\n\n\n\n\n\n network \n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/network?cluster=myclustername&node=myloadbalancername&format=json\"\n\n{\n\"end\": 1512989748,\n\"start\": 1512989450,\n\"target_responses\": [\n{\n\"datapoints\":\n\n20247725.5,\n1512989450\n]\n],\n\"target\": \"myclustername Octets tx Per Second\"\n},\n{\n\"datapoints\":\n\n17697329.3046875,\n1512989450\n]\n],\n\"target\": \"myclustername Octets rx Per Second\"\n}\n]\n}\nShow more\n\nYou must explicitly specify the load balancer in the request.\n\n\n\n\n\n rate\/status_code \n\nSee an example of a rate\/status_code monitoring request:\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/rate\/status_code?cluster=myclustername&format=json\"\n\nSee example results (abbreviated) from a rate\/status_code monitoring request:\n\n{\n\"start\": 1436194902,\n\"end\": 1436195202,\n\"target_responses\": [\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"},{"document_id":"ibmcld_00626-5090-6346","score":0.0153846154,"text":"\nAdd \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store. For more information, see [replication database maintenance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationreplication-database-maintenance).\n\n\n\nFor security purposes, the IBM Cloudant team recommends that you use IAM API keys or IBM Cloudant legacy authentication [API keys](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountapi-keys) rather than account-level credentials for replication jobs. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication API document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication) and the legacy [Authorization API document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-api"},{"document_id":"ibmcld_00614-4378-5507","score":0.0153846154,"text":"\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/disk_use?cluster=myclustername&format=json\"\n\nSee an example result after you request disk use data in JSON format:\n\n[\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.used)\",\n\"datapoints\":\n523562172416.0, 1391019360],\n524413976576.0, 1391019420],\n519036682240.0, 1391019480],\n518762102784.0, 1391019540],\n523719393280.0, 1391019600]\n]\n},\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.free)\",\n\"datapoints\":\n6488926978048.0, 1391019360],\n6487768301568.0, 1391019420],\n6493145661440.0, 1391019480],\n6493420257280.0, 1391019540],\n4330660167680.0, 1391019600]\n]\n}\n]\nShow more\n\n\n\n\n\n With format=raw \n\nThe raw format data contains a series of text strings, identifying the name of the metric and associated values.\n\nThe text string (for example sumSeries(net.cloudant.mycustomer001.db.df.srv.used)) is the name of the metric. The next two numbers are the start and end times, expressed as UTC epoch seconds. The final number is the step size in seconds.\n\nThe numbers after the | character contain the metric data that is obtained from your chosen endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-112397-114109","score":0.0320184426,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-447531-449109","score":0.0315136476,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":0.031024531,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":0.0305503731,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_07578-448564-450242","score":0.0300904977,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-448546-450224","score":0.0296442688,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00558-1499-3456","score":0.0292110874,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01150-4410-6468","score":0.0163934426,"text":"\nWhat is Event Streams's maximum message size? \n\nEvent Streams's maximum message size is 1 MB, which is the Kafka default.\n\n\n\n\n\n What are Event Streams's replication settings? \n\nEvent Streams is configured to provide strong availability and durability. The following configuration settings apply to all topics and cannot be changed:\n\n\n\n* replication.factor = 3\n* min.insync.replicas = 2\n\n\n\n\n\n\n\n What are the restrictions and defaults for topics and partitions? \n\n\n\n* Topic names are restricted to a maximum of 100 characters.\n* The default number of partitions for a topic is one.\n* Each IBM Cloud space has a limit of 100 partitions. To create more partitions, you must use a new IBM Cloud space.\n\n\n\n\n\n\n\n How do I check which Event Streams plan I've provisioned? \n\nTo confirm which type of Event Streams plan you've provisioned (Lite, Standard, or Enterprise), complete the following steps:\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams that you want to check.\n2. Click the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n\n\n\n\n Can I change my Event Streams plan using the IBM Cloud console? \n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n\n\n\n\n What are the differences between the Event Streams Standard and Event Streams Enterprise plans?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-faqs"},{"document_id":"ibmcld_07578-699255-701206","score":0.0161290323,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-699213-701164","score":0.0158730159,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07103-31052-33321","score":0.0327868852,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11143-7-2028","score":0.0322580645,"text":"\nNavigating the IBM Cloud console \n\nThe [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com) is the user interface that you use to manage all your IBM Cloud resources. You can create a free account, log in, access documentation, access the catalog, view pricing information, get support, or check the status of IBM Cloud components. After you log in, the menu bar contains a Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/icons\/icon_hamburger.svg) and more links.\n\n\n\n Watch a tour \n\n\n\n* Video transcript\n\nWelcome to IBM Cloud, your open, secure, and enterprise-ready cloud platform with over 350 unique products for you to start building the solutions that you need today! Just log in, and you're ready to start building in the cloud.\n\nFrom the global navigation, you can explore how to get started with key technologies in IBM Cloud. Choose from technologies including serverless computing with Functions [Click Menu icon > Functions], container-based deployments on Kubernetes [Click Kubernetes to expand the options] or Red Hat OpenShift [Click OpenShift to expand the options], and VPC infrastructure [Click VPC Infrastructure to expand the options]. Developers can start with API management tools, app development starter kits, DevOps toolchains, and more to expedite and automate your app development.\n\nYou can get started creating resources through any of these guided journeys [Click Kubernetes > Clusters].\n\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_07103-34419-36390","score":0.0314980159,"text":"\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).\n\n\n\n\n\n 16 July 2021 \n\nNew beta dynamic website web crawl\n: The Web crawler can now crawl dynamic websites that use JavaScript to render content. If you enable this beta feature, the time it takes to crawl the site increases. For more information, see [Web crawl](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-web-cloud).\n\n\n\n\n\n 23 June 2021 \n\nNew Plus plan\n: Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. Currently, the Plus plan is available from the Dallas location. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas location. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n Endpoint deprecation reminder \n\nChange to Discovery API endpoint\n: As part of work done to fully support Identity and Access Management (IAM) authentication, the endpoint that you use to access your Discovery service programmatically is changing. The old endpoint URLs are deprecated and will be retired on 26 May 2021. Update your API calls to use the new URLs.\n\nThe pattern for the endpoint URL changed from gateway-{location}.watsonplatform.net\/discovery\/api\/ to api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11142-7-1829","score":0.0310096154,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_07103-29564-31587","score":0.0305361305,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11143-1499-3764","score":0.0300768883,"text":"\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].\n\nWhen you're working in IBM Cloud [Click IBM Cloud menu option], check out your dashboard to get a high-level overview of your account's resources, users, support cases, compliance monitoring, and usage, with quick links out to each area. You can tailor the information that's displayed to only what you need by creating custom dashboards and adding widgets for specific resources, team notes, management tasks, and more [Click the Actions menu icon > Create dashboard > Management > Create].\n\nFor any account management tasks that you need to take care of, go to Manage > Account [Click Manage menu option > Account]. Here you can create and manage your resource groups, Cloud Foundry orgs, create tags to organize resources, manage your account settings, and more.\n\nFrom the same Manage menu, you can go to Billing and usage [Click Manage menu option > Billing and usage] to view your usage, view invoices, and set spending notifications to help keep track of your costs.\n\nThen, through the Manage > Access (IAM) option [Click Manage menu item > Access (IAM)], you can invite users to your account and manage their access to account resources including IAM-enabled, Cloud Foundry, and classic infrastructure resources.\n\nIn a connected world, security is more important than ever, and we've built it right into the platform [Click Menu icon > Security and Compliance]. With the IBM Cloud Security and Compliance Center [Click Dashboard], you can set up a unified dashboard to monitor security and compliance, govern configuration, and gain insights into threats.\n\nIf you prefer to work from the command line [Click IBM Cloud Shell menu item], you can manage your IBM Cloud account and resources from your browser with IBM Cloud Shell.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_07103-32746-34817","score":0.0294181268,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07578-447531-449109","score":0.0289915966,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16362-2897-4995","score":0.0158730159,"text":"\nThe assistant ID can be found in Assistant settings.\n\nIn Assistant settings, the assistant ID is in the Assistant IDs and API details section.\n\n\n\n\n\n\n\n What do the draft and live tags mean? \n\nA Draft tag indicates that the information is linked to your draft environment, which means that you can preview these updates but they are not visible to your users. A Live tag indicates that the information is linked to your live environment, which means that the content is available to your users to interact with.\n\nFor more information, see [Environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments).\n\n\n\n\n\n Why can't I log in? \n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n\n\n\n\n Why am I being asked to log in repeatedly? \n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n Why don't I see the Analytics page? \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-faqs"},{"document_id":"ibmcld_01025-7-2061","score":0.0147058824,"text":"\nFAQs - Lite plan \n\nThis is a collection of frequently asked questions (FAQ) about the IBM\u00ae Db2\u00ae on Cloud Lite plan.\n\n\n\n Will my free plan expire? \n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n\n\n\n\n\n Will my data be deleted? \n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n\n\n\n\n\n How can I download a backup of my data on the Lite plan? \n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n\n\n\n\n Can I change the email I use for reactivation? \n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12343-7-1769","score":0.0327868852,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_12341-1239-2954","score":0.0322580645,"text":"\nThe releases of these SDKs should be published on [NPM](https:\/\/www.npmjs.com\/). Your NPM package should be [scoped](https:\/\/docs.npmjs.com\/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https:\/\/www.npmjs.com\/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https:\/\/github.com\/airbnb\/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_00620-14227-15704","score":0.0314980159,"text":"\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- <\/section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_02698-7-1759","score":0.031024531,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_00620-8515-9974","score":0.0300904977,"text":"\npanic(err)\n}\nb, _ := json.MarshalIndent(allDocsResult3, \"\", \" \")\nfmt.Println(string(b))\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\n)\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! ! for examples.This practice means you define the size of the data set and the range of the _id field to return, but that isn't quite the same as pagination.The startkey\/endkey values are in double quotation marks because they're expected to be JSON-encoded and JSON.stringify('order00077') === \"order00077\".<-- <\/section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --><-- <section \"id=\"section-pagination-options\" \"> --> Pagination options For performance reasons, if you are displaying large amounts of data, you must consider using pagination. In these examples, documents are fetched in blocks of five. However, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_02683-12957-13877","score":0.0296442688,"text":"\nproperty.getPropertyDataFormat(); \/\/ YAML\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ Yaml String is returned\n}\nShow more\n\n\n\n\n\n Set listener for feature or property changes \n\nThe SDK provides mechanism to notify you in real time when feature flag's or property's configuration changes. You can subscribe to configuration changes by using the same appConfigClient.\n\nappConfigClient.registerConfigurationUpdateListener(new ConfigurationUpdateListener() {\n@Override\npublic void onConfigurationUpdate() {\nSystem.out.println(\"Received updated configurations\");\n\/\/ add your code\n\/\/ To find the effect of any configuration changes, you can call the feature or property related methods\n\n\/\/ Feature feature = appConfigClient.getFeature(\"numeric-feature\");\n\/\/ Integer newValue = (Integer) feature.getCurrentValue(entityId, entityAttributes);\n}\n});\n\n\n\n\n\n Fetch most recent data \n\nappConfigClient.fetchConfigurations();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_00510-7-1689","score":0.015625,"text":"\nData modeling \n\nThe Data modeling document is the first best practice document in the series. It shows you the following best practices:\n\n\n\n* What you need to know about your APIs.\n* How to model your data.\n* What size documents you must use.\n* What to avoid.\n* How to configure your databases.\n\n\n\nFor more information, see [Indexing and querying](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the API that you are targeting \n\nYou can use [Java\u2122](https:\/\/github.com\/IBM\/cloudant-java-sdk), [Python](https:\/\/github.com\/IBM\/cloudant-python-sdk), [Go](https:\/\/github.com\/IBM\/cloudant-go-sdk), or [Node.js](https:\/\/github.com\/IBM\/cloudant-node-sdk) or some other use-case-specific language or platform. One of these languages most likely comes with convenient client-side libraries that integrate IBM Cloudant access nicely, following the conventions that you expect for your tools. These languages are great for programmer efficiency, but they also hide the API from view.\n\nThis abstraction is what you want, the whole reason for using a client library is to save yourself repeated, tedious boiler-plating. However, you must understand the underlying API is vital when you troubleshoot and report problems. When you report a suspected problem to IBM Cloudant, it helps us help you if you can provide a way for us to reproduce the problem.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00646-3898-5632","score":0.0153846154,"text":"\nFor example, when your webpage is first loaded, it calls the GET \/todolist endpoint. The GET \/todolist endpoint uses the postFind method to query the database for all documents (by using the index created after the todo database), and then orders the notes by timestamp, and returns them to the front end for display.\n\nFiltering by tag uses the same postFind method, but by using the second index, you create and delete notes by using the postDocument and deleteDocument methods.\n\n\n\n\n\n\n\n Summary \n\nIBM Cloudant allows rapid development of web applications, as its HTTP API is modeled by the [Node.js SDK](https:\/\/www.npmjs.com\/package\/@ibm-cloud\/cloudant) and is easy to integrate with your own code. You create an IBM Cloudant database and add JSON documents that model your own data. Remember to create secondary indexes to help service your query access patterns so that query performance remains quick as your data volume grows.\n\nIf you don't fancy writing JavaScript, we have SDKs for [Java\u2122, Python, and Go](https:\/\/cloud.ibm.com\/apidocs\/cloudant), plus our [HTTP API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Don't forget. The [IBM Cloudant Dashboard](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-connectingibm-cloudant-dashboard) is a great way to explore your databases, create and modify documents, and refine your index and querying skills.\n\nYou can find more best practice guidance in our [blog](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) and [documentation](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant\/getting-started.html). For a video guide to IBM Cloudant and its capabilities, see the course in our [learning center](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-web-based-todo-list"},{"document_id":"ibmcld_00620-9537-11012","score":0.0149253731,"text":"\nHowever, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users. The _id of the sixth document becomes the startkey of your request for the next page of results.See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=6\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\nint pageSize = 5;\nPostAllDocsOptions.Builder docsOptionsBuilder =\nnew PostAllDocsOptions.Builder()\n.db(\"orders\")\n.limit(pageSize + 1); \/\/ Fetch pageSize + 1 documents\n\nAllDocsResult response =\nservice.postAllDocs(docsOptionsBuilder.build())\n.execute()\n.getResult();\n\nwhile (response.getRows().size() > 1) {\nList<DocsResultRow> responseDocuments = response.getRows();\n\/\/ on the last page, show all documents:\nif (responseDocuments.size() <= pageSize) {\nSystem.out.println(responseDocuments);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_12463-25842-27664","score":0.0149253731,"text":"\n: Secrets Manager is now available in the London (eu-gb), Tokyo (jp-tok), and Washington DC (us-east) regions.\n\nFor more information, see [Regions and endpoints](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-endpoints).\n\n\n\n\n\n 15 February 2021 \n\nNow available: Secrets Manager Java SDK\n: You can now use the IBM Cloud Secrets Manager Java SDK to connect to your Secrets Manager service instance.\n\nFor more information, check out the [IBM Cloud Secrets Manager Java SDK repository in GitHub](https:\/\/github.com\/IBM\/secrets-manager-java-sdk).\n\n\n\n\n\n 27 January 2021 \n\nNow available: Secrets Manager Go and Python SDKs\n: You can now use the IBM Cloud Secrets Manager Go and Python SDKs to connect to your Secrets Manager service instance.\n\nFor more information, check out the SDK repositories in GitHub:\n\n\n\n* [IBM Cloud Secrets Manager Go SDK](https:\/\/github.com\/IBM\/secrets-manager-go-sdk)\n* [IBM Cloud Secrets Manager Python SDK](https:\/\/github.com\/IBM\/secrets-manager-python-sdk)\n\n\n\n\n\n\n\n 18 December 2020 \n\nAnnouncing Secrets Manager general availability\n: Secrets Manager is now generally available in the IBM Cloud catalog!\n\nTo find out more about this release, check out the [announcement blog](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-secrets-manager-is-now-generally-available).\n\n\n\n\n\n 15 December 2020 \n\nSydney availability\n: You can now create a Secrets Manager service instance in the Sydney (au-syd) region.\n\nFor more information, see [Regions and endpoints](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-endpoints).\n\n\n\n\n\n 14 December 2020 \n\nNow available: Secrets Manager CLI plug-in\n: The Secrets Manager CLI plug-in is now available for download!\n\nYou can use the Secrets Manager CLI to interact with the secrets that you store in your Secrets Manager instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":0.0327868852,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":0.0322580645,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-12399-14287","score":0.0317460317,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":0.03125,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":0.0307692308,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":0.0303030303,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":0.0298507463,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":0.0294117647,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":0.0289855072,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-13891-15856","score":0.0285714286,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16410-13218-15390","score":0.0163934426,"text":"\nTo compare how different human annotators annotated the same documents, specify an evaluation threshold. If the annotations made by one human annotator differ from the annotations made by another human annotator to the point where the difference results in a low score, it means that the annotators do not agree. The disagreement needs to be investigated and resolved.\n\n\n\n\n\n Procedure \n\nTo set the inter-annotator agreement threshold:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Settings > IAA Settings tab.\n3. Specify a value between 0 and 1, such as .5 or .8, and then click Save.\n\n\n\n\n\n\n\n\n\n Connecting to annotation guidelines \n\nAfter you create annotation guidelines for your project, you can configure Knowledge Studio to connect to them. For help with choosing the correct annotation to apply, human annotators can review the guidelines while annotating documents. Administrators can also review the guidelines if they need assistance while resolving annotation conflicts in overlapping documents.\n\n\n\n Procedure \n\nTo connect the ground truth editor and adjudication tool to your annotation guidelines:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. select the Settings > Annotation Guidelines tab.\n3. Specify the URL to where your guidelines are hosted.\n4. Click Save. The system connects the ground truth editor and adjudication tool to your annotation guidelines. Depending on the access permissions granted to users when you created the guidelines, human annotators and workspace administrators might be able to update the guidelines after opening them, for example, to add clarifications and examples.\n\n\n\n\n\n\n\n Annotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16417-5155-7505","score":0.0163934426,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16425-15959-18174","score":0.0161290323,"text":"\nThe guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on. Be sure to include examples of difficult decisions and their preferred resolutions. The best way to determine what you need to add to the annotation guidelines is to carefully review document conflicts. Real examples of annotations that real people disagreed upon and how they were resolved can be a great help to human annotators as they tackle the annotation of new documents.\n* Update type system\n\nYou might need to update the type system for these reasons:\n\n\n\n* The documents that comprise the training data have references to concepts that are important types in the domain but are not represented anywhere in the type system. This suggests that you might need to add types that capture the missing concepts or relationships. Be careful not to try to define a type for every concept in a field, or every entity that occurs in domain documents; the type system should be limited to only the most fundamental types.\n* An existing type is being consistently misused by human annotators. If a type consistently causes confusion, then you might need to rename it or eliminate it if it is redundant.\n* An existing type is never used by human annotators because it is never referenced in the documents. If the type is unlikely to ever be used in literature from this domain, then remove it from the type system.\n* Two types are often interchanged when human annotators annotate documents. Consider whether the two types could be consolidated into one type that accurately represents the concept or relationship. For example, if the type system contains both PERSON and PEOPLE, which are often used interchangeably, it might be best to use one type named PERSONPEOPLE that covers both cases instead of two separate types.\n\n\n\nUse caution when you update the type system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16481-5154-7504","score":0.0161290323,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16490-15929-18144","score":0.0158730159,"text":"\nThe guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on. Be sure to include examples of difficult decisions and their preferred resolutions. The best way to determine what you need to add to the annotation guidelines is to carefully review document conflicts. Real examples of annotations that real people disagreed upon and how they were resolved can be a great help to human annotators as they tackle the annotation of new documents.\n* Update type system\n\nYou might need to update the type system for these reasons:\n\n\n\n* The documents that comprise the training data have references to concepts that are important types in the domain but are not represented anywhere in the type system. This suggests that you might need to add types that capture the missing concepts or relationships. Be careful not to try to define a type for every concept in a field, or every entity that occurs in domain documents; the type system should be limited to only the most fundamental types.\n* An existing type is being consistently misused by human annotators. If a type consistently causes confusion, then you might need to rename it or eliminate it if it is redundant.\n* An existing type is never used by human annotators because it is never referenced in the documents. If the type is unlikely to ever be used in literature from this domain, then remove it from the type system.\n* Two types are often interchanged when human annotators annotate documents. Consider whether the two types could be consolidated into one type that accurately represents the concept or relationship. For example, if the type system contains both PERSON and PEOPLE, which are often used interchangeably, it might be best to use one type named PERSONPEOPLE that covers both cases instead of two separate types.\n\n\n\nUse caution when you update the type system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16417-3559-5683","score":0.0158730159,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16527-12995-15319","score":0.015625,"text":"\nThe document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50. Annotate only mentions initially, examine the results, and refine your annotation guidelines and the type system as needed. When you're satisfied with the results of mention annotation, move on to annotate relations and coreferences.\n\nWhile fundamental work is underway to define a set of entity types and mention-annotation guidelines, avoid putting a lot of effort into annotating relation mentions. Mention changes will undo relation annotation work. Do take some time to define a set of relation types and their allowable entity type pairs so that relation type needs are taken into consideration before the entity type inventory is finalized.\n\nExpect the type system to evolve with the experience of people trying to annotate to it. If you revise the type system after you create human annotation tasks, you must decide whether to apply the changes to each task. If you apply the changes, human annotators will have to revisit the documents that they annotated previously.\n\nWhen you test the model, you can review statistics that show how frequently the entity types and relation types occur in your sample documents. Be sure to review these statistics. To ensure that your application receives enough context to accurately annotate large collections of documents, your test data must include a large sampling of the most important entity types and relation types.\n\nAfter you train your first model, you will likely need to make modifications based on the performance statistics. However, to create a reliable statistical model for machine annotation, you want the type system to be as close to final as possible before you begin large-scale annotation tasks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"},{"document_id":"ibmcld_16481-3559-5682","score":0.015625,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16454-13234-15485","score":0.0153846154,"text":"\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50. Annotate only mentions initially, examine the results, and refine your annotation guidelines and the type system as needed. When you're satisfied with the results of mention annotation, move on to annotate relations and coreferences.\n\nWhile fundamental work is underway to define a set of entity types and mention-annotation guidelines, avoid putting a lot of effort into annotating relation mentions. Mention changes will undo relation annotation work. Do take some time to define a set of relation types and their allowable entity type pairs so that relation type needs are taken into consideration before the entity type inventory is finalized.\n\nExpect the type system to evolve with the experience of people trying to annotate to it. If you revise the type system after you create human annotation tasks, you must decide whether to apply the changes to each task. If you apply the changes, human annotators will have to revisit the documents that they annotated previously.\n\nWhen you test the model, you can review statistics that show how frequently the entity types and relation types occur in your sample documents. Be sure to review these statistics. To ensure that your application receives enough context to accurately annotate large collections of documents, your test data must include a large sampling of the most important entity types and relation types.\n\n> Important: After you train your first model, you will likely need to make modifications based on the performance statistics. However, to create a reliable statistical model for machine annotation, you want the type system to be as close to final as possible before you begin large-scale annotation tasks.\n\n\n\n\n\n When to define roles \n\nUsing roles enables you to define more precise entity types.\n\nEvery entity that you add has a role.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"},{"document_id":"ibmcld_16563-10714-12816","score":0.0153846154,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-963331-965355","score":0.0163934426,"text":"\nRestoring a volume from a snapshot creates an entirely new boot or data volume. The new volume has the same properties of the original volume, including encryption. If you restore from a bootable snapshot, you create a boot volume. Similarly, you can create a data volume from a snapshot of a data volume. The volume that you create from the snapshot uses the same volume profile and contains the same data and metadata as the original volume. You can restore a volume when you provision an instance, update an existing instance, or create a stand-alone volume by using the UI, CLI, or the volumes API. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones do not require hydration. The data is available as soon as the volume is created.\n\n\n\n* I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal?\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16410-6875-8784","score":0.0163934426,"text":"\nTo add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16727-963207-965231","score":0.0161290323,"text":"\nRestoring a volume from a snapshot creates an entirely new boot or data volume. The new volume has the same properties of the original volume, including encryption. If you restore from a bootable snapshot, you create a boot volume. Similarly, you can create a data volume from a snapshot of a data volume. The volume that you create from the snapshot uses the same volume profile and contains the same data and metadata as the original volume. You can restore a volume when you provision an instance, update an existing instance, or create a stand-alone volume by using the UI, CLI, or the volumes API. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones do not require hydration. The data is available as soon as the volume is created.\n\n\n\n* I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal?\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16468-6902-8930","score":0.0161290323,"text":"\nIn addition, some percentage of documents must occur in all of the annotation sets that you add to the task (you specify the overlap percentage when you create the annotation sets).\n\n\n\n Important \n\n\n\n* An annotation task is a temporal concept that exists to allow human annotators to annotate text in isolated spaces. It also ensures that only approved annotations are promoted to ground truth.\n* An annotation set can be included in one active task at a time. To add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_15916-2745-4751","score":0.0158730159,"text":"\nRestoring a volume from a snapshot creates an entirely new boot or data volume. The new volume has the same properties of the original volume, including encryption. If you restore from a bootable snapshot, you create a boot volume. Similarly, you can create a data volume from a snapshot of a data volume. The volume that you create from the snapshot uses the same volume profile and contains the same data and metadata as the original volume. You can restore a volume when you provision an instance, update an existing instance, or create a stand-alone volume by using the UI, CLI, or the volumes API. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones do not require hydration. The data is available as soon as the volume is created.\n\n\n\n\n\n\n\n What happens to snapshots when I delete my volume? \n\nDeleting a volume from which you created a snapshot has no effect on the snapshot. Snapshots exist independently of the original source volume and have their own lifecycle. To delete a volume, all snapshots must be in a stable state.\n\n\n\n\n\n Can I set up a snapshot schedule?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-faqs&interface=ui"},{"document_id":"ibmcld_07578-894428-896189","score":0.0158730159,"text":"\nFor more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n* What is IOPS and how do it relate to my Block Storage for VPC volume performance?\n\n What is IOPS and how do it relate to my Block Storage for VPC volume performance? \n\nInput\/output operations per second (IOPS) is used to measure the performance of your Block Storage for VPC volumes. A number of variables impact IOPS values, such as the balance of read\/write operations, queue depth, and data block sizes. In general, the higher the IOPS of your Block Storage for VPC volumes, the better the performance. For more information about expected IOPS for Block Storage for VPC profiles, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles). For more information about how block size affects performance, see [Block storage capacity and performance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-capacity-performancehow-block-size-affects-performance).\n* Is the allocated IOPS enforced by instance or by volume?\n\n Is the allocated IOPS enforced by instance or by volume? \n\nIOPS is enforced at the volume level.\n* What are IOPS profiles and how do they affect volume performance?\n\n What are IOPS profiles and how do they affect volume performance? \n\nIOPS profiles define IOPS\/GB performance for volumes of various capacities. You can select from three predefined [IOPS tiers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilestiers) that offer reliable IOPS performance for your workload requirements. You can also define [custom IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilescustom) and specify a range of IOPS for a volume size that you choose.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14984-3011-4697","score":0.015625,"text":"\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_16727-894305-896066","score":0.015625,"text":"\nFor more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n* What is IOPS and how do it relate to my Block Storage for VPC volume performance?\n\n What is IOPS and how do it relate to my Block Storage for VPC volume performance? \n\nInput\/output operations per second (IOPS) is used to measure the performance of your Block Storage for VPC volumes. A number of variables impact IOPS values, such as the balance of read\/write operations, queue depth, and data block sizes. In general, the higher the IOPS of your Block Storage for VPC volumes, the better the performance. For more information about expected IOPS for Block Storage for VPC profiles, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles). For more information about how block size affects performance, see [Block storage capacity and performance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-capacity-performancehow-block-size-affects-performance).\n* Is the allocated IOPS enforced by instance or by volume?\n\n Is the allocated IOPS enforced by instance or by volume? \n\nIOPS is enforced at the volume level.\n* What are IOPS profiles and how do they affect volume performance?\n\n What are IOPS profiles and how do they affect volume performance? \n\nIOPS profiles define IOPS\/GB performance for volumes of various capacities. You can select from three predefined [IOPS tiers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilestiers) that offer reliable IOPS performance for your workload requirements. You can also define [custom IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilescustom) and specify a range of IOPS for a volume size that you choose.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14996-2951-4749","score":0.0153846154,"text":"\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_09568-3117-4891","score":0.0153846154,"text":"\nRabbitMQ Disk Alarms \n\nBy default, when the RabbitMQ server detects that free disk space has dropped below a certain threshold, it raises a disk alarm. The threshold for Messages for RabbitMQ is 80% of your deployment's disk size. The alarm blocks incoming messages from publishers and prevents messages in memory from being written to disk. The alarm is cluster-wide so if disk space on one node gets too low, the alarm blocks on all nodes. To clear the alarm, either messages that have been written to disk need to be consumed and that space is reclaimed, or scale your deployment to a larger disk size.\n\nMore information about memory alarms can be found in the [RabbitMQ documentation](https:\/\/www.rabbitmq.com\/disk-alarms.html).\n\n\n\n\n\n Disk IOPS \n\nThe number of input\/output operations per second (IOPS) is limited by the type of storage volume that is being used. Storage volumes for Messages for RabbitMQ deployments are provisioned on [Block Storage Endurance Volumes in the 10 IOPS per GB tier](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-orderingthroughConsoleorderingthroughConsoleEndurance). IOPS limits can affect RabbitMQ message throughput and storage operations. Reaching these limits can cause disk to fall behind on reclaiming space after messages are consumed, leading to disk alarms and publisher throttling until activity slows down. You can increase the number IOPS available to your deployment by increasing disk space.\n\n\n\n\n\n Quorum Queues \n\nHigh-availability can be managed with [quorum queues](https:\/\/www.rabbitmq.com\/quorum-queues.html). Using quorum queues impacts performance; it needs more memory and disk space for the WAL that it uses to maintain state for operations. It also needs more disk I\/O as it persists all data on disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-performance"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16444-7-2064","score":0.0327868852,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16563-1598-3452","score":0.0320020481,"text":"\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor more information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16507-1455-3632","score":0.0320020481,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-7-2044","score":0.03125,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16563-3072-4738","score":0.0307692308,"text":"\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows you how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n4. Select Dictionary, then click Next.\n5. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-3021-4769","score":0.0303030303,"text":"\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16464-1626-3475","score":0.0298507463,"text":"\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n What to do next \n\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16463-4148-5042","score":0.0294117647,"text":"\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16507-10816-12778","score":0.0287784679,"text":"\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.\n\nThis task shows you how to create a dictionary that is editable. If you want to upload and pre-annotate your documents with a read-only dictionary, click the Menu icon next to the Create Dictionary button, and then select Upload Dictionary.\n\n\n\n\n\n Procedure \n\nTo create an editable dictionary and pre-annotate documents, follow these steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select the Assets > Dictionaries page.\n3. Click Create Dictionary, enter a name, and then click Save.\n4. From the Entity type list, select an entity type to associate with the dictionary.\n\nYou can also associate an entity type with the dictionary from the Machine Learning Model > Pre-annotation page. Click the overflow menu button in the Dictionaries row in the page, then click Map entity types.\n5. Add entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16464-4463-6317","score":0.0287784679,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.8529278651,"ndcg_cut_10":0.8529278651}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16369-4569-5779","score":0.0163934426,"text":"\n(For the complete function, see the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/content-carousel).)\n\ncarouselData.forEach((cardData) => {\nconst { url, title, description, alt } = cardData;\nconst cardElement = document.createElement('div');\ncardElement.classList.add('swiper-slide');\n\ncardElement.innerHTML = \n<div class=\"bx--tile Carousel__Card\">\n<img class=\"Carousel__CardImage\" src=\"${url}\" alt=\"${alt}\" \/>\n<div class=\"Carousel__CardText\">\n<div class=\"Carousel__CardTitle\">${title}<\/div>\n<div class=\"Carousel__CardDescription\">${description}<\/div>\n<\/div>\n\n<a href=\"https:\/\/www.ibm.com\" class=\"Carousel__CardButton bx--btn bx--btn--primary\" target=\"_blank\">\nView more details\n<\/a>\n\n<button type=\"button\" class=\"Carousel__CardButton Carousel__CardButtonMessage bx--btn bx--btn--primary\">\nTell me more about this\n<\/button>\n<\/div>\n;\n\n...\n\n});\nShow more\n4. In your onLoad event handler, use the [on()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodson) instance method to subscribe to the customResponse event, registering the carouselCustomResponseHandler() function as the callback.\n\ninstance.on({","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-content-carousel"},{"document_id":"ibmcld_16507-3099-4772","score":0.0163934426,"text":"\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_11098-3440-5517","score":0.0161290323,"text":"\nSo as a much simpler, business-oriented example, consider a city-wide fire, such as the one that burned down much of Chicago in the late 1800s. Fires on that scale are unusual, but not unique. As a business, should you spend time and money making sure that your computer systems could survive such a fire? The answer depends on various factors, but if for instance, your entire customer base is in Chicago, worrying about events that will wipe out the whole city is likely not useful. So it is worth thinking about what sorts of things might fail, how likely they are to happen, and how damaging they would be, before deciding what level of redundancy is appropriate.\n\n\n\n Geographic redundancy \n\nLevels of redundancy have both a technical and a geographic component. If you have two houses, are you more likely to become homeless if the houses are next door to each other or if they are in different countries? Similar considerations drive computer system redundancy, and are behind IBM\u00ae\u2019s use of local, regional, and global redundancy. Local redundancy duplicates some or all of a computer system in the same data center. This protects against many kinds of outages, but not all. Regional redundancy, as implemented by IBM, provides at least three copies of the system in three different data centers, so a single local event, like a large fire, is unlikely to take down all the systems. Global redundancy is available for customers that want to avoid outages that are caused by large regional events such as severe hurricanes and typhoons.\n\nZoom\n\n![Geographic levels of redundancy.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/overview\/images\/geographic-redundancy.svg)\n\nFigure 2. Local, regional, and global geographic redundancy\n\n\n\n\n\n Technical redundancy \n\nMost public clouds have standardized geographic redundancy, although the various vendors do it in slightly different ways. But technical redundancy is not provided by the cloud vendors. Instead, they provide the tools for customers to build their own technical redundancy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ha-considerations"},{"document_id":"ibmcld_16444-1600-3658","score":0.0161290323,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_10864-3733-5982","score":0.0158730159,"text":"\nA need is created for an elastic system where normal workload might be small, but needs to scale quickly with predictable response time. So the ability to handle many simultaneous events with no prior warning to the system is desirable. It is difficult to build a system to meet these requirements that use traditional server architectures. As they tend to either be underpowered, and unable to handle peak load in traffic, or be over-provisioned and highly expensive.\n\nIt is possible to implement IoT applications that use traditional server architectures. However, usually the combination of different services and data bridges requires high performance and flexible pipelines. Spanning from IoT devices up to cloud storage, and an analytics platform. Often pre-configured bridges lack the programmability to implement and fine-tune a particular solution architecture. Given the variety of pipelines, and the lack of standardization around data fusion in general (IoT in particular), it is common to see environments where the pipeline requires custom data transformation. These custom data transformations apply to format conversion, filtering, or augmentation. Cloud Functions is an excellent tool to implement such a transformation, in a serverless manner, where the custom logic is hosted on a fully managed and elastic cloud platform.\n\nLook at the following sample IoT application that uses Cloud Functions, Node-RED, Cognitive, and other services: [Serverless transformation of IoT data-in-motion with Cloud Functions](https:\/\/medium.com\/openwhisk\/serverless-transformation-of-iot-data-in-motion-with-openwhisk-272e36117d6c).\n\n\n\n\n\n API backend \n\nServerless computing platforms give developers a rapid way to build APIs without servers. Cloud Functions supports automatic generation of REST API for actions.\n\nAdditionally, Cloud Functions actions can be connected to an API Management tool of choice. Similar to other use cases, all considerations for scalability, and other Qualities of Services apply.\n\nSee the following example that includes a discussion of [using Serverless as an API backend](https:\/\/martinfowler.com\/articles\/serverless.htmlACoupleOfExamples).\n\n\n\n\n\n Mobile back end \n\nMany mobile applications require server-side logic.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-use_cases"},{"document_id":"ibmcld_16444-3168-4952","score":0.0158730159,"text":"\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.\n\n\n\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16317-7-2491","score":0.015625,"text":"\nUsing variables to manage conversation information \n\nWhen customers reply to your assistant, they share information about themselves and what they want. Your assistant remembers this information, and other information about a conversation, as variables. Your assistant can use variables to provide a more personalized and customized experience, and to get users quickly to the solutions they need.\n\nVariables are a powerful tool that you can use to build a better assistant. Variables make possible all of the following benefits:\n\n\n\n* Personalization. The best virtual assistant experiences are targeted and personalized for each customer. When an assistant greets a customer by saying \"Hello, Frank! Welcome back,\" it tells Frank that it remembers his name and that it has talked to him before. By storing this kind of information in variables and then referencing them in your assistant's output, you can personalize the conversation and help your assistant seem more human.\n* Acceleration. Over the course of a conversation, your customers answer questions and make choices. These customer responses are stored as variables, which your assistant can then use to guide a conversation. By choosing the right steps and not wasting your customers' time, you can get them as quickly as possible to the right solution.\n* Modularity. Some information might be useful for many different purposes (for example, a customer's current account balance or contact information). Rather than retrieving or recalculating this information in multiple locations, you can do so once, by using a variable to store the result and then access it wherever you need it.\n\n\n\nA variable is simply a named container for a piece of information; by referencing this container by name, your assistant can store or retrieve the information at run time. For example, a variable that is called account_balance might store your customer's current account balance, a value your assistant can update or retrieve as needed.\n\nThe data that is stored by a variable is characterized by the type of data that it contains, such as text, a numeric value, a date, or even a list of multiple values. The operations that you can perform with a variable vary depending on its data type.\n\n\n\n Action variables and session variables \n\nWatson Assistant supports two categories of variables:\n\n\n\n* Action variables: When a step collects information from the customer, the customer response is automatically stored in an action variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-info"},{"document_id":"ibmcld_16456-13093-15345","score":0.015625,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16369-2522-3936","score":0.0153846154,"text":"\nCreate a handler for the [customResponse](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventscustomresponse) event. This handler renders the content carousel, using the styles defined by the Swiper library. (You can see the definitions of these styles in the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/content-carousel).)\n\nThis function also relies on a helper function (createSlides()), which we will create in the next step. (The complete code for this function also initializes the Swiper library; for more information, see the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/content-carousel).)\n\nfunction carouselCustomResponseHandler(event, instance) {\nconst { element, message } = event.data;\n\nelement.innerHTML = \n<div class=\"Carousel\">\n<div class=\"swiper\">\n<div class=\"swiper-wrapper\"><\/div>\n<\/div>\n<div class=\"Carousel__Navigation\" >\n<button type=\"button\" class=\"Carousel__NavigationButton Carousel__NavigationPrevious bx--btn bx--btn--ghost\">\n<svg fill=\"currentColor\" width=\"16\" height=\"16\" viewBox=\"0 0 32 32\" aria-hidden=\"true\"><path d=\"M20 24L10 16 20 8z\"><\/path><\/svg>\n<\/button>\n<div class=\"Carousel__BulletContainer\"><\/div>\n<button type=\"button\" class=\"Carousel__NavigationButton Carousel__NavigationNext bx--btn bx--btn--ghost\">","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-content-carousel"},{"document_id":"ibmcld_16530-13093-15345","score":0.0153846154,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11603-6477-8007","score":0.0163934426,"text":"\n<metric category=\"config\" context=\"host\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Virtualization Solution<\/name>\n<value>KVM<\/value>\n<\/metric>\n.\n.\n.\n<\/metrics>\n\n\n\nYou might experience a delay before your data is available.\n\n\n\n\n\n Troubleshooting \n\nUse the following troubleshooting tips for IMCS.\n\n\n\n Uninstalling the Metrics Collector \n\n\n\n1. Run the following command to uninstall IMCS if you have any issues during the installation process. Then, reinstall it.\n\n.\/uninstall-linux.sh\n\nRemoving IBM Metric Collector for SAP...\nSuccessfully removed IBM Metric Collector for SAP.\n\n\n\n\n\n\n\n No metrics reported when you run the curl command \n\nNo reported metrics message is often due to the port not assigned to SAP Metrics Collector. It needs port 18181 available for localhost. If you have any other applications that use the port, you must close the applications.\n\n\n\n1. Use the following command to see whether the port is assigned to another application.\n\nnmap -sT -O localhost\n\nStarting Nmap 6.40 (http:\/\/nmap.org) at (date and time)\nNmap scan report for localhost (your localhost address)\nHost is up (0.0s latency).\nOther addresses for localhost (not scanned): (localhost addresses)\nrDNS record for (localhost): sap-mc-redhat\nNot shown: (number of) closed ports\nPORT STATE SERVICE\n(port)\/tcp open ssh\n(port)\/tcp open smtp\nDevice type: general purpose\nRunning: Linux 3.X\nOS CPE: cpe:\/o:linux:linux_kernel:3\nOS details: Linux 3.7 3.9\nNetwork Distance: 0 hops\n\n\n\n\n\n\n\n nmap not found","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-metrics-collector-for-sap-linux"},{"document_id":"ibmcld_14508-7830-9886","score":0.0163934426,"text":"\nIf the client installed the following, you can monitor them.\n\n\n\n* VMware Aria Automation\n* VMware Aria Orchestrator\n* VMware Aria Business for Cloud\n* VMware Site Recovery Manager\n\n\n\nThe VMware SDDC Health Management Pack provides the following dashboards:\n\n\n\n* SDDC Management Health Overview Dashboard - You can use SDDC Management Health overview dashboard to view and analyze the application-specific problems in the SDDC components.\n* SDDC Health Historic Trend Dashboard - The VMware SDDC Health Management Pack consists of SDDC health historic trend dashboard, which displays the health trend for each component in the SDDC stack.\n* SDDC VMware Aria Operations Manager Sizing Dashboard - The SDDC VMware Aria Operations Manager Sizing Dashboard provides VMware Aria Operations Manager cluster capacity to process object and metrics.\n\n\n\nThe plug-ins in the VMware SDDC Health Management Pack collect metrics for object types that are contained in the plug-ins. The Management Pack collects health metrics for the following components:\n\n\n\n* vCenter Server\n* Management Pack for NSX for vSphere\n* VMware Aria Automation\n* VMware Aria Operations Manager\n* VMware Aria Business\n* VMware Aria Operations for Logs\n* VMware Site Recovery Manager\n* vCenter HA\n* vMware vSAN Health\n* Services in vCenter Server Appliance\n* VMware Aria Operations Manager Sizing\n* VMware Aria Orchestrator\n\n\n\n\n\n\n\n Management Pack for NSX-T \n\nThe NSX-T management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks. The pack includes the following items.\n\n\n\n* Configuration assurance\n* Health\n* Performance\n* Capacity\n* Troubleshooting for NSX-T objects\n\n\n\n\n\n\n\n Management Pack for NSX for vSphere \n\nThe NSX for vSphere management pack offers operations management coverage for deployments of VMware's NSX virtual networking technologies. This management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrops"},{"document_id":"ibmcld_09834-7-1796","score":0.0161290323,"text":"\nMonitoring a Windows environment \n\nThe standard monitoring agent cannot be installed on a Windows platform. In order to monitor a Windows system with IBM Cloud Monitoring, you can leverage the [Prometheus Windows Exporter](https:\/\/promcat.io\/apps\/windows) to perform the collection of the metrics on the system.\n\nOnce the metrics are collected you have two options for publishing the metrics, remotely scraping the metrics with a Linux monitoring agent,or pushing from a local instance of Prometheus using remote write. Step 3 will cover these two options, but step 1 and 2 are the same regardless of how the metrics are sent.\n\nComplete the following steps to configure the following Windows images to send metrics to a monitoring instance:\n\n\n\n* Windows Server 2019 Standard Edition (64 bit)\n* Windows Server 2016 Standard Edition (64 bit)\n\n\n\n\n\n Step 1: Configure the Prometheus Windows exporter \n\nConfigure the [Prometheus windows_exporter](https:\/\/github.com\/prometheus-community\/windows_exporter) to collect Windows system metrics.\n\nThe Prometheus Windows exporter runs as a Windows service. You configure the metrics that you want to monitor by enabling collectors.\n\nThe following collectors are supported:\n\n\n\nTable 1. Collectors\n\n Collector name Information about metrics collected per collector \n\n cpu [CPU metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cpu.md) \n cs [Computer system metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cs.md) \n logical_disk [Disk metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.logical_disk.md) \n os [Operating System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.os.md)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-windows"},{"document_id":"ibmcld_14508-9410-11470","score":0.0161290323,"text":"\nThe pack includes the following items.\n\n\n\n* Configuration assurance\n* Health\n* Performance\n* Capacity\n* Troubleshooting for NSX-T objects\n\n\n\n\n\n\n\n Management Pack for NSX for vSphere \n\nThe NSX for vSphere management pack offers operations management coverage for deployments of VMware's NSX virtual networking technologies. This management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks. Coverage includes configuration assurance, health, performance, capacity, and troubleshooting for NSX logical switches, logical routers, edge services, distributed firewall, and load balancers.\n\nThe NSX for vSphere management pack is tightly integrated with VMware Aria Operations and vSphere host data is correlated with the NSX services that run with these hosts. With log integration by VMware Aria Operations for Logs, error and outage conditions, triggered by log messages, are alerted within the management pack object and problem windows.\n\n\n\n\n\n VMware Aria Operations Federation Management Pack \n\nVMware Aria Operations Federation Management Pack enables a multisite VMware Aria Operations deployment into a single pane of glass. It allows a deployment of VMware Aria Operations with the capability of receiving key metrics for specified objects from VMware Aria Operations deployments.\n\n\n\n\n\n Management Pack for Hybrid Cloud Extension (HCX) \n\nVMware Aria Operations Management Pack for HCX extends the Operations Management capabilities of VMware Aria Operations to hybrid capabilities presented by HCX. With the management pack, you can collect metrics, change events, and resource topology information from HCX. It enables the monitoring, isolation, and resolution of performance bottlenecks in the HCX Interconnects, Migrations, or Protected workloads.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware Aria Operations 8.12.x Sizing Guidelines](https:\/\/kb.vmware.com\/s\/article\/91692)\n* [VMware Aria Operations Documentation](https:\/\/docs.vmware.com\/en\/VMware-Aria-Operations\/index.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrops"},{"document_id":"ibmcld_09834-1423-2910","score":0.0158730159,"text":"\ncs [Computer system metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cs.md) \n logical_disk [Disk metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.logical_disk.md) \n os [Operating System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.os.md) \n system [System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.system.md) \n net [Network interface metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.net.md) \n memory [Memory metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.memory.md) \n\n\n\nComplete the following steps to configure the Prometheus Windows exporter in your Windows system:\n\n\n\n1. Login to your Windows system, for example, you can connect via remote desktop (RDP).\n2. [Download the Prometheus windows_exporter](https:\/\/github.com\/martinlindhe\/wmi_exporter\/releases) appropriate for your environment.\n3. Identify the collectors that include data for the metric data that you want to collect.\n4. Change to the directory where you downloaded the Prometheus Windows exporter.\n5. Run the windows_exporter and configure the collectors that you want to enable. For example:\n\n.windows_exporter-0.16.0-amd64.exe --collectors.enabled <COLLECTORS>\n\nWhere <COLLECTORS> indicates the list of connectors that you want to configure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-windows"},{"document_id":"ibmcld_13464-5732-7496","score":0.0158730159,"text":"\n: Uses a [fast Fourier transform (FFT)](https:\/\/en.wikipedia.org\/wiki\/Fast_Fourier_transform) algorithm to return the discrete Fourier transform of a time series. The string that is specified for the second parameter determines the type of transform:\n\n\n\n* forward or f for a forward transform\n* inverse or i for an inverse transform\n\n\n\nTS_SEG_FFT(DoubleSegmentTimeSeries, String)\n: Output: DoubleArrayTimeSeries\n: Uses a [fast Fourier transform (FFT)](https:\/\/en.wikipedia.org\/wiki\/Fast_Fourier_transform) algorithm to return the discrete Fourier transform for each segment of the input time series. The string that is specified for the second parameter determines the type of transform:\n\n\n\n* forward or f for a forward transform\n* inverse or i for an inverse transform\n\n\n\n: Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_AUTO_CORRELATION(DoubleTimeSeries)\n: Output: DoubleArray\n: Use an [auto correlation](https:\/\/en.wikipedia.org\/wiki\/Autocorrelation) algorithm to return the correlation of a time series with a delayed copy of itself.\n\nTS_SEG_AUTO_CORRELATION(DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries\n: Use an [auto correlation](https:\/\/en.wikipedia.org\/wiki\/Autocorrelation) algorithm to return the correlation of each segment of the input time series with a delayed copy of itself. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_CROSS_CORRELATION(DoubleTimeSeries, DoubleTimeSeries)\n: Output: DoubleArray\n: Use a [cross correlation](https:\/\/en.wikipedia.org\/wiki\/Cross-correlation) algorithm to return a measure of the similarity of two time series.\n\nTS_SEG_CROSS_CORRELATION(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-data_processing_functions"},{"document_id":"ibmcld_11603-7711-8687","score":0.015625,"text":"\nrDNS record for (localhost): sap-mc-redhat\nNot shown: (number of) closed ports\nPORT STATE SERVICE\n(port)\/tcp open ssh\n(port)\/tcp open smtp\nDevice type: general purpose\nRunning: Linux 3.X\nOS CPE: cpe:\/o:linux:linux_kernel:3\nOS details: Linux 3.7 3.9\nNetwork Distance: 0 hops\n\n\n\n\n\n\n\n nmap not found \n\nYou can install nmap on your system by using the appropriate package manager like yum or apt-get.\n\n* Command for Red Hat: yum install nmap\n* Command for SUSE: zypper install nmap\n\n\n\n\n\n\n\n Additional information \n\nIf you don't have an IBM Cloud API key, the IMCS can't collect all of the metrics that are required by SAP, which include\n\n* Network Adapter Mapping - replaced with local MAC ID.\n* Network Adapter Bandwidth - Port Speed - defaults to 0.\n* Disk Volume Mapping - replaced with Volume Attachment ID.\n* Disk Guaranteed IOPS - defaults to 0.\n\nYou must provide an API key so that all metrics can be collected. Otherwise, this virtual server is not fully supported by SAP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-metrics-collector-for-sap-linux"},{"document_id":"ibmcld_12561-9263-11199","score":0.015625,"text":"\nYou can also use the Usage Reports API to get [account summary usage](https:\/\/github.ibm.com\/BSS\/metering-report-downloader\/wiki\/Regular-Usage-Reportsaccount-summary-report) and [resource instance usage](https:\/\/github.ibm.com\/BSS\/metering-report-downloader\/wiki\/Regular-Usage-Reportsaccount-instance-report).\n\nThe following examples show queries that you can use to download your enterprise account .csv report. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\ncurl -X GET -H 'Authorization: Bearer <IAM Token>' '{base_url}\/v1\/resource-usage-reports?month=2023-03&format=csv&recurse=true&enterprise_id={enterprise_id}'\n\n\n\n Understanding .csv table headings and JSON report fields for enterprise account summary \n\nThe following table shows the correlation between the heading titles in your .csv report and JSON report fields.\n\nEntity Metadata\n\nEntity Hierarchy\n\nBilling Units\n\nCredit Pools\n\nOverages\n\nEnterprise Usage Summary\n\nEnterprise Resource Usage\n\n\n\nTable 1. Enterprise usage report CSV contents for entity metadata\n\n .csv Header Description \n\n Entity ID ID of the requested entity (enterprise_id\/account_group_id\/account_id) \n Entity Type Type of the requested entity (enterprise\/account_group\/account) \n Billing Month The month in which usages were incurred. Represented in yyyy-mm format \n Currency Rate Currency Exchange Rate with USD as the base \n Created Time Timestamp at which the CSV report was generated \n\n\n\nWhen recurse=true, the usage in the Enterprise Resource Usage section is aggregated by each metric of a service plan and it's broken down by child accounts. Each row represents the total usage of a service plan metric in some child account. When recurse=false, the usage is aggregated by each metric of a service plan and each row represents the total usage of a service plan metric of all the sub-accounts or child-accounts in the requested entity hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_09807-6204-7430","score":0.0153846154,"text":"\n!\/usr\/bin\/env python3\n\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(sys.argv[0])), '..'))\n\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Parse arguments.\ndef usage():\nprint('usage: %s <ENDPOINT_URL> <MONITOR_TOKEN> <INSTANCE_GUID>' % sys.argv[0])\nprint('ENDPOINT_URL: IBM Cloud endpoint URL (e.g. https:\/\/us-south.monitoring.cloud.ibm.com')\nprint('MONITOR_TOKEN: token that is associated to a team.')\nsys.exit(1)\n\nif len(sys.argv) != 3:\nusage()\n\nURL = sys.argv[1]\nMONITOR_TOKEN = sys.argv[2]\n\n Instantiate the client\nsdclient = SdMonitorClient(token=MONITOR_TOKEN,sdc_url=URL)\nShow more\n\n\n\n\n\n References \n\n\n\n* [Extracting metrics from a Monitoring instance by using the Monitoring Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-metrics_python)\n* [Managing dashboards by using the Monitoring Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboard_python)\n* [Managing alerts by using the Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_python)\n* [Python Client](https:\/\/github.com\/draios\/python-sdc-client)\n* [Monitoring Python samples](https:\/\/github.com\/draios\/python-sdc-client\/tree\/master\/examples)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-python-client"},{"document_id":"ibmcld_00208-31543-33509","score":0.0153846154,"text":"\nEach storage node has multiple paths to its own Solid-State Drives and its partner node's SSDs as well. This configuration protects against path failure, and also controller failure because the node can still access its partner's disks seamlessly. For more information, see [Availability and Durability of Block Storage for Classic](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-storageavailability).\n\n\n\n\n\n How can I identify a Block Storage for Classic volume from my OS? \n\nVarious reasons exist for why you would want to look up the LUN ID of the attached storage volumes on the Compute host. For example, you might have multiple storage devices that are mounted on the same host with the same volume sizes. You want to detach and decommission one of them. However, you are not sure how to correlate what you see on your Linux\u00ae host with what you see in the console. Another example might be that you have multiple Block Storage for Classic volumes that are attached to an esxi server. You want to expand the volume size of one of the LUNs, and you need to know the correct LUN ID of the storage to do that. For OS-specific instructions, click one of the following links.\n\n\n\n* [Viewing LUN information in Linux\u00ae](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-identifyLUNidentifyLUNLin)\n* [Viewing LUN information in Windows\u00ae](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-identifyLUNidentifyLUNWin)\n* [Viewing LUN information in VMWare\u00ae](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-identifyLUNidentifyLUNVMware)\n\n\n\n\n\n\n\n Can I get storage performance metrics (IOPS or latency) from the Support teams? \n\nIBM Cloud\u00ae does not provide storage performance IOPS and latency metrics. Customers are expected to monitor their own Block Storage for Classic devices by using their choice of third-party monitoring tools.\n\nThe following examples are utilities that you might consider to use to check performance statistics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-block-storage-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03369-66296-68553","score":0.0327868852,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03329-1102-2607","score":0.0322580645,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_16364-103662-105841","score":0.0317460317,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02998-1325-2715","score":0.03125,"text":"\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03049-1355-3132","score":0.0307692308,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_07578-18457-20516","score":0.0303030303,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-18457-20516","score":0.0298507463,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16364-146046-148039","score":0.0294117647,"text":"\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-101992-104197","score":0.0289855072,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03313-17920-19395","score":0.0285714286,"text":"\nTo do so, add a new intent or entity, and then delete it. This action starts a new training process.\n\n\n\n\n\n Is there a range of IP addresses that are being used by a webhook? \n\nUnfortunately, the IP address ranges from which Watson Assistant may call a webhook URL are subject to change, which in turn prevent using them in any static firewall configuration. Please use the https transport and specify an authorization header to control access to the webhook.\n\n\n\n\n\n How do I see my monthly active users in Watson Assistant? \n\nTo see your monthly active users (MAU) do the following:\n\n\n\n1. Sign in to [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com)\n2. Click on the Manage menu, then choose Billing and usage.\n3. Click on Usage.\n4. For Watson Assistant, select View Plans.\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n\n\n\n\n Error: New Off Topic not supported \n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n\n\n\n\n\n Is it possible to increase the number of intents per skill \n\nNo, it is not possible to increase the number of intents per skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-1790-3940","score":0.0327868852,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":0.0322580645,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-7-2335","score":0.0317460317,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-1659-3917","score":0.03125,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03353-5263-7331","score":0.0307692308,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03353-4-2000","score":0.0303030303,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03120-4-2233","score":0.0298507463,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03027-4976-6968","score":0.0294117647,"text":"\nEnglish (en) GA Deprecated \n Arabic (ar) GA Deprecated \n Chinese (Simplified) (zh-cn) GA Deprecated \n Chinese (Traditional) (zh-tw) GA Deprecated \n Czech (cs) GA Deprecated \n Dutch (nl) GA Deprecated \n French (fr) GA Deprecated \n German (de) GA Deprecated \n Italian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03027-7-1946","score":0.0289855072,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_02839-3583-5403","score":0.0285714286,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03106-4717-6754","score":0.0327868852,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-auditing"},{"document_id":"ibmcld_16248-4582-6619","score":0.0322580645,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-auditing"},{"document_id":"ibmcld_03049-7-1790","score":0.0317460317,"text":"\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03043-4515-6369","score":0.03125,"text":"\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-diagram.png)\n\nFor help creating a search skill, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n Create the skill \n\nYou can add one skill of each skill type to an assistant.\n\n\n\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add)\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add)\n\n\n\n\n\n\n\n Skill limits \n\n\n\nSkill limit details\n\n Skills per service instance \n\n 50 \n\n\n\nSkill versions do not count toward the skill limit.\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants. From the Skills page, find the tile for the skill that you want to delete. The Assistants field lists the assistants that currently use the skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_02844-1555-3643","score":0.0307692308,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_03139-1239-2954","score":0.0303030303,"text":"\nSee [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for more information.\n\nYou cannot import logs from one skill into another skill.\n\n\n\n\n\n Downloading a skill \n\nTo back up actions or dialog skill data, download the skill as a JSON file, and store the JSON file.\n\n\n\n1. Find the actions or dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Download.\n3. Specify a name for the JSON file and where to save it, and then click Save.\n\n\n\nAlternatively, you can use the \/workspaces API to export a dialog skill. Include the export=true parameter with the GET workspace request. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1getworkspace) for more details.\n\n\n\n\n\n Uploading a skill \n\nTo reinstate a backup copy of an actions or dialog skill that you exported from another service instance or environment, create a new skill by importing the JSON file of the skill you exported.\n\nIf the Watson Assistant service changes between the time you export the skill and import it, due to functional updates which are regularly applied to instances in cloud-hosted continuous delivery environments, your imported skill might function differently than it did before.\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-skills-icon.png).\n2. Click Create skill.\n3. Choose to create either an actions or dialog skill, then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_03373-7076-8670","score":0.0298507463,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03054-3104-4808","score":0.0294117647,"text":"\n[Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Click the Search skill option, and then click Next.\n4. Specify the details for the new skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n\nCurrently, you cannot rename your search skill later.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n5. Click Continue.\n6. Choose the Discovery for IBM Cloud Pak for Data instance that you want to extract information from.\n\nIf no instances are available, ask an administrator whether Discovery is deployed in your environment. If so, ask to be given access to the Discovery instance. If not, you cannot create a search skill.\n7. Choose the project that you want to use, by doing one of the following things:\n\n\n\n* Choose an existing project, and then click Configure. Skip to the [Configure the search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-configure) procedure.\n* If you do not have a project or do not want to use any of the projects that are listed, click Create a new project to add one. Follow the procedure in [Create a data collection](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-create-discovery-collection).\n\n\n\n\n\n\n\n\n\n Create a data collection \n\nWhen the Discovery application opens in a new browser tab or window, the Projects page might be displayed briefly. You do not need to create a project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03120-3469-5331","score":0.0289855072,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03381-4-1869","score":0.0285714286,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09229-16048-18016","score":0.0327868852,"text":"\nen-th English (en) Thai (th) general \n en-tr English (en) Turkish (tr) general \n en-uk English (en) Ukrainian (uk) general \n en-ur English (en) Urdu (ur) general \n en-vi English (en) Vietnamese (vi) general \n en-zh English (en) Simplified Chinese (zh) general \n en-zh-TW English (en) Traditional Chinese (zh-TW) general \n\n\n\n\n\n\n\n Estonian \n\nThe following Estonian translation model can be customized.\n\n\n\nTable 15. Estonian translation model\n\n Model ID Source Target Domain \n\n et-en Estonian (et) English (en) general \n\n\n\n\n\n\n\n Finnish \n\nThe following Finnish translation model can be customized.\n\n\n\nTable 16. Finnish translation model\n\n Model ID Source Target Domain \n\n fi-en Finnish (fi) English (en) general \n\n\n\n\n\n\n\n French \n\nThe following French translation model can be customized.\n\n\n\nTable 17. French translation model\n\n Model ID Source Target Domain \n\n fr-en French (fr) English (en) general \n\n\n\n\n\n\n\n French (Canadian) \n\nThe following French (Canadian) translation model can be customized.\n\n\n\nTable 18. Canadian French translation model\n\n Model ID Source Target Domain \n\n fr-CA-en Canadian French (fr-CA) English (en) general \n\n\n\n\n\n\n\n German \n\nThe following German translation models can be customized.\n\n\n\nTable 19. German translation models\n\n Model ID Source Target Domain \n\n de-en German (de) English (en) general \n de-fr German (de) French (fr) general \n de-it German (de) Italian (it) general \n\n\n\n\n\n\n\n Greek \n\nThe following Greek translation model can be customized.\n\n\n\nTable 20. Greek translation model\n\n Model ID Source Target Domain \n\n el-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09229-17595-19748","score":0.0322580645,"text":"\nel-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general \n\n\n\n\n\n\n\n Hindi \n\nThe following Hindi translation model can be customized.\n\n\n\nTable 23. Hindi translation model\n\n Model ID Source Target Domain \n\n hi-en Hindi (hi) English (en) general \n\n\n\n\n\n\n\n Hungarian \n\nThe following Hungarian translation model can be customized.\n\n\n\nTable 24. Hungarian translation model\n\n Model ID Source Target Domain \n\n hu-en Hungarian (hu) English (en) general \n\n\n\n\n\n\n\n Indonesian \n\nThe following Indonesian translation model can be customized.\n\n\n\nTable 25. Indonesian translation model\n\n Model ID Source Target Domain \n\n id-en Indonesian (id) English (en) general \n\n\n\n\n\n\n\n Irish \n\nThe following Irish translation model can be customized.\n\n\n\nTable 26. Irish translation model\n\n Model ID Source Target Domain \n\n ga-en Irish (ga) English (en) general \n\n\n\n\n\n\n\n Italian \n\nThe following Italian translation models can be customized.\n\n\n\nTable 27. Italian translation models\n\n Model ID Source Target Domain \n\n it-de Italian (it) German (de) general \n it-en Italian (it) English (en) general \n\n\n\n\n\n\n\n Japanese \n\nThe following Japanese translation model can be customized.\n\n\n\nTable 28. Japanese translation model\n\n Model ID Source Target Domain \n\n ja-en Japanese (ja) English (en) general \n\n\n\n\n\n\n\n Kannada \n\nThe following Kannada translation model can be customized.\n\n\n\nTable 29. Kannada translation model\n\n Model ID Source Target Domain \n\n kn-en Kannada (kn) English (en) general \n\n\n\n\n\n\n\n Korean \n\nThe following Korean translation model can be customized.\n\n\n\nTable 30. Korean translation model\n\n Model ID Source Target Domain \n\n ko-en Korean (ko) English (en) general \n\n\n\n\n\n\n\n Latvian \n\nThe following Latvian translation model can be customized.\n\n\n\nTable 31. Latvian translation model\n\n Model ID Source Target Domain","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09226-18248-20249","score":0.0317460317,"text":"\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_16460-9978-11758","score":0.03125,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-9963-11743","score":0.0307692308,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_16460-10316-12439","score":0.0303030303,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-10301-12424","score":0.0298507463,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_07103-9826-12106","score":0.0294117647,"text":"\nThe problems were related to a new version of the optical character recognition (OCR v2) feature that was enabled automatically for English, German, French, Spanish, Dutch, Brazilian Portuguese, and Hebrew collections during that timeframe. The new version changes sentence boundaries in ways that can negatively impact other functions, including element identification in contracts and the document labeling view in the entity extractor tool.\n\nIf you experience any of these issues with documents that were added or processed during this period, revert the version of OCR that is applied to the documents. Starting on 12 November 2022, OCR v1 is applied to all collections where OCR is enabled. To go back to using OCR v1, make a change that will reprocess the affected documents. For example, you can re-add documents that were added during the timeframe to reprocess them. Or you can reprocess an entire collection.\n\nTo reprocess a collection, from the Manage collections page, open the collection, and then go to the Processing settings tab. Expand the More processing settings section, set the OCR switch to Off, and then set it back to On. Click Apply changes and reprocess to reprocess your collection.\n\n\n\n\n\n 2 November 2022 \n\nA new and improved optical character recognition technology is available\n: A new version of optical character recognition technology is now available. This latest version (OCR v2) is used automatically when you enable OCR for English, German, French, Spanish, Dutch, Brazilian Portuguese, and Hebrew collections in all IBM Cloud service plans. The new optical character recognition model was developed by IBM Research to be better at extracting text from scanned documents and other images that have the following limitations:\n\n\n\n* Low quality images due to incorrect scanner settings, insufficient resolution, bad lighting (such as with mobile capture), loss of focus, unaligned pages, and badly printed documents\n* Documents with irregular fonts or a variety of colors, font sizes, and backgrounds\n\n\n\n\n\n\n\n 1 November 2022 \n\nEntity extractor loads the first 40,000 characters from training data documents\n: Even extra long documents from the collection that you use to define custom entity examples are loaded into the document view of the tool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07104-32103-34057","score":0.0289855072,"text":"\nFor more information, see [Monitoring usage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapiapi-usage).\n\n\n\n\n\n 30 August 2020 \n\nUpdate to API version\n: The current API version (v2) is now 2020-08-30. The following change was made with this version:\n\nChange to 'options' object\n: The List enrichments method no longer returns the options object per enrichment. Use the Get enrichment method to return the options object for a single enrichment.\n\n\n\n\n\n 2.1.3 release, 19 June 2020 \n\nNew release now available\n: IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data version 2.1.3 is available.\n: Discovery for Cloud Pak for Data now works with IBM Cloud Pak\u00ae for Data 3.0.1.\n\nNew Finnish and Hebrew language support\n: Added basic support for Finnish and Hebrew. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nChange to Analyze endpoint\n: The Analyze endpoint, which supports stateless document ingestion workflows. For details, see the [Analyze API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapi). The Analyze API supports JSON documents only. Use of the Analyze API affects license usage.\n\nNew options for Content Miner\n: The content mining application includes two new options: Cyclic time scale on the Time series dashboard, and the Contextual view tab.\n\nNew shortcut for Content Mining projects\n: For Content Mining projects only, the Improve and customize page includes a shortcut: the Launch application button. Previously, you were required to open the Integrate and deploy page, select the Launch application tab, and click the Launch button.\n\nImproved segment limit\n: The segment limit when splitting documents has been increased to 1,000. For details, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\nImproved Filenet connector","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes-data"},{"document_id":"ibmcld_09903-9624-10554","score":0.0285714286,"text":"\nHebrew [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00644-14024-16089","score":0.0327868852,"text":"\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.\n\nUsing stable=true can cause high latency as it consults only one of the copies of the index, even if the other copies would respond faster.\n\n\n\n\n\n Combining parameters \n\nIf you specify stable=false and update=false, you see greater inconsistency between results, even for the same query and without making database changes. We recommend against this combination unless you are sure that your system can tolerate this behavior.\n\n\n\n\n\n\n\n Sorting returned rows \n\nThe data that is returned by a view query is in the form of an array. Each element within the array is sorted by using standard [UTF-8](https:\/\/en.wikipedia.org\/wiki\/UTF-8) sorting. The sort is applied to the key defined in the view function.\n\nThe basic order of the output is shown in the following table:\n\n\n\nTable 2. Order of returned rows\n\n Value Order \n\n null First \n false \n true \n Numbers \n Text (lowercase) \n Text (uppercase) \n Arrays (according to the values of each element, by using the order given in this table) \n Objects (according to the values of keys, in key order by using the order given in this table) Last \n\n\n\nYou can reverse the order of the returned view information by setting the descending query value true.\n\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_00539-2548-4016","score":0.0322580645,"text":"\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00644-20617-22169","score":0.0317460317,"text":"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nFor example, if you have a database that returns one result when you use a start_key of alpha and an end_key of beta, you would get a 400 (Bad request) error with a reversed order. The reason is that the entries in the view are reversed before the key filter is applied.\n\nSee the example that uses HTTP to illustrate why reversing the order of start_key and end_key might return a query parse error:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true&start_key=\"alpha\"&end_key=\"beta\" HTTP\/1.1\n\nSee the example illustrating why reversing the order of start_key and end_key might cause a 400 error.\n\nClient libraries use POST method instead of GET because they have the same behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL\/users\/_design\/allusers\/_view\/getVerifiedEmails?descending=true&start_key=\"alpha\"&end_key=\"beta\"\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.startKey(\"alpha\")\n.endKey(\"beta\")\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_03285-34490-35530","score":0.03125,"text":"\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your dialog or actions to handle such a failure by creating intents or actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the output.generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Goodbye.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"end_session\"\n}\n]\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03891-23613-25771","score":0.0307692308,"text":"\nClusters that do not use a system channel can join and unjoin ordering nodes to an application channel. You can verify if a cluster does or does not use a system channel by clicking the cluster's tile and looking near the Orderer Type text.\n\nJoining an orderer to an application channel will make it either a follower or a consenter. It will be a consenter if the node is found in the the channel's config block in the consenters section. Otherwise the orderer will be a follower. Both types of orderers will receive transaction\/block data, but only a consenter can vote and play a role in the consensus algorithm. A node can be promoted from a follower to a consenter by first joining it to the channel, and then editing the channel's config to add it as a consenter. Similarly these steps can be reversed to demote an orderer and unjoin it completely if need be.\n\nJoining an orderer to the application channel can be started by clicking the cluster's tile. Next click either the plus sign on a channel tile or the Join channel blue button. Follow the prompts and select which orderer nodes to join. Then click Submit. Once an orderer has joined it will begin downloading blocks to catch up to the current level.\n\n\n\n\n\n\n\n Removing ordering service nodes \n\nIf a user wants to delete an ordering node, it must first remove the node from all channels where it is a consenter. This is because the console does not distinguish between a deleted node and an unavailable node, and will keep an ordering node as part of its consenter set until it is removed.\n\nAs a result, when you delete a node, a check is performed to see if it is a consenter on any channels. If it is, you will not be able to delete the node until it has been removed as a consenter from all channels. After removing the node as a consenter from all channels, you will be able to delete the node by clicking the trash can icon. Note that this action will have to be taken in the console where the node was created.\n\nAs part of this same process, make sure to reach out to the other console operators to let them know that the node has been deleted so they can remove the tile from their console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-orderer"},{"document_id":"ibmcld_00644-22813-24283","score":0.0303030303,"text":"\n\"allusers\",\n\"getVerifiedEmails\",\n)\n\npostViewOptions.SetDescending(true)\npostViewOptions.StartKey = \"alpha\"\npostViewOptions.EndKey = \"beta\"\n\nviewResult, response, err := service.PostView(postViewOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(viewResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nThe end_key of beta is seen before the start_key of alpha, resulting in a query parse error.\n\nThe solution is to reverse not just the sort order, but also the start_key and end_key parameter values.\n\nThe following example shows correct filtering and reversing the order of output, by using the descending query argument, and reversing the start_key and end_key query arguments.\n\nSee the example that uses HTTP to apply correct filtering and sorting to a global query:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true&start_key=\"beta\"&end_key=\"alpha\" HTTP\/1.1\n\nSee the example to apply correct filtering and sorting to a global query.\n\nClient libraries use POST method instead of GET because they have the same behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_04126-7-1694","score":0.0298507463,"text":"\nCompression and optimization concepts \n\nIBM Cloud\u00ae Internet Services applies gzip and brotli compression to some types of content. CIS also compresses items based on the browser's UserAgent to speed up page loading time.\n\nIf you're already using gzip, CIS honors your gzip settings as long as you're passing the details in a header from your web server for the files.\n\nCIS only supports the content type gzip towards your origin server and can also only deliver content either gzip-compressed, brotli-compressed, or not compressed.\n\nCIS's reverse proxy is also able to convert between compressed formats and uncompressed formats, meaning that it can pull content from a customer's origin server through gzip and serve it to clients uncompressed (or reversed). This is done independently of caching.\n\nThe Accept-Encoding header is not respected and is removed.\n\n\n\n What gets compressed \n\nIn addition to CIS's serving stale content and minification of CSS, JS, and HTML to speed up your site, CIS also provides gzip and brotli compression to help site owners.\n\nCIS returns gzip or brotli encoded responses to compatible clients and browsers for the following content-types:\n\ntext\/html\ntext\/richtext\ntext\/plain\ntext\/css\ntext\/x-script\ntext\/x-component\ntext\/x-java-source\ntext\/x-markdown\napplication\/javascript\napplication\/x-javascript\ntext\/javascript\ntext\/js\nimage\/x-icon\nimage\/vnd.microsoft.icon\napplication\/x-perl\napplication\/x-httpd-cgi\ntext\/xml\napplication\/xml\napplication\/xml+rss\napplication\/vnd.api+json\napplication\/x-protobuf\napplication\/json\nmultipart\/bag\nmultipart\/mixed\napplication\/xhtml+xml\nfont\/ttf\nfont\/otf\nfont\/x-woff\nimage\/svg+xml\napplication\/vnd.ms-fontobject\napplication\/ttf","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compression-concepts"},{"document_id":"ibmcld_03069-6360-8216","score":0.0294117647,"text":"\n[Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/ask_watson.png) icon to open the Try it out pane.\n2. Enter, I want to learn more about your restaurant.\n\nYour assistant indicates that the about_restaurant intent is recognized, and returns a response with the image and text that you specified for the dialog node.\n\n![Shows the Try it out pane recognizing the #about_restaurant intent and showing the image and text response.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ass-test-about-restaurant.png)\n\n\n\nCongratulations! You have added a custom intent, and a dialog node that knows how to handle it.\n\nThe about_restaurant intent is designed to recognize a variety of general questions about the restaurant. You added a single node to capture such questions. The response is long, but it is a single statement that can potentially answer questions about all of the following topics:\n\n\n\n* The restaurant owners\n* The restaurant history\n* The philosophy\n* The number of sites\n* The days of operation\n* The meals served\n* The fact that the restaurant bakes cakes to order\n\n\n\nFor general, low-hanging fruit types of questions, a single, general answer is suitable.\n\n\n\n\n\n\n\n Step 4: Manage cake orders \n\nCustomers place orders in person, over the phone, or by using the order form on the website. After the order is placed, users can cancel the order through the virtual assistant. First, define an entity that can recognize order numbers. Then, add an intent that recognizes when users want to cancel a cake order.\n\n\n\n Adding an order number pattern entity \n\nYou want the assistant to recognize order numbers, so you will create a pattern entity to recognize the unique format that the restaurant uses to identify its orders.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"},{"document_id":"ibmcld_03403-6208-8025","score":0.0289855072,"text":"\nTest the intent by checking whether user utterances that are similar to, but not exactly the same as, the examples you added to the training data have successfully trained your assistant to recognize input with an about_restaurant intent.\n\n\n\n1. Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/ask_watson.png) icon to open the \"Try it out\" pane.\n2. Enter, I want to learn more about your restaurant.\n\nYour assistant indicates that the about_restaurant intent is recognized, and returns a response with the image and text that you specified for the dialog node.\n\n![Shows the Try it out pane recognizing the #about_restaurant intent and showing the image and text response.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-test-about-restaurant.png)\n\n\n\nCongratulations! You have added a custom intent, and a dialog node that knows how to handle it.\n\nThe about_restaurant intent is designed to recognize a variety of general questions about the restaurant. You added a single node to capture such questions. The response is long, but it is a single statement that can potentially answer questions about all of the following topics:\n\n\n\n* The restaurant owners\n* The restaurant history\n* The philosophy\n* The number of sites\n* The days of operation\n* The meals served\n* The fact that the restaurant bakes cakes to order\n\n\n\nFor general, low-hanging fruit types of questions, a single, general answer is suitable.\n\n\n\n\n\n\n\n Step 4: Manage cake orders \n\nCustomers place orders in person, over the phone, or by using the order form on the website. After the order is placed, users can cancel the order through the virtual assistant. First, define an entity that can recognize order numbers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_08775-3653-3948","score":0.0285714286,"text":"\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"creationDate\": \"2020-03-05T16:39:25Z\"\n},\n{\n\"id\": \"12e8c9c2-a162-472d-b7d6-8b9a86b815a6\",\n\"creationDate\": \"2020-03-02T16:28:38Z\"\n}\n]\n}\n\nThe resources object lists each key version, along with the ID and creation date, in reverse chronological order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-versions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14690-2721-4678","score":0.0327868852,"text":"\nset security address-book global address SL17 10.2.48.0\/20\nset security address-book global address SL18 10.2.176.0\/20\nset security address-book global address SL19 10.3.64.0\/20\nset security address-book global address SL20 10.3.80.0\/20\nset security address-book global address SL_PRIV_MGMT 10.135.70.22\/32\nset security address-book global address SL_PUB_MGMT 169.50.51.92\/32\nset security address-book global address-set SERVICE address SL1\nset security address-book global address-set SERVICE address SL2\nset security address-book global address-set SERVICE address SL3\nset security address-book global address-set SERVICE address SL4\nset security address-book global address-set SERVICE address SL5\nset security address-book global address-set SERVICE address SL6\nset security address-book global address-set SERVICE address SL7\nset security address-book global address-set SERVICE address SL8\nset security address-book global address-set SERVICE address SL9\nset security address-book global address-set SERVICE address SL10\nset security address-book global address-set SERVICE address SL11\nset security address-book global address-set SERVICE address SL12\nset security address-book global address-set SERVICE address SL13\nset security address-book global address-set SERVICE address SL14\nset security address-book global address-set SERVICE address SL15\nset security address-book global address-set SERVICE address SL16\nset security address-book global address-set SERVICE address SL17\nset security address-book global address-set SERVICE address SL18\nset security address-book global address-set SERVICE address SL19\nset security address-book global address-set SERVICE address SL20\nset security screen ids-option untrust-screen icmp ping-death\nset security screen ids-option untrust-screen ip source-route-option\nset security screen ids-option untrust-screen ip tear-drop\nset security screen ids-option untrust-screen tcp syn-flood alarm-threshold 1024","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-iaas-def-config"},{"document_id":"ibmcld_04111-30975-32287","score":0.0322580645,"text":"\nPUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/mobile_redirect internet-svcs.performance.update internet-svcs.mobile-redirect-setting.update \n Get prefetch \/ preload settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/prefetch_preload internet-svcs.performance.read internet-svcs.prefetch-preload-setting.read \n Update prefetch \/ preload settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/prefetch_preload internet-svcs.performance.update internet-svcs.prefetch-preload-setting.update \n Get HTTP2 settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/http2 internet-svcs.security.read internet-svcs.http2-setting.read \n Update HTTP2 settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/http2 internet-svcs.security.update internet-svcs.http2-setting.update \n Get IPv6 settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ipv6 internet-svcs.zones.read internet-svcs.ipv6-setting.read \n Update IPv6 settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ipv6 internet-svcs.zones.update internet-svcs.ipv6-setting.update \n Get websocket settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/websocket internet-svcs.zones.read internet-svcs.websockets-setting.read \n Update websocket settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/websocket internet-svcs.zones.update internet-svcs.websockets-setting.update \n Get response buffering settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04111-31994-33483","score":0.0317460317,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/websocket internet-svcs.zones.read internet-svcs.websockets-setting.read \n Update websocket settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/websocket internet-svcs.zones.update internet-svcs.websockets-setting.update \n Get response buffering settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/response_buffering internet-svcs.performance.read internet-svcs.response-buffering-setting.read \n Update response buffering settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/response_buffering internet-svcs.performance.update internet-svcs.response-buffering-setting.update \n Get hotlink protection settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/hotlink_protection internet-svcs.performance.read internet-svcs.hotlink-protection-setting.read \n Update hotlink protection settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/hotlink_protection internet-svcs.performance.update internet-svcs.hotlink-protection-setting.update \n Get maximum upload size settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/max_upload internet-svcs.performance.read internet-svcs.max-upload-setting.read \n Update maximum upload size settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/max_upload internet-svcs.performance.update internet-svcs.max-upload-setting.update \n Get TLS client authentication settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_client_auth internet-svcs.security.read internet-svcs.tls-client-auth-setting.read \n Update TLS client authentication settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_14287-12756-14547","score":0.03125,"text":"\nset firewall name OUTSIDE2INSIDE rule 30 destination port 500\nset firewall name OUTSIDE2INSIDE rule 40 action accept\nset firewall name OUTSIDE2INSIDE rule 40 ipsec match-ipsec\nset firewall name OUTSIDE2INSIDE rule 50 action accept\nset firewall name OUTSIDE2INSIDE rule 50 protocol gre\nset firewall name OUTSIDE2INSIDE rule 60 action accept\nset firewall name OUTSIDE2INSIDE rule 60 protocol tcp\nset firewall name OUTSIDE2INSIDE rule 60 destination port 1723\nset firewall name OUTSIDE2INSIDE rule 70 action accept\nset firewall name OUTSIDE2INSIDE rule 70 protocol tcp\nset firewall name OUTSIDE2INSIDE rule 70 destination port 80\nset firewall name OUTSIDE2INSIDE rule 80 action accept\nset firewall name OUTSIDE2INSIDE rule 80 protocol tcp\nset firewall name OUTSIDE2INSIDE rule 80 destination port 443\nset firewall name OUTSIDE2INSIDE rule 90 action accept\nset firewall name OUTSIDE2INSIDE rule 90 state established enable\nset firewall name SLSERVICE2INSIDE\nset firewall name SLSERVICE2INSIDE default-action drop\nset firewall name SLSERVICE2INSIDE rule 10 action accept\nset firewall name SLSERVICE2INSIDE rule 10 protocol all\nset firewall name SLSERVICE2INSIDE rule 10 source group network-group SLSERVICES\nset firewall name INSIDE2SLSERVICE\nset firewall name INSIDE2SLSERVICE default-action drop\nset firewall name INSIDE2SLSERVICE rule 10 action accept\nset firewall name INSIDE2SLSERVICE rule 10 protocol all\nset firewall name INSIDE2SLSERVICE rule 10 destination group network-group SLSERVICES\nset firewall name VMACCESS2MGMT\nset firewall name VMACCESS2MGMT default-action drop\nset firewall name VMACCESS2MGMT rule 10 action drop\nset firewall name VMACCESS2MGMT rule 10 protocol all\nset firewall name VMACCESS2MGMT rule 10 source group network-group 1103VMACCESS\nset firewall name STORAGE2MGMT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-set-up-brocade"},{"document_id":"ibmcld_04111-23286-24810","score":0.0307692308,"text":"\nPUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/browser_cache_ttl internet-svcs.performance.update internet-svcs.browser-cache-ttl-setting.update \n Get always online (serve stale content) settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/always_online internet-svcs.performance.read internet-svcs.always-online-setting.read \n Update always online (serve stale content) settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/always_online internet-svcs.performance.update internet-svcs.always-online-setting.update \n Get development mode settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/development_mode internet-svcs.performance.read internet-svcs.development-mode-setting.read \n Update development mode settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/development_mode internet-svcs.performance.update internet-svcs.development-mode-setting.update \n Get sort query string for cache settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/sort_query_string_for_cache internet-svcs.performance.read internet-svcs.sort-query-string-for-cache-setting.read \n Update sort query string for cache settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/sort_query_string_for_cache internet-svcs.performance.update internet-svcs.sort-query-string-for-cache-setting.update \n Get SSL settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ssl internet-svcs.security.read internet-svcs.ssl-setting.read \n Update SSL settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ssl internet-svcs.security.update internet-svcs.ssl-setting.update \n Get security level settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04111-28638-30139","score":0.0303030303,"text":"\nPUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/script_load_optimization internet-svcs.performance.update internet-svcs.script-load-optimization-setting.update \n Get image load optimization settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/image_load_optimization internet-svcs.performance.read internet-svcs.image-load-optimization-setting.read \n Update image load optimization settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/image_load_optimization internet-svcs.performance.update internet-svcs.image-load-optimization-setting.update \n Get minification settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/minify internet-svcs.performance.read internet-svcs.minify-setting.read \n Update minification settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/minify internet-svcs.performance.update internet-svcs.minify-setting.update \n Get minimum TLS version settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/min_tls_version internet-svcs.security.read internet-svcs.min-tls-version-setting.read \n Update minimum TLS version settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/min_tls_version internet-svcs.security.update internet-svcs.min-tls-version-setting.update \n Get IP geolocation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ip_geolocation internet-svcs.zones.read internet-svcs.ip-geolocation-setting.read \n Update IP geolocation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ip_geolocation internet-svcs.zones.update internet-svcs.ip-geolocation-setting.update \n Get server side exclude settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04111-26521-27885","score":0.0298507463,"text":"\nPUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/browser_check internet-svcs.security.update internet-svcs.browser-check-setting.update \n Get opportunistic encryption settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/opportunistic_encryption internet-svcs.security.read internet-svcs.opportunistic-encryption-setting.read \n Update opportunistic encryption settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/opportunistic_encryption internet-svcs.security.update internet-svcs.opportunistic-encryption-setting.update \n Get challenge TTL settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/challenge_ttl internet-svcs.security.read internet-svcs.challenge-ttl-setting.read \n Update challenge TTL settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/challenge_ttl internet-svcs.security.update internet-svcs.challenge-ttl-setting.update \n Get always use HTTPS settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/always_use_https internet-svcs.security.read internet-svcs.always-use-https-setting.read \n Update always use HTTPS settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/always_use_https internet-svcs.security.update internet-svcs.always-use-https-setting.update \n Get true client IP header settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/true_client_ip_header internet-svcs.zones.read internet-svcs.true-client-ip-header-setting.read \n Update true client IP header settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_14690-7-1834","score":0.0294117647,"text":"\nThe IBM Cloud IaaS vSRX default configuration \n\nThe following configuration is provided as a reference and not intended for use in your vSRX cluster.\n\nset version 18.4R1.8\nset groups node0 system host-name edge01-vSRX-Node0\nset groups node1 system host-name edge01-vSRX-Node1\nset apply-groups \"${node}\"\nset system login class security permissions security-control\nset system login class security permissions view-configuration\nset system login user vSRX_USER uid 2000\nset system login user vSRX_USER class super-user\nset system login user vSRX_USER authentication encrypted-password \"Secret\"\nset system root-authentication encrypted-password \"Secret\"\nset system services ssh\nset system services netconf ssh port 830\nset system services web-management http interface fxp0.0\nset system services web-management https port 8443\nset system services web-management https system-generated-certificate\nset system services web-management https interface fxp0.0\nset system services web-management https interface reth0.0\nset system services web-management https interface reth1.0\nset system services web-management session session-limit 100\nset system name-server 10.134.217.115\nset system syslog user * any emergency\nset system syslog file messages any any\nset system syslog file messages authorization info\nset system syslog file interactive-commands interactive-commands any\nset system ntp server 10.134.217.115\nset chassis cluster reth-count 4\nset chassis cluster redundancy-group 0 node 0 priority 100\nset chassis cluster redundancy-group 0 node 1 priority 1\nset chassis cluster redundancy-group 1 node 1 priority 1\nset chassis cluster redundancy-group 1 node 0 priority 100\nset chassis cluster redundancy-group 1 preempt\nset security log mode stream\nset security log report\nset security address-book global address SL1 10.0.64.0\/19","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-iaas-def-config"},{"document_id":"ibmcld_04111-29822-31275","score":0.0289855072,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ip_geolocation internet-svcs.zones.read internet-svcs.ip-geolocation-setting.read \n Update IP geolocation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ip_geolocation internet-svcs.zones.update internet-svcs.ip-geolocation-setting.update \n Get server side exclude settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/server_side_exclude internet-svcs.security.read internet-svcs.server-side-exclude-setting.read \n Update server-side exclude settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/server_side_exclude internet-svcs.security.update internet-svcs.server-side-exclude-setting.update \n Get security header settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/security_header internet-svcs.security.read internet-svcs.security-header-setting.read \n Update security header settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/security_header internet-svcs.security.update internet-svcs.security-header-setting.update \n Get mobile redirect settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/mobile_redirect internet-svcs.performance.read internet-svcs.mobile-redirect-setting.read \n Update mobile redirect settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/mobile_redirect internet-svcs.performance.update internet-svcs.mobile-redirect-setting.update \n Get prefetch \/ preload settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/prefetch_preload internet-svcs.performance.read internet-svcs.prefetch-preload-setting.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04111-25425-26833","score":0.0285714286,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_1_3 internet-svcs.security.read internet-svcs.tls-1-3-setting.read \n Update TLS 1.3 only settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_1_3 internet-svcs.security.update internet-svcs.tls-1-3-setting.update \n Get automatic HTTPS rewrites settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/automatic_https_rewrites internet-svcs.security.read internet-svcs.automatic-https-rewrites-setting.read \n Update automatic HTTPS rewrites settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/automatic_https_rewrites internet-svcs.security.update internet-svcs.automatic-https-rewrites-setting.update \n Get WAF settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/waf internet-svcs.security.read internet-svcs.waf-setting.read \n Update WAF settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/waf internet-svcs.security.update internet-svcs.waf-setting.update \n Get browser integrity check settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/browser_check internet-svcs.security.read internet-svcs.browser-check-setting.read \n Update browser integrity check settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/browser_check internet-svcs.security.update internet-svcs.browser-check-setting.update \n Get opportunistic encryption settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/opportunistic_encryption internet-svcs.security.read internet-svcs.opportunistic-encryption-setting.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":0.0327868852,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-199697-200931","score":0.0322580645,"text":"\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- <\/section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- <\/section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04183-0-2205","score":0.0317460317,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04186-18298-19703","score":0.03125,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-18343-19753","score":0.0307692308,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-198873-200152","score":0.0303030303,"text":"\n<-- <\/section \"id=\"section-set-context-cis-service-examples\" \"> --><-- <\/section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04132-3821-5296","score":0.0298507463,"text":"\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_13139-17831-19468","score":0.0294117647,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-74160-75348","score":0.0289855072,"text":"\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.\n\nibmcloud cis firewall-delete dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall-delete bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Firewall rules \n\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-196613-197723","score":0.0285714286,"text":"\n! ! ! ! ! ! !\n<-- <section \"id=\"section-delete-ratelimit-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.RATELIMIT_RULE_ID: The ID of rate limit rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-ratelimit-rule-options\" \"> --><-- <section \"id=\"section-delete-ratelimit-rule-examples\" \"> --> Examples Delete rate limiting rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis ratelimit-rule-delete 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-ratelimit-rule-examples\" \"> --><-- <\/section \"id=\"section-delete-ratelimit-rule\" \"> --><-- <\/section \"id=\"section-ratelimit\" \"> --><-- <section \"id=\"section-resource-instance\" \"> --> Resource instance Manipulate CIS Service instances by using the following instance commands.<-- <section \"id=\"section-list-cis-service-instances\" \"> --> ibmcloud cis instances List all CIS service instances. ibmcloud cis instances --output FORMAT] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":0.0327868852,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-33215-34565","score":0.0322580645,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04195-6086-8151","score":0.0317460317,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04334-31256-32402","score":0.0301177536,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04148-0-1895","score":0.0300768883,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_04334-25771-26954","score":0.0287784679,"text":"\nCreate a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --json '{\"name\": \"testCNAME\", \"type\": \"CNAME\", \"content\": \"example.com\"}' -i \"cis-demo\"\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --type A --name testA --content \"127.0.0.1\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-update \n\nUpdate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID [--type TYPE] [--name NAME] [--content CONTENT] [--proxied PROXIED] [--ttl TTL] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_08853-23942-25236","score":0.015625,"text":"\n29 December 2020 \n\n\n\n New resources New data sources Enhancements \n\n <br><br> * [ibm_cis_certificate_order](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cis_certificate_order)<br> * [ibm_cis_certificate_upload](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cis_certificate_upload)<br> * [ibm_cis_dns_records_import](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cis_dns_records_import)<br> * [ibm_cis_dns_record](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cis_dns_record)<br> * [ibm_cis_page_rule](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cis_page_rule)<br> * [ibm_is_virtual_endpoint_gateway](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_virtual_endpoint_gateway)<br> * [ibm_is_virtual_endpoint_gateway_ip](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_virtual_endpoint_gateway_ip)<br><br><br> <br><br> * [ibm_cis_certificates](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/cis_certificates)<br> * [ibm_cis_custom_certificates](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/cis_custom_certificates)<br","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-new-in-terraform"},{"document_id":"ibmcld_07578-978380-979969","score":0.0153846154,"text":"\nYou must re-import the certificate with a different CRN, and then update the VPN server with the new certificate CRN.\n* Can I use a customized hostname for the VPN server?\n\nYes, you can. You must create a CNAME DNS record and point it to the VPN server hostname in your DNS provider. After that, edit the client profile by replacing direct remote 445df6c234345.us-south.vpn-server.appdomain.cloud with remote your-customized-hostname.com.\n\n445df6c234345.us-south.vpn-server.appdomain.cloud is an example VPN server hostname.\n\nIf you are using [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started) as your DNS provider, refer to [CNAME Type record](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-ciscname-type-record) for information about how to add a CNAME DNS record.\n* What information should I provide in an IBM Support case if I need help?\n\nSupply the following content in your [IBM Support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case):\n\n\n\n1. Your VPN server ID.\n2. Your VPN client and operating system version.\n3. The logs from your VPN client.\n4. The time range when you encountered the problem.\n5. If user-ID-based authentication is used, supply the username.\n6. If certificate-based authentication is used, supply the common name of your client certificate.\n\nTo view the common name of your client certificate, use the OpenSSL command openssl x509 -noout -text -in your_client_certificate_file in the subject section.\n\n\n\n* How do I assign the VPN client role using IAM access management tags in the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04334-32129-33511","score":0.0153846154,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16727-978256-979845","score":0.0151515152,"text":"\nYou must re-import the certificate with a different CRN, and then update the VPN server with the new certificate CRN.\n* Can I use a customized hostname for the VPN server?\n\nYes, you can. You must create a CNAME DNS record and point it to the VPN server hostname in your DNS provider. After that, edit the client profile by replacing direct remote 445df6c234345.us-south.vpn-server.appdomain.cloud with remote your-customized-hostname.com.\n\n445df6c234345.us-south.vpn-server.appdomain.cloud is an example VPN server hostname.\n\nIf you are using [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started) as your DNS provider, refer to [CNAME Type record](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-ciscname-type-record) for information about how to add a CNAME DNS record.\n* What information should I provide in an IBM Support case if I need help?\n\nSupply the following content in your [IBM Support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case):\n\n\n\n1. Your VPN server ID.\n2. Your VPN client and operating system version.\n3. The logs from your VPN client.\n4. The time range when you encountered the problem.\n5. If user-ID-based authentication is used, supply the username.\n6. If certificate-based authentication is used, supply the common name of your client certificate.\n\nTo view the common name of your client certificate, use the OpenSSL command openssl x509 -noout -text -in your_client_certificate_file in the subject section.\n\n\n\n* How do I assign the VPN client role using IAM access management tags in the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.9197207891,"ndcg_cut_5":0.9197207891,"ndcg_cut_10":0.9197207891}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04625-7-1865","score":0.0163934426,"text":"\nAdding and using a custom domain \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nDomains provide the URL route that is allocated to your organization in IBM Cloud\u00ae. Custom domains direct requests for your apps to a URL that you own. A custom domain can be a shared domain, a shared subdomain, or a shared domain and host. Unless a custom domain is specified, IBM Cloud uses a default shared domain in the route to your app. You can create and use a custom domain by using either the IBM Cloud console or the command-line interface.\n\nThe default shared domain is mybluemix.net, but appdomain.cloud is another domain option that you can use. For more information about migrating to appdomain.cloud, see [Updating your domain](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-update-domain).\n\nTo use a custom domain, you must register the custom domain on a public DNS server, and then configure the custom domain in IBM Cloud. Next, you must map the custom domain to the IBM Cloud system domain on the public DNS server. After your custom domain is mapped to the system domain, requests for your custom domain are routed to your app in IBM Cloud.\n\n\n\n Adding a custom domain from the IBM Cloud console \n\nComplete these steps to add a custom domain for your org by using the console:\n\n\n\n1. Go to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"},{"document_id":"ibmcld_04149-3050-4970","score":0.0163934426,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04625-2824-4330","score":0.0161290323,"text":"\n* US-SOUTH - api.us-south.cf.cloud.ibm.com\n* US-EAST - api.us-east.cf.cloud.ibm.com\n* EU-DE - api.eu-de.cf.cloud.ibm.com\n* EU-GB - api.eu-gb.cf.cloud.ibm.com\n* AU-SYD - api.au-syd.cf.cloud.ibm.com\n\n\n\n2. Create a custom domain for your organization by typing the following command:\n\nibmcloud app domain-create <MY_ORGNAME> <MY_DOMAIN>\n3. Add the route with the custom domain to an app.\n\nFor Cloud Foundry apps, run the following command:\n\nibmcloud app route-map <MY_APPNAME> <MY_DOMAIN> -n <MY_HOSTNAME>\n\n\n\n\n\n\n\n Mapping the custom domain to the system domain \n\nAfter you configure the custom domain in IBM Cloud, map the custom domain to the IBM Cloud system domain on your registered DNS server:\n\n\n\n1. Set up a 'CNAME' record for the custom domain name on your DNS server. Steps for setting up the CNAME record vary depending on your DNS provider. For example, if you use GoDaddy, you follow the [Domains Help](https:\/\/www.godaddy.com\/help\/add-a-cname-record-19236) guidance from GoDaddy.\n2. Map the custom domain name to the secure endpoint for the IBM Cloud region where your app is running. Use the following region endpoints to provide the URL route that is allocated to your organization in IBM Cloud. For example, point your CNAME to custom-domain.us-east.cf.cloud.ibm.com.\n\nCloud Foundry endpoints:\n\n\n\n* US-SOUTH - custom-domain.us-south.cf.cloud.ibm.com\n* US-EAST - custom-domain.us-east.cf.cloud.ibm.com\n* EU-DE - custom-domain.eu-de.cf.cloud.ibm.com\n* EU-GB - custom-domain.eu-gb.cf.cloud.ibm.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"},{"document_id":"ibmcld_04334-33215-34565","score":0.0161290323,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_07449-7-1566","score":0.0158730159,"text":"\nManaging custom name servers for a domain \n\nDomains running on the IBM Cloud\u00ae network can point to a maximum of five (5) custom name servers. Custom name servers can be added, deleted, or changed at any time. Follow these steps to add, edit, or delete custom name servers for a domain.\n\n\n\n1. From your browser, open the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/) and log in to your account.\n2. Select the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg), then click Classic Infrastructure.\n3. From the Classic Infrastructure menu, select Services > Domain Registration to open the Domains page.\n4. Select the Domain Name to expand the domain into its snapshot view.\n5. Select Unlocked from the Lock Domain.\n6. Click the > character to expand the domain and configure name servers.\n\nZoom\n\n![Sample domains collapsed image](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/86dadb3996e7fa2b119c2c09bda56dbc01297416\/dns\/images\/custom-name-server-collapsed.png)\n\nFigure 1. Domains page with the domain collapsed\n\nZoom\n\n![Sample domains expanded image](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/86dadb3996e7fa2b119c2c09bda56dbc01297416\/dns\/images\/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add\/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"},{"document_id":"ibmcld_04148-0-1895","score":0.0158730159,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_02151-2385-4050","score":0.015625,"text":"\nThen, click the name of the space.\n\nDepending on how you want to modify the user permissions, select or clear the checkbox for a specific role. The roles that you can assign at the space level are Manager, Developer, and Auditor. For more information, see [Cloud Foundry roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-mngcfcfroles).\n* To manage your domains, click the Actions icon ![Action icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) for the respective org, and select Domains.\n\nAs an account owner or organization manager, you can view the system domain and add custom domains for applications that are built within an org and its spaces. If you're a space manager, this page displays read-only list of the domains that are assigned to the space.\n\nIf you add a custom domain, you must configure your DNS server to resolve your custom domain to point to the IBM Cloud system domain. In this way, when IBM Cloud receives a request for your custom domain, it's properly routed to your app. The system domain is always available to a space, and custom domains might also be allocated to a space. Apps that are created in a space might use any of the domains that are listed for that space. For more information about creating and by using custom domains, see [Managing your domains](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-update-domain).\n* To manage the allocated quota for an org, click the Actions icon ![Action icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) for the respective org, and select Quotas.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-orgupdates"},{"document_id":"ibmcld_04334-20830-22207","score":0.015625,"text":"\nibmcloud cis custom-pages [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n`-d, --domain\n: DNS Domain ID.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList existing custom pages for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis custom-pages -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n DNS record \n\nManipulate how the DNS Record performs using the following dns-record commands:\n\n\n\n ibmcloud cis dns-record-create \n\nCreate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-create DNS_DOMAIN_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-create DNS_DOMAIN_ID --type TYPE --name NAME --content CONTENT [--ttl TTL] [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.\n\n--content\n: DNS record content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_05353-1394-3012","score":0.0153846154,"text":"\n[Prepare to add a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain) (outside of Code Engine).\n3. [Configure custom domain mappings](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscustom-domain) (from the Code Engine console or CLI).\n4. [Complete the custom domain configuration with your domain registrar](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-registrar) (outside of Code Engine).\n\n\n\nAfter the custom domain mapping is created, you can [test](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingstest-custom-domain), [update](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsupdate-custom-domain), [view](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsview-domain-mapping), or [delete](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsdelete-custom-domain) your custom domain mappings.\n\n\n\n Considerations before you use custom domain mappings in Code Engine \n\nBefore you implement custom domain mappings in Code Engine, be aware of the following considerations:\n\n\n\n* Code Engine supports custom domain mappings for domains that are protected with a SSL\/TLS certificate, which is signed by a public, trusted certificate authority (CA).\n* You can define custom domain mappings that point to public domain names.\n* If your domain name can be resolved only by a nonpublic domain name system (DNS), you must provide a certificate that lists the domain name and is signed by a public, trusted CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings"},{"document_id":"ibmcld_04334-34286-35758","score":0.0153846154,"text":"\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14311-3835-5367","score":0.0327868852,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-2669-4435","score":0.0317540323,"text":"\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_16000-0-2579","score":0.0315136476,"text":"\n\n\n\n\n\n\n  Understanding Internet Communication Protocols \n\nGenerally speaking, a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information. The internet has a large suite of protocols to cover many situations. In creating web-based applications and programming interfaces, software developers commonly use three of these communication protocols to describe the state of the network and the ways that data packets are moved across the network:\n\n\n\n*  ICMP, Internet Control Message Protocol, part of the internet protocol suite defined in RFC 792.\n*  TCP, Transmission Control Protocol\n*  UDP, User Datagram Protocol\n\n\n\nThe protocols that are used for a particular implementation of, say, an API call, can influence the overall behavior of your network. So it is worthwhile to understand the basic differences between them. If you need more information, many good articles are available on the internet with detailed descriptions of the protocols.\n\n\n\n  ICMP \n\nICMP is a control protocol, meaning that it is designed to carry information about the status of the network itself. It is essentially a network layer (OSI layer 3) error-reporting and error-control protocol for the network. The best-known examples of ICMP in practice are the ping and traceroute utilities. The ping utility uses ICMP to probe remote hosts for responsiveness and overall round-trip time of the probe messages. The traceroute utility uses ICMP to discover and trace network routes that the ICMP packets take when they travel to their destination.\n\nWhat developers need to know is that ICMP packets have no TCP or UDP port numbers that are associated with them because port numbers are a layer 4 (transport layer) construct.\n\n\n\n\n\n  TCP and UDP \n\nBoth Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are OSI layer 4 transport protocols. These protocols are used to pass the actual data. The main difference between TCP and UDP, from a developer's perspective, is how they handle packet order.\n\nTCP is a connection-oriented protocol, it guarantees that all sent packets reach the destination in the correct order.\n\nAlternatively, UDP is a connection-less protocol. Communication is datagram-oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach a destination and can arrive out of order, or possibly they don't arrive at all.\n\nTypically, UDP is used for real-time communication, where a little percentage of the packet loss rate is preferable to the overhead of a TCP connection.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-understanding-icp"},{"document_id":"ibmcld_14311-7-1811","score":0.0305788982,"text":"\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_15141-6204-8279","score":0.0301177536,"text":"\nThe VPN server receives the username and passcode from the VPN client and makes an IAM call to verify the passcode and permission with IAM policy.\n\n\n\n* The passcode is an one-time password. The user MUST re-generate the passcode for re-connection, even if the re-connection is initiated by the VPN server.\n* The SoftLayer MFA is not supported because SoftLayer MFA enforcement is not done via the browser.\n\n\n\nIf you use user ID\/passcode authentication, maintenance activities force users to re-authenticate by fetching and re-entering the code. The connection is restored only after the new code is entered. This is applicable using stand-alone or HA mode.\n\n\n\n\n\n Client certificate revocation lists \n\nOptionally, you can import a certificate revocation list (CRL), which is a time-stamped list of certificates that have been revoked by a certificate authority (CA). A certificate in a certificate revocation list (CRL) might not be expired, but is no longer trusted by the certificate authority that issued the certificate. The VPN client uses this list to validate digital certificates.\n\nAfter you import a CRL, the VPN client uses this list to validate digital certificates. The CRL is saved as a string (not a file) in the system. If you need to download the CRL in the future, it is renamed as <vpn_server_name>.pem.\n\nFor more information, see [Setting up client-to-server authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-authentication).\n\n\n\n\n\n Transport protocol \n\nThe transport layer oversees the delivery of data from a process on one device to a process on another device. Transport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_16242-7-2224","score":0.0158730159,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16242-1610-3614","score":0.0153846154,"text":"\nFor example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support. If the customer picks this choice, the assistant uses your Fallback action.\n\nStep validation attempts before offering support: If a customer provides invalid answers for a step in an action, the assistant can offer to connect to other support in the Fallback action. The step validation count measures how many invalid answers can occur before the assistant provides this choice.\n\nThis table shows the default settings for each mode.\n\n\n\nDefault settings\n\n Clarifying Confident \n\n Clarify when one action matches More often Sometimes \n Clarify when more than one action matches More often Sometimes \n Offer support option when asking a clarifying question More often Sometimes \n Step validation attempts before offering support 1 time 3 times \n\n\n\n\n\n\n\n Choosing a mode for individual actions \n\nWhen you edit an action, you can see the mode that it uses and change it if you need to.\n\n\n\n1. Click the Action response mode icon ![Action response mode icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-icon.svg). The mode in use is checked.\n\nZoom\n\n![Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_15141-7808-9997","score":0.0151515152,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_16359-6868-8948","score":0.0151515152,"text":"\nAs part of development that is in progress to help the assistant learn automatically from user choices, the actions that are included and their order in the list is randomized on purpose. Randomizing the order helps to prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.\n\n\n\n Customizing clarifying questions \n\nTo customize clarification, you can:\n\n\n\n* Change settings like the wording your assistant uses to introduce the clarification list or when no action matches.\n* Enable response modes to modify the assistant's behavior when it asks questions. For more information, see [Response modes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\nTo change settings, complete the following steps:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Clarifying questions tab, you can edit the Ask clarifying questions section:\n\n\n\nAsk clarifying question settings\n\n Field Default text Description \n\n Assistant says Did you mean: The text that is displayed before the list of clarification choices. You can change it to something else, such as What do you want to do? or Pick what to do next. \n No action matches None of the above The choice that customers can click when none of the other choices are right. If the customer picks this choice, the assistant uses your No action matches action. You can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_04107-6095-8145","score":0.0149253731,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02776-3988-5695","score":0.0327868852,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_13616-13587-15670","score":0.0322580645,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_04997-3175-3972","score":0.0317460317,"text":"\nSee [IBM Cloud Docs: Enabling the HIPAA Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedenabling-hipaa) for additional information.\n\n\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nPlease visit [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) page to learn about IBM\u2019s GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey.\n\n\n\n* [IBM Data Processing Addendum (DPA)](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=dpa)\n\n\n\n\n\n\n\n Privacy shield \n\nIBM Cloud Object Storage is privacy shield certified. For more information please visit [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compliance"},{"document_id":"ibmcld_12035-7-1995","score":0.03125,"text":"\nCompliance \n\nIBM Cloud\u00ae Schematics actively participates in several industry compliance programs. As compliance focal, you can use the Schematics goals to check that your organization is adhering to the external and internal standards for your industry. For more information about monitoring compliance, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nTo monitor your resources with Schematics, see [Managing security and compliance with Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-monitoring-instances).\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nAbout GDPR and how Schematics adheres to it, see [General Data Protection Regulation](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdpr). View [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) to learn about IBM's GDPR readiness journey and the GDPR capabilities and offerings to support your compliance journey.\n\n\n\n\n\n Privacy shield \n\nSchematics is privacy shield that is certified. For more information, see the [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/us-en\/privacy\/privacy-shield).\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nSchematics is audited by a Third-party security firm and meet ISO 27001, ISO 27017, ISO 27018, and ISO 27701 requirements. For more information, see the [Schematics Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the Schematics compliance page cover the Schematics service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27017\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-compliance"},{"document_id":"ibmcld_09492-16883-18851","score":0.0307692308,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-Security"},{"document_id":"ibmcld_09513-12728-14481","score":0.0303030303,"text":"\nThis is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-Security"},{"document_id":"ibmcld_12297-14875-16224","score":0.0298507463,"text":"\n* [Creating network zones by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-zone-ui)\n\n\n\n* [Understanding network rules](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-network-rules)\n\n\n\n* [Create network rules by using the CBR API](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-api)\n* [Creating network rules by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-ui)\n\n\n\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-next-steps)\n\n\n\n[Data privacy and governance](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-data-privacy-and-governancedata-privacy-and-governance)\n\n[General Data Protection Regulation (GDPR)](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprgeneral-data-protection-regulation-gdpr)\n\n\n\n* [How do you audit access to Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprhow-do-i-audit-access-to-ibm-schematics)\n* [Supporting classifications of personal data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprsupported-classifications-of-personal-data)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_09105-6159-7945","score":0.0294117647,"text":"\n<br> <br>When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key. <br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional. An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required. The base64-encoded key material, an existing key-wrapping key, that you want to store and manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keyshow-to-encode-root-key-material).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keys"},{"document_id":"ibmcld_09060-4951-6938","score":0.0289855072,"text":"\nThe unique identifier of the target key ring that you would like the newly create key to be a part of. If unspecified, the header is automatically set to 'default' and the key will sit in the default key ring in the specified Key Protect service instance. For more information, see [Grouping keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys). \n correlation_ID Optional.The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A human-readable name for convenient identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_09059-7769-9779","score":0.0285714286,"text":"\nA human-readable name for convenient identification of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description An extended description of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nIf the expirationDate is provided in your create key request, the key will transition to the deactivated state within one hour past the key's expiration date.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.167160455}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14953-5907-7890","score":0.0327868852,"text":"\nsecurity-group is.security-group.security-group.create Security Group was created \n security-group is.security-group.security-group.delete Security Group was deleted \n security-group is.security-group.security-group.update Security Group was updated \n security-group is.security-group.security-group.read One or more security groups were retrieved \n security-group is.security-group.security-group-rule.create Rule was added to Security Group \n security-group is.security-group.security-group-rule.delete Rule was removed from Security Group \n security-group is.security-group.security-group-rule.update Security Group Rule was updated \n security-group is.security-group.security-group-rule.read One or more security group rules was retrieved \n security-group is.security-group.security-group-interface.attach Interface was attached to Security Group \n security-group is.security-group.security-group-interface.detach Interface was removed from Security Group \n security-group is.security-group.security-group-interface.read One or more security group interfaces was retrieved \n\n\n\n\n\n\n\n Subnet events \n\n\n\nTable 8. Actions that generate events for Subnet\n\n Resource Action Description \n\n subnet is.subnet.subnet.create Subnet was created \n subnet is.subnet.subnet.update Subnet was updated \n subnet is.subnet.subnet.delete Subnet was deleted \n subnet is.subnet.subnet.read One or more subnets was retrieved \n subnet is.subnet.network-acl.update Subnet's Network ACL was replaced \n subnet is.subnet.public-gateway.attach Public Gateway was attached to Subnet \n subnet is.subnet.public-gateway.detach Public Gateway was detached from Subnet \n subnet is.subnet.public-gateway.read A subnet public-gateway attachment was retrieved \n\n\n\n\n\n\n\n Virtual private endpoints events \n\nThe following table lists the actions that are related to virtual private endpoints and the generation of events.\n\n\n\nTable 9. Actions that generate events for virtual private endpoints\n\n Resource Action Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-at-events"},{"document_id":"ibmcld_06282-18946-20824","score":0.0322580645,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-19050-20928","score":0.0317460317,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_10689-19663-21541","score":0.03125,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-group"},{"document_id":"ibmcld_16688-2022-3442","score":0.0307692308,"text":"\nEU-DE https:\/\/private.eu-de.security-compliance-secure.cloud.ibm.com\/api \n EU-GB https:\/\/private.eu-gb.security-compliance-secure.cloud.ibm.com\/api \n JP-OSA https:\/\/private.jp-osa.security-compliance-secure.cloud.ibm.com\/api \n JP-TOK https:\/\/private.jp-tok.security-compliance-secure.cloud.ibm.com\/api \n US-EAST https:\/\/private.us-east.security-compliance-secure.cloud.ibm.com\/api \n AU-SYD https:\/\/private.au-syd.security-compliance-secure.cloud.ibm.com\/api \n CA-TOR https:\/\/private.ca-tor.security-compliance-secure.cloud.ibm.com\/api \n BR-SAO https:\/\/private.br-sao.security-compliance-secure.cloud.ibm.com\/api \n\n\n\n\n\n\n\n Public REST API endpoints \n\n\n\nTable 3. Public REST API endpoints for the IBM Cloud Security and Compliance Center Workload Protection service\n\n Region Public REST API endpoint \n\n US-SOUTH https:\/\/us-south.security-compliance-secure.cloud.ibm.com\/api \n EU-DE https:\/\/eu-de.security-compliance-secure.cloud.ibm.com\/api \n EU-GB https:\/\/eu-gb.security-compliance-secure.cloud.ibm.com\/api \n JP-OSA https:\/\/jp-osa.security-compliance-secure.cloud.ibm.com\/api \n JP-TOK https:\/\/jp-tok.security-compliance-secure.cloud.ibm.com\/api \n US-EAST https:\/\/us-east.security-compliance-secure.cloud.ibm.com\/api \n AU-SYD https:\/\/au-syd.security-compliance-secure.cloud.ibm.com\/api \n CA-TOR https:\/\/ca-tor.security-compliance-secure.cloud.ibm.com\/api \n BR-SAO https:\/\/br-sao.security-compliance-secure.cloud.ibm.com\/api","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-endpoints"},{"document_id":"ibmcld_14951-77474-79053","score":0.0303030303,"text":"\n* [Create a load balancer](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-load-balancer) (POST \/load_balancers) can now accept a list of security groups\n* [Get load balancer details](https:\/\/cloud.ibm.com\/apidocs\/vpcget-load-balancer) (GET \/load_balancers\/{id}) now returns references to the security groups to which a load balancer is attached\n\n\n\nNew security group methods have been added for managing security group targets:\n\n\n\n* [Attach a security group to a target network interface or load balancer](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-security-group-target-binding) (PUT \/security_groups\/{security_group_id}\/targets\/{id})\n* [List targets attached to a security group](https:\/\/cloud.ibm.com\/apidocs\/vpclist-security-group-targets) (GET \/security_groups\/{security_group_id}\/targets)\n* [Retrieve a target in a security group](https:\/\/cloud.ibm.com\/apidocs\/vpcget-security-group-target) (GET \/security_groups\/{security_group_id}\/targets\/{id})\n* [Delete targets from a security group](https:\/\/cloud.ibm.com\/apidocs\/vpcdelete-security-group-target-binding) (DELETE \/security_groups\/{security_group_id}\/targets\/{id})\n\n\n\nUse the security group target methods to manage security group attachments to both load balancers and network interfaces. The original methods specific to network interfaces are now deprecated:\n\n\n\n* GET \/security_groups\/{security_group_id}\/network_interfaces\n* DELETE \/security_groups\/{security_group_id}\/network_interfaces\/{id}\n* GET \/security_groups\/{security_group_id}\/network_interfaces\/{id}\n* PUT \/security_groups\/{security_group_id}\/network_interfaces\/{id}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-api-change-log"},{"document_id":"ibmcld_10689-20960-22768","score":0.0298507463,"text":"\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add.\n\nExample command to create a VPC cluster with only your own security groups:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nUp to five of your own security groups are applied to the workers on the cluster.\n\n\n\n\n\n\n\n Adding security groups to worker pools at worker pool create time \n\nBy default, the security groups applied to a worker pool are the same security groups that are indicated at cluster create time. However, you can specify additional security groups to apply to a worker pool. If you apply additional security groups to the worker pool, then the security group applied to the workers on the cluster is a combination of the [security groups applied at cluster create](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-groupvpc-sg-cluster) and the security groups applied to the worker pool.\n\nA maximum of five security groups can be applied to a worker, including the security groups applied by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-group"},{"document_id":"ibmcld_06282-20243-22150","score":0.0294117647,"text":"\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add.\n\nExample command to create a VPC cluster with only your own security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nUp to five of your own security groups are applied to the workers on the cluster.\n\n\n\n\n\n\n\n Adding security groups to worker pools at worker pool create time \n\nBy default, the security groups applied to a worker pool are the same security groups that are indicated at cluster create time. However, you can specify additional security groups to apply to a worker pool. If you apply additional security groups to the worker pool, then the security group applied to the workers on the cluster is a combination of the [security groups applied at cluster create](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-cluster) and the security groups applied to the worker pool.\n\nA maximum of five security groups can be applied to a worker, including the security groups applied by default.\n\nThe security groups applied to a worker pool cannot be changed once the worker pool is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-20347-22170","score":0.0289855072,"text":"\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add.\n\nExample command to create a VPC cluster with only your own security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nUp to five of your own security groups are applied to the workers on the cluster.\n\n\n\n\n\n\n\n Adding security groups to worker pools at worker pool create time \n\nBy default, the security groups applied to a worker pool are the same security groups that are indicated at cluster create time. However, you can specify additional security groups to apply to a worker pool. If you apply additional security groups to the worker pool, then the security group applied to the workers on the cluster is a combination of the [security groups applied at cluster create](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=uivpc-sg-cluster) and the security groups applied to the worker pool.\n\nA maximum of five security groups can be applied to a worker, including the security groups applied by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_12775-7-1982","score":0.0285714286,"text":"\nManaging security groups \n\nYou can manage security groups by using the Security Groups page, or the Device Details page in the IBM Cloud\u00ae console.\n\n\n\n Managing security groups from the Security Groups page \n\nTo manage security groups from the Security Groups page, complete the following steps:\n\n\n\n1. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/), click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg) > Classic Infrastructure to view the Classic Infrastructure landing page.\n2. From the Classic Infrastructure menu, select Security > Network Security > Security Groups to view the Security Groups page.\n3. On the Security Groups page, you can complete several management tasks.\n\n\n\n* View a list of security groups.\n* Create a group.\n* Edit group information.\n* Duplicate a group.\n* Delete a group.\n\n\n\n\n\n\n\n\n\n Managing security group rules from the Security Groups page \n\nTo manage security group rules from the Security Groups page, complete the following steps:\n\n\n\n1. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/), click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg) > Classic Infrastructure to get to the Classic Infrastructure landing page.\n2. From the Classic Infrastructure menu, select Security > Network Security > Security Groups to get to the Security Groups page.\n3. On the Security Groups page, click on a security group name to open the Details page.\n4. On the Security Group Details page, you can complete several management tasks.\n\n\n\n* View a list of rules that are defined for the security group.\n* Create new rules.\n* Edit a rule.\n* Delete a rule.\n* View the virtual server instances and the associated interfaces that are assigned to the security group.\n\n\n\n\n\nIf you delete the last rule in a security group, then inbound and outbound traffic is not allowed by this security group.\n\n\n\n\n\n Managing security groups from the Device Details page","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-groups?topic=security-groups-managing-sg"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04109-7-2036","score":0.0327868852,"text":"\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country\/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions"},{"document_id":"ibmcld_13915-6476-8449","score":0.0322580645,"text":"\nUnlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf\n\nAfter this rule set is merged, a new firewall rule set named CPP is added and applied to the loopback interface. It is recommend that you modify this rule set to suit your environment.\n\nPlease note that CPP rules cannot be stateful, and will only apply on ingress traffic.\n\n\n\n\n\n Zone firewalling \n\nAnother firewall concept within the IBM Cloud\u00ae Virtual Router Appliance is zone based firewalls. In zone-based firewall operation an interface is assigned to a zone (only one zone per interface) and firewall rule sets are assigned to the boundaries between zones with the idea that all interfaces within a zone have the same security level and are allowed to route freely. Traffic is only scrutinized when it is passing from one zone to another. Zones drop any traffic coming into them which is not explicitly allowed.\n\nAn interface can either belong to a zone or have a per-interface firewall configuration; an interface cannot do both.\n\nImagine the following office scenario with three departments, each department with its own VLAN:\n\n\n\n* Department A - VLANs 10 and 20 (interface dp0bond1.10 and dp0bond1.20)\n* Department B - VLANs 30 and 40 (interface dp0bond1.30 and dp0bond1.40)\n* Department C - VLAN 50 (interface dp0bond1.50)\n\n\n\nA zone can be created for each department and the interfaces for that department can be added to the zone. The following example illustrates this:\n\nset security zone-policy zone DEPARTMENTA interface dp0bond1.10\nset security zone-policy zone DEPARTMENTA interface dp0bond1.20\nset security zone-policy zone DEPARTMENTB interface dp0bond1.30","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_04334-72037-73413","score":0.0317460317,"text":"\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet firewall rule details.\n\nibmcloud cis firewall dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_07578-1006129-1007999","score":0.03125,"text":"\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1006000-1007870","score":0.0307692308,"text":"\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04334-73111-74523","score":0.0303030303,"text":"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.\n\nibmcloud cis firewall-delete FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_13915-3198-5235","score":0.0298507463,"text":"\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2\n\nIn the ruleset, ALLOW_LEGACY, there are two rules defined. The first rule drops any traffic sourced from an address group named network-group1. The second rule discards and logs any traffic destined for the telnet port (tcp\/23) from the address group named network-group2. The default-action indicates that anything else is accepted.\n\n\n\n\n\n Allowing data center access \n\nIBM\u00a9 offers several IP subnets to provide services and support to systems running within the data center. For example, DNS resolver services are running on 10.0.80.11 and 10.0.80.12. Other subnets are used during provisioning and support. You can find the IP ranges used in the data centers in [this topic](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-dedicated?topic=hardware-firewall-dedicated-ibm-cloud-ip-ranges).\n\nYou can allow data center access by placing the proper SERVICE-ALLOW rules at the beginning of the firewall rule sets with an action of accept. Where the rule set must be applied depends on the routing and firewall design being implemented.\n\nIt is recommended that you place the firewall rules in the location which causes the least duplication of work. For example, allowing backend subnets inbound on dp0bond0 would be less work than allowing backend subnets outbound toward each VLAN virtual interface.\n\n\n\n Per-interface firewall rules \n\nOne method for configuring the firewall on a VRA is to apply firewall rule sets to each interface. In this case an interface can be a dataplane interface (dp0s0) or a virtual interface (dp0bond0.303). Each interface has three possible firewall assignments:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_13927-3027-3785","score":0.0294117647,"text":"\nThe following is an example of SERVICE-ALLOW. This is not a complete private IP rule set.\n\nset firewall name SERVICE-ALLOW rule 1 action 'accept'\nset firewall name SERVICE-ALLOW rule 1 destination address '10.0.64.0\/19'\nset firewall name SERVICE-ALLOW rule 2 action 'accept'\nset firewall name SERVICE-ALLOW rule 2 destination address '10.1.128.0\/19'\nset firewall name SERVICE-ALLOW rule 3 action 'accept'\nset firewall name SERVICE-ALLOW rule 3 destination address '10.0.86.0\/24'\n\nAfter you define the firewall rules, you can assign them as you see fit. Two examples are listed.\n\nApplying to a zone: set zone-policy zone private from dmz firewall name SERVICE-ALLOW\n\nApplying to a bond interface: set interfaces bonding bond0 firewall local name SERVICE-ALLOW","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-setting-up-nat-rules-on-vyatta-5400"},{"document_id":"ibmcld_04334-70962-72477","score":0.0289855072,"text":"\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--page\n: Page number of paginated results. The default value is 0.\n\n--per-page\n: Maximum number of access rules per page. The minimum value is 5. The default value is 20.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList firewall rules.\n\nibmcloud cis firewalls -t access-rules -i \"cis-demo\"\nibmcloud cis firewalls -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewalls -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall \n\nGet details of a firewall rule.\n\nibmcloud cis firewall FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_13915-1601-3647","score":0.0285714286,"text":"\nAs GLOBAL_STATELESS does not specify protocol tcp, the global-state-policy tcp command would not apply on this rule.\n\nset security firewall name GLOBAL_STATEFUL_TCP rule 1 action accept\nset security firewall name GLOBAL_STATEFUL_TCP rule 1 protocol tcp\n\nIn this case protocol tcp is explicitly defined. The global-state-policy tcp command would enable stateful tracking of traffic that matches rule 1 of GLOBAL_STATEFUL_TCP\n\nTo make individual firewall rules 'stateful':\n\nset security firewall name TEST rule 1 allow\nset security firewall name TEST rule 1 state enable\n\nThis would enable stateful tracking of all traffic that can be tracked statefully and matches rule 1 of TEST, regardless of the existence of global-state-policy commands.\n\n\n\n\n\n ALG for assisted stateful tracking \n\nA few protocols such as FTP utilize more complex sessions that the normal stateful firewall operation can track. There are preconfigured modules that enable these protocols to be statefully managed.\n\nIt is suggested to disable these ALG modules, unless they are required for the successful use of the respective protocols.\n\nset system alg ftp 'disable'\nset system alg icmp 'disable'\nset system alg pptp 'disable'\nset system alg rpc 'disable'\nset system alg rsh 'disable'\nset system alg sip 'disable'\nset system alg tftp 'disable'\n\n\n\n\n\n Firewall rule sets \n\nFirewall rules are grouped together into named sets to make applying rules to multiple interfaces easier. Each rule set has a default action associated with it. Consider the following example:\n\nset security firewall name ALLOW_LEGACY default-action accept\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-4-2033","score":0.0327868852,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03270-3352-5135","score":0.0322580645,"text":"\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03113-6206-7586","score":0.0317460317,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03113-4996-6502","score":0.03125,"text":"\n[UI location where the code that is triggered by named event handlers is authored](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02882-27313-29495","score":0.0307692308,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02952-3289-5462","score":0.0303030303,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03273-11911-13556","score":0.0298507463,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03188-1732-3801","score":0.0294117647,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_02952-1632-3754","score":0.0289855072,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03054-27011-29125","score":0.0285714286,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02988-8862-10727","score":0.0327868852,"text":"\nThe confidence property is a decimal percentage that represents your assistant's confidence in the recognized intent.\n\nWhile testing your dialog, you can see details of the intents that are recognized in user input by specifying this expression in a dialog node response:\n\n<? intents ?>\n\nFor the user input, Hello now, your assistant finds an exact match with the #greeting intent. Therefore, it lists the #greeting intent object details first. The response also includes the 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the Try it out pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-expression-language"},{"document_id":"ibmcld_03310-10261-12004","score":0.0322580645,"text":"\nThe response also includes the top 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the \"Try it out\" pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nIf you want to include text in the response, use the toJson() method in the expression to cast the returned intents list into a JSON object. For example:\n\nRecognized intents are: <? intents.toJson() ?>\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:\n\n\n\n* To execute a node if the user input is \"Yes\", add this expression to the node condition: input.text == 'Yes'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"},{"document_id":"ibmcld_03145-1287-2166","score":0.0317460317,"text":"\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n* Rename intents\n* Delete intents\n* Add, edit, or delete intent user examples\n* Move an example to a different intent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_03334-20892-22106","score":0.03125,"text":"\nRepeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/delete-c10.png)\n* To delete the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents that are listed on the current page. Click Delete.\n* To delete one or more specific intents, select the intents that you want to delete, and then click Delete.\n\n![Shows that an intent was selected and the delete icon is in focus](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-delete.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03010-16826-18510","score":0.0307692308,"text":"\n[Shows an intent with a user example list where one of the user examples has a Resolve conflicts button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-resolve-conflicts.png)\n3. Choose whether to delete the example from the intent or to move it to another intent.\n\n![Shows the intent conflict details page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-fix-conflict.png)\n\nSimilar user examples are displayed for each intent. These examples are not necessarily in conflict. They are shown to give you a quick view of the other types of user examples that are defined for each intent. It provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03334-19597-21305","score":0.0303030303,"text":"\nIt provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03010-13387-14939","score":0.0298507463,"text":"\n[Shows the results from a search for intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-search-results.png)\n\n\n\n\n\n\n\n Exporting intents \n\nYou can export a number of intents to a CSV file, so you can then import and reuse them for another Watson Assistant application.\n\n\n\n1. Go to the Intents page.\n\n\n\n* To export all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Export all intents icon. ![Export option](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/export-c10.png)\n* To export the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents on the current page. Click Export.\n* To export one or more specific intents, select the intents that you want to export, and then click Export.\n\n![Shows that two intents are selected and the export icon is in focus](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-export.png)\n\n\n\n2. Specify the name and location in which to store the CSV file that is generated.\n\n\n\n\n\n\n\n Importing intents and examples \n\nIf you have a large number of intents and examples, you might find it easier to import them from a comma-separated value (CSV) file than to define them one by one. Be sure to remove any personal data from the user examples that you include in the file.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03010-18014-19579","score":0.0294117647,"text":"\n[Shows the Move menu with a list of one intent options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/delete-c10.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03010-11212-12967","score":0.0289855072,"text":"\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\n\n\nLimit details\n\n Intents per skill Examples per skill \n\n 2,000 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nThe search capability was introduced with the 1.5.0 release.\n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page header, click the Search icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03334-18585-20063","score":0.0285714286,"text":"\n[Shows an intent list with a conflict](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-conflicts.png)\n2. Click an intent with a conflict to open it. Find the user example that is causing the conflict, and then click Resolve conflicts.\n\n![Shows an intent with a user example list where one of the user examples has a Resolve conflicts button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-resolve-conflicts.png)\n3. Choose whether to delete the example from the intent or to move it to another intent.\n\n![Shows the intent conflict details page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-fix-conflict.png)\n\nSimilar user examples are displayed for each intent. These examples are not necessarily in conflict. They are shown to give you a quick view of the other types of user examples that are defined for each intent. It provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-123564-124806","score":0.0327868852,"text":"\n[Creating classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_09841-1360-2978","score":0.0322580645,"text":"\nmqcloud.trust-store-cert.create An event is created when you import a certificate into a trust store \n mqcloud.trust-store-cert.delete An event is created when you delete a certificate from a trust store \n mqcloud.trust-store-cert.update An event is created when you update a certificate in a trust store \n mqcloud.admin-credentials.create An event is created when you create administrator credentials \n mqcloud.admin-credentials.delete An event is created when you delete administrator credentials \n mqcloud.admin-credentials.update An event is created when you update administrator credentials \n mqcloud.admin-apikey.create An event is created when you create an API key for an administrator \n mqcloud.admin-apikey.update An event is created when you update an API key for an administrator \n mqcloud.app-credentials.create An event is created when you create application credentials \n mqcloud.app-credentials.delete An event is created when you delete application credentials \n mqcloud.app-credentials.update An event is created when you update application credentials \n mqcloud.app-apikey.update An event is created when you update an API key for an application \n mqcloud.cluster.create An event is created when you create a cluster \n\n\n\n\n\n\n\n Where to view the events \n\nThe following table shows the location (region) in IBM Cloud where you can monitor MQ on Cloud events:\n\n\n\n MQ on Cloud service instance location Activity Tracker service instance location \n\n Dallas (us-south) Dallas (us-south) \n Frankfurt (eu-de) Frankfurt (eu-de) \n London (eu-gb) London (eu-gb) \n Washington DC (us-east) Washington DC (us-east)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-at_events"},{"document_id":"ibmcld_12297-159404-160750","score":0.0317460317,"text":"\n[Blueprint create fails](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails)\n\n\n\n* [Blueprint create fails with an invalid blueprint template: failed to clone Git repository error](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails1)\n* [Blueprint create fails with an invalid blueprint template: unable to find file error](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails2)\n* [Blueprint create fails with the requested resource group as invalid](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails3)\n* [Blueprint create fails with the error blueprint JSON validation failed: field missing or invalid in config](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails4)\n* [Blueprint create fails with the error blueprint JSON validation failed - field missing or invalid](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failsbp-create-fails5)\n* [Why is Schematics not able to clone the private GitHub repository?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failstsg-privategithub)\n* [Why is Schematics not able to clone the public GitHub repository?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-failstsg-publicgithub)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_05713-131400-132874","score":0.03125,"text":"\n* [Deciding on your cluster setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersprepare_cluster_level)\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersnext_steps)\n\n\n\n[Creating classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-124536-125809","score":0.0307692308,"text":"\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n[Creating Satellite clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatellite-clusters)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatcluster-prereqs)\n* [Creating Red Hat OpenShift clusters on Satellite from the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatcluster-create-console)\n* [Creating Red Hat OpenShift clusters on Satellite from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusterssatcluster-create-cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_16034-11047-13098","score":0.0303030303,"text":"\n* Removed security group network interface commands security-group-network-interface, security-group-network-interface-add, security-group-network-interface-remove and security-group-network-interfaces.\n\n\n\n\n\n\n\n Note \n\n\n\n* Support for primary_ipv4_address property in primary-network-interface and network-interface options for the instance-create, instance-create-from-template, instance-template-create and instance-template-create-override-source-template commands were removed. Use primary_ip property to create the resource with wanted IP address.\n* Support for IPV4 option for the instance-create, instance-network-interface-create, instance-create-from-template, instance-template-create and instance-template-create-override-source-template commands were removed. Use the address option to create the resource with wanted IP address.\n* Support for PNIC-IP option and primary_ipv4_address property in network-interface option for the bare-metal-server-create command was removed. Use primary_ip property in network-interface option and pnic-rip-address option to create the bare metal server with wanted IP address.\n* Support for IP option for the bare-metal-server-network-interface-create command was removed. Use address option to create the bare-metal-server-network-interface with wanted IP address.\n\n\n\n\n\n\n\n\n\n v3.5.0 \n\nVersion 3.5.0 was released on 2022-03-25.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer-listener-create,load-balancer-listener-update, load-balancer-pool-create and load-balancer-pool-update commands to support UDP protocol.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.4.0 \n\nVersion 3.4.0 was released on 2022-02-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template commands to support metadata service.\n* Update instance-create and instance-create-from-template commands to support trusted profile.\n\n\n\n\n\n\n\n Removed commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_10253-6464-8037","score":0.0298507463,"text":"\ncronjobs.batch get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n daemonsets.apps get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n daemonsets.extensions get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.apps get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.apps\/rollback <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.apps\/scale get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.extensions get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.extensions\/rollback <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.extensions\/scale get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-iam-service-access-roles"},{"document_id":"ibmcld_05846-6547-8120","score":0.0294117647,"text":"\ncronjobs.batch get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n daemonsets.apps get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n daemonsets.extensions get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.apps get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.apps\/rollback <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.apps\/scale get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.extensions get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.extensions\/rollback <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n deployments.extensions\/scale get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-roles"},{"document_id":"ibmcld_05444-86766-88182","score":0.0289855072,"text":"\n[Creating a job from images in a public registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-jobcreate-job)\n\n\n\n* [Creating a job with the console](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-jobcreate-job-ui)\n* [Creating a job with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-jobcreate-job-cli)\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-jobnextsteps-jobcreatepub)\n\n\n\n[Creating a job from images in IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage)\n\n\n\n* [Creating a job that references an image in Container Registry with the console](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage-console)\n* [Creating a job with an image in Container Registry with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage-cli)\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-crimagenextsteps-jobcreatecr)\n\n\n\n[Creating a job from images in a private registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-privatecreate-job-private)\n\n\n\n* [Creating a job that references an image in a private registry with the console](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-privatecreate-job-private-console)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-sitemap"},{"document_id":"ibmcld_03106-3091-5136","score":0.0285714286,"text":"\ncatalog_integration.create creates a custom extension \n catalog_integration.delete deletes a custom extension \n catalog_integration.update updates a custom extension \n counterexample.create marks test user input in the \"Try it out\" pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant \n counterexample.delete deletes a counterexample \n counterexample.update edits a counterexample \n data.delete deletes multiple training data items, such as multiple entities or intents \n data.update does a bulk action, such as importing a CSV file of intents or entities to the skill \n data_type.create creates a saved response \n data_type.delete deletes a saved response \n data_type.update updates a saved response \n entity.create creates an entity \n entity.delete deletes an entity \n entity.update edits an entity \n environment.create adds an environment \n environment.delete deletes an environment \n environment.updates updates an environment \n example.create adds a user input example to an intent \n example.delete deletes a user example from an intent \n example.update edits a user example that is associated with an intent \n integration_defintion.create creates an integration \n integration_defintion.delete deletes an integration \n integration_defintion.update updates an integration \n intent.create creates an intent \n intent.delete deletes an intent \n intent.update edits an intent \n log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page \n node.create creates a dialog node \n node.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-auditing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03085-4-2046","score":0.0327868852,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_03043-4515-6369","score":0.0322580645,"text":"\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-diagram.png)\n\nFor help creating a search skill, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n Create the skill \n\nYou can add one skill of each skill type to an assistant.\n\n\n\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add)\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add)\n\n\n\n\n\n\n\n Skill limits \n\n\n\nSkill limit details\n\n Skills per service instance \n\n 50 \n\n\n\nSkill versions do not count toward the skill limit.\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants. From the Skills page, find the tile for the skill that you want to delete. The Assistants field lists the assistants that currently use the skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03049-7-1790","score":0.0317460317,"text":"\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03049-3966-5647","score":0.03125,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03373-7076-8670","score":0.0307692308,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03106-4717-6754","score":0.0303030303,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-auditing"},{"document_id":"ibmcld_16248-4582-6619","score":0.0298507463,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-auditing"},{"document_id":"ibmcld_03385-2475-4140","score":0.0294117647,"text":"\n[open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Delete. Confirm the deletion.\n\n\n\n\n\n\n\n Downloading a skill \n\nYou can download a dialog or actions skill in JSON format. You might want to download a skill if you want to use the same skill in a different instance of the Watson Assistant service. You can download a dialog skill from one instance and upload it to another instance as a new skill, for example.\n\nYou cannot download a search skill.\n\nTo download a skill, complete the following steps:\n\n\n\n1. Find the skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Download.\n3. Specify a name for the JSON file and where to save it, and then click Save.\n\n\n\nFor dialog skills only:\n\n\n\n* You can download a dialog skill by using the API also. Include the export=true parameter with the request. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1getworkspace) for more details.\n* For information about how to download a specific dialog skill version, see [Downloading a skill version](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versionsversions-export).\n\n\n\n\n\n\n\n Overwriting a skill \n\nTo overwrite or replace an existing skill, upload the new version of the skill as a JSON file into the existing skill.\n\nYou can overwrite a dialog or actions skill. You cannot overwrite a search skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasks"},{"document_id":"ibmcld_13055-2475-4140","score":0.0289855072,"text":"\n[open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Delete. Confirm the deletion.\n\n\n\n\n\n\n\n Downloading a skill \n\nYou can download a dialog or actions skill in JSON format. You might want to download a skill if you want to use the same skill in a different instance of the Watson Assistant service. You can download a dialog skill from one instance and upload it to another instance as a new skill, for example.\n\nYou cannot download a search skill.\n\nTo download a skill, complete the following steps:\n\n\n\n1. Find the skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Download.\n3. Specify a name for the JSON file and where to save it, and then click Save.\n\n\n\nFor dialog skills only:\n\n\n\n* You can download a dialog skill by using the API also. Include the export=true parameter with the request. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1getworkspace) for more details.\n* For information about how to download a specific dialog skill version, see [Downloading a skill version](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versionsversions-export).\n\n\n\n\n\n\n\n Overwriting a skill \n\nTo overwrite or replace an existing skill, upload the new version of the skill as a JSON file into the existing skill.\n\nYou can overwrite a dialog or actions skill. You cannot overwrite a search skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-tasks"},{"document_id":"ibmcld_03385-4-1596","score":0.0285714286,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Working with skills \n\nPerform common tasks, such as renaming or deleting a skill.\n\n\n\n Renaming a skill \n\nYou can change the name of a skill and its associated description after you create the skill.\n\nTo rename a skill, follow these steps:\n\n\n\n1. From the Skills page, find the skill that you want to rename.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Rename.\n3. Edit the name, and then click Save.\n\n\n\n\n\n\n\n Duplicating a skill \n\nYou can duplicate a skill to make a copy of it.\n\nTo duplicate a skill, follow these steps:\n\n\n\n1. From the Skills page, find the skill that you want to duplicate.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Duplicate. The copied skill has the word copy added to the end of its name.\n\n\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02900-2946-5130","score":0.0327868852,"text":"\nHowever, the conversation cannot digress away from a node under the following circumstances:\n\n\n\n* If any of the child nodes of the current node contain the anything_else or true condition\n\n\n\nThese conditions are special in that they always evaluate to true. Because of their known behavior, they are often used in dialogs to force a parent node to evaluate a specific child node in succession. To prevent breaking existing dialog flow logic, digression are not allowed in this case. Before you can enable digressions away from such a node, you must change the child node's condition to something else.\n\n\n\n* If the node is configured to jump to another node or skip user input after it is processed\n\n\n\nThe final step section of a node specifies what should happen after the node is processed. When the dialog is configured to jump directly to another node, it is often to ensure that a specific sequence is followed. And when the node is configured to skip user input, it is equivalent to forcing the dialog to process the first child node after the current node in succession. To prevent breaking existing dialog flow logic, digressions are not allowed in either of these cases. Before you can enable digressions away from this node, you must change what is specified in the final step section.\n\n\n\n\n\n\n\n Customizing digressions \n\nYou do not define the start and end of a digression. The user is entirely in control of the digression flow at run time. You only specify how each node should or should not participate in a user-led digression. For each node, you configure whether:\n\n\n\n* a digression can start from and leave the node\n* a digression that starts elsewhere can target and enter the node\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_02900-4643-6783","score":0.0322580645,"text":"\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\n\n\n Digressions away from this node \n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response toggle to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it was. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular? If the user changes subjects at this point, you might want the dialog to return so the user can pick a menu type and get the information they wanted.\n* Nodes with slots: Choose whether you want to allow users to digress away from the node before all of the slots are filled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_03218-24900-26959","score":0.0317460317,"text":"\nFor each node, you configure whether:<-- <ul> --> * a digression can start from and leave the node * a digression that starts elsewhere can target and enter the node * a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed<-- <\/ul> -->To change the digression behavior for an individual node, complete the following steps:<-- <ol> -->1. Click the node to open its edit view.2. Click Customize, and then click the Digressions tab.\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\nDigressions away from this node\n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n<-- <ul> -->\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response switch to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it left off. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_03188-1732-3801","score":0.03125,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_16302-0-1237","score":0.0307692308,"text":"\n\n\n\n\n\n\n  Publishing dialog and actions \n\nIf the dialog feature is enabled, the publishing and deployment processes remain the same. However, some slight differences in functionality exist.\n\nTo learn about the overall publishing and deployment model for Watson Assistant, see the [Publishing and deploying your assistant overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview). For more information about the Publish page and how the publishing process works, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). The following slight differences exist when the dialog feature is enabled in an assistant:\n\n\n\n*  On the Publish page, the information in the Content type column lists whether your content changes contain a dialog.\n*  The version tiles on the Publish and Environments pages show whether the published content contains actions, or actions and a dialog. For example, if the dialog feature is enabled in your assistant, the version tile displays Contains actions & dialog.\n*  When you export a version of your content from the Publish page, two JSON files are downloaded. One file is for actions and one file is for the dialog.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-publish"},{"document_id":"ibmcld_03156-4700-6686","score":0.0303030303,"text":"\n[Screenshot of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nDo not add an external node name to the root node that you created in Step 2. When an escalation occurs, your assistant looks at the external node name of the last processed node to learn which user goal was not met successfully. If you include an external node name in the node with the connect to human agent intent, then you will prevent your assistant from learning the last real, goal-oriented node that the user interacted with before escalating the issue.\n\n\n\n4. If a child node in the branch conditions on a follow-up request or question that you do not want the assistant to handle, add a Connect to human agent response type to the node.\n\nFor example, you might want to add this response type to nodes that cover sensitive issues only a human should handle or that track when an assistant repeatedly fails to understand a user.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point. Later, when you set up the Intercom integration, you can choose a human agent as a backup for each branch.\n\n\n\nYour dialog is now ready to support your assistant in Intercom.\n\n\n\n Dialog considerations \n\nSome rich responses that you add to a dialog are displayed differently within the \"Try it out\" pane from how they are displayed to Intercom users. The following table describes how the response types are treated by Intercom.\n\n\n\n Response type How displayed to Intercom users \n\n Option The options are displayed as a numbered list. In the title or description field, provide instructions that explain to the user how to choose an option from the list. \n Image The image title, description, and the image itself are rendered. \n Pause Whether or not you enable it, a typing indicator is not displayed during the pause.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-intercom"},{"document_id":"ibmcld_02882-18936-21214","score":0.0298507463,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_16300-0-2464","score":0.0294117647,"text":"\n\n\n\n\n\n\n  Analyzing dialog and actions \n\nThe Analyze page provides a summary of the interactions between users and your assistant. If the dialog feature is enabled, the Analyze page remains the same, but some slight differences in functionality exist.\n\n\n\n  Overview tab \n\nWhen you view the Overview page, you can see action completion information in the Action completion diagram if a dialog node triggers an action. The Action completion diagram is empty if you are using only a dialog in your assistant. The three cards that display information about the most frequent actions, least frequent actions, and least completed actions are not available if your assistant uses only a dialog.\n\nFor more information about the Analyze page and how to use analytics with actions, see [Use analytics to review your entire assistant at a glance](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview).\n\n\n\n\n\n  Action completion tab \n\nThe Action completion page of Watson Assistant provides an overview of how all your assistant's actions are doing. If the dialog feature is enabled, the Action completion tab is relevant only if a dialog node triggers an action. If your assistant uses only a dialog, then this tab will be empty.\n\nFor more information about understanding action completion with actions, see [Understand your most and least successful actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-action-completion).\n\n\n\n\n\n  Conversations tab \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nFrom the Conversations page, an intent that directly calls an action is displayed in the Topics column. For example, you might set up an intent called buy_takeout in the dialog, and that intent calls the order pizza action. This conversation topic is listed as buy_takeout > order pizza in the Topics column.\n\nYou might also see Dialog called action listed in the Requests column next to a conversation. In this case, customer input triggered an intent. Then, the customer engaged with the assistant before an action was eventually called.\n\nFor more information about analyzing conversations with actions, see [Review customer conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-analyze"},{"document_id":"ibmcld_03369-75826-77957","score":0.0289855072,"text":"\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.\n\nUse contextual entities to teach your skill to recognize the context in which such names are used. For more information about contextual entities, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFor more information about how to use contextual entites to identify names of people, see the [Detecting Names And Locations With Watson Assistant](https:\/\/medium.com\/ibm-watson\/detecting-names-and-locations-with-watson-assistant-e3e1fa2a8427) blog post on Medium.\n\nHow legacy numeric system entities are processed has changed\n: All new dialog skills use the new system entities automatically.\n\nFor existing skills that use legacy numeric system entities, how the entities are processed now differs based on the skill language.\n\n\n\n* Arabic, Chinese, Korean, and Japanese dialog skills that use legacy numeric system entities function the same as before.\n* If you choose to continue to use the legacy system entities in European-language dialog skills, a new legacy API format is used. The new legacy API format simulates the legacy system entities behavior. In particular, it returns a metadata object and does not stop the service from idenfifying multiple system entities for the same input string. In addition, it returns an interpretation object, which was introduced with the new version of system entities. Review the interpretation object to see the useful information that is returned by the new version.\n\n\n\nUpdate your skills to use the new system entities from the Options>System Entities page.\n\nWeb chat security is generally available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-7497-9493","score":0.0285714286,"text":"\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https:\/\/cldr.unicode.org\/index\/downloads\/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Display formats](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 17 May 2023 \n\nDisplay iframe inline\n: In the web chat, there are now two ways an iframe response can be included:\n\n\n\n* As a preview card that describes the embedded content. Customers can click this card to display the frame and interact with the content.\n* Inline, meaning within the conversation. This new option is good for smaller pieces of iframe content.\n\n\n\nFor more information, see [Adding an iframe response](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-add-iframe).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 5 May 2023","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16527-11091-13443","score":0.0327868852,"text":"\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"},{"document_id":"ibmcld_07411-16780-17930","score":0.0322580645,"text":"\nID PTR:f20cfe91-b936-4bad-a8d1-f7afa4ac32a6\nName 192.168.1.100\nType PTR\nCreated On 2020-04-10 09:34:49.722454606 +0000 UTC\nModified On 2020-04-10 09:34:49.722454606 +0000 UTC\nTTL 900\nData\nptrdname www.example.com\n\n\n\n\n\n Creating type 'CNAME' resource record \n\nUse ibmcloud dns resource-record-create command with --type CNAME option to create a type CNAME resource record. --name and --cname are mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type CNAME --name web --cname www.example.com\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID CNAME:6e80f079-effd-409a-a520-b8c1b10f6e6e\nName web.example.com\nType CNAME\nCreated On 2020-04-10 09:36:13.186040793 +0000 UTC\nModified On 2020-04-10 09:36:13.186040793 +0000 UTC\nTTL 900\nData\ncname www.example.com\n\n\n\n\n\n Creating type 'AAAA' resource record \n\nUse ibmcloud dns resource-record-create command with --type AAAA option to create a type AAAA resource record. --name and --ipv6 are mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type AAAA --name www --ipv6 2019::2020","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_04543-1966-3290","score":0.0317460317,"text":"\n* ibmcloud is flow-log-create --bucket bucket-name --target 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --active false\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic --name my-flow-log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference"},{"document_id":"ibmcld_15545-2070-3394","score":0.03125,"text":"\n* ibmcloud is flow-log-create --bucket bucket-name --target 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --active false\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic --name my-flow-log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-2122-3446","score":0.0307692308,"text":"\n* ibmcloud is flow-log-create --bucket bucket-name --target 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --active false\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic --name my-flow-log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-1966-3290","score":0.0303030303,"text":"\n* ibmcloud is flow-log-create --bucket bucket-name --target 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --active false\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic --name my-flow-log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-2022-3346","score":0.0298507463,"text":"\n* ibmcloud is flow-log-create --bucket bucket-name --target 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --active false\n* ibmcloud is flow-log-create --bucket bucket-name --target my-vpc --target-type vpc --name my-flow-log --output JSON\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-subnet --target-type subnet --vpc my-vpc --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance\n* ibmcloud is flow-log-create --bucket bucket-name --target my-instance --target-type instance --name my-flow-log\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic\n* ibmcloud is flow-log-create --bucket bucket-name --target my-network-interface --target-type nic --name my-flow-log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_07411-14782-16101","score":0.0294117647,"text":"\nName _sip._tcp.video.example.com\nType SRV\nCreated On 2020-04-10 09:15:56.940189115 +0000 UTC\nModified On 2020-04-10 09:15:56.940189115 +0000 UTC\nTTL 900\nData\nport 953\npriority 10\ntarget media.example.com\nweight 10\n\n\n\n\n\n Creating type 'TXT' resource record \n\nUse the ibmcloud dns resource-record-create command with --type TXT option to create a type TXT resource record. --name and --text are mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type TXT --name text --text \"This is a text record.\"\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID TXT:92648285-c7e5-49ef-bf8b-a5be91d5c5d3\nName text.example.com\nType TXT\nCreated On 2020-04-10 09:16:50.169135062 +0000 UTC\nModified On 2020-04-10 09:16:50.169135062 +0000 UTC\nTTL 900\nData\ntext This is a text record.\n\n\n\n\n\n Creating type 'MX' resource record \n\nUse ibmcloud dns resource-record-create command with --type MX option to create a type MX resource record. --name and --exchange are the mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type MX --name mail --preference 10 --exchange exchange.example.com\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_11211-22215-24035","score":0.0289855072,"text":"\n* --network value: Space-separated list of identifier or name and optional IP address to associate with the instance.\n* --processors value: Number of processors to allocate to the instance. Default is 1 core.\n* --processor-type value: Type of processors: 'shared' or 'dedicated' or 'capped'.\n* --volumes value: Space separated list of identifiers or names of the volume(s) to associate with the instance.\n* --key-name value: Name of SSH key.\n* --sys-type value: Name of System Type (\"s922\", \"e880\", \"e980\"). Default is \"s922\".\n* --storage-type value: Storage type for server deployment when deploying a stock image (use \"ibmcloud pi storage-types\" to see available storage types in the targeted region). If --storage-pool or --storage-affinity is provided then this it cannot be specified. Only valid when one of the IBM supplied stock images is deployed. Storage type and pool for a custom image (an imported image or an image that is created from a PVMInstance capture) defaults to the storage type and pool the image was created in.\n* --storage-connection value: The storage connection type. Valid value is \"vSCSI\".\n* --storage-pool value: Storage pool for server deployment. Only valid when you deploy one of the IBM supplied stock images. Storage type and pool for a custom image (an imported image or an image that is created from a PVMInstance capture) defaults to the storage type and pool the image was created in.\n* --storage-affinity value: Affinity policy for storage pool selection. Valid values are \"affinity\" and \"anti-affinity\". If --storage-pool is provided then this it cannot be specified.\n* --storage-affinity-instance value: PVM instance identifier or name to base storage affinity policy against; required if \"--storage-affinity affinity\" is specified and --storage-affinity-volume is not provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas-cli-plugin?topic=power-iaas-cli-plugin-power-iaas-cli-reference"},{"document_id":"ibmcld_16454-11402-13678","score":0.0285714286,"text":"\nFor example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03126-3707-6008","score":0.0327868852,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03118-1768-3298","score":0.0322580645,"text":"\n(Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes. If you use the v1 \/message method, you must implement your own state management, and you cannot take advantage of versioning or any of the other features of an assistant.\n\n\n\n\n\n Authoring applications \n\nThe v1 API provides methods that enable an application to create or modify dialog skills, as an alternative to building a skill graphically using the Watson Assistant user interface. An authoring application uses the API to create and modify skills, intents, entities, dialog nodes, and other artifacts that make up a dialog skill. For more information, see the [v1 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1).\n\nNote: The v1 authoring methods create and modify workspaces rather than skills. A workspace is a container for the dialog and training data (such as intents and entities) within a dialog skill. If you create a new workspace using the API, it will appear as a new dialog skill in the Watson Assistant user interface.\n\nFor a list of the available API methods, see [API methods summary](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-methods).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_03293-18722-20426","score":0.0317460317,"text":"\nAnnotation-based entites are those for which you annotate occurrences of the entity in sample sentences to teach your assistant about the context in which the entity is typically used.\n\nIn order to train a contextual entity model, you can take advantage of your intent examples, which provide readily-available sentences to annotate.\n\nThis feature is generally available in English-language dialog skills and is available as a beta feature in French-langage dialog skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1. From your dialog skill, click the Intents tab.\n2. Click an intent to open it.\n\nFor this example, the intent buy_supplies defines the order function for an online retailer.\n\n![Select the #buy_supplies intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oe-intent.png)\n3. Click Annotate entities, and then review the intent examples for potential entity mentions.\n\n![Shows the Annotate entities toggle](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oe-annotate.png)\n4. Click any word, words, or punctuation that is part of a single entity mention from the intent examples.\n\nIn this example, mobile phones is the entity mention.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities"},{"document_id":"ibmcld_16364-67629-69709","score":0.03125,"text":"\n: We have added step-by-step documentation for connecting to [Genesys](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled. (For more information about the enhanced intent recognition model, and how to determine whether it is enabled, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).)\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message. It shows you the confidence score of top three possible action when the input triggers an action. You can also follow the step in the action editor along with the conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-31953-34073","score":0.0307692308,"text":"\nDeploy your assistant on the phone in minutes\n: We have partnered with [IntelePeer](https:\/\/intelepeer.com\/) to enable you to generate a phone number for free within the phone integration. Simply choose to generate a free number when following the prompts to create a phone integration, finish the setup, and a number is assigned to your assistant. These numbers are robust and ready for production.\n\nConnect to your existing service desks\n: We have added step-by-step documentation for connecting to [Genesys](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled.\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_02970-17020-19106","score":0.0303030303,"text":"\nYou can also define an English entity value\/synonym, and fuzzy matching will match only your defined entity value\/synonym. For example, fuzzy matching may match the term unsure with insurance; but if you have unsure defined as a value\/synonym for an entity like @option, then unsure will always be matched to @option, and not to insurance.\n\nYour fuzzy matching setting has no impact on synonym recommendations. Even if fuzzy matching is enabled, synonyms are suggested for the exact value you specify only, not the value and slight variations of the value.\n\nTo understand how fuzzy matching and autocorrection are related to one another, see the [autocorrection documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-checkdialog-runtime-spell-check-vs-fuzzy-matching).\n\n\n\n\n\n\n\n Adding contextual entities \n\nIf you are using version 1.3 of the product, see [Adding contextual entities in v1.3](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based-v130) instead. The way you annotate entity mentions changed between releases.\n\nAnnotation-based entites are those for which you annotate occurrences of the entity in sample sentences to teach your assistant about the context in which the entity is typically used.\n\nIn order to train a contextual entity model, you can take advantage of your intent examples, which provide readily-available sentences to annotate.\n\nThis feature is generally available in English-language dialog skills and is available as a beta feature in French-langage dialog skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities"},{"document_id":"ibmcld_03054-18427-20301","score":0.0298507463,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03118-4-2208","score":0.0294117647,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_16364-82764-84754","score":0.0289855072,"text":"\n* For a Phone integration, if you connect to existing speech service instances, make sure those speech services use credentials that were generated with the latest endpoint syntax (a URL that starts with https:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/).\n* For a search skill, if you connect to an existing Discovery service instance, make sure the Discovery service uses credentials that were generated with the supported syntax (a URL that starts with https:\/\/api.{location}.discovery.watson.cloud.ibm.com\/).\n* If you are using [Jupyter notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs) to do advanced analytics, check your Jupyter notebook files to make sure they don't specify URLs with the old watsonplatform.net syntax. If so, update your files.\n* No action is required for the following integration types:\n\n\n\n* Intercom\n* SMS with Twilio\n* WhatsApp with Twilio\n* Zendesk service desk connection from web chat\n\n\n\n\n\n\n\n\n\n 23 March 2021 \n\nActions skill improvement\n: Actions have a new toolbar making it easier to send feedback, access settings, save, and close.\n\n\n\n\n\n 17 March 2021 \n\nChannel transfer response type\n: Dialog skills now include a channel transfer response type. If your assistant uses multiple integrations to support different channels for interaction with users, there might be some situations when a customer begins a conversation in one channel but then needs to transfer to a different channel. The most common such situation is transferring a conversation to the web chat integration, to take advantage of web chat features such as service desk integration. For more information, see [Adding a Channel transfer response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-channel-transfer).\n\nIntercom and WhatsApp integrations now available in Lite plan\n: The integrations for Intercom and WhatsApp are now available in the Lite plan for Watson Assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03383-17365-19519","score":0.0285714286,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03054-19820-21851","score":0.0327868852,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03383-19002-21103","score":0.0322580645,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-19029-21139","score":0.0317460317,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03383-17365-19519","score":0.03125,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":0.0307692308,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03373-7076-8670","score":0.0303030303,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03043-4515-6369","score":0.0298507463,"text":"\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-diagram.png)\n\nFor help creating a search skill, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n Create the skill \n\nYou can add one skill of each skill type to an assistant.\n\n\n\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add)\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add)\n\n\n\n\n\n\n\n Skill limits \n\n\n\nSkill limit details\n\n Skills per service instance \n\n 50 \n\n\n\nSkill versions do not count toward the skill limit.\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants. From the Skills page, find the tile for the skill that you want to delete. The Assistants field lists the assistants that currently use the skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03383-20671-22804","score":0.0294117647,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":0.0289855072,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03054-22692-24767","score":0.0285714286,"text":"\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.\n* Search skill only: If only a search skill is linked to an assistant, and no dialog skill is linked to the assistant, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Try it out pane of the search skill.\n\nYou cannot test the full end-to-end user experience from the dialog skill's Try it out pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its Try it out pane.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, you must test it by using the API.\n\n\n\n1. From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2. Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n3. Copy the bearer token also. You will need to pass the token when you make an API call.\n4. From the dialog builder in the user interface, add a search skill response type to a dialog node.\n5. Make a note of the unique ID of the assistant to which you added the dialog that you edited in the previous step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2893079283}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":0.0327868852,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":0.0322580645,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16368-7-2072","score":0.0317460317,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-4-1877","score":0.03125,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-7-1721","score":0.0307692308,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-12876-14604","score":0.0303030303,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03421-1518-3290","score":0.0298507463,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-1365-2938","score":0.0294117647,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03196-30333-32476","score":0.0289855072,"text":"\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03166-4-2012","score":0.0285714286,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":0.0327868852,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-7-2072","score":0.0322580645,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16365-12876-14604","score":0.0317460317,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03080-7-1901","score":0.03125,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16389-0-2061","score":0.0307692308,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_03421-4-1877","score":0.0303030303,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03421-1518-3290","score":0.0298507463,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16334-24425-26157","score":0.0294117647,"text":"\n(For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history. For more information, see [instance.scrollToMessage()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsscrollToMessage).\n* A new pre:open event is available. This event is fired when the web chat window is opened, but before the welcome message or chat history are loaded. For more information, see [window:pre:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen).\n* A new chat history widget is available for embedding in service desk agent UIs. This new widget is based on a read-only view of the standard web chat widget. For information about using the new chat history widget in integrations built using the starter kit, see [Embedded agent application](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter\/blob\/main\/docs\/AGENT_APP.md).\n\n\n\n\n\n\n\n 4.4.1 \n\nRelease date: 6 July 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 4.4.0 \n\nRelease date: 25 June 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 4.3.0 \n\nRelease date: 7 June 2021\n\n\n\n* Search suggestions: If a search skill is configured for your assistant, the suggestions include a new View related content section. This section contains search results that are relevant to the user input.\n* Focus trap: A new enableFocusTrap option enables maintaining focus inside the web chat widget while it is open.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_03080-1529-3357","score":0.0289855072,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16334-27263-29119","score":0.0285714286,"text":"\nFor more information about the suggestions feature, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate). For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* onError callback: The new onError callback option in the web chat configuration enables you to specify a callback function that is called if errors occur in the web chat. This makes it possible for you to handle any errors or outages that occur with the web chat. For more information, see [Listening for errors](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail).\n* Session ID available in widget state: The state information returned by the getState() instance method now includes the session ID for the current conversation. For more information, see [instance.getState()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsgetState).\n* IBM watermark: The web chat can now display a Built with IBM Watson watermark to users. This watermark is always enabled for any new web chat integrations on Lite plans. For more information, see [Create a web chat instance to add to your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":0.0327868852,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16368-7-2072","score":0.0322580645,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16299-1512-2608","score":0.0317460317,"text":"\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)\n* [Extending your assistant using webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview): You use webhooks to call external services that extend the capabilities of your assistant or log activity.\n* Developing a custom channel: If none of the built-in channel integrations meet your needs, you can use the Watson Assistant REST API and SDKs to develop a custom client application that interacts with your assistant. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_02855-13982-15842","score":0.03125,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16368-1661-3409","score":0.0307692308,"text":"\nFor more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages). By subscribing to events, you can implement custom behavior or even intercept and modify message content. For more information about the event system, see [Events](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) in the web chat API reference.\n\n\n\nIf you want to use the web chat API to customize your web chat implementation, you don't have to start from scratch. Tutorials are available that show examples of common web chat customizations. For more information, see [Web chat development tutorials](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials).\n\n\n\n Development tasks \n\nYou can use the web chat API to customize and extend the web chat in the following ways.\n\nWeb chat style and content\n: \n\n* [Customizing the look of the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developlook)\n* [Customizing the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develophome-screen)\n* [Customizing strings](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developstrings)\n* [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developglobal-audiences)\n\n\n\nOpening, closing, and rendering the web chat window\n:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_02855-12369-14489","score":0.0303030303,"text":"\nThe text in the Option label field has two functions:\n\n\n\n* The text is shown in the suggestions list as an option for customers to select.\n* When selected by a customer, the text is sent to your assistant as a new message. The label must be able to function as input that your dialog understands and knows how to handle.\n\n\n\nBy default, the option label Connect with agent is used. Change the option label to a message that helps your customers reach whatever form of support you do offer. If you offer a toll-free support line, you might add Get the support line phone number. Or if you offer an online support request form, you might add Open a support ticket.\n\nWhether you use the default option label or add your own, make sure your dialog is designed to recognize the message and respond to it appropriately. For more information, see [Connecting customers with support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support).\n\n\n\n\n\n\n\n Dialog considerations \n\nThe rich responses that you add to a dialog are displayed in the web chat as expected, with the following exceptions:\n\n\n\n* Connect to human agent: This response type is ignored.\n* Option: If your option list contains up to four choices, they are displayed as buttons. If your list contains five or more options, then they are displayed in a drop-down list.\n* Pause: This response type pauses the assistant's activity in the chat. However, activity does not resume after the pause until another response is triggered. Whenever you include a pause response type, add another, different response type, such as text, after it.\n\n\n\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-5574-7284","score":0.0298507463,"text":"\nFor more information, see the [Using a custom launcher tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16384-7-2422","score":0.0294117647,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16299-7-2120","score":0.0289855072,"text":"\nOverview: Customizing and developing \n\nThe Watson Assistant user interface makes it easy to build an assistant and deploy it to your customers without writing any code. For advanced users and developers, there are powerful ways you can further customize and extend the capabilities of your assistant.\n\nA deployed assistant includes numerous components that work together to deliver the help your customers need over the channels they use.\n\n![Watson Assistant architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant using a channel such as the web chat or phone integration.\n* Based on natural language understanding, the assistant makes a decision about how to route the customer's request to the appropriate resolution mechanism, which might be an action or a search of existing content.\n* The assistant might also need to communicate with external services or hand off the conversation to a human agent.\n\n\n\nThere are multiple points at which a developer can customize and extend how the assistant behaves, or how it interacts with external services. These customization points include the following:\n\n\n\n* Customizing actions: By writing expressions and editing JSON data, you can extensively customize how an action evaluates step conditions, how it stores data, how it responds to customer input, and how it interacts with channels. (More information coming soon.)\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_03166-8640-10452","score":0.0285714286,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.819427028}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02875-7-2073","score":0.0327868852,"text":"\nAdding custom dialog flows for integrations \n\nUse the JSON editor in dialog to access information that is submitted from the web chat integration.\n\nThe context object that is passed as part of the v2 \/message API request contains an integrations object. This object makes it possible to pass information that is specific to a single integration type in the context. For more information about context variables, see [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables).\n\nThe integrations object is available from the v2 API in version 2020-04-01 or later only.\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-integrations"},{"document_id":"ibmcld_02855-16710-18404","score":0.0322580645,"text":"\nThe next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nRemember that a session ends if there's no interaction with the user after 1 hour (or whatever inactivity timeout setting you specify, which can be up to 7 days). Any contextual information that you pass or collect is reset after the inactivity time period is passed. For more information, see [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-settings).\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16388-7-1918","score":0.0317460317,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_03421-8091-9846","score":0.03125,"text":"\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses. The first response checks whether the current user is a member of your rewards program by checking for the presence of the $ismember context variable. If the variable is present, the response addresses the user as a member. The next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nIf you're using a Lite plan, remember that a session ends if there's no interaction with the user after 5 minutes. When the session ends, any contextual information that you pass or collect is reset.\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-authenticate).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-8169-9970","score":0.0307692308,"text":"\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses. The first response checks whether the current user is a member of your rewards program by checking for the presence of the $ismember context variable. If the variable is present, the response addresses the user as a member. The next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nIf you're using a Lite plan, remember that a session ends if there's no interaction with the user after 5 minutes. When the session ends, any contextual information that you pass or collect is reset.\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03180-5630-7213","score":0.0303030303,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_03080-5624-7473","score":0.0298507463,"text":"\nFor more information about how to customize it, see [HTML content](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhtml).\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-set-context)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03188-3379-5204","score":0.0294117647,"text":"\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)\n\n\n\n\n\n* [SMS with Twilio](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-smsdeploy-sms-dialog)\n\n\n\n\n\n* [Assistant preview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-linkdeploy-web-link-dialog)\n\n\n\nIf you need to provide customized responses for different channels, and you do not need to modify your dialog flow based on which integration is in use, you can also use the channels array to target your responses to specific integrations. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_16298-6367-7794","score":0.0289855072,"text":"\nFor more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n\/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, \/\/ Required\niss: 'www.ibm.com', \/\/ Required\nacr: 'loa1' \/\/ Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_02855-27616-29462","score":0.0285714286,"text":"\nreturn new Promise(function(resolve, reject) {\n\/\/ And then pass the new JWT into the callback and the service will resume processing messages.\nevent.identityToken = 'YOUR NEW JWT';\nresolve();\n});\n}});\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n<\/script>\nShow more\n\n\n\n\n\n\n\n Passing sensitive data \n\nYou can optionally copy the public key that is provided by IBM, and use it to add an additional level of encryption to support passing sensitive data from the web chat.\n\nUse this method to send sensitive information in messages that come from your website, such as a information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from your dialog. Information that is passed to your assistant in this way is stored in a private variable in your assistant. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for less important customers. You likely do not want non-VIPs to know that they are categorized as such. But you must pass this informataion to your dialog because it changes the route of the conversation. You can pass the customer MVP status as an encrypted variable. This private context variable will be available for use by the dialog, but not by anything else.\n\n\n\n1. From the web chat configuration page, copy the public key from the IBM provided public key field.\n2. From your website, write a function that signs a JSON Web Token.\n\nFor example, the following NodeJS code snippet shows a function that accepts a userID and payload content and sends it to the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1772392868}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":0.0327868852,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":0.0322580645,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16375-1468-2933","score":0.0317460317,"text":"\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",\n\/\/ A UUID like '6435434b-b3e1-4f70-8eff-7149d43d938b' included in the embed code provided in Watson Assistant.\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\/\/ The callback function that is called after the widget instance has been created.\nonLoad: function(instance) {\ninstance.render();\n},\nshowLauncher: false, \/\/ Hide the web chat launcher, you will open the WebView from your mobile application\nopenChatByDefault: true, \/\/ When the web chat WebView is opened, the web chat will already be open and ready to go.\nhideCloseButton: true \/\/ And the web chat will not show a close button, instead relying on the controls to close the WebView\n};\nsetTimeout(function(){const t=document.createElement('script');t.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/versions\/\" + (window.watsonAssistantChatOptions.clientVersion || 'latest') + \"\/WatsonAssistantChatEntry.js\";document.head.appendChild(t);});\n<\/script>\n<\/body>\n<\/html>\nShow more\n\nIn your app, make sure you include logic to hide your web chat launching mechanism when the device is offline. If the device goes offline in the middle of a conversation, appropriate error messages and retries occur.\n\n\n\n\n\n Using a JavaScript bridge","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_16380-1665-3330","score":0.03125,"text":"\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM. This example looks up the element using the ID we assigned to it:\n\nconst customElement = document.querySelector('WebChatContainer');\n3. In the web chat embed script, set the element property, specifying the reference to your custom element.\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\n\/\/ The important piece.\nelement: customElement,\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n4. Make sure that the main web chat window is hidden by default. You can do this in the onLoad event handler, after render has been called. You must also add handlers to listen for the window:open and window:close events so the customer can open and close the web chat after the page loads. In our example, we are using a CSS class called HideWebChat to do this (see the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/webchat\/examples\/custom-element\/client\/javascript-animation\/index.html) for the definition of this class):\n\nfunction onLoad(instance) {\ninstance.render();\ninstance.on({ type: 'window:close', handler: closeHandler });\ninstance.on({ type: 'window:open', handler: openHandler });\ninstance.elements.getMainWindow().addClassName('HideWebChat');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16377-7-1723","score":0.0307692308,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_16368-1661-3409","score":0.0303030303,"text":"\nFor more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages). By subscribing to events, you can implement custom behavior or even intercept and modify message content. For more information about the event system, see [Events](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) in the web chat API reference.\n\n\n\nIf you want to use the web chat API to customize your web chat implementation, you don't have to start from scratch. Tutorials are available that show examples of common web chat customizations. For more information, see [Web chat development tutorials](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials).\n\n\n\n Development tasks \n\nYou can use the web chat API to customize and extend the web chat in the following ways.\n\nWeb chat style and content\n: \n\n* [Customizing the look of the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developlook)\n* [Customizing the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develophome-screen)\n* [Customizing strings](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developstrings)\n* [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developglobal-audiences)\n\n\n\nOpening, closing, and rendering the web chat window\n:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16380-7-2028","score":0.0298507463,"text":"\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16295-7-1721","score":0.0294117647,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16375-7-1735","score":0.0289855072,"text":"\nAdding the web chat to your mobile application \n\nIf you have a mobile application built on a mobile framework such as iOS, Android, or React Native, you can use a WebView with a JavaScript bridge to communicate between your app and the Watson Assistant web chat.\n\nUsing WebViews with a JavaScript bridge is a common pattern with a similar implementation for all mobile frameworks.\n\n\n\n Including the web chat as a WebView \n\nYou can include the web chat interface as part of a page of your mobile app, or as a separate panel that your app opens. In either case, you must host an HTML page that includes the web chat embed script, and then include that page as a WebView in your app.\n\nIn the embed script, use the showLauncher option to hide the web chat launcher icon, and the openChatByDefault option to open the web chat automatically when the page loads. In most cases, you will also want to use the hideCloseButton option and use the native controls of your app to control how the web chat page or panel closes. For more information about the configuration options you can specify in the embed script, see the [Web chat API reference](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration).\n\nThe following example shows an embed script that includes these configuration options:\n\n<html>\n<head>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n<\/head>\n<body>\n<script>\nwindow.watsonAssistantChatOptions = {\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_16377-1361-3020","score":0.0285714286,"text":"\nTo create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens. This handler uses the [customPanels.getPanel()](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-topicid) instance method to open a custom panel that will contain the pre-chat form.\n\nYour handler should return a promise that is resolved when the custom panel is closed. This prevents the web chat window from opening until after the pre-chat form is completed.\n\nfunction windowOpenHandler(event, instance) {\nreturn new Promise((resolve) => {\n\/\/ Save a reference to the resolve function so we can resolve\n\/\/ this promise later.\npromiseResolve = resolve;\ncreateOpenPanel(event, instance);\n\nconst customPanel = instance.customPanels.getPanel();\ncustomPanel.open({ hidePanelHeader: true,\ndisableAnimation: true });\n});\n}\n2. In your onLoad event handler, use the [on()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodson) instance method to subscribe to the window:open event, registering the handler as the callback.\n\ninstance.on({ type: 'window:open', handler: windowOpenHandler });\n3. Create a function that creates the pre-chat form you want to show inside the custom panel. Make sure you resolve the promise when the user closes the panel.\n\nfunction createOpenPanel(event, instance) {\nconst customPanel = instance.customPanels.getPanel();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03369-64600-66787","score":0.0327868852,"text":"\n: Want a quick way to see how your dialog is doing at responding to customer queries? Enable the new coverage metric to find out. The coverage metric measures the rate at which your dialog is confident that it can address a customer's request per message. For conversations that are not covered, you can review the logs to learn more about what the customer wanted. For the metric to work, you must design your dialog to include an Anything else node that is processed when no other dialog node intents are matched. For more information, see [Graphs and statistics](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n\nTry out the enhanced intent detection model\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time.\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-72974-74749","score":0.0322580645,"text":"\nFor more information, see [Create a data collection](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-create-discovery-collection).\n\n\n\n\n\n\n\n 16 September 2020 \n\nSearch skill refinement change\n: The search refinement beta feature that was added in [June](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes24jun2020) now is disabled by default. Enable the feature to refine the search results that are returned from the Discovery service. For more information, see [Configure the search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-configure).\n\n\n\n\n\n 25 August 2020 \n\nGive the web chat integration a try!\n: You can now use the web chat integration with a Lite plan. Previously, the web chat was available to Plus or higher plans only. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n\n\n 12 August 2020 \n\nv2 Logs API is available\n: If you have a Premium plan, you can use the v2 API logs method to list log events for an assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs) documentation.\n\n\n\n\n\n 5 August 2020 \n\nEnable your skill to improve itself\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nShow more of search results","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-110490-112399","score":0.0317460317,"text":"\nFor more information, see [Configure the search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-configure).\n\n\n\n\n\n 25 August 2020 \n\nGive the web chat integration a try!\n: You can now use the web chat integration with a Lite plan. Previously, the web chat was available to Plus or higher plans only. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n\n\n 12 August 2020 \n\nv2 Logs API is available\n: If you have a Premium plan, you can use the v2 API logs method to list log events for an assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs) documentation.\n\n\n\n\n\n 5 August 2020 \n\nEnable your skill to improve itself\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16365-14167-16117","score":0.03125,"text":"\n{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use a Content Security Policy (CSP), and implement other basic web security precautions.\n\n\n\n\n\n\n\n Billing \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nBy default, the web chat creates a unique, anonymous ID the first time a new user starts a session. This identifier is stored in a first-party cookie, which remains active for 45 days. If the same user returns to your site and chats with your assistant again while this cookie is still active, the web chat integration recognizes the user and uses the same user ID. This means that you are charged only once per month for the same anonymous user.\n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16334-35243-37326","score":0.0307692308,"text":"\n* Bug fix: Fixing a bug that prevented the web chat integration preview from working after security was enabled.\n\n\n\n\n\n\n\n 3.2.0 \n\nRelease date: 26 October 2020\n\n\n\n* Security improvement: If you enable security, you no longer need to include the identityToken property when the web chat is loaded on a web page. If a token is not initially provided, the existing identityTokenExpired event will be fired when the web chat is first opened to obtain one from your handler.\n* Starter kit update: The starter kit now allow you to customize the timeout that occurs when the web chat integration checks whether any service desk agents are online.\n\n\n\n\n\n\n\n 3.1.1 \n\nRelease date: 22 October 2020\n\n\n\n* Accessibility improvement: Changed how the announcement text is generated to prevent announcements from being duplicated. Announcement text is hidden text that is provided for use by screen readers to indicate when dynamic web page changes occur.\n\n\n\n\n\n\n\n 3.1.0 \n\nRelease date: 8 October 2020\n\n\n\n* Suggestions now allow for trial and error: If customers select a suggestion and find that the response is not helpful, they can open the suggestions list again and try a different suggestion.\n\n\n\n\n\n\n\n 3.0.0 \n\nRelease date: 22 September 2020\n\n\n\n* Choose when a link to support is included in suggestions: The Suggestions beta feature has moved to its own tab. Now you can enable suggestions even if your web chat is not set up to connect to a service desk solution. That's because now you can control if and when the option to connect to customer support is available from the suggestions list. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n* Search result format change: To support the ability to show more than 3 search results in a response, the search skill response type format changed. If you are using pre:receive or receive handlers to process search results, you might need to update your code. The results property was replaced by the primary_results and additional_results properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_03162-2864-4981","score":0.0303030303,"text":"\nFor more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n2. From the web chat integration page in Watson Assistant, set the Allow transfers to live agents switch to On, and then choose Salesforce as the service desk type. Click Next.\n3. For Watson Assistant to connect to a Salesforce service desk, it needs information about your organization's Salesforce chat deployment and button implementations. Specifically, it needs the API endpoint, organization ID, deployment ID, and button ID. The service can derive the values that it needs from code snippets that you copy and paste to this configuration page.\n\nIn a separate browser tab or window, open your Salesforce account settings page. Log in with a user ID that has administrative privileges. You must switch back and forth between your Salesforce and Watson Assistant web chat integration setup pages. It's easier to do so if you have both pages open at once.\n\n\n\n* Get the deployment code for your Salesforce Agent Configuration chat deployment.\n\nGo to the Salesforce Feature Settings>Service>Chat>Deployments page. Find your organization's deployment. Scroll to the end of the chat deployment configuration page and copy the Deployment Code snippet.\n* Paste the deployment code snippet into the Deployment code field in the Watson Assistant Salesforce configuration page.\n* Get the Chat Button code.\n\nGo to the Salesforce Feature Settings>Service>Chat>Chat Buttons & Invitations page. Find your organization's button implementation. Scroll to the end of the page, and then copy the Chat Button Code snippet.\n* Paste the chat button code snippet into the Chat button code field in the Watson Assistant Salesforce configuration page, and then click Next.\n\n\n\n4. Add a chat app that enables the Salesforce agent to see a history of the chat. To do so, create a Visualforce page, and then add a chat app to the page.\n5. Add custom fields to the Salesforce chat transcript layout.\n\nThis is a one-time task. If the fields already exist for your organization, you can skip this step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_03166-15591-17736","score":0.0298507463,"text":"\n* For information about CSS helper classes that you can use to change the home screen style, see the [prebuilt templates](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhtml) documentation.\n\n\n\n\n\n\n\n Showing more suggestions \n\nSuggestions give your customers a way to try something else when the current exchange with the assistant isn't delivering what they expect. A question mark icon ![Question mark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/question-mark.png) is displayed in the web chat that customers can click at any time to see other topics that might be of interest or, if configured, to request support. Customers can click a suggested topic to submit it as input or click the X icon to close the suggestions list.\n\nStarting with web chat version 3.1, if customers select a suggestion and the response is not helpful, they can open the suggestions list again to try a different suggestion. The input generated by the first choice is submitted and recorded as part of the conversation. However, any contextual information that is generated by the initial suggestion is reset when the subsequent suggestion is submitted.\n\nThe suggestions are shown automatically in situations where the customer might otherwise become frustrated. For example, if a customer uses different wording to ask the same question multiple times in succession, and the same dialog node is triggered each time, then related topic suggestions are shown in addition to the triggered node's response. The suggestions that are offered give the customer a quick way to get the conversation back on track.\n\nThe suggestions list is populated with dialog nodes that condition on intents that are related in some way to the matched intent. The intents are ones that the AI model considered to be possible alternatives, but that didn't meet the high confidence threshold that is required for a node to be listed as a disambiguation option. Any dialog node with a node name (or external node name) can be shown as a suggestion, unless its Show node name setting is set to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03313-6149-8039","score":0.0294117647,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n\n\n\n\n I can't log in \n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_07578-5954-7906","score":0.0289855072,"text":"\nYou can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-5954-7906","score":0.0285714286,"text":"\nYou can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03871-31988-33751","score":0.0327868852,"text":"\nSelect Provide a JSON identity file from the IBM Blockchain Platform and then browse to the admin identity that you exported from your console. If the identity is the administrator of multiple nodes in your network, you can associate the identity with multiple nodes.\n\n\n\nWhen you have associated an admin identity with your peers, CA, and an ordering node, you can connect to your network and use the extension to deploy smart contracts.\n\n\n\n\n\n\n\n Adding wallets and users \n\nUse the following steps to create a new wallet by using a certificate and private key:\n\n\n\n1. Hover your mouse over the Fabric Wallets pane and click +.\n2. Choose to Create a new wallet and add an identity from the options. Provide a name for your wallet and your identity.\n3. Enter the MSP ID of your organization.\n4. Choose to add a certificate and private key.\n5. If you use a certificate and private key, browse to the certificate and private key.\n\n\n\nYou can also add new users to the wallets that have already been created:\n\n\n\n1. In the Fabric Wallets pane, right-click a wallet and select Add Identity.\n2. Provide a name for the identity and an MSP ID.\n3. You can upload a JSON file, provide a certificate and private key, or provide an enrollment ID and secret.\n\n\n\n* If you are connecting to a network on the IBM Blockchain Platform, you can download an identity from your IBM Blockchain console, either by exporting an identity from your wallet or by enrolling and then exporting an identity using your Certificate Authority. You can then upload the JSON file directly to VS Code.\n* If you use a certificate and private key, browse to the certificate and private key.\n* If you use an enrollment ID and secret, choose the gateway to enroll with and enter the enrollment ID and secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"},{"document_id":"ibmcld_16234-1331-2901","score":0.0322580645,"text":"\nAdding users from this menu enables them to read, write, and manage all assistants in the service instance.\n4. Click Submit.\n\n\n\nAfter you click Submit, any user that you invite receives an email to access the instance. After they accept the invite, they can open the service instance and manage all assistants.\n\n\n\n\n\n Managing access with Identity and Access Management \n\nAnother way to add users to your assistants is using Identity and Access Management (IAM). If you want to add users, and you don't want them to have full Manager access, use IAM to add them. From IAM, you can also manage access roles of those users that are already added to your assistants.\n\n\n\n Opening Identity and Access Management \n\n\n\n1. Open the Manage menu. ![Manage menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/user--avatar.svg)\n2. Click Manage users.\n3. In Access and permissions, click Identity and Access Management in step 2.\n\nZoom\n\n![Access and permissions](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/access-control-manage-users-modal.png)\n\nAccess and permissions\n\n\n\n\n\n\n\n Adding users in Identity and Access Management \n\n\n\n1. In IAM, click Invite users.\n2. Enter the email address of the person who needs access.\n3. In How do you want to assign access?, choose Access policy.\n\nZoom\n\n![Access policy](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/access-policy.png)\n\nAccess policy\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control"},{"document_id":"ibmcld_03966-9450-11507","score":0.0317460317,"text":"\nBe sure that you have [set the identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_16234-7-1792","score":0.03125,"text":"\nManaging access \n\nIf you need to collaborate with others on your assistants, you can quickly add users to your service instance from the Manage menu. Or to tailor specific access to your assistants, use the [Identity and Access Management (IAM) page](https:\/\/cloud.ibm.com\/iam\/users) in IBM Cloud.\n\n\n\n Adding users from the Manage menu \n\nIn the new Watson Assistant, each assistant contains all the draft and live resolution methods (actions and search integration) and channels you add (such as web chat, Facebook, or Slack). The simplest way to provide access is to add users to your Watson Assistant service instance with manager access to all assistants. Users get all the privileges that they need to build and deploy any assistant.\n\nTo quickly add users with manager access to all assistants, complete the following steps:\n\n\n\n1. Open the Manage menu. ![Manage menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/user--avatar.svg)\n2. Click Add users.\n3. Enter the email addresses of the users that you want to provide full access to. Separate email addresses with commas, spaces, or line breaks.\n\nZoom\n\n![Add users](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/add-users.png)\n\nAdd users\n\nAdding users from this menu enables them to read, write, and manage all assistants in the service instance.\n4. Click Submit.\n\n\n\nAfter you click Submit, any user that you invite receives an email to access the instance. After they accept the invite, they can open the service instance and manage all assistants.\n\n\n\n\n\n Managing access with Identity and Access Management \n\nAnother way to add users to your assistants is using Identity and Access Management (IAM).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control"},{"document_id":"ibmcld_02774-5358-7120","score":0.0307692308,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_06966-6860-8310","score":0.0303030303,"text":"\nFor more information, see [Giving users access to a Watson Discovery instance](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-discovery\/discovery-admin-add-users.html).\n3. Enable document-level security for the data source when you connect to it.\n\n\n\n\n\n Creating users for document-level security \n\nYou must create users that match the users available on the source system that Discovery is connecting to so that they can query with document-level security enabled.\n\n\n\n1. Log in to Discovery as an administrator.\n2. Create users who match the users available on your source or who are connected to the identity provider that your source system uses. If you create users for document-level security, keep the following points in mind:\n\n\n\n* Optional: For each user that you want to have access to query results, you must add users. The username must match the username that the source uses. This option is only for development and testing purposes. To create users individually, see [Managing users](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/users.html).\n* To connect to an identity provider that the source is using, see [Connecting to your identity provider](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/ldap.html).\n\n\n\n\n\nDiscovery does not synchronize changes that are made to the users in the identity provider with the user list for the service. Discovery administrators must ensure that the user list is current and remove any noncurrent users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-types"},{"document_id":"ibmcld_03966-11017-13066","score":0.0298507463,"text":"\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user. If that option is not available, it can be enabled on your CA by overriding the CA configuration. See an example of how to enable this feature in [Modifying a CA configuration after deployment](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-ca-modify-json). Note this action does not revoke the associated certificates for the user. If you need to do that you would need to insert the associated signed certificate into the organization MSP under the \"revocation_list\": section. And then update that MSP definition everywhere that it occurs on the network.\n\n\n\n Creating new CA admins \n\nBy default, only the CA admin that is created during deployment has the ability to register new identities. You can create identities with the ability the register new users by using the Attributes panel of the registration process.\n\nOn the second side panel, click the Add Attribute button. Provide an attribute name of hf.Registrar.Roles. Enter an attribute value of . You can also use this panel to create an identity that can register only certain identity types, such as clients or peers, or within a certain affiliation. You can also create an identity that has the ability to revoke an identity and all the certificates that the identity has been issued. You can see a full list of the attributes in the [Registering a new identity](https:\/\/hyperledger-fabric-ca.readthedocs.io\/en\/release-1.4\/users-guide.htmlregistering-a-new-identity) section of the Fabric CA users guide.\n\n\n\n\n\n\n\n Enrolling an identity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_02734-7-2170","score":0.0294117647,"text":"\nAnonymous authentication \n\nWith IBM Cloud\u00ae App ID, you can allow users to anonymously browse your application under an anonymous user profile. If the user chooses to sign in, you can allow them to still access their anonymous attributes by attaching their anonymous profile to their user identity with App ID.\n\n\n\n Understanding progressive authentication \n\nWhen a user chooses not to sign in immediately, they are considered an anonymous user. For example, say you're an online retailer and you want to allow users to add objects to their shopping cart without signing in. However, you ask them to sign in to complete their purchase. If a user chooses to sign in, you can allow them to access the same objects that were in their shopping carts before they signed in.\n\nYou can use App ID to gather information about anonymous users into an anonymous user profile, which you can use to help personalize their experience of your application. If the user chooses to signs in, you can attach the user attributes that are part of the anonymous profile to their user identity that is stored in App ID. Anonymous profiles are temporarily valid. While you develop your app, you can [configure the lifetime](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpidp-token-lifetime) of anonymous tokens.\n\nWhen a user signs in, they become an identified user. If an existing identified user profile does not exist, you can create a new identified user profile. After a user is identified, App ID issues new access and identity tokens and their anonymous token becomes invalid. However, an identified user can still access the attributes of their anonymous profile because they are accessible with the new access and identity tokens.\n\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_03871-30641-32553","score":0.0289855072,"text":"\nEnter the User ID for the console instance.\n6. Enter the Password for the console instance.\n7. Select Proceed without certificate verification, or Cancel if you're planning to add the CA certificates to the operating systems trusted CA certificate store.\n8. Enter a name for your environment.\n9. Select the CAs and peers that belong to your organization, along with the ordering nodes of your channels, click OK when done.\n\n\n\nIn steps 5 and 6, you can alternatively enter an API key and secret that you generate using the [IBM Blockchain Platform REST APIs](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-ibp-v2-apisconsole-icp-manage-create-api-key).\n\nYou also need to import your admin identities into the wallet pane and associate them with your nodes. You need to associate an admin identity with your peers, CA, and an ordering node before you can connect with your network.\n\n\n\n1. Click on the environment that you created in the Fabric Environments pane.\n2. You can see an Alert sign next to the peer and ordering node. Click on the alert to associate an admin identity with the node.\n3. Select Add a new wallet.\n4. Select Create a new wallet.\n5. Enter a name for your wallet to identify the orderer or peer admin of your network.\n6. Select Add a new identity.\n7. Enter name for your peer or orderer admin identity.\n8. Select Provide a JSON identity file from the IBM Blockchain Platform and then browse to the admin identity that you exported from your console. If the identity is the administrator of multiple nodes in your network, you can associate the identity with multiple nodes.\n\n\n\nWhen you have associated an admin identity with your peers, CA, and an ordering node, you can connect to your network and use the extension to deploy smart contracts.\n\n\n\n\n\n\n\n Adding wallets and users \n\nUse the following steps to create a new wallet by using a certificate and private key:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"},{"document_id":"ibmcld_02766-7-2005","score":0.0285714286,"text":"\nManaging authentication \n\nIdentity providers (IdP's) add a level of security for your mobile and web apps, through authentication. With IBM Cloud\u00ae App ID, you can configure one or several identity providers to create a custom sign-in experience for your users.\n\nApp ID interacts with identity providers by using various protocols such as OpenID Connect, SAML, and more. For example, OpenID Connect is the protocol that is used with many social providers such as Facebook, Google. Enterprise providers such as [Azure Active Directory](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-azure-active-directory) or [Active Directory Federation Service](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-active-directory-federation-service), generally use SAML as their identity protocol. For [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), the service uses SCIM to verify identity information.\n\nWhen you use social or enterprise identity providers, App ID reads user account information. Because the service never has write access to the information, users must go through their chosen identity provider to do actions, such as resetting their password. For example, if a user signs in to your app with Facebook, and then wanted to change their password, they must go to www.facebook.com to do so.\n\nWhen you use [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), App ID is the identity provider. The service uses your registry to verify your users identity. Because App ID is the identity provider, users can take advantage of advanced functionality, such as resetting their password, directly in your app.\n\nWorking with application identity? Check out [Application identity](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-app).\n\nSeveral identity providers can be configured to be used by App ID. Check out the following table to learn about your options.\n\n\n\nTable 1. Identity provider options\n\n Identity provider Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":0.0327868852,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16377-7-1723","score":0.0322580645,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_16365-7-1700","score":0.0317460317,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16366-2985-3766","score":0.03125,"text":"\nFor more information, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity\n: You can protect your users' private information and prevent unauthorized messages to your assistant by enabling security on the Security tab. For more information about web chat security and how it works, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16384-7-2422","score":0.0307692308,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16334-23017-24816","score":0.0303030303,"text":"\n* Support for Carbon components: As part of the new styling support, you can now use [Carbon components](https:\/\/www.carbondesignsystem.com\/components\/overview\/) in user-defined responses and web chat writeable elements. These components will inherit any theming customizations you have made to the web chat.\n* New embedded script: The embedded script you use to add the web chat to your website has been updated to avoid unexpected code changes when you lock on to a web chat version. (For more information about web chat versioning, see [Versioning](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-versions).) The previous version of the script will continue to work but is now deprecated. If you want to upgrade your existing web chat deployments to use the new script, copy the updated code snippet from the Embed tab of the web chat integration settings. (Remember to reapply any customizations you have made.)\n* Removal of deprecated methods and events:\n\n\n\n* The error event has been replaced by the onError method in the [configuration object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/testfest.html?to=api-configurationconfigurationobject).\n* The getID method has been removed.\n\n\n\n* Microsoft Internet Explorer 11 is no longer a supported browser.\n\n\n\n\n\n\n\n 4.5.1 \n\nRelease date: 30 August 2021\n\n\n\n* Bug fixes for the interactive launcher beta feature. (For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16380-7-2028","score":0.0298507463,"text":"\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16368-6482-8187","score":0.0294117647,"text":"\n[development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Example: For a working example that shows how to add custom elements to the home screen, see [Home screen custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/home-screen-custom-element).\n* To change the home screen style, use [CSS helper classes](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhelper_classes).\n\n\n\nCustomizing strings\n: You can customize the strings that define the various labels and hardcoded phrases displayed by the web chat. To customize strings, use the [updateLanguagePack()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace strings in the current language pack. For more information, see [Languages](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n\nSupporting global audiences\n: By default, the strings displayed by the web chat are in English. To change to a different language, use the [updateLanguagePack()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace the current language pack with one of the available translated language packs. For more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Opening, closing, and rendering the web chat window \n\nReplacing the default launcher","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16381-0-734","score":0.0289855072,"text":"\n\n\n\n\n\n\n  Web chat development tutorials \n\nThe tutorials in this section provide detailed examples, including code snippets, showing customizations that you can implement using the web chat API.\n\nEach tutorial includes links to a [GitHub repository](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/) where you can download complete working code for the example. You can run this code to see the customization in action, adapt it for your own web chat implementation, or use it as a guide for similar customizations of your own.\n\nThe GitHub repository also includes additional tutorials and examples that have not yet been added to this documentation, so feel free to browse.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials"},{"document_id":"ibmcld_16365-10062-12114","score":0.0285714286,"text":"\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
