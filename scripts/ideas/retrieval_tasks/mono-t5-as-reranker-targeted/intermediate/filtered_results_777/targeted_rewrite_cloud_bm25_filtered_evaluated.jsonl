{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02361-22962-24900","score":28.9566853496,"text":"\nIn the UI, you can define custom views, dashboards, parsing templates, screens, and exclusion rules that you can use to view and analyze data.\n\nTo reuse resource definitions that you define in your auditing instance, you can export these resources from an IBM Cloud Activity Tracker instance as a JSON file. Then, you can import the definitions into other auditing instances. For example, you can reuse your resources across different environments for your stage, pre-production, and production instances. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-reuse_resource_definitions).\n\nBackup resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from an auditing instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision an auditing instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for an auditing instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_09275-30068-31881","score":28.3970595851,"text":"\nFor example, you can reuse your logging resources across different environments for your stage, pre-production, and production logging instances. [Learn more](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-reuse_resource_definitions).\n\nBackup logging resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from a logging instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision a logging instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for a logging instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_05138-7979-9034","score":21.6614254504,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"},{"document_id":"ibmcld_02361-24500-26305","score":21.6566470481,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_05010-7-1832","score":20.9551150363,"text":"\nFAQ - General \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n How can I find out the total size of my bucket by using the API? \n\nYou can use the [Resource Configuration API](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) to get the bytes used for a given bucket.\n\n\n\n\n\n How can I view my buckets? \n\nYou can view and navigate your buckets using the console, CLI or the API.\n\nFor example, the CLI command ibmcloud cos buckets will list all buckets associated with the targeted service instance.\n\n\n\n\n\n Can I migrate data from AWS S3 into IBM Cloud Object Storage? \n\nYes, you can use your existing tools to read and write data into IBM Cloud Object Storage. You need to configure HMAC credentials allow your tools to authenticate. Not all S3-compatible tools are currently unsupported. For details, see [Using HMAC credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-uhc-hmac-credentials-main).\n\n\n\n\n\n Can I use AWS S3 SDKs with IBM Cloud Object Storage? \n\nYes, IBM COS SDKs are based on the official AWS S3 API SDKs, but are modified to use IBM Cloud features, such as IAM, Key Protect, Immutable Object Storage, and others. When using these SDKs, use HMAC authorization and an explicit endpoint. For details, see [About IBM COS SDKs](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-sdk-about).\n\n\n\n\n\n Is there a 100-bucket limit to an account? What happens if I need more? \n\nYes, 100 is the current bucket limit. Generally, prefixes are a better way to group objects in a bucket, unless the data needs to be in a different region or storage class. For example, to group patient records, you would use one prefix per patient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_06808-1384-2991","score":20.656037953,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_05168-15740-17188","score":20.5870542533,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04866-4961-6763","score":20.2927287503,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":20.2927287503,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-6428-8391","score":20.2436344382,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14654-7-1943","score":20.2503967313,"text":"\nPlanning for vCenter Server instances \n\nPlan your instance based on the IBM Cloud\u00ae data center location, your workload capacity requirements, and add-on services requirements. Review the following requirements before you order your VMware vCenter Server\u00ae instance.\n\n\n\n* New deployments of vCenter Server instances with VMware vSphere\u00ae 6.5 or 6.7 are not supported.\n* New deployments of vCenter Server multizone instances are not supported.\n* New deployments of vCenter Server with NSX-V instances are not supported.\n\n\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vCenter Server deployment has strict requirements on the physical infrastructure. Therefore, you can deploy instances only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vCenter Server deployment.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for vCenter Server instances\n\n Geography Data center Pod Server options for NSX-T<br><br>[1] Server options for NSX-V<br><br>[2] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake<br><br>[3] \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_planning"},{"document_id":"ibmcld_14823-7-1880","score":19.4609897702,"text":"\nPlanning for VMware vSphere \n\nReview the following requirements before you order a VMware vSphere\u00ae instance. Plan your VMware vSphere based on the IBM Cloud\u00ae data center location and your workload capacity requirements.\n\nYou are responsible for setting up the environment, installing, and configuring various VMware\u00ae components after the VMware ESXi\u2122 servers are deployed. The following examples are VMware components: VMware vCenter Server\u00ae, VMware NSX\u00ae, and VMware vSAN\u2122.\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vSphere deployment has strict requirements on the physical infrastructure. Therefore, you can deploy clusters only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vSphere deployment.\n\nCascade Lake bare metal servers are available in\n\nmultizone regionIBM Cloud data centers. For more information, see [Multizone region (MZR) overview](https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-multi-zone-region-mzr-overview).\n\nIf you select a vSAN component, the location list is filtered by SSD (Solid-State Disk) availability.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for VMware vSphere instances\n\n Geography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"},{"document_id":"ibmcld_14823-1485-2621","score":19.3769311941,"text":"\nGeography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD04 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD05 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK02 01-02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK04 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK05 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n\n\n\n\n\n\n\n Related links \n\n\n\n* [Ordering VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-req)\n* [Adding ESXi servers to VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_addingservers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"},{"document_id":"ibmcld_13162-12751-14416","score":19.26679047,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-11690-13171","score":18.3693732748,"text":"\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16729-11586-13439","score":18.3039087654,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_03538-14399-15690","score":18.17468069,"text":"\nYour account settings would look like:\n\nibmcloud atracker setting get\nOK\nIBM Cloud Activity Tracker settings\nMetadata region primary: us-east\nDefault targets: []\nPermitted target regions: [us-east]\nPrivate api endpoint only: false\nAPI version: 2\n\nYour target would look like:\n\nibmcloud atracker target ls\nListing IBM Cloud Activity Tracker targets for all regions...\nOK\nName ID Region Type Service to Service Enabled CreatedAt UpdatedAt\ntarget-logdna <LOGDNA TARGET ID 1> us-east logdna - 2022-05-16T17:16:05.234Z 2022-05-16T17:16:05.234Z\n\n\n\n\n\n Data Lake scenario \n\nYou can choose any of the following options to send auditing events to a data lake:\n\n\n\n* Configure your account to route auditing events to Activity Tracker Event Routing hosted event search instances. Stream the events to Event Streams, and then, send them to a data lake. You can filter the data to be streamed to the data lake.\n\nSimplify the Activity Tracker Event Routing hosted event search configuration so only 1 instance needs to be configured to feed auditing events to Event Streams.\n* Configure Activity Tracker Event Routing in your account to route auditing events directly to an IBM Cloud Object Storage data lake.\n\nUse this option for Financial Services Cloud workloads where end-to-end compliance is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-scenarios&interface=cli"},{"document_id":"ibmcld_03537-14329-15620","score":18.17468069,"text":"\nYour account settings would look like:\n\nibmcloud atracker setting get\nOK\nIBM Cloud Activity Tracker settings\nMetadata region primary: us-east\nDefault targets: []\nPermitted target regions: [us-east]\nPrivate api endpoint only: false\nAPI version: 2\n\nYour target would look like:\n\nibmcloud atracker target ls\nListing IBM Cloud Activity Tracker targets for all regions...\nOK\nName ID Region Type Service to Service Enabled CreatedAt UpdatedAt\ntarget-logdna <LOGDNA TARGET ID 1> us-east logdna - 2022-05-16T17:16:05.234Z 2022-05-16T17:16:05.234Z\n\n\n\n\n\n Data Lake scenario \n\nYou can choose any of the following options to send auditing events to a data lake:\n\n\n\n* Configure your account to route auditing events to Activity Tracker Event Routing hosted event search instances. Stream the events to Event Streams, and then, send them to a data lake. You can filter the data to be streamed to the data lake.\n\nSimplify the Activity Tracker Event Routing hosted event search configuration so only 1 instance needs to be configured to feed auditing events to Event Streams.\n* Configure Activity Tracker Event Routing in your account to route auditing events directly to an IBM Cloud Object Storage data lake.\n\nUse this option for Financial Services Cloud workloads where end-to-end compliance is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-scenarios"},{"document_id":"ibmcld_13466-0-409","score":17.9926423103,"text":"\n\n\n\n\n\n\n  Data transport automation to Db2 on Cloud \n\nIBM Cloud\u00ae Data Engine supports automating the transport and transformation of data from IBM Cloud\u00ae Object Storage to IBM\u00ae Db2\u00ae on Cloud. Read how you can [automate serverless data pipelines for your data warehouse or data lakes](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/automate-serverless-data-pipelines-for-your-data-warehouse-or-data-lakes).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-db2"},{"document_id":"ibmcld_16728-5097-7108","score":17.9888731813,"text":"\n[solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Bring Your Own IP Address](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-4-2165","score":61.8878432947,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":58.4628247893,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":37.0600364015,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_11192-0-1195","score":36.9630419636,"text":"\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/planning-analytics?topic=planning-analytics-exploring-scorecards"},{"document_id":"ibmcld_03363-1671-3630","score":36.8980994532,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-1611-3443","score":31.465164664,"text":"\nIn each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_00854-6688-8259","score":31.3787463781,"text":"\nGit Repos and Issue Tracking\n\n Endpoint Description \n\n https:\/\/hosted-git-metrics.[region].devops.cloud.ibm.com\/health Get the health of the service component \n https:\/\/hosted-git-metrics.[region].devops.cloud.ibm.com\/status Get the status of the service component \n https:\/\/hosted-git-metrics.[region].devops.cloud.ibm.com\/status-all Get the status of the service component and its dependencies \n https:\/\/hosted-git-metrics.[region].devops.cloud.ibm.com\/version Get the build version of the service component \n https:\/\/hosted-git-monitor.[region].devops.cloud.ibm.com\/health Get the health of the service component \n https:\/\/hosted-git-monitor.[region].devops.cloud.ibm.com\/load_balancer Get the status of the load balancer \n https:\/\/hosted-git-monitor.[region].devops.cloud.ibm.com\/scorecard Get the status of the scorecard \n https:\/\/hosted-git-monitor.[region].devops.cloud.ibm.com\/status Get the status of the service component \n https:\/\/hosted-git-monitor.[region].devops.cloud.ibm.com\/version Get the build version of the service component \n\n\n\n\n\n\n\n Metrics \n\nThe following table lists the Metrics endpoints that do not require authentication:\n\n\n\nTable 5. Metrics\n\n Endpoint Description \n\n https:\/\/otc-metrics-listener.[region].devops.cloud.ibm.com\/status Get the status of the service component \n https:\/\/otc-metrics-listener.[region].devops.cloud.ibm.com\/version Get the version of the service component \n\n\n\n\n\n\n\n Slack Invite \n\nThe following table lists the Slack Invite endpoints that do not require authentication:\n\n\n\nTable 6. Slack Invite\n\n Endpoint Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-non-auth-endpoints-cd"},{"document_id":"ibmcld_16259-7-2018","score":25.4424284878,"text":"\nUse analytics to review your entire assistant at a glance \n\nThe Analyze page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see analytics information, select Analyze in the navigation bar.\n\n\n\n Choosing the environment and date range \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All charts and cards reflect data based on the environment and the date range you select. When you change the environment or the date range, the charts and cards on the page update to reflect the new date range. You can also use Refresh to ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-time-period.png)\n\n\n\n\n\n Unique users, conversations, and user requests \n\nThese three traffic metrics -- unique users, conversations, and user requests -- provide you with data about the volume of user engagements with your assistant.\n\n![Unique users, conversations, and user requests](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-traffic.png)\n\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_09795-7-2120","score":23.3634895834,"text":"\nPricing \n\nThis topic includes information about pricing for the IBM Cloud Monitoring. You can also review the sample scenarios to learn more about the costs of a Monitoring instance.\n\nIBM Cloud Monitoring pricing is based on hourly consumption. You are billed monthly based on the number of connected agents and the agent deployment mode, the number of custom metric time series, extra number of containers per agent and additional API calls above 1M. There are two agent modes: agent for orchestrated environments, and agent for non-orchestrated environments.\n\nAll other IBM Cloud Monitoring functionality, including dashboards, panels, and alerts, are included in the base service price and pricing does not vary.\n\nThe costs that are provided in this topic are guidelines and do not represent actual costs. They represent a starting point for estimates of costs that would be incurred in environments with a similar configuration. Actual costs can vary by geography. The prices that are used are based on actual prices as of April 1, 2023 and it is possible they can change.\n\n\n\n Before you begin \n\nRead this section to understand concepts and costs that are associated with the Monitoring service.\n\n\n\n* [Service plans](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-service_plans).\n* [Time-series](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-about-timeseries).\n* [Sources of custom metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-about-collect-metrics).\n* [Collecting metrics by infrastructure](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-collect-metrics-by-host).\n\n\n\n\n\n\n\n Consumption charges \n\nIn your monthly usage charges, consumption is measured hourly and your bill breaks down into the following concepts:\n\n\n\nTable 2. Billing usage metrics\n\n Metric Description \n\n NODE_HOURS Tracks the number of agents that are running in an agent for orchestrated environments.<br><br>This does not include the agents tracked by LITE_NODE_HOURS<br><br>For example, if you have 1 agent connected continuously, that agent will be billed 720 NODE_HOURS at the end of the month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans"},{"document_id":"ibmcld_14503-4971-7126","score":23.3251710105,"text":"\nThe client can also configure their compute VMs to uses these forwarders, if required.\n* VMware Update Manager (VUM) provides updating of vSphere hosts and VM hardware and tools. VUM uses the Proxy to gain access to the internet repositories.\n\n\n\nVMware Aria Operations collects data from objects in the environment. Each piece of data that is collected is called a metric observation or value. VMware Aria Operations uses the vCenter adapter to collect raw metrics from vCenter. In addition to the metrics it collects, VMware Aria Operations calculates capacity metrics, badge metrics, and metrics to monitor the health of your system. Alert definitions are a combination of symptoms and recommendations that identify problem areas and generate alerts on which you act for those areas.\n\n\n\n\n\n Monitored components \n\n\n\n Monitoring of vCenter \n\nThe monitoring of vCenter is accomplished with VMware Aria Operations and the VMware SDDC Health Management Pack. VMware Aria Operations for Logs collects the log data from vCenter and the Content Pack for vSphere adds specific understanding to the logs and in turn sends alerts to VMware Aria Operations.\n\nThe VMware SDDC Health Management Pack monitors the SDDC Management stack and provides badges for health and alerts related to configuration and compliance of SDDC product components that include vCenter.\n\n\n\n\n\n Monitoring of vSphere hosts \n\nMonitoring of the vSphere hosts is accomplished with VMware Aria Operations through vCenter and the collection of logs through VMware Aria Operations for Logs.\n\n\n\n\n\n Monitoring of vSAN \n\nTo monitor vSAN, VMware Aria Operations, and VMware Aria Operations for Logs are used. In vCenter, you can use an extra set of vSAN Health Checks. Installation of the Management Pack for vSAN provides more dashboards to aid with the monitoring of vSAN.\n\nVMware Aria Operations generates an alert if a problem occurs in the SDDC product components in the storage area network that the VMware vSAN adapter is monitoring. An alert that is related to configuration compliance and health is passed through VMware SDDC Health Solution management pack from VMware vSAN Management Pack.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-arch"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":24.068084456,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":24.0397575125,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-7-2257","score":21.6803567144,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":21.6803567144,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":21.0950221409,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-4-2366","score":20.7613073463,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":20.7613073463,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01471-5654-7396","score":20.251818213,"text":"\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01533-10805-12534","score":20.2221300375,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-10857-12586","score":20.2221300375,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01468-7-2067","score":19.6166236493,"text":"\nManaging quota limits for storage and pull traffic \n\nYou can limit the amount of storage and pull traffic that can be used in your IBM Cloud account by setting and managing custom quota limits in IBM Cloud\u00ae Container Registry.\n\n\n\n Setting quota limits for storing and pulling images \n\nYou can limit the amount of storage and pull traffic to your private images by setting your own quota limits.\n\nWhen you upgrade to the IBM Cloud Container Registry standard plan, you benefit from unlimited amount of storage and pull traffic to your private images. To avoid exceeding your preferred payment level, you can set individual quotas for the amount of storage and pull traffic. Quota limits are applied to all\n\nnamespacesthat you set up in IBM Cloud Container Registry. If you're using the free service plan, you can also set custom quotas within your free amount of storage and pull traffic.\n\nTo set a quota, complete the following steps.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n3. Change the quota limit for storage and pull traffic. To change the pull traffic usage, specify the traffic option, and replace <traffic_quota> with the value in megabytes that you want to set for the pull traffic quota. If you want to change the amount of storage in your account, specify the storage option, and replace <storage_quota> with the value in megabytes that you want to set.\n\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quota"},{"document_id":"ibmcld_00348-11019-12529","score":18.5261008848,"text":"\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Rest Of APAC\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - South America\"\n],\n\"totals\": [\n15, \/\/ Total Hits from start time to end time.\n4.9301e-5, \/\/ Total Bandwidth from start time to end time.\n0, \/\/ Hits by type 0XX\n0, \/\/ Hits by type 200\n0, \/\/ Hits by type 206\n0, \/\/ Hits by type 2XX\n0, \/\/ Hits by type 302\n0, \/\/ Hits by type 304\n0, \/\/ Hits by type 3XX\n0, \/\/ Hits by type 404\n13, \/\/ Hits by type 4XX\n2, \/\/ Hits by type 5XX\n0, \/\/ Hits by type Other\n0, \/\/ Bandwidth by region Australasia\n3.6554e-5, \/\/ Bandwidth by region EMEA\n0, \/\/ Bandwidth by region India\n0, \/\/ Bandwidth by region Japan\n1.1524e-5, \/\/ Bandwidth by region North America\n1.223e-6, \/\/ Bandwidth by region Rest Of APAC\n0 \/\/ Bandwidth by region South America\n],\n\"percentage\": [ \/\/ The percentage of the bandwidth by regions\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\n0, \/\/ Australasia","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-api"},{"document_id":"ibmcld_00348-10050-11511","score":18.4860245844,"text":"\n\"type\": \"INTEGRATED\",\n\"names\": [\n\"TotalHits\",\n\"TotalBandwidth\",\n\"0XX\",\n\"200\",\n\"206\",\n\"2XX\",\n\"302\",\n\"304\",\n\"3XX\",\n\"404\",\n\"4XX\",\n\"5XX\",\n\"Other\",\n\"Australasia\",\n\"EMEA\",\n\"India\",\n\"Japan\",\n\"North America\",\n\"Rest Of APAC\",\n\"South America\"\n],\n\"descriptions\": [\n\"All hits to the Edge servers from the end-users.\",\n\"Total number of megabytes transferred between the Edge to the end user.\",\n\"Number of hits that returned response code - 0XX\",\n\"Number of hits that returned response code - 200\",\n\"Number of hits that returned response code - 206\",\n\"Number of hits that returned response code - 2XX\",\n\"Number of hits that returned response code - 302\",\n\"Number of hits that returned response code - 304\",\n\"Number of hits that returned response code - 3XX\",\n\"Number of hits that returned response code - 404\",\n\"Number of hits that returned response code - 4XX\",\n\"Number of hits that returned response code - 5XX\",\n\"Number of hits that returned response code not within 2XX to 5XX\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-api"},{"document_id":"ibmcld_01468-1672-3502","score":16.8421443228,"text":"\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000\n\n\n\n\n\n\n\n Reviewing quota limits and usage \n\nYou can review your quota limits and check your current storage and pull traffic usage for your account.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n\n\n\n\n\n\n\n Staying within quota limits \n\nIf you exceed the quota limits that are set for your IBM Cloud account, you can free up storage and change your service plan or quota limits so that you can continue pushing and pulling images to and from your namespace.\n\nFrom 1 February 2022, both [tagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nTo free up image storage in your IBM Cloud account, complete the following steps.\n\nDepending on the size of the image, it might take a while for the image to be removed and for the storage to be available.\n\n\n\n1. Find the names of the images that you want to remove.\n\n\n\n* To list only tagged images, run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quota"},{"document_id":"ibmcld_04360-2697-3466","score":16.7766526653,"text":"\nibmcloud billing enterprise-usage [--account-group ACCOUNT_GROUP_NAME | --account-group-id ACCOUNT_GROUP_ID | --account ACCOUNT_NAME | --account-id ACCOUNT_ID] [--month MONTH] [--children] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n--account ACCOUNT_NAME (optional)\n: Name of target account.\n\n--account-id ACCOUNT_ID (optional)\n: ID of target account.\n\n--account-group ACCOUNT_GROUP_NAME (optional)\n: Name of target account group.\n\n--account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of target account group.\n\n--children (optional)\n: Show children usage reports.\n\n--month MONTH (optional)\n: Target month. Default to current month.\n\n--output FORMAT (optional)\n: Specify output format. Only JSON is supported.\n\n-q, --quiet (optional)\n: Suppress verbose output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_billing"},{"document_id":"ibmcld_11421-1359-2601","score":16.4777170328,"text":"\nVOLUME GROUP: rootvg VG IDENTIFIER: 00f6db0a00004c000000016b94f02\nVG STATE: active PP SIZE: 32 megabyte(s)\nVG PERMISSION: read\/write TOTAL PPs: 639 (20448 megabytes)\nMAX LVs: 256 FREE PPs: 477 (15264 megabytes)\nLVs: 12 USED PPs: 162 (5184 megabytes)\nOPEN LVs: 11 QUORUM: 2 (Enabled)\nTOTAL PVs: 1 VG DESCRIPTIORS: 2\nSTALE PVs: 0 STALE PPs: 0\nACTIVE PVs: 1 AUTO ON: yes\nMAX PPs per VG: 32512\nMAX PPs per PV: 1016 MAX PVs: 32\nLTG size(Dynamic): 512 kilobyte(s) AUTO SYNC: no\nHOT SPARE: no BB POLICY: relocatable\nPV RESTRICTION: none INFINITE RETRY: no\nDISK BLOCK SIZE: 512 CRITICAL VG: no\nFS SYNC OPTION: no CRITICAL PVs: no\n\nShow more\n\nRunning the df -g command displays information about the total space and available space on a file system. In this instance, the rootvg volume group has enough space for creating a new file system, expanding an existing one, and storing the mksysb source image.\n\nThe storage information is shown as follow:\n\n df -g\nFilesystem GB blocks Free %Used Iused %Iused Mounted on\n\/dev\/hd4 0.09 0.06 41% 2619 17% \/\n\/dev\/hd2 2.16 0.26 89% 36565 37% \/usr\n\/dev\/hd9var 0.19 0.16 17% 953 3% \/var\n\/dev\/hd3 0.22 0.22 1% 33 1% \/tmp\n\/dev\/hd1 0.03 0.03 2% 7 1% \/home\n\/dev\/hd11admin 0.12 0.12 1% 5 1% \/admin\n\/proc - - - - - \/proc","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-restoring-aix-mksysb-image"},{"document_id":"ibmcld_04360-1365-3035","score":16.2851546622,"text":"\nibmcloud billing resource-group-usage \n\nShow monthly usage for a resource group (account admin or resource group admin only):\n\nibmcloud billing resource-group-usage GROUP_NAME [-d YYYY-MM] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\nGROUP_NAME (required)\n: Name of the resource group.\n\n-d MONTH_DATE (optional)\n: Display data for the month and date that is specified by using the YYYY-MM format. If not specified, usage of the current month is shown.\n\n--output FORMAT (optional)\n: Specify output format. Only JSON is supported.\n\n-q, --quiet (optional)\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud billing resource-instances-usage \n\nShow monthly resource instances usage under the current account:\n\nibmcloud billing resource-instances-usage [-o ORG] [-g RESOURCE_GROUP] [-d YYYY-MM] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n-o ORG_NAME (optional)\n: Filter instances by organization.\n\n-g GROUP_NAME\n: Filter instance by resource group.\n\n-d MONTH_DATE (optional)\n: Display data for month and date that is specified by using the YYYY-MM format. If not specified, usage of the current month is shown.\n\n--output FORMAT (optional)\n: Specify output format. Accepted inputs are JSON and CSV.\n\n-q, --quiet (optional)\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud billing enterprise-usage \n\nShow enterprise usage reports:\n\nibmcloud billing enterprise-usage [--account-group ACCOUNT_GROUP_NAME | --account-group-id ACCOUNT_GROUP_ID | --account ACCOUNT_NAME | --account-id ACCOUNT_ID] [--month MONTH] [--children] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n--account ACCOUNT_NAME (optional)\n: Name of target account.\n\n--account-id ACCOUNT_ID (optional)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_billing"},{"document_id":"ibmcld_03435-20211-22413","score":15.4429428522,"text":"\nAccount usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-at_events_acc_mgt"},{"document_id":"ibmcld_02379-20817-23063","score":15.1634673714,"text":"\nThis section explains events that are generated when a user looks at the information that is provided through the Manage > Billing and usage > Usage section, or request an export of the data.\n\nYou can get events with reason.reasonCode = 404 that are generated when there is no usage data available for the request. The severity is set to normal.\n\n\n\n requestData fields \n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-summary.read, billing.account-summary.download, and billing.account-instances-usage-report.download:\n\n\n\nTable 16. Account usage summary requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-usage-report.read:\n\n\n\nTable 17. Account usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"},{"document_id":"ibmcld_12544-4880-7097","score":15.0079801029,"text":"\nUsers in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit. When accounts in the enterprise create and use resources, the cost for this usage is deducted from the credit pool.\n\nWhen existing subscriptions are added to the enterprise, each individual subscription term is re-created within the credit pool, including characteristics such as the remaining credit balance, start dates, and end dates. As credit is used, the subscription terms burn down individually according to when they expire. For example, you imported two accounts with existing subscriptions in August 2019. One subscription, 32100456, is for $1,000 for 18 months that began in January 2019. Because it spans multiple years, the subscription is divided into terms of up to one year each. The other subscription, 55543210 is for $500 a month for two years that began in April 2019, which is also divided into multiple terms. Then, you purchased a new one-year subscription, 00012345, through your enterprise for $1,500 a month that starts in July 2020. As enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":18.5471304179,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06843-4238-6198","score":16.881097636,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-9696-11699","score":15.8775522785,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06836-7569-8653","score":15.1380369276,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_16729-294066-295916","score":14.2969599929,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07844-4589-6711","score":13.8407548992,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_12415-7-1973","score":13.6158878789,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_07844-3757-5369","score":13.3970656526,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07844-2925-4586","score":13.3067207231,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07578-1213887-1215935","score":13.2639969882,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8503449055,"ndcg_cut_10":0.8503449055}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":22.7801236845,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":22.4398749446,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":22.3383281177,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_03164-1607-3518","score":20.4762049113,"text":"\nFor more information about it, read the [Slack blog post](https:\/\/medium.com\/slack-developer-blog\/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17. On the Event Subscriptions page in Slack, find the Subscribe to Bot Events section. Click Add Bot User Event, and then select the event types you want to subscribe to. You must select at least one of the following types:\n\n\n\n* message.im: Listens for message events that are posted in a direct message channel.\n* app_mention: Listens for only message events that mention your app or bot.\n\nChoose the app_mention entry in normal font, not the app_mention entry that is in bold font.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-slack"},{"document_id":"ibmcld_04111-35313-36062","score":20.2212606136,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":19.4831877745,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":19.4468631203,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-34153-35639","score":18.529220488,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_03403-26509-28185","score":18.2054235698,"text":"\n[Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close.png) to close the edit view.\n\n\n\nNow, when you test, you can provide a set of number or a mix of numbers and text as input, and the dialog reminds you of the correct order number format. You have successfully tested your dialog, found a weakness in it, and corrected it.\n\nAnother way you can address this type of scenario is to add a node with slots. See the [Adding a node with slots to a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots) tutorial to learn more about using slots.\n\n\n\n\n\n\n\n Step 5: Add the personal touch \n\nIf the user shows interest in the bot itself, you want the virtual assistant to recognize that curiosity and engage with the user in a more personal way. You might remember the General_About_You intent, which is provided with the General content catalog, that we considered using earlier, before you added your own custom about_restaurant intent. It is built to recognize just such questions from the user. Add a node that conditions on this intent. In your response, you can ask for the user's name and save it to a $username variable that you can use elsewhere in the dialog, if available.\n\n\n\n Add a node that handles questions about the bot \n\nAdd a dialog node that can recognize the user's interest in the bot, and respond.\n\n\n\n1. Click the Dialog tab.\n2. Find the Welcome node in the dialog tree.\n3. Click the More![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the Welcome node, and then select Add node below.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03114-11593-13085","score":18.1819536368,"text":"\n\"body\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"url\": \"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index\",\n\"id\": \"6682eca3c5b3778ccb730b799a8063f3\",\n\"result_metadata\": {\n\"confidence\": 0.08401551980328191,\n\"score\": 0.73975396\n},\n\"highlight\": {\n\"Shortdesc\":\n\"IBM <em>Watson<\/em> <em>Assistant<\/em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n],\n\"url\":\n\"https:\/\/cloud.ibm.com\/docs\/<em>assistant<\/em>?topic=<em>assistant<\/em>-index\"\n],\n\"body\":\n\"IBM <em>Watson<\/em> <em>Assistant<\/em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n]\n}\n}\n]\n}\n]\n},\n\"user_id\": \"58e1b04e-f4bb-469a-9e4c-dffe1d4ebf23\"\n}\nShow more\n\nFor each search result, the title, body, and url properties include content returned from the Discovery query. The search skill configuration determines which fields in the Discovery collection are mapped to these fields in the response. Your application can use these fields to display the results to the user (for example, you might use the body text to show an abstract or description of the matching document, and the url value to create a link the user can click to open the document).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responses"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":47.5827044664,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":46.4333408341,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":46.045927396,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-43319-44485","score":43.7971285437,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-7-1743","score":40.3642936341,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":36.9272308407,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-15747-17355","score":33.7435188668,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-2884-4620","score":32.6749640268,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":32.4447006709,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_12330-7-2140","score":32.1129673247,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9469024295,"ndcg_cut_10":0.9469024295}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16287-7751-9832","score":24.125473113,"text":"\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images\/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03158-6114-8033","score":22.849681561,"text":"\nThe list of voices is automatically filtered to use the same language as your assistant. To see all voices, toggle the Filter voices based on assistant language switch to Off.\n\nFor more information about voice options, and to listen to audio samples, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) in the Text to Speech documentation.\n\nClick Next.\n\n\n\nAny speech service charges that are incurred by the phone integration are billed with the Watson Assistant service plan as voice add-on charges. After the instances are created, you can access them directly from the IBM Cloud dashboard. Any use of the speech instances that occurs outside of your assistant are charged separately as speech service usage costs.\n\nThe phone integration setup is now complete. On the Phone page, you can click the tabs to view or edit the phone integration.\n\nIf you chose to generate a free telephone number, your new number is displayed on the Phone number tab immediately. However, provisioning the new number so it is ready to use might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured using a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods to add phone numbers:\n\n\n\n* To add phone numbers one by one, type each number in the table, along with an optional description. Click the checkmark icon ![checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16287-6128-8192","score":22.2148877238,"text":"\nFor more information about language models, see [Languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models) in the Speech to Text documentation.\n\nClick Next.\n10. On the Text to Speech page, select the instance of the Text to Speech service you want to use for the phone integration.\n\n\n\n* If you have existing Text to Speech instances, select the instance you want to use from the list.\n* If you do not have any existing Text to Speech instances, click Create new instance to create a new Standard instance.\n\n\n\n11. In the Choose your Text to Speech voice field, select the voice you want to use.\n\nThe list of voices is automatically filtered to use the same language as your assistant. To see all voices, toggle the Filter voices based on assistant language switch to Off.\n\nFor more information about voice options, and to listen to audio samples, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) in the Text to Speech documentation.\n\nClick Next.\n\n\n\nAny speech service charges incurred by the phone integration are billed with the Watson Assistant service plan as voice add-on charges. After the instances are created, you can access them directly from the IBM Cloud dashboard. Any use of speech instances that occurs outside of your assistant is charged separately as speech service usage costs.\n\nThe phone integration setup is now complete. On the Phone page, you can click the tabs to view or edit the phone integration.\n\nIf you chose to generate a free telephone number, your new number is displayed on the Phone number tab immediately. However, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16287-2974-4988","score":21.6791461488,"text":"\nChoose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are integrating with a contact center, follow the instructions to configure the contact center. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Select contact center page, select the tile of the connect center you would like to use.\n2. On the Connect to contact center page, enter the required information. There is a Test Connection button on the page to validate the connection. Click Next.\n\n\n\n6. If you are using an existing phone number, follow the instructions to configure the SIP trunk. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n\n\n\n7. On the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03165-4477-6547","score":21.512075552,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03158-2940-4987","score":21.4861781697,"text":"\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-4-2042","score":21.4609915063,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nBy adding the phone integration to your assistant, you can make your assistant available to customers over the phone.\n\nWhen you add the phone integration to your assistant, you can automatically generate a working phone number that is automatically connected to your assistant. Or, if you prefer, you can connect the assistant to your existing infrastructure by configuring an existing Session Initiation Protocol (SIP) trunk.\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX). If you choose to generate a free phone number for your assistant, a SIP trunk is automatically provisioned from IntelePeer. You can also choose to use an existing SIP trunk from a provider such as IntelePeer, Genesys, or Twilio.\n\nGenerating a free phone number is available only with new phone integrations. If you have an existing phone integration and you want to switch to a free phone number, you must delete the existing integration and create a new one.\n\nWhen your customer makes a phone call using the telephone number connected to your assistant, the phone integration answers. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service. The audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16287-7-2037","score":21.1782037743,"text":"\nIntegrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nAdding the phone integration to your assistant makes your assistant available to customers over the phone.\n\nIf an end user asks to speak to a person, the phone integration can transfer the call to an agent. Supported live agent and contact center integrations:\n\n\n\n* Genesys\n* Twilio Flex\n* NICE CXone\n* Bring your own\n\n\n\nThere are several ways to add the phone integration to your assistant:\n\n\n\n* You can generate a free phone number that is automatically provisioned from IntelePeer. This is available only with new phone integrations. If you have an existing phone integration, you must delete it and create a new one to switch to a free phone number.\n* You can connect to a contact center with live agents. For more information about setting up the integration, see [Integrating with phone and NICE CXone contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone).\n* You can use and connect an existing number by configuring a Session Initiation Protocol (SIP) trunk from a provider such as Genesys, IntelePeer, or Twilio.\n\n\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03165-4-1869","score":21.0291453451,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with SMS with Twilio \n\nAdd a text messaging integration so your assistant can exchange messages with your customers.\n\nThe Short Messaging Service (SMS) supports text-only messages. Typically, SMS restricts the text message length to 160 characters. The Multimedia Messaging Service (MMS) supports sending images and text messages that are over 160 characters in length. When you create a phone number with Twilio, MMS message support is included automatically.\n\nCustomers send text messages to your Twilio-hosted phone number. Twilio uses a messaging webhook that you set up to send a POST request with the text message body to your assistant. Each response from the assistant is sent back to Twilio to be converted to an outbound SMS message that is sent to the customer. The responses are sent to the Twilio API for processing. You provide your Twilio account SID and project authentication token information, which serve as your Twilio API access credentials.\n\nThis feature is available only to Plus plan users.\n\n\n\n Before you begin \n\nIf you don't have a text messaging phone number, set up a SMS with Twilio account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account or start a free trial.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03160-10290-11610","score":20.9616429733,"text":"\nIn the JSON editor, add a [connect_to_agent response](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context), specifying your phone number as the sip.uri (replace {phone_number} with the phone number of your SIP trunk):\n\n\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:+{phone_number}@flex.twilio.com\",\n\"transfer_headers_send_method\": \"refer_to_header\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Ok, I'm transferring you to an agent\"\n},\n\"agent_unavailable\": {\n\"message\": \"\"\n}\n}\n]\n}\n}\nShow more\n\nNote that this example does not show how to use the context passed from Watson Assistant to Twilio Flex. You can reference the User-to-User information from within the Twilio Flex flow as follows:\n\n{\n\"context\": {\n\"widgets\": {\n\"redirect_1\": {\n\"User-to-User\": \"value\",\n}\n}\n}\n}\n\nwhere redirect_1 is the name of your redirect widget. For example, if you set up multiple queues, you might want to use a Twilio Split widget to pick a queue based on the returned context.\n\n\n\n\n\n Test your assistant \n\nYour assistant should now be able to answer phone calls to your phone number and transfer calls back to your Twilio Flex flow. To test your assistant:\n\n\n\n1. Call your phone number. When the assistant responds, ask for an agent.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-1033-2260","score":37.1168782782,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-394005-396150","score":36.4465129058,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":36.4465129058,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10154-7-1896","score":36.1454794882,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10214-7-1980","score":35.3960703148,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10214-1438-3413","score":32.6934245217,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_05707-7-2073","score":31.6544860594,"text":"\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https:\/\/www.ibm.com\/cloud\/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_10534-1903-3343","score":31.202153527,"text":"\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksoverview-by-resource)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10170-12206-14575","score":30.0739142928,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_07578-267680-269608","score":29.8425160199,"text":"\nRunning, adding, or changing custom programs are not supported on IBM Cloud Qiskit Runtime. If you used this function previously, you can instead use code that calls primitives. To get performance benefits comparable to uploaded programs, you can use use sessions, which are a service aware context manager that minimizes artificial queuing latency inside an iterative workload.\n\n\n\nRed Hat OpenShift for HPC\n\n\n\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [User access permissions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_referencecluster_create_permissions).\n* How many worker nodes can I deploy in my Red Hat OpenShift cluster through this offering?\n\nBefore you deploy a cluster, it is important to ensure that the cluster-related resource quota settings in your IBM Cloud account are appropriate for the size of the cluster that you would like to create. For more information, see [Service and quota limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationstech_limits).\n\nThe maximum number of worker nodes that are supported for the worker_nodes_per_zone deployment value is 1,000 (see [Deployment values](https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-deployment-values)). However, the default quota, as noted in [Service and quota limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationstech_limits), is 500 worker nodes across all of the clusters in a region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14546-4405-6573","score":10.2371578412,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_06206-0-1702","score":8.2704376149,"text":"\n\n\n\n\n\n\n  Why am I still seeing charges for block storage devices after deleting my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nYou have already deleted your cluster but your account is still charged for the storage volumes associated with the cluster.\n\n  Why it\u2019s happening \n\nWhen you delete your cluster, you have the option to delete the storage volumes used by the cluster. If you select no, the storage volumes remain in your account, and continue incurring charges until they are deleted.\n\n  How to fix it \n\nDelete the storage volumes from your account.\n\n\n\n1.  Find the cluster ID of the deleted cluster. This ID will be used to remove associated block storage volumes. If you don't have the cluster ID of the deleted cluster, run ibmcloud ks cluster ls and a make a note of the cluster IDs whose block storage volumes you want to keep.\n\nibmcloud ks cluster ls\n2.  Find the remaining volumes that are associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud ks storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nExample output for Classic Block Storage volumes. Note the volume ID and the cluster ID.\n\n102413596 blntvemw0j6snjt04jr0\n\nVPC clusters:\n\nibmcloud ks storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n3.  Remove the volumes.\n\nClassic clusters:\n\nibmcloud sl block volume-cancel VOLUME_ID\n\nVPC clusters:\n\nibmcloud is vold VOLUME_NAME_OR_ID\n4.  Optional: Verify there are no more volumes associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud ks storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nVPC clusters:\n\nibmcloud ks storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts_storage_clean_volume"},{"document_id":"ibmcld_10640-0-1702","score":8.2704376149,"text":"\n\n\n\n\n\n\n  Why am I still seeing charges for block storage devices after deleting my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nYou have already deleted your cluster but your account is still charged for the storage volumes associated with the cluster.\n\n  Why it\u2019s happening \n\nWhen you delete your cluster, you have the option to delete the storage volumes used by the cluster. If you select no, the storage volumes remain in your account, and continue incurring charges until they are deleted.\n\n  How to fix it \n\nDelete the storage volumes from your account.\n\n\n\n1.  Find the cluster ID of the deleted cluster. This ID will be used to remove associated block storage volumes. If you don't have the cluster ID of the deleted cluster, run ibmcloud oc cluster ls and a make a note of the cluster IDs whose block storage volumes you want to keep.\n\nibmcloud oc cluster ls\n2.  Find the remaining volumes that are associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud oc storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nExample output for Classic Block Storage volumes. Note the volume ID and the cluster ID.\n\n102413596 blntvemw0j6snjt04jr0\n\nVPC clusters:\n\nibmcloud oc storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n3.  Remove the volumes.\n\nClassic clusters:\n\nibmcloud sl block volume-cancel VOLUME_ID\n\nVPC clusters:\n\nibmcloud is vold VOLUME_NAME_OR_ID\n4.  Optional: Verify there are no more volumes associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud oc storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nVPC clusters:\n\nibmcloud oc storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts_storage_clean_volume"},{"document_id":"ibmcld_11408-11687-13539","score":8.2602741867,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_07578-749295-751647","score":8.2499551377,"text":"\n* Public bandwidth usage over GB allocation is charged per GB.\n\n\n\n* What IMS permissions do I need to view and change bandwidth allocations (or add and remove devices to and from bandwidth pools)?\n\nThe BANDWIDTH_MANAGE IMS infrastructure classic permission is the only required permission for bandwidth metering. After you allow this permission, you can complete the following actions:\n\n\n\n* Create a bandwidth pool\n* Move a device into or out of a pool\n* Void a device\u2019s move into a pool\n* Cancel a pool\n\n\n\nCertain actions pertaining to bandwidth pools, including visibility, might be constrained based on device-level permission. Reconcile your device-level permissions on specific devices to manage their bandwidth and membership in pools.\n* Why don't I see the same number of devices as displayed on the devices count?\n\nThis issue might be due to permission restrictions because some users do not have permission to view specific devices. This issue might also be the result of devices that were reclaimed in the middle of the billing cycle, but are still contributing to the cost of the pool.\n* What kind of devices generate bandwidth?\n\nCompute devices use bandwidth. For example, devices that generate bandwidth include bare metal servers, virtual servers, firewalls (FSA 10G), and Netscaler devices.\n* Why doesn't the allocation display the same value that I ordered?\n\nThe allocation that is shown is related to the proration policy. For example, imagine that you order 20 TB of bandwidth on the 15th of the month. The allocation that is shown on the bandwidth summary page will show 10 TB until the next billing cycle. Then, the allocation displays the full amount of what was ordered.\n* What is the maximum number of devices that I can attach to a bandwidth pool?\n\nYou can attach an unlimited number of devices to a bandwidth pool.\n* Is there a charge for traffic on the Classic Private Network?\n\nThere is no charge for traffic between Virtual Servers for Classic or Bare Metal Servers for Classic, on the Classic Private network, within the same Classic account.\n\n\n\nCitrix Netscaler VPX\n\n\n\n* What is Citrix Netscaler VPX?\n\nCitrix NetScaler is an application delivery controller that makes applications five times better by accelerating performance, ensuring application availability and protection and substantially lowering operational costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-838174-839929","score":7.9420869117,"text":"\n* Secondary: 208.91.112.52\n\n\n\n\n\nFortiGate Security Appliance 10 Gbps\n\n\n\n* What is the difference between FortiGate Security Appliance (FSA) 10 Gbps and FSA 1 Gbps? What about Virtual Router Appliance?\n\nFSA 10 Gbps provides faster throughput compared to FSA 1 Gbps. It allows the customer to protect multiple VLANs (both private and public). More add-ons such as Anti-Virus (AV), Intrusion Prevention (IPS), and web filtering can be enabled on demand.\n\nVirtual Router Appliance also protects multiple VLANs. However, Virtual Router Appliance does not provide next-generation firewall add-ons and purpose-built security processors.\n* Can FSA 10G and a network gateway be associated with the same VLAN?\n\nNo, it is not possible to have an FSA 10G and a network gateway device to be associated with the same customer VLAN.\n* Does this offering charge for private network connectivity?\n\nIBM offers private connectivity free of charge, which is one of the key differentiators in the marketplace.\n* Is FSA 1 Gbps also a multi-VLAN offering?\n\nNo, only FSA 10 Gbps supports multiple VLANs.\n* Is FSA 10 Gbps available in Federal data centers?\n\nFSA 10 Gbps is not currently available in Federal data centers.\n* Can an FSA 10 Gbps be used in place of a Virtual Router Appliance?\n\nYes.\n* Do you plan to upgrade FSA 1G with the same capability of the FSA 10G appliance?\n\nNot currently.\n* Can the FSA 10 Gbps span over multiple pods in a data center?\n\nNot currently. FSA 10 Gbps is only able to protect VLANs for the pod it is deployed in.\n\n\n\nHardware Firewall\n\n\n\n* What is a firewall?\n\nA firewall is a network device that is connected upstream from a server. The firewall blocks unwanted traffic from a server before the server is reached.\n* Why should I use a firewall?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-838047-839802","score":7.9420869117,"text":"\n* Secondary: 208.91.112.52\n\n\n\n\n\nFortiGate Security Appliance 10 Gbps\n\n\n\n* What is the difference between FortiGate Security Appliance (FSA) 10 Gbps and FSA 1 Gbps? What about Virtual Router Appliance?\n\nFSA 10 Gbps provides faster throughput compared to FSA 1 Gbps. It allows the customer to protect multiple VLANs (both private and public). More add-ons such as Anti-Virus (AV), Intrusion Prevention (IPS), and web filtering can be enabled on demand.\n\nVirtual Router Appliance also protects multiple VLANs. However, Virtual Router Appliance does not provide next-generation firewall add-ons and purpose-built security processors.\n* Can FSA 10G and a network gateway be associated with the same VLAN?\n\nNo, it is not possible to have an FSA 10G and a network gateway device to be associated with the same customer VLAN.\n* Does this offering charge for private network connectivity?\n\nIBM offers private connectivity free of charge, which is one of the key differentiators in the marketplace.\n* Is FSA 1 Gbps also a multi-VLAN offering?\n\nNo, only FSA 10 Gbps supports multiple VLANs.\n* Is FSA 10 Gbps available in Federal data centers?\n\nFSA 10 Gbps is not currently available in Federal data centers.\n* Can an FSA 10 Gbps be used in place of a Virtual Router Appliance?\n\nYes.\n* Do you plan to upgrade FSA 1G with the same capability of the FSA 10G appliance?\n\nNot currently.\n* Can the FSA 10 Gbps span over multiple pods in a data center?\n\nNot currently. FSA 10 Gbps is only able to protect VLANs for the pod it is deployed in.\n\n\n\nHardware Firewall\n\n\n\n* What is a firewall?\n\nA firewall is a network device that is connected upstream from a server. The firewall blocks unwanted traffic from a server before the server is reached.\n* Why should I use a firewall?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07597-0-1885","score":7.800496572,"text":"\n\n\n\n\n\n\n  FAQs for FortiGate Security Appliance 10 Gbps \n\nThe following are some frequently asked questions you may have about working with the FortiGate Security Appliance 10 Gbps firewall.\n\n\n\n  What is the difference between FortiGate Security Appliance (FSA) 10 Gbps and FSA 1 Gbps? What about Virtual Router Appliance? \n\nFSA 10 Gbps provides faster throughput compared to FSA 1 Gbps. It allows the customer to protect multiple VLANs (both private and public). More add-ons such as Anti-Virus (AV), Intrusion Prevention (IPS), and web filtering can be enabled on demand.\n\nVirtual Router Appliance also protects multiple VLANs. However, Virtual Router Appliance does not provide next-generation firewall add-ons and purpose-built security processors.\n\n\n\n\n\n  Can FSA 10G and a network gateway be associated with the same VLAN? \n\nNo, it is not possible to have an FSA 10G and a network gateway device to be associated with the same customer VLAN.\n\n\n\n\n\n  Does this offering charge for private network connectivity? \n\nIBM offers private connectivity free of charge, which is one of the key differentiators in the marketplace.\n\n\n\n\n\n  Is FSA 1 Gbps also a multi-VLAN offering? \n\nNo, only FSA 10 Gbps supports multiple VLANs.\n\n\n\n\n\n  Is FSA 10 Gbps available in Federal data centers? \n\nFSA 10 Gbps is not currently available in Federal data centers.\n\n\n\n\n\n  Can an FSA 10 Gbps be used in place of a Virtual Router Appliance? \n\nYes.\n\n\n\n\n\n  Do you plan to upgrade FSA 1G with the same capability of the FSA 10G appliance? \n\nNot currently.\n\n\n\n\n\n  Can the FSA 10 Gbps span over multiple pods in a data center? \n\nNot currently. FSA 10 Gbps is only able to protect VLANs for the pod it is deployed in.\n\n\n\n\n\n  What are the default DNS servers of FortiGate 10 Gbps? \n\nBy default, FortiGate uses the following FortiGuard's DNS servers.\n\n\n\n*  Primary: 208.91.112.53\n*  Secondary: 208.91.112.52\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/fortigate-10g?topic=fortigate-10g-faqs-for-fortigate-security-appliance-10gbps"},{"document_id":"ibmcld_16727-749809-752143","score":7.6802795162,"text":"\nReconcile your device-level permissions on specific devices to manage their bandwidth and membership in pools.\n* Why don't I see the same number of devices as displayed on the devices count?\n\nThis issue might be due to permission restrictions because some users do not have permission to view specific devices. This issue might also be the result of devices that were reclaimed in the middle of the billing cycle, but are still contributing to the cost of the pool.\n* What kind of devices generate bandwidth?\n\nCompute devices use bandwidth. For example, devices that generate bandwidth include bare metal servers, virtual servers, firewalls (FSA 10G), and Netscaler devices.\n* Why doesn't the allocation display the same value that I ordered?\n\nThe allocation that is shown is related to the proration policy. For example, imagine that you order 20 TB of bandwidth on the 15th of the month. The allocation that is shown on the bandwidth summary page will show 10 TB until the next billing cycle. Then, the allocation displays the full amount of what was ordered.\n* What is the maximum number of devices that I can attach to a bandwidth pool?\n\nYou can attach an unlimited number of devices to a bandwidth pool.\n* Is there a charge for traffic on the Classic Private Network?\n\nThere is no charge for traffic between Virtual Servers for Classic or Bare Metal Servers for Classic, on the Classic Private network, within the same Classic account.\n\n\n\nCitrix Netscaler VPX\n\n\n\n* What is Citrix Netscaler VPX?\n\nCitrix NetScaler is an application delivery controller that makes applications five times better by accelerating performance, ensuring application availability and protection and substantially lowering operational costs. Choose the best Citrix NetScaler edition that meets your application requirements, and deploy it on the appropriate dedicated system for your performance needs. To learn more about Citrix NetScaler, refer to the [NetScaler page](http:\/\/www.citrix.com\/products\/netscaler-application-delivery-controller\/overview.html) on the Citrix website.\n* Why is load balancing needed?\n\nLoad balancing traffic has become a key aspect of many customer implementations as it distributes application requests and loads over multiple servers. It also provides a number of benefits to the overall topology including:\n\n\n\n* Security.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16094-8464-10265","score":7.4218759057,"text":"\n1. Click Security groups under Network, then click Create.\n2. Enter vpc-secure-private-sg as name and select the VPC you created earlier.\n3. Click Create security group.\n\n\n\n\n\n\n\n Create a virtual server instance \n\nTo create a virtual server instance in the newly created subnet:\n\n\n\n1. Click on the subnet vpc-secure-private-subnet created earlier under Subnets.\n2. Click Attached resources, under Attached instances, click Create.\n3. To configure the instance:\n\n\n\n1. Enter a unique name, vpc-secure-private-vsi and resource group as earlier.\n2. Select the same Location already used by the bastion virtual server.\n3. Select Public type of virtual server.\n4. Set the Operating System to Ubuntu Linux. You can pick any version of the image.\n5. Select Compute (2 vCPUs and 4 GB RAM) as your profile. To check other available profiles, click View all profiles.\n6. For SSH keys pick the SSH key you created earlier for the bastion.\n\n\n\n4. Scroll to Networking and select the VPC your created.\n5. Under Network interfaces, click on the Edit icon\n\n\n\n* Select vpc-secure-private-subnet as the subnet.\n* Uncheck the default security and group and activate vpc-secure-private-sg.\n* Click Save.\n\n\n\n6. Click Create virtual server instance.\n\n\n\n\n\n\n\n Add virtual server instance(s) to the maintenance security group \n\nFor administrative work on the servers, you have to associate the specific virtual servers with the maintenance security group. In the following, you will enable maintenance, log into the private server, update the software package information, then disassociate the security group again.\n\nLet's enable the maintenance security group for the server.\n\n\n\n1. Navigate to Security groups and select vpc-secure-maintenance-sg security group.\n2. Click on theAttached resources tab, then Edit interfaces.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-secure-management-bastion-server"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":22.7215588283,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_03166-23681-24372","score":21.8355069181,"text":"\nFor Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU) \n\n\n\nFor more information about how the web chat widget tracks MAUs, see [Billing](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03798-0-2240","score":21.4674248907,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_03107-4-1607","score":21.2671432881,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Managing your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16252-7-1601","score":20.969682001,"text":"\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_16365-15662-16934","score":20.140360711,"text":"\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03704-1531-3564","score":19.959513208,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":19.6929751736,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":19.6929751736,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02597-3131-5174","score":19.4094523755,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01327-4660-7015","score":22.0665176377,"text":"\nActions that generate events for namespaces \n\n\n\nTable 9. Actions that generate events for namespaces\n\n Action Description Data Event \n\n container-registry.namespace.create Create a namespace in Container Registry.<br><br>Assign a Container Registry namespace to a resource group. \n container-registry.namespace.delete Delete a namespace from Container Registry. \n container-registry.namespace.list List the Container Registry namespaces in your IBM account. \n\n\n\n\n\n\n\n Actions that generate events for plans \n\n\n\nTable 10. Actions that generate events for plans\n\n Action Description Data Event \n\n container-registry.plan.get Display information about the current pricing plan. \n container-registry.plan.set Upgrade to the standard plan. \n\n\n\n\n\n\n\n Actions that generate events for quotas \n\n\n\nTable 11. Actions that generate events for quotas\n\n Action Description Data Event \n\n container-registry.quota.get Display the current quotas for traffic and storage, and the usage information against those quotas. \n container-registry.quota.set Modify the quotas. Quota settings must be managed separately for your account in each registry instance. You can set quota limits for storage in your free or standard plan. \n\n\n\n\n\n\n\n Actions that generate events for retention policies \n\n\n\nTable 12. Actions that generate events for retention policies\n\n Action Description Data Event \n\n container-registry.retention.analyze List the images that are deleted if you apply a specific retention policy. \n container-registry.retention.list List the image retention policies for your account. \n container-registry.retention.set Set a policy to retain images in a namespace in Container Registry by applying specified criteria. \n\n\n\n\n\n\n\n Actions that generate events for settings \n\n\n\nTable 13. Actions that generate events for settings\n\n Action Description Data Event \n\n container-registry.settings.get Get registry service settings for the targeted account, such as whether platform metrics are enabled. \n container-registry.settings.set Update registry service settings for the targeted account, such as enabling platform metrics. \n\n\n\n\n\n\n\n Actions that generate events for signing images \n\n\n\nTable 14. Actions that generate events for signing images\n\n Action Description Data Event \n\n container-registry.signature.delete Delete a signature from an image in Container Registry. True","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-at_events"},{"document_id":"ibmcld_01409-1655-3233","score":21.8965533819,"text":"\nList images. GET \/api\/v1\/images container-registry.image.list container-registry.image.list \n Delete more than one image. POST \/api\/v1\/images\/bulkdelete container-registry.image.delete container-registry.image.bulkdelete \n List images by digest. POST \/api\/v1\/images\/digests container-registry.image.list container-registry.image.list \n Create tag. POST \/api\/v1\/images\/tags container-registry.image.pull<br><br>container-registry.image.push container-registry.image.tag \n Delete image. DELETE \/api\/v1\/images\/{image} container-registry.image.delete container-registry.image.delete \n Inspect an image. GET \/api\/v1\/images\/{image}\/json container-registry.image.inspect container-registry.image.inspect \n Get image manifest. GET \/api\/v1\/images\/{image}\/manifest container-registry.image.inspect container-registry.manifest.inspect \n\n\n\n\n\n\n\n Message API methods \n\n\n\nTable 3. Messages\n\n Action Method IAM ACTION AT ACTION \n\n Return any published system messages. GET \/api\/v1\/messages \n\n\n\n\n\n\n\n Namespace API methods \n\n\n\nTable 4. Namespaces\n\n Action Method IAM ACTION AT ACTION \n\n List namespaces. GET \/api\/v1\/namespaces container-registry.namespace.list container-registry.namespace.list \n Detailed namespace list. GET \/api\/v1\/namespaces\/details container-registry.namespace.list container-registry.namespace.list \n Create namespace. PUT \/api\/v1\/namespaces\/{namespace} container-registry.namespace.create container-registry.namespace.create \n Assign namespace. PATCH \/api\/v1\/namespaces\/{namespace} container-registry.namespace.create container-registry.namespace.update \n Delete namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_at_iam"},{"document_id":"ibmcld_01409-4151-6017","score":21.7013517336,"text":"\nGET \/api\/v1\/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST \/api\/v1\/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST \/api\/v1\/retentions\/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace. GET \/api\/v1\/retentions\/{namespace} container-registry.retention.get container-registry.retention.get \n\n\n\n\n\n\n\n Settings API methods \n\n\n\nTable 8. Settings\n\n Action Method IAM ACTION AT ACTION \n\n Get registry service settings for the targeted account, such as whether platform metrics are enabled. GET \/api\/v1\/settings container-registry.settings.get container-registry.settings.get \n Update registry service settings for the targeted account, such as enabling platform metrics. PATCH \/api\/v1\/settings container-registry.settings.set container-registry.settings.set \n\n\n\n\n\n\n\n Tag API methods \n\n\n\nTable 9. Tags\n\n Action Method IAM ACTION AT ACTION \n\n Delete tag. DELETE \/api\/v1\/tags\/{image} container-registry.image.delete container-registry.image.untag \n\n\n\n\n\n\n\n Trash API methods \n\n\n\nTable 10. Trash\n\n Action Method IAM ACTION AT ACTION \n\n List images in the trash. GET \/api\/v1\/trash container-registry.image.delete container-registry.trash.list \n Restore a digest and all associated tags. POST \/api\/v1\/trash\/{digest}\/restoretags container-registry.image.push container-registry.trash.restore \n Restore deleted image. POST \/api\/v1\/trash\/{image}\/restore container-registry.image.push container-registry.trash.restore \n\n\n\n\n\n\n\n\n\n Vulnerability Advisor API methods \n\n\n\n Report API methods \n\n\n\nTable 11. Report\n\n Action Method IAM ACTION AT ACTION \n\n Get the vulnerability assessment for all images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_at_iam"},{"document_id":"ibmcld_01409-2859-4626","score":21.3748181502,"text":"\nGET \/api\/v1\/namespaces\/details container-registry.namespace.list container-registry.namespace.list \n Create namespace. PUT \/api\/v1\/namespaces\/{namespace} container-registry.namespace.create container-registry.namespace.create \n Assign namespace. PATCH \/api\/v1\/namespaces\/{namespace} container-registry.namespace.create container-registry.namespace.update \n Delete namespace. DELETE \/api\/v1\/namespaces\/{namespace} container-registry.namespace.delete container-registry.namespace.delete \n\n\n\n\n\n\n\n Plan API methods \n\n\n\nTable 5. Plans\n\n Action Method IAM ACTION AT ACTION \n\n Get plans for the targeted account. GET \/api\/v1\/plans container-registry.plan.get container-registry.plan.get \n Update plans for the targeted account. PATCH \/api\/v1\/plans container-registry.plan.set container-registry.plan.set \n\n\n\n\n\n\n\n Quota API methods \n\n\n\nTable 6. Quotas\n\n Action Method IAM ACTION AT ACTION \n\n Get quotas for the targeted account. GET \/api\/v1\/quotas container-registry.quota.get container-registry.quota.get \n Update quotas for the targeted account. PATCH \/api\/v1\/quotas container-registry.quota.set container-registry.quota.set \n\n\n\n\n\n\n\n Retention API methods \n\n\n\nTable 7. Retentions\n\n Action Method IAM ACTION AT ACTION \n\n List retention policies for all namespaces in the targeted IBM Cloud account. GET \/api\/v1\/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST \/api\/v1\/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST \/api\/v1\/retentions\/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_at_iam"},{"document_id":"ibmcld_05596-5434-6943","score":19.7886328912,"text":"\nThe image is created in your private registry. You can run the ibmcloud cr images command to verify that the image was created.\n\nREPOSITORY NAMESPACE TAG DIGEST CREATED SIZE VULNERABILITY STATUS\nus.icr.io\/namespace\/cf-py namespace latest cb03170b2cb2 3 minutes ago 271 MB OK\n\n\n\n\n\n\n\n Step 3: Deploy a container from your image \n\nDeploy your app as a container in a Kubernetes cluster.\n\n\n\n1. Create a configuration YAML file that is named cf-py.yaml and update <registry_namespace> with the name of your private image registry. This configuration file defines a container deployment from the image that you created in the previous lesson and a service to expose the app to the public.\n\napiVersion: apps\/v1\nkind: Deployment\nmetadata:\nlabels:\napp: cf-py\nname: cf-py\nnamespace: default\nspec:\nselector:\nmatchLabels:\napp: cf-py\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\napp: cf-py\nspec:\ncontainers:\n- image: us.icr.io\/<registry_namespace>\/cf-py:latest\nname: cf-py\n\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: cf-py-nodeport\nlabels:\napp: cf-py\nspec:\nselector:\napp: cf-py\ntype: NodePort\nports:\n- port: 5000\nnodePort: 30872\nShow more\n\n\n\nTable 2. Understanding the YAML file components\n\n Parameter Description \n\n image In us.icr.io\/<registry_namespace>\/cf-py:latest, replace <registry_namespace> with the namespace of your private image registry. If you are unsure what your namespace is, run the ibmcloud cr namespaces command to find it. \n nodePort Expose your app by creating a Kubernetes service of type NodePort.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cf_tutorial"},{"document_id":"ibmcld_05596-4175-5823","score":19.7248654602,"text":"\nSet the app directory\nas the working directory\nWORKDIR \/cf-py\/\nCOPY . .\n\nInstall any requirements that are defined\nRUN pip install --no-cache-dir -r requirements.txt\n\nUpdate the openssl package\nRUN apt-get update && apt-get install -y \nopenssl\n\nStart the app.\nCMD [\"python\", \"welcome.py\"]\nShow more\n3. Save your changes in the nano editor by pressing ctrl + o. Confirm your changes by pressing enter. Exit the nano editor by pressing ctrl + x.\n4. Build a Docker image that includes your app code and push it to your private registry.\n\ndocker build -t <region>.icr.io\/namespace\/cf-py .\n\n\n\nTable 1. Understanding this command's components\n\n Option Description \n\n build The build command. \n -t registry.<region>.icr.io\/namespace\/cf-py Your private registry path, which includes your unique namespace and the name of the image. For this example, the same name is used for the image as the app directory, but you can choose any name for the image in your private registry. If you are unsure what your namespace is, run the ibmcloud cr namespaces command to find it. \n . The location of the Dockerfile. If you are running the build command from the directory that includes the Dockerfile, enter a period (.). Otherwise, use the relative path to the Dockerfile. \n\n\n\nThe image is created in your private registry. You can run the ibmcloud cr images command to verify that the image was created.\n\nREPOSITORY NAMESPACE TAG DIGEST CREATED SIZE VULNERABILITY STATUS\nus.icr.io\/namespace\/cf-py namespace latest cb03170b2cb2 3 minutes ago 271 MB OK\n\n\n\n\n\n\n\n Step 3: Deploy a container from your image \n\nDeploy your app as a container in a Kubernetes cluster.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cf_tutorial"},{"document_id":"ibmcld_01377-13470-15034","score":19.2125040036,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-13496-15060","score":19.2125040036,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01377-8075-10005","score":18.7766607974,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":18.7766607974,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14738-7598-10031","score":22.9545628387,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_14598-9419-11893","score":22.7551892186,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_01092-7-2034","score":21.8934525105,"text":"\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.idrca.doc\/overview\/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dr"},{"document_id":"ibmcld_15843-7468-9604","score":21.590259719,"text":"\nAudit records IBM provides audit records of the VPC resource lifecycle through IBM Cloud Activity Tracker. The Customer uses IBM Cloud Activity Tracker tooling to monitor audit records. \n Security groups and ACLs IBM provides the ability to restrict access to virtual server instances by using security groups and networks ACLs. The Customer uses security groups and network ACLs to secure their virtual server instances, such as restricting what IP addresses can SSH into the instance. \n Public Network Access IBM provides options to use a public gateway or floating IP addresses. The Customer chooses how to connect their workload to the public internet, if applicable, either through a public gateway or floating IP. \n Access restriction IBM provides security measures for customers to restrict access to resources and resource groups. The Customer restricts user access to the appropriate resources and resource groups. \n Activity tracker IBM provides logging and monitoring tools. The Customer integrates IBM Cloud Activity Tracker and IBM Cloud Monitoring data into their auditing and monitoring processes. \n Encryption IBM Cloud VPN for VPC supports encrypted traffic by using IKE\/IPsec policies. The Customer ensures that their connection is encrypted end-to-end, if required. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Load balancer and VPN disaster recovery IBM Cloud Load Balancer and VPN for VPC have off-site storage and replication of configuration data in an out-of-region disaster recovery node with daily backups. This data is fully managed by IBM Cloud and no customer input is required to ensure service recovery, although there can be up to a 24-hour loss of configuration data. The Customer sets up their backup and recovery strategies for workload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpc"},{"document_id":"ibmcld_08669-4740-6634","score":20.8222373167,"text":"\nYou are responsible for the security and compliance of your application data.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM responsibilities Your responsibilities \n\n Applications Maintain controls that are commensurate to [various industry compliance standards](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-security-and-compliancecompliance-ready). Set up and maintain security and regulation compliance for your apps and data. For example, you can enable extra security settings to meet your compliance needs by choosing how and when to [import](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [wrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-wrap-keys), [rotate](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [rewrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-rewrap-keys), and [delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) keys. \n Encryption IBM is responsible for the encryption of keys. Keep your root of trust, the master key parts, on either your workstation or smart cards. \n Master key backups IBM never touches your master key. Backup your master key in a regular basis to your smart card or workstation. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_07285-5829-8487","score":20.4488125517,"text":"\nIdentity and access IBM provides the function to restrict access to resources through the IBM Cloud console and REST APIs. The Customer is responsible for managing access to resources through IBM Cloud Identity and Access Management (IAM). \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks, such as security controls implementation and compliance certification.\n\n\n\nTable 5. Responsibilities for security and regulation compliance\n\n Task IBM Responsibilities Your Responsibilities \n\n Encryption IBM does not provide encryption capabilities. The Customer is responsible for encryption of data on disk, in motion, and in backups. The Customer is also responsible for choosing and managing appropriate additional security features. If the Customer uses Key Protect (Bring Your Own Key), or another form of encryption, the Customer is responsible for managing the service authorization and keys. \n Security IBM is responsible for ensuring the security of data on disk and data in motion within its infrastructure. The Customer is responsible for restricting user access to the appropriate resources and resource groups. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks, such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Diversity IBM provides diverse network options for consumption. The Customer must ensure diversity of Direct Link is deployed. \n Redundancy IBM provides diverse network options for consumption. Direct Link is not a redundant service. The Customer is responsible for establishing redundancy, as needed, via BGP schema. The Customer must also understand that Direct Link is not a redundant service. While IBM Cloud supplies Diverse Router (XCR) options, failover must be built into the BGP scheme a customer deploys between multiple Direct Links. \n Host service in multiple regions IBM is responsible for hosting this service in multiple regions. The Customer is responsible for designing and deploying their workload in a way that achieves the wanted availability and Disaster Recovery capabilities by using provided tools. For example, deploy in different zones of a region, use at least two load balancers that are located in different zones, and either use DNS records to point to the load balancers, or ensure that your application can handle a list of IP addresses that it can connect to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-responsibilities"},{"document_id":"ibmcld_01092-1621-2411","score":20.0111785761,"text":"\nThe RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default. The RPO for DR backups on Amazon Web Services is 24 hours. The RTO if a disaster occurs is 4 hours.\n\n\n\n\n\n Brazil: Supplementary Rule 14 (applies to systems provisioned for the Brazilian federal government) \n\nAt this time, the disaster recovery (DR) option for Db2 Warehouse on Cloud offerings is not available in Brazil for the federal government due to Supplementary Rule 14.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dr"},{"document_id":"ibmcld_14774-27023-28718","score":19.8958338077,"text":"\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_00471-1736-4209","score":19.6925982259,"text":"\nSee [IBM Cloudant backup and recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery) documentation for recommended tooling. \n\n\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Scaling IBM scales infrastructure to meet capacity selected by the customer. Customer chooses the provisioned throughput capacity for their IBM Cloudant instances. \n Upgrades IBM handles all upgrades and patches of the IBM Cloudant service for the customer. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 3. Responsibilities for security and regulation compliance\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n At-rest encryption By default, IBM encrypts all disks by using IBM Cloudant-managed encryption keys. If the customer wants bring-your-own-key (BYOK) encryption, then the customer is required to use Key Protect to store the customer-managed encryption key. The customer must select an appropriate key management service instance, and select a disk encryption key option during provisioning of an IBM Cloudant Dedicated Hardware plan instance. \n Make data unreadable to IBM Cloudant Operators None, IBM does not render data unreadable to IBM Cloudant Operators. If you intend to store sensitive information in an IBM Cloudant database, you must use client-side encryption to render data unreadable to IBM Cloudant operators. For example, for PCI DSS compliance, you must encrypt the Primary Account Number (PAN) before sending a document that contains it to the database. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes the following tasks:\n\n\n\n* Provide dependencies on disaster recovery sites.\n* Provision disaster recovery environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-responsibilities"},{"document_id":"ibmcld_08669-6042-7847","score":19.6419401483,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00512-1696-3972","score":18.0055686439,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00513-7-2197","score":17.3768074438,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00512-7-2158","score":16.7040682363,"text":"\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00576-7385-9302","score":14.9856944927,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-20968-23077","score":14.9061645749,"text":"\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00589-25445-26913","score":14.6332467909,"text":"\nGET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_disk_size\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_info\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design_docs cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.any-document.read \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n COPY \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n POST\/DELETE \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.design-document.write \n GET\/HEAD \/$DATABASE\/_security cloudantnosqldb.database-security.read \n PUT \/$DATABASE\/_security cloudantnosqldb.database-security.write \n GET\/HEAD \/$DATABASE\/_shards cloudantnosqldb.database-shards.read \n COPY (Depends on write document type.) \/$DATABASE\/$DOCUMENT_ID cloudantnosqldb.any-document.read + cloudantnosqldb.design-document.write either or both cloudantnosqldb.local-document.write either or both cloudantnosqldb.data-document.write","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_00612-7-2163","score":14.4867081201,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_06633-1299-3259","score":14.4802058108,"text":"\nYou can extend high-availability further by adding [PostgreSQL members](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-horizontal-scaling) to the instance, for greater in-region redundancy, or by provisioning [read-only replicas](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-read-only-replicas) for cross-regional failover or read offloading.\n\nDatabases for PostgreSQL is designed and built to provide a robust, resilient, and performant Database as a Service offering. Review the PostgreSQL documentation on [replication techniques](https:\/\/www.postgresql.org\/docs\/current\/wal-async-commit.html) to understand the constraints and tradeoffs that are associated with the asynchronous replication strategy that is deployed by default with Databases for PostgreSQL.\n\nIn scenarios where a database becomes critically unhealthy, such as a server crash on the leader, Databases for PostgreSQL attempts a failover. This auto failover capability is capped at 16 MB of data lag from leader to follower (a few rows of data once accounting for more PostgreSQL data overhead) and is not performed if the lag threshold is exceeded. If the potential for 16 MB of data loss is intolerable for the application, horizontally scale your Databases for PostgreSQL instance to three members and configure Databases for PostgreSQL to use a synchronous replication strategy on a per user or per database basis.\n\n\n\n Synchronous replication \n\nBy default, streaming replication is asynchronous. If the primary server crashes, some transactions that were committed might not have been replicated to the standby server, causing data loss. Cloud Databases ensures that data loss is kept to a minimum substantial data loss; however, synchronous replication offers the ability to confirm that all changes were made by a transaction have been transferred to a synchronous member, ensuring consistency across a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-high-availability"},{"document_id":"ibmcld_00550-7-2005","score":14.4731913165,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_09521-7-2114","score":14.2927608813,"text":"\nLimitations & Exclusions \n\nMaximo Application Suite SaaS is implemented using a defined set of technologies and operates within a security profile designed to ensure our client's data is secure and the applications operate efficiently and effectively. As a result of the decisions made regarding technologies and to meet the high security standards, there are differences between what is available using the Managed Services and what a client could do if they hosted and operated the Suite themselves.\n\nThe following items are not included or allowed in the Maximo Application Suite SaaS offering:\n\n\n\n Databases \n\nThe following are database limitations of the MAS-SaaS offering:\n\n\n\n* Only IBM DB2 Warehouse is supported. Oracle and SQLServer are not supported. Conversion services are available.\n* If converting from Oracle to DB2, Oracle compatibility mode is not supported.\n* Customers are not allowed direct access to MAS-SaaS database(s). If direct database access is needed, customer should look into the [MAS-Dedicated](https:\/\/cloud.ibm.com\/docs\/mas-ms) offering.\n* DB2 Text Search is not supported.\n* Running SQL statements (update\/insert\/delete) directly on the database is not allowed and IBM SRE team will not be able to execute those statements for you. DBC scripts are not allowed. Customers should carry out these changes using the Maximo UI via [Automation Scripts](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) or the [Maximo Integration Framework](https:\/\/www.ibm.com\/docs\/en\/maximo-ora-con\/8.1.0?topic=architecture-maximo-integration-framework-overview).\n\n\n\n\n\n\n\n Java Extensions \n\nJava extensions are not supported. Maximo Manage [Automation Scripting](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) capability should instead be used. Existing Maximo customers who have Java extensions will need to migrate \/ convert these functions into automation scripts within the application.\n\n\n\n\n\n 3rd Party Applications \n\nMaximo Application Suite SaaS will not host or support 3rd party applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-limitations-exclusions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03369-66296-68553","score":40.5709102762,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03329-1102-2607","score":40.5148225974,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_16364-103662-105841","score":40.3640819171,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02998-1325-2715","score":40.0552478253,"text":"\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03049-1355-3132","score":39.1708875165,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_07578-18457-20516","score":38.9805813846,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-18457-20516","score":38.9805813846,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16364-146046-148039","score":37.4102198137,"text":"\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-101992-104197","score":36.9416391268,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03313-17920-19395","score":36.9402941638,"text":"\nTo do so, add a new intent or entity, and then delete it. This action starts a new training process.\n\n\n\n\n\n Is there a range of IP addresses that are being used by a webhook? \n\nUnfortunately, the IP address ranges from which Watson Assistant may call a webhook URL are subject to change, which in turn prevent using them in any static firewall configuration. Please use the https transport and specify an authorization header to control access to the webhook.\n\n\n\n\n\n How do I see my monthly active users in Watson Assistant? \n\nTo see your monthly active users (MAU) do the following:\n\n\n\n1. Sign in to [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com)\n2. Click on the Manage menu, then choose Billing and usage.\n3. Click on Usage.\n4. For Watson Assistant, select View Plans.\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n\n\n\n\n Error: New Off Topic not supported \n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n\n\n\n\n\n Is it possible to increase the number of intents per skill \n\nNo, it is not possible to increase the number of intents per skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09120-94597-96242","score":9.3397685255,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-95785-97389","score":9.3383511797,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_04488-93746-95375","score":9.3324969525,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-22025-23534","score":9.2860169281,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-29325-30645","score":9.2683225251,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-30080-31503","score":9.2651047137,"text":"\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09055-69659-70937","score":9.2625574789,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08987-28071-29358","score":9.261164682,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_04488-28730-30034","score":9.2532859548,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09087-21484-22833","score":9.2385104573,"text":"\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12573-4001-5682","score":17.2693146262,"text":"\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group. This option is exclusive with --parent-account-group and --parent-enterprise.\n\n--parent-enterprise (required)\n: Set enterprise as the parent. This option is exclusive with --parent-account-group and --parent-account-group-id.\n\n\n\n\n\n\n\n ibmcloud enterprise account-show \n\nDisplay details of an account.\n\nibmcloud enterprise account-show (-n, --name NAME | --id ID)\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of the account. This option is exclusive with --id.\n\n\n\n\n\n\n\n ibmcloud enterprise accounts \n\nList accounts.\n\nibmcloud enterprise accounts [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID] [--recursive]\n\n\n\n Command options \n\n--parent-account-group ACCOUNT_GROUP_NAME (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant accounts.\n\n\n\n\n\n\n\n ibmcloud enterprise account-import \n\nImport a stand-alone account.\n\nibmcloud enterprise account-import (--account-id ID) [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID]\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_12573-2772-4341","score":17.130772267,"text":"\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.\n\n--parent-account-group ACCOUNT_GROUP_NAME (optional).\n: Name of the parent account group. If omitted, the parent would be the current enterprise.\n\n\n\n\n\n\n\n ibmcloud enterprise account-delete \n\nDelete an account.\n\nibmcloud enterprise account-delete (-n, --name NAME | --id ID) [-q, --quiet]\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME\n: Name of the account group. This option is exclusive with --id.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud enterprise account-move \n\nMove an account under different parent.\n\nibmcloud enterprise account-move (-n, --name NAME | --id ID) (--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID | --parent-enterprise)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_12573-1474-3115","score":16.954464347,"text":"\nibmcloud enterprise account-group-update \n\nUpdate an account group.\n\nibmcloud enterprise account-group-update (-n, --name NAME | --id ID) (--new-name NEW_NAME)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account group. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account group. This option is exclusive with --id.\n\n--new-name NEW_NAME (required)\n: New name of target account group.\n\n\n\n\n\n\n\n ibmcloud enterprise account-group \n\nDisplay details of account group.\n\nibmcloud enterprise account-group (-n, --name NAME | --id ID)\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of the account group. This option is exclusive with --id.\n\n\n\n\n\n\n\n ibmcloud enterprise account-groups \n\nList account groups.\n\nibmcloud enterprise account-groups [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID] [--recursive]\n\n\n\n Command options \n\n--parent-account-group ACCOUNT_GROUP_NAME (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_04360-1365-3035","score":16.6717319372,"text":"\nibmcloud billing resource-group-usage \n\nShow monthly usage for a resource group (account admin or resource group admin only):\n\nibmcloud billing resource-group-usage GROUP_NAME [-d YYYY-MM] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\nGROUP_NAME (required)\n: Name of the resource group.\n\n-d MONTH_DATE (optional)\n: Display data for the month and date that is specified by using the YYYY-MM format. If not specified, usage of the current month is shown.\n\n--output FORMAT (optional)\n: Specify output format. Only JSON is supported.\n\n-q, --quiet (optional)\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud billing resource-instances-usage \n\nShow monthly resource instances usage under the current account:\n\nibmcloud billing resource-instances-usage [-o ORG] [-g RESOURCE_GROUP] [-d YYYY-MM] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n-o ORG_NAME (optional)\n: Filter instances by organization.\n\n-g GROUP_NAME\n: Filter instance by resource group.\n\n-d MONTH_DATE (optional)\n: Display data for month and date that is specified by using the YYYY-MM format. If not specified, usage of the current month is shown.\n\n--output FORMAT (optional)\n: Specify output format. Accepted inputs are JSON and CSV.\n\n-q, --quiet (optional)\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud billing enterprise-usage \n\nShow enterprise usage reports:\n\nibmcloud billing enterprise-usage [--account-group ACCOUNT_GROUP_NAME | --account-group-id ACCOUNT_GROUP_ID | --account ACCOUNT_NAME | --account-id ACCOUNT_ID] [--month MONTH] [--children] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n--account ACCOUNT_NAME (optional)\n: Name of target account.\n\n--account-id ACCOUNT_ID (optional)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_billing"},{"document_id":"ibmcld_03435-20211-22413","score":16.4797727873,"text":"\nAccount usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-at_events_acc_mgt"},{"document_id":"ibmcld_02379-22602-24722","score":15.9915436882,"text":"\nEnterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated) \n\nThis section explains events that are generated when you configure the IAM account settings from the Access (IAM) > Settings dashboard.\n\n\n\n Configuring MFA \n\nWhen you set on MFA in your account by configuring the Account Login section in the Access (IAM) > Settings dashboard, you get 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.\n* Event with action billing.account-mfa.set-on that indicates that MFA is enabled in the account.\n\n\n\nWhen you set off MFA, you get the following 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"},{"document_id":"ibmcld_04360-2697-3466","score":15.844554098,"text":"\nibmcloud billing enterprise-usage [--account-group ACCOUNT_GROUP_NAME | --account-group-id ACCOUNT_GROUP_ID | --account ACCOUNT_NAME | --account-id ACCOUNT_ID] [--month MONTH] [--children] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n--account ACCOUNT_NAME (optional)\n: Name of target account.\n\n--account-id ACCOUNT_ID (optional)\n: ID of target account.\n\n--account-group ACCOUNT_GROUP_NAME (optional)\n: Name of target account group.\n\n--account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of target account group.\n\n--children (optional)\n: Show children usage reports.\n\n--month MONTH (optional)\n: Target month. Default to current month.\n\n--output FORMAT (optional)\n: Specify output format. Only JSON is supported.\n\n-q, --quiet (optional)\n: Suppress verbose output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_billing"},{"document_id":"ibmcld_12573-5339-6020","score":15.6156048359,"text":"\nThis option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant accounts.\n\n\n\n\n\n\n\n ibmcloud enterprise account-import \n\nImport a stand-alone account.\n\nibmcloud enterprise account-import (--account-id ID) [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID]\n\n\n\n Command options \n\n--account-id\n: ID of source account.\n\n--parent-account-group PARENT_ACCOUNT_GROUP (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id PARENT_ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_12544-4880-7097","score":15.4470782408,"text":"\nUsers in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit. When accounts in the enterprise create and use resources, the cost for this usage is deducted from the credit pool.\n\nWhen existing subscriptions are added to the enterprise, each individual subscription term is re-created within the credit pool, including characteristics such as the remaining credit balance, start dates, and end dates. As credit is used, the subscription terms burn down individually according to when they expire. For example, you imported two accounts with existing subscriptions in August 2019. One subscription, 32100456, is for $1,000 for 18 months that began in January 2019. Because it spans multiple years, the subscription is divided into terms of up to one year each. The other subscription, 55543210 is for $500 a month for two years that began in April 2019, which is also divided into multiple terms. Then, you purchased a new one-year subscription, 00012345, through your enterprise for $1,500 a month that starts in July 2020. As enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_02379-20817-23063","score":15.2309171361,"text":"\nThis section explains events that are generated when a user looks at the information that is provided through the Manage > Billing and usage > Usage section, or request an export of the data.\n\nYou can get events with reason.reasonCode = 404 that are generated when there is no usage data available for the request. The severity is set to normal.\n\n\n\n requestData fields \n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-summary.read, billing.account-summary.download, and billing.account-instances-usage-report.download:\n\n\n\nTable 16. Account usage summary requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-usage-report.read:\n\n\n\nTable 17. Account usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":34.359973863,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":34.359973863,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-12399-14287","score":26.1718517228,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":25.8141585498,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":25.8141585498,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":25.7123359696,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":25.2202028437,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":25.2202028437,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":23.9032257967,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-13891-15856","score":23.8947680992,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03354-4-1897","score":23.5950541805,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_09956-1678-3537","score":21.7590584399,"text":"\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table\n* _v_schema\n* _v_database\n\n\n\n\n\n\n\n\n\n Viewing the retention time interval with the web console \n\n\n\n Viewing the default retention time interval for the system with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Go to Databases. The retention time interval for the system is displayed in the Retention time interval section at the top of the page.\n\n\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. View the retention time interval:\n\n\n\n* For a table:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to view the retention interval is located.\n3. Ensure that you are in the DB Objects > Tables tab.\n4. Identify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_05070-25374-27355","score":21.4652288111,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nfunction extendRetentionPeriodOnObject(bucketName, objectName, additionalSeconds) {\nconsole.log(Extend the retention period on ${objectName} in bucket ${bucketName} by ${additionalSeconds} seconds.);\nreturn cos.extendObjectRetention({\nBucket: bucketName,\nKey: objectName,\nAdditionalRetentionPeriod: additionalSeconds\n}).promise()\n.then((data) => {\nconsole.log(New retention period on ${objectName} is ${data.RetentionPeriod});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_01178-22864-25119","score":21.269782523,"text":"\nSegment By Service instance, Service instance name \n\n\n\n\n\n\n\n Number of under in-sync replica partitions \n\nThe number of partitions with fewer than two in-sync replicas.\n\n\n\nTable 18. Number of under in-sync replica partitions metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_under_minisr_partitions \n Metric Type gauge \n Value Type none \n Segment By Service instance \n\n\n\nIdeally this value should be zero. A nonzero value might highlight a temporary issue with the cluster.\n\n\n\n\n\n Produce message conversion time \n\nIndicates that the accumulated time spent performing message conversion from clients that are producing by using older protocol versions.\n\n\n\nTable 19. Produce message conversion time metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_produce_conversions_time_quantile \n Metric Type gauge \n Value Type second \n Segment By Service instance, Quantile, Service instance name \n\n\n\nIdeally zero. A consistent growth in this indicates that some clients are down-level and should be upgraded. Ensure that all clients are at the latest levels.\n\n\n\n\n\n Rebalancing consumer groups \n\nThe number of rebalancing consumer groups in an Event Streams instance.\n\n\n\nTable 20. Rebalancing consumer groups metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_rebalancing_consumergroups \n Metric Type gauge \n Value Type none \n Segment By Service instance, Service instance name \n\n\n\nWhile it is expected that this figure is occasionally >0 (as broker restarts happen frequently,) sustained high levels suggest that consumers might be restarting frequently and leaving or rejoining the consumer groups. Check you client logs.\n\n\n\n\n\n Reserved disk space percentage \n\nThe percentage of reserved disk space that is required for all allocated partitions if fully used.\n\n\n\nTable 21. Reserved disk space percentage metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_reserved_disk_space_percent \n Metric Type gauge \n Value Type percent \n Segment By Service instance, Service instance name \n\n\n\nShows the percentage of disk space that would be used if your topics were filled to the extent of their configured retention size.\n\n\n\n\n\n Schema greatest version percentage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-metrics"},{"document_id":"ibmcld_04866-25931-27510","score":21.2239688308,"text":"\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\nfunction deleteLegalHoldFromObject(bucketName, objectName, legalHoldId) {\nconsole.log(Deleting legal hold ${legalHoldId} from object ${objectName} in bucket ${bucketName});\nreturn cos.client.deleteLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} deleted from object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Extend the retention period of an object \n\nThis implementation of the POST operation uses the extendRetention query parameter to extend the retention period of a protected object in a protected bucket.\n\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period that is stored in the object metadata is either increased by the given extra time or replaced with the new value, depending on the parameter that is set in the extendRetention request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-25910-27489","score":21.2239688308,"text":"\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\nfunction deleteLegalHoldFromObject(bucketName, objectName, legalHoldId) {\nconsole.log(Deleting legal hold ${legalHoldId} from object ${objectName} in bucket ${bucketName});\nreturn cos.client.deleteLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} deleted from object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Extend the retention period of an object \n\nThis implementation of the POST operation uses the extendRetention query parameter to extend the retention period of a protected object in a protected bucket.\n\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period that is stored in the object metadata is either increased by the given extra time or replaced with the new value, depending on the parameter that is set in the extendRetention request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_09958-13738-15454","score":21.0076177851,"text":"\nThe table\u2019s retention lower bound and retention start time are equal to or just before the commit time of this altering transaction.\n\nUnlike when you create a table, existing visible rows in the table are treated as if they were inserted by this altering transaction. The existing visible rows receive virtual insert timestamps that are equal to the retention start time. With these timestamps, the rows are potentially visible to time travel queries.\n\n\n\n\n\n Altering temporal schemas to nontemporal with the web console \n\nTo alter a temporal schema to nontemporal, set retention time interval to 0.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Alter your table as described in [Updating retention time interval for schemas](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemasupdating_rt_sch).\n\n\n\n\n\n\n\n Altering nontemporal schemas to temporal with the web console \n\nTo alter a nontemporal schema to temporal, set retention time interval to a nonzero value.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Alter your table as described in [Updating retention time interval for schemas](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemasupdating_rt_sch).\n\n\n\n\n\n\n\n Altering temporal databases to nontemporal with the web console \n\nTo alter a temporal database to nontemporal, set retention time interval to 0.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_05070-20435-22267","score":20.6302952151,"text":"\nfunction getProtectionConfigurationOnBucket(bucketName) {\nconsole.log(Retrieve the protection on bucket ${bucketName});\nreturn cos.getBucketProtectionConfiguration({\nBucket: bucketName\n}).promise()\n.then((data) => {\nconsole.log(Configuration on bucket ${bucketName}:);\nconsole.log(data);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\nfunction putObjectAddLegalHold(bucketName, objectName, legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_05070-24369-25822","score":20.582082835,"text":"\nfunction addLegalHoldToObject(bucketName, objectName, legalHoldId) {\nconsole.log(Adding legal hold ${legalHoldId} to object ${objectName} in bucket ${bucketName});\nreturn cos.client.addLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\nfunction deleteLegalHoldFromObject(bucketName, objectName, legalHoldId) {\nconsole.log(Deleting legal hold ${legalHoldId} from object ${objectName} in bucket ${bucketName});\nreturn cos.client.deleteLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} deleted from object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\nShow more\n\n\n\n\n\n Extend the retention period of a protected object \n\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_09958-14981-16459","score":20.437014193,"text":"\nAlter your table as described in [Updating retention time interval for schemas](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemasupdating_rt_sch).\n\n\n\n\n\n\n\n Altering temporal databases to nontemporal with the web console \n\nTo alter a temporal database to nontemporal, set retention time interval to 0.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Alter your table as described in [Updating retention time interval for databases](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-databasesupdating_retention_db).\n\n\n\n\n\n\n\n Altering nontemporal databases to temporal with the web console \n\nTo alter a nontemporal database to temporal, set retention time interval to a nonzero value.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Alter your table as described in [Updating retention time interval for databases](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-databasesupdating_retention_db).\n\n\n\n\n\n\n\n\n\n What to do next \n\nAfter you created time travel objects, you can start running time travel queries. For more information, see the following links:\n\n\n\n* [Running queries syntax](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt)\n* [Querying historical data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-queryingdata_tt)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":38.9253388799,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":38.9253388799,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":31.8018081423,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":31.6482493578,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":30.5332494839,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":30.0004622238,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":29.5458332317,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":29.0180886924,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-545406-546780","score":28.988441976,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06160-10037-11653","score":28.9802673642,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02932-4408-6545","score":18.5381346304,"text":"\nFor example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.\n\n\n\n\n\n How autocorrection works \n\nNormally, user input is saved as-is in the text field of the input object of the message. If, and only if the user input is corrected in some way, a new field is created in the input object, called original_text. This field stores the user's original input that includes any misspelled words in it. And the corrected text is added to the input.text field.\n\nIf you want to ask users to confirm the assistant's understanding of their meaning, you can do so in a way that takes into account that their input might have been corrected. Set the condition for the dialog node or conditional response that is asking for confirmation to original_text. This means that if the user's input was automatically corrected, show the corresponding response. And the response can contain the expression: You said: <?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-check"},{"document_id":"ibmcld_03137-4194-5167","score":18.3143492352,"text":"\nIf it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autocorrection"},{"document_id":"ibmcld_16267-2886-4844","score":18.2764897025,"text":"\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong, meaning words that have implied significance because they occur in your action steps or dialog entity values, entity synonyms, or intent user examples.\n\n\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nIn dialog, fuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nIn dialog, when you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-autocorrection"},{"document_id":"ibmcld_07043-7-2215","score":18.1920244928,"text":"\nGlossary \n\n\n\nDefinitions of Discovery terms\n\n Term Definition \n\n Classifier A resource that you can train to recognize document types and categorize them in your collection. You can create two types of classifiers, a text classifier and a document classifier. A text classifier can classify documents based on words and phrases that are extracted from the body text with their part of speech information taken into account. A document classifier can classify documents based on words and phrases that are extracted from the body text fields with information from their part of speech and the other enrichments that are applied to the body text taken into account. The information from the other nonbody fields are also used. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-doc-classifier) \n Collection A set of documents that you can enrich and later search for meaningful information. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections). \n Content Intelligence A feature that you can use to enrich documents in a Document Retrieval project such that the project can recognize information that is relevant to business contracts. A Document Retrieval project with this feature enabled is referred to as a Document Retrieval for Contracts project type. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsdoc-retrieval-contracts) \n Data source An external application or service where valuable knowledge resources are stored. Connect to a service where your data is stored so you can crawl the data without having to move it. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections). \n Domain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-glossary"},{"document_id":"ibmcld_07033-18031-20115","score":18.1690113074,"text":"\nThe system learns from the types of examples you label, and applies what it learns to identify potential new examples. For example, after you label red, orange, yellow, green, and blue as examples of the color entity type, the Example suggestions panel might show indigo and violet as suggested examples for you to label. Suggestions are not displayed until after you label many examples of an entity type.\n\nThe following example shows suggestions that are made for family member mentions.\n\nZoom\n\n![Shows suggestions for family member entities.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/suggestions-example.png)\n\nFigure 10. Entity example suggestions\n\nYou might notice that a term that you chose to bulk label is not labeled, but is displayed as a suggestion instead. A term is skipped in the following situations:\n\n\n\n* The term might occur in different noun phrases in different sections of the document. For example, the term father might occur in the noun phrases the kindest father and to her father. When a word is included in a noun phrase with adjectives, the meaning can change. Therefore, such terms sometimes are suggested rather than labeled automatically.\n* A word might be a valid example on its own and as part of a multiple-word mention. For example, a mention of IBM might refer to the company International Business Machines, Corp. or might be used as part of a product name, such as IBM Cloud Pak for Data. However, a word or phrase can be part of only one example. Example labels cannot overlap one another. Therefore, you must choose which example suggestion is the most accurate. In this example, where the term IBM is used as part of a product name, it is more accurate to label the full phrase as an example of the Product entity type.\n* The service might recognize that a term is a possible example of more than one entity type. For example, the word top might mean the best or might mean shirt.\n\n\n\nTo investigate a suggestion further, click it to see the word in context within the document.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractor"},{"document_id":"ibmcld_07108-7-1958","score":18.0881108287,"text":"\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_07043-1723-3942","score":17.8176970084,"text":"\nDomain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant. For example, when you apply the Entity enrichment, terms that mention city names or famous people are tagged as locations or people of interest. \n Facet A category by which you can filter search query results. Automatically, facets based on entity types are applied to the query results for Document Retrieval projects and facets based on the parts of speech are applied to Content Mining projects. You can define your own facet categories based on document fields, including fields generated by enrichments, or based on dictionaries or patterns. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-facets) \n Index As you upload data or connect to data that is stored in an external repository, the data is crawled and ingested. As part of the processing, an index is created to keep track of important information that is recognized from the source. The main difference between a data source and a collection is that content in the data source is crawled, normalized, and indexed as it is added to a collection. \n Project A container for the collections of data that fuel your research or search applications. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects). \n Regular expression A regular expression, also known as a regex, is a standardized format for defining search patterns. You can define patterns with special significance to your application. For example, the bill of materials (BOM) numbers for parts that you manufacture might have a standard syntax of two uppercase letters followed by four numbers (GT2345). You can teach Discovery to recognize BOM mentions by adding a regular expression that can recognize and tag occurrences of the pattern in text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-glossary"},{"document_id":"ibmcld_03137-2586-4710","score":17.3904340524,"text":"\nIf there are misspelled terms that you expected your assistant to correct, but it did not, then review the rules that your assistant uses to decide whether to correct a word to see if the word falls into the category of words that your assistant intentionally does not change.\n\n\n\n\n\n Autocorrection rules \n\nTo avoid overcorrection, your assistant does not correct the spelling of the following types of input:\n\n\n\n* Capitalized words\n* Emojis\n* Locations, such as states and street addresses\n* Numbers and units of measurement or time\n* Proper nouns, such as common first names or company names\n* Text within quotation marks\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong, meaning words that have implied significance because they occur in your action steps or dialog entity values, entity synonyms, or intent user examples.\n\n\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nIn dialog, fuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nIn dialog, when you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autocorrection"},{"document_id":"ibmcld_07549-23293-25526","score":17.2719258882,"text":"\nIf a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.If you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.Additional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.<-- <\/section \"id=\"section-en-notice-add-term\" \"> --><-- <section \"id=\"section-en-notice-term\" \"> --> 8. Termination You may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.Moreover, your license from a particular copyright holder is reinstated permanently if the copyright older notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.<-- <\/section \"id=\"section-en-notice-term\" \"> --><-- <section \"id=\"section-en-notice-accept\" \"> --> 9.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_02932-2728-4915","score":16.7161101234,"text":"\nIf there are misspelled terms that you expected your assistant to correct, but it did not, then review the rules that your assistant uses to decide whether to correct a word to see if the word falls into the category of words that your assistant intentionally does not change.\n\n\n\n\n\n Autocorrection rules \n\nTo avoid overcorrection, your assistant does not correct the spelling of the following types of input:\n\n\n\n* Capitalized words\n* Emojis\n* Location entities, such as states and street addresses\n* Numbers and units of measurement or time\n* Proper nouns, such as common first names or company names\n* Text within quotation marks\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong in this skill, meaning words that have implied significance because they occur in entity values, entity synonyms, or intent user examples.\n\nMentions of a contextual entity can be corrected inadvertently. That's because terms that function as contextual entity mentions are fluid; they cannot be predetermined and avoided by the spell checker function in the way a list of dictionary-based terms can be.\n\n\n\nIf the word that is not corrected is not obviously one of these types of input, then it might be worth checking whether the entity has fuzzy matching enabled for it.\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nFuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-check"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03369-75826-77957","score":20.7300163393,"text":"\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.\n\nUse contextual entities to teach your skill to recognize the context in which such names are used. For more information about contextual entities, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFor more information about how to use contextual entites to identify names of people, see the [Detecting Names And Locations With Watson Assistant](https:\/\/medium.com\/ibm-watson\/detecting-names-and-locations-with-watson-assistant-e3e1fa2a8427) blog post on Medium.\n\nHow legacy numeric system entities are processed has changed\n: All new dialog skills use the new system entities automatically.\n\nFor existing skills that use legacy numeric system entities, how the entities are processed now differs based on the skill language.\n\n\n\n* Arabic, Chinese, Korean, and Japanese dialog skills that use legacy numeric system entities function the same as before.\n* If you choose to continue to use the legacy system entities in European-language dialog skills, a new legacy API format is used. The new legacy API format simulates the legacy system entities behavior. In particular, it returns a metadata object and does not stop the service from idenfifying multiple system entities for the same input string. In addition, it returns an interpretation object, which was introduced with the new version of system entities. Review the interpretation object to see the useful information that is returned by the new version.\n\n\n\nUpdate your skills to use the new system entities from the Options>System Entities page.\n\nWeb chat security is generally available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_02990-7468-9182","score":20.2169815863,"text":"\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n How long are log files kept for a workspace? \n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n\n\n\n\n\n How do I create a webhook? \n\nTo define a webhook and add its details, open the skill where you want to add the webhook. Open the Options page, and then click Webhooks to add details about your webhook. To invoke the webhook, call it from one or more of your dialog nodes. For more information, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\n\n\n\n\n Can I have more than one entry in the URL field for a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-faqs"},{"document_id":"ibmcld_03313-12458-14207","score":20.0304918596,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-filter-reference). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n Is it possible to recover a deleted skill?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_03383-20671-22804","score":19.978382609,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":19.978382609,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_07578-85554-87392","score":19.9323658087,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-85529-87367","score":19.9323658087,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02953-11701-13401","score":19.9172025451,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill is 100,000.\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_02953-12940-14393","score":19.8772741236,"text":"\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03054-27011-29125","score":19.86078013,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04111-19172-20546","score":43.4935067968,"text":"\nDelete a mTLS application DELETE \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id} internet-svcs.security.manage internet-svcs.access-apps.delete \n Get mTLS policies GET \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies internet-svcs.security.read internet-svcs.access-policies.read \n Create a mTLS policy POST \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies internet-svcs.security.manage internet-svcs.access-policies.create \n Update a mTLS policy PUT \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies\/{policy_id} internet-svcs.security.update internet-svcs.access-policies.update \n Delete a mTLS policy DELETE \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id} internet-svcs.security.manage internet-svcs.access-policies.delete \n\n\n\n\n\n\n\n Origin TLS Client Authentication \n\n\n\nTable 20. Edge Functions\n\n Action Method IAM ACTION AT ACTION \n\n List certificates used for origin TLS client authentication at domain level. GET \/v1\/{crn}\/zones\/{domain_id}\/origin_tls_client_auth internet-svcs.security.read internet-svcs.origin-tls-client-auth.read \n Create a certificate used for origin TLS client authentication at domain level. POST \/v1\/{crn}\/zones\/{domain_id}\/origin_tls_client_auth\/{cert_id} internet-svcs.security.manage internet-svcs.origin-tls-client-auth.create \n Delete a certificate used for origin TLS client authentication used at domain level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_05877-8738-10241","score":42.0466253633,"text":"\nCreate an authentication policy file that is named default.yaml. This policy is namespace-scoped and configures workloads in the service mesh to accept only encrypted requests with TLS. Note that no targets specifications are included because the policy applies to all services in the mesh in this namespace.\n\napiVersion: \"security.istio.io\/v1beta1\"\nkind: \"PeerAuthentication\"\nmetadata:\nname: \"default\"\nspec:\nmtls:\nmode: STRICT\n2. Apply the authentication policy to a namespace.\n\nkubectl apply -f default.yaml -n <namespace>\n3. Create a destination rule file that is named destination-mtls.yaml. This policy configures service mesh workloads in a namespace to send traffic by using TLS. Note that the host: .local wildcard applies this destination rule to all services in the mesh.\n\napiVersion: \"networking.istio.io\/v1beta1\"\nkind: \"DestinationRule\"\nmetadata:\nname: \"destination-mtls\"\nspec:\nhost: \".local\"\ntrafficPolicy:\ntls:\nmode: ISTIO_MUTUAL\n4. Apply the destination rule.\n\nkubectl apply -f destination-mtls.yaml -n <namespace>\n5. If you want to achieve mTLS for service mesh workloads in other namespaces, repeat these steps each namespace.\n\n\n\nDestination rules are also used for non-authentication reasons, such as routing traffic to different versions of a service. Any destination rule that you create for a service must also contain the same TLS block that is set to mode: ISTIO_MUTUAL. This block prevents the rule from overriding the mesh-wide mTLS settings that you configured in this section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-qs"},{"document_id":"ibmcld_05876-32979-34054","score":37.9244772317,"text":"\n2. Apply the authentication policy to a namespace.\n\nkubectl apply -f default.yaml -n <namespace>\n3. Create a destination rule file that is named destination-mtls.yaml. This policy configures service mesh workloads in a namespace to send traffic by using TLS. Note that the host: .local wildcard applies this destination rule to all services in the mesh.\n\napiVersion: \"networking.istio.io\/v1beta1\"\nkind: \"DestinationRule\"\nmetadata:\nname: \"destination-mtls\"\nspec:\nhost: \".local\"\ntrafficPolicy:\ntls:\nmode: ISTIO_MUTUAL\n4. Apply the destination rule.\n\nkubectl apply -f destination-mtls.yaml -n <namespace>\n5. If you want to achieve mTLS for service mesh workloads in other namespaces, repeat these steps each namespace.\n\n\n\nDestination rules are also used for non-authentication reasons, such as routing traffic to different versions of a service. Any destination rule that you create for a service must also contain the same TLS block that is set to mode: ISTIO_MUTUAL. This block prevents the rule from overriding the mesh-wide mTLS settings that you configured in this section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-mesh"},{"document_id":"ibmcld_04184-7-1931","score":37.0771744494,"text":"\nUsing mutual TLS \n\nMutual Transport Layer Security (mTLS) authentication ensures that traffic is both secure and trusted in both directions between a client and server. It is only available for customers at the Enterprise or Security plan level.\n\nWhen mTLS is configured, access is granted only to requests with a corresponding client certificate. When a request reaches the application, CIS responds with a request for the client certificate. If the client fails to present the certificate, the request is not allowed to proceed. Otherwise, the key exchange proceeds.\n\nZoom\n\n![Diagram of mTLS handshake](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/mtls-handshake.png)\n\nFigure 1. Diagram of an mTLS handshake\n\n\n\n Configuring mutual TLS \n\nMutual TLS is not enabled by default. It is an additional service that requires prior authorization and enablement.\n\nTo obtain authorization, you must submit an IBM Support case.\n\nAfter mTLS is turned on for your account, take the following steps to enable it.\n\n\n\n1. Navigate to the Security page in the CIS UI.\n2. Select the Mutual TLS tab.\n3. Click Enable to enable the feature.\n\n\n\nAfter mTLS is enabled, it cannot be disabled.\n\nTo set up mTLS authentication in the IBM Cloud Internet Services UI for a particular endpoint:\n\n\n\n1. In the Root certificates table, click Add to define a new root certificate.\n2. Paste the certificate content into the content field, provide a name for the Root CA, and add one or more fully qualified domain names (FQDN) of the endpoints that you want to use this certificate. These FQDNs are the hostnames that are used for the resources being protected by the application policy. You must associate the Root CA with the FQDN that the application being protected uses.\n3. Click Save.\n\nIf your zone is using an intermediate certificate in addition to the root certificate, upload the entire chain.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features"},{"document_id":"ibmcld_05876-31590-33332","score":36.7952732785,"text":"\nMake sure that the istio-global-proxy-accessLogFile option in the [managed-istio-custom ConfigMap](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize) is set to \"\/dev\/stdout\". Envoy proxies print access information to their standard output, which you can view by running kubectl logs commands for the Envoy containers. If you notice that the ibm-cloud-provider-ip pod for a gateway is stuck in pending, see [this troubleshooting topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio_gateway_affinity).\n\n\n\n\n\n\n\n Securing in-cluster traffic by enabling mTLS \n\nEnable encryption for workloads in a namespace to achieve mutual TLS (mTLS) inside the cluster. Traffic that is routed by Envoy among pods in the cluster is encrypted with TLS. The certificate management for mTLS is handled by Istio. For more information, see the [Istio mTLS documentation](https:\/\/istio.io\/latest\/docs\/tasks\/security\/authentication\/authn-policy).\n\n\n\n1. Create an authentication policy file that is named default.yaml. This policy is namespace-scoped and configures workloads in the service mesh to accept only encrypted requests with TLS. Note that no targets specifications are included because the policy applies to all services in the mesh in this namespace.\n\napiVersion: \"security.istio.io\/v1beta1\"\nkind: \"PeerAuthentication\"\nmetadata:\nname: \"default\"\nspec:\nmtls:\nmode: STRICT\n2. Apply the authentication policy to a namespace.\n\nkubectl apply -f default.yaml -n <namespace>\n3. Create a destination rule file that is named destination-mtls.yaml. This policy configures service mesh workloads in a namespace to send traffic by using TLS. Note that the host: .local wildcard applies this destination rule to all services in the mesh.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-mesh"},{"document_id":"ibmcld_04111-18082-19461","score":35.4179869584,"text":"\nAction Method IAM ACTION AT ACTION \n\n Get certificates uploaded for mTLS GET \/v1\/{crn}\/zones\/{domain_id}\/access\/certificates internet-svcs.security.read internet-svcs.access-certificates.read \n Upload a certificate for mTLS POST \/v1\/{crn}\/zones\/{domain_id}\/access\/certificates internet-svcs.security.manage internet-svcs.access-certificates.create \n Update a certificate for mTLS PUT \/v1\/{crn}\/zones\/{domain_id}\/access\/certificates\/{cert_id} internet-svcs.security.update internet-svcs.access-certificates.update \n Delete a certificate for mTLS DELETE \/v1\/{crn}\/zones\/{domain_id}\/access\/certificates\/{cert_id} internet-svcs.security.manage internet-svcs.access-certificates.delete \n Get mTLS applications GET \/v1\/{crn}\/zones\/{domain_id}\/access\/apps internet-svcs.security.read internet-svcs.access-apps.read \n Create a mTLS application POST \/v1\/{crn}\/zones\/{domain_id}\/access\/apps internet-svcs.security.manage internet-svcs.access-apps.create \n Update a mTLS application PUT \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id} internet-svcs.security.update internet-svcs.access-apps.update \n Delete a mTLS application DELETE \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id} internet-svcs.security.manage internet-svcs.access-apps.delete \n Get mTLS policies GET \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies internet-svcs.security.read internet-svcs.access-policies.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04168-3136-4483","score":35.3669138476,"text":"\n* [Enabling Proxy protocol](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-enable-proxy-protocol)\n\n\n\n* [Using service endpoints to privately connect to CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-service-endpoints)\n* Working with TLS\n\n\n\n* [Setting Transport Layer Security (TLS) options](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options)\n* [Using mutual TLS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features)\n* [Authenticated origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-authenticated-origin-pull)\n\n\n\n* Working with WAFs\n\n\n\n* [WAF actions and rule sets](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-settings)\n* [Using the CIS Security Events capability](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-using-the-cis-security-events-capability)\n\n\n\n* Working with firewall rules\n\n\n\n* [Creating, editing, and deleting firewall rules](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-firewall-rules)\n* [Assigning firewall rule actions](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions)\n* [Using fields, functions, and expressions](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions)\n* [Prioritizing options](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-priority)\n\n\n\n* Working with global load balancers\n\n\n\n* [Configuring a global load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configure-glb)\n* Global load balancer features","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_07578-1006129-1007999","score":35.2130015205,"text":"\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1006000-1007870","score":35.2130015205,"text":"\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04111-17057-18429","score":34.7279650309,"text":"\nUpdate a logpush job PUT \/v1\/{crn}\/zones\/{domain_id}\/logpush\/jobs\/{job_id} internet-svcs.zones.update internet-svcs.logpush-jobs.update \n Delete a logpush job DELETE \/v1\/{crn}\/zones\/{domain_id}\/logpush\/jobs\/{job_id} internet-svcs.zones.manage internet-svcs.logpush-jobs.delete \n Initiate the logpush ownership challenge POST \/v1\/{crn}\/zones\/{domain_id}\/logpush\/ownership internet-svcs.zones.manage internet-svcs.logpush-ownership.create \n Validate the logpush ownership challenge token POST \/v1\/{crn}\/zones\/{domain_id}\/logpush\/ownership\/validate internet-svcs.zones.manage internet-svcs.logpush-ownership-validate.create \n\n\n\n\n\n\n\n Custom Pages \n\n\n\nTable 18. Custom Pages\n\n Action Method IAM ACTION AT ACTION \n\n Get custom error pages GET \/v1\/{crn}\/zones\/{domain_id}\/custom_pages internet-svcs.zones.read internet-svcs.custom-pages.read \n Update custom error page PUT \/v1\/{crn}\/zones\/{domain_id}\/custom_pages\/{page_id} internet-svcs.zones.update internet-svcs.custom-pages.update \n\n\n\n\n\n\n\n Mutual TLS \n\n\n\nTable 19. Mutual TLS\n\n Action Method IAM ACTION AT ACTION \n\n Get certificates uploaded for mTLS GET \/v1\/{crn}\/zones\/{domain_id}\/access\/certificates internet-svcs.security.read internet-svcs.access-certificates.read \n Upload a certificate for mTLS POST \/v1\/{crn}\/zones\/{domain_id}\/access\/certificates internet-svcs.security.manage internet-svcs.access-certificates.create","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00542-4445-6620","score":16.7796804265,"text":"\nFor sensitive data, that you determine must remain invisible to IBM Cloudant, you must encrypt or otherwise protect (pseudonymize) your data before you send it to us. Do not use PI as a document _id in your URLs, for example, https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID, since PI is always visible and written to the access logs.\n\n\n\n\n\n Data locations \n\nLocations where IBM Cloudant processes personal data are made available, and kept up to date, through the DSA.\n\nFor more information about data locations, see the [DSA under 7. IBM Hosting and Processing Locations](https:\/\/www.ibm.com\/software\/reports\/compatibility\/clarity-reports\/report\/html\/softwareReqsForProduct?deliverableId=2EBB5860B34311E7A9EB066095601ABB).\n\n\n\n\n\n Service security \n\n\n\n Using IBM Cloudant securely \n\nAs a user of IBM Cloudant, you must follow these guidelines:\n\n\n\n* Use the default CORS configuration to prevent unexpected access.\n* Use API keys liberally, since components can have least privileged access, which is coupled with the audit log. This practice helps you understand who accessed which data.\n* Encrypt or otherwise protect (pseudonymize) sensitive data that you determine must remain invisible to IBM Cloudant.\n\n\n\n\n\n\n\n Physical and environmental security measures \n\nPhysical security of our data centers is handled by the infrastructure providers: IBM Cloud\u00ae, AWS, and 21Vianet. All hold externally audited certifications for their physical security. IBM Cloudant doesn't provide further details of the physical security controls in place at our data centers.\n\nPhysical security of the office locations that are used by our personnel is handled by IBM Corporate. Certification details and attestation reports (that is, ISO and SOC2) can be provided to the customer upon request.\n\n\n\n\n\n Technical and Organizational Measures \n\nTechnical and Organizational Measures (TOMs) are employed by IBM Cloudant to ensure the security of Personal Data. IBM Cloudant holds externally audited certifications for the controls IBM Cloudant employs. Certification details and attestation reports (that is, ISO and SOC2) can be provided to the customer upon request.\n\n\n\n\n\n Service access to data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-general-data-protection-regulation-gdpr-"},{"document_id":"ibmcld_00636-7-2113","score":11.6613341397,"text":"\nSecuring your data in IBM Cloudant \n\n\n\n IBM Cloudant DBaaS data protection and security \n\nProtecting application data for large-scale web and mobile apps can be complex, especially with distributed and NoSQL databases.\n\nJust as it reduces the effort of maintaining your databases to keep them running and growing nonstop, IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae also ensures that your data stays secure and protected.\n\n\n\n\n\n Tier one physical platforms \n\nThe IBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by those providers, including (but not limited to):\n\n\n\n* Certifications - Compliance with SSAE16, SOC2 Type 1, ISAE 3402, ISO 27001, CSA, and other standards.\n* Access and identity management.\n* General physical security of data centers and network operations center monitoring.\n* Server hardening.\n* IBM Cloudant gives you the flexibility to choose or switch among the different providers as your SLA and cost requirements change.\n\n\n\nMore details about the certifications are available in the [Compliance information](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-compliancecompliance).\n\n\n\n\n\n Secure access control \n\nIBM Cloudant has a multitude of built-in security features, for you to control access to data:\n\n\n\nTable 1. IBM Cloudant security features\n\n Feature Description \n\n Authentication IBM Cloudant is accessed by using an HTTPS API. Where the API endpoint requires it, the user is authenticated for every HTTPS request IBM Cloudant receives. IBM Cloudant supports both legacy and IAM access controls. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication). \n Authorization IBM Cloudant supports both legacy and IAM access controls. The IBM Cloudant team recommends that you use IAM access controls for authentication whenever possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-securing-your-data-in-cloudant"},{"document_id":"ibmcld_00637-7-2030","score":11.3738005248,"text":"\nSecurity \n\nProtecting application data for large-scale web and mobile apps can be complex, especially with distributed and NoSQL databases.\n\nJust as it reduces the effort of maintaining your databases to keep them running and growing nonstop, IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae also ensures your data stays secure and protected.\n\n\n\n Tier one physical platforms \n\nThe IBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by those providers, including (but not limited to):\n\n\n\n* Certifications - Compliance with SSAE16, SOC2 Type 1, ISAE 3402, ISO 27001, CSA, and other standards.\n* Access and identity management.\n* General physical security of data centers and network operations center monitoring.\n* Server hardening.\n* IBM Cloudant gives you the flexibility to choose or switch among the different providers as your SLA and cost requirements change.\n\n\n\nMore details about the certifications are available in the [Compliance information](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-compliancecompliance).\n\n\n\n\n\n Secure access control \n\nIBM Cloudant has a multitude of built-in security features for you to control access to data:\n\n\n\nTable 1. IBM Cloudant security features\n\n Feature Description \n\n Authentication IBM Cloudant is accessed by using an HTTPS API. Where the API endpoint requires it, the user is authenticated for every HTTPS request IBM Cloudant receives. IBM Cloudant supports both legacy and IAM access controls. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication API document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication). \n Authorization IBM Cloudant supports both legacy and IAM access controls. The IBM Cloudant team recommends that you use IAM access controls for authentication whenever possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-security"},{"document_id":"ibmcld_14391-6359-8465","score":11.0184643863,"text":"\nFor all other VMware component updates, you must ensure that newly deployed ESXi servers and clusters have the most recent updates that you require. IBM Cloud for VMware Solutions does not offer support for applying updates and patches for VMware components. You must monitor and apply these updates yourself.\n\nTo download ESXi updates from VMware, you can configure VMware Update Manager (VUM), which is integrated into your vCenter Server. For more information, see [VMware Support](https:\/\/www.vmware.com\/support.html).\n\n\n\n\n\n Does the management services NSX Edge pose a security risk? \n\nAlthough the VMware NSX Edge\u2122 for management services is on a public subnet, the following security measures are in place to ensure that it does not pose a security risk:\n\n\n\n* The NSX Edge firewall is configured to allow only outgoing HTTPS (TCP port 443) traffic that is initiated by the management virtual machines.\n* SNAT (Source Network Address Translation) is used so that private IP addresses are not visible outside the private network.\n* Remote access for the management services NSX Edge appliance is disabled.\n* Passwords for accessing the management services NSX Edge from the private network are randomized and encrypted.\n\n\n\n\n\n\n\n Does the customer-managed NSX Edge pose a security risk? \n\nAlthough the customer-managed NSX Edge is connected to the public VLAN, security measures are in place to ensure that it does not pose a security risk. The following security measures are in place:\n\n\n\n* A firewall rule is in place to allow only outgoing traffic from the private subnet range of IP addresses.\n* A SNAT rule (disabled by default) is in place to convert all IP addresses from the private subnet to a single IP address on the public subnet.\n* Remote access for the customer-managed NSX Edge appliance is disabled.\n* Passwords for accessing the customer-managed NSX Edge from the private network are randomized and encrypted.\n\n\n\n\n\n\n\n How do I choose the data centers for my instances? \n\nThe instance deployments have strict physical infrastructure requirements, which vary among IBM Cloud data centers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions"},{"document_id":"ibmcld_00478-7-2275","score":10.6938935081,"text":"\nCompliance \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae provides a trustworthy and secure cloud database system. The service is built on best-in-industry standards, including ISO 27001:2013.\n\n\n\n Tier-1 physical systems \n\nIBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by these providers.\n\n\n\n\n\n General Data Protection Regulation (GDPR) \n\nThe GDPR seeks to create a harmonized data protection law framework across the EU. It also aims to give citizens back the control of their personal data, while it imposes strict rules on those entities who host and \"process\" this data, anywhere in the world. The Regulation also introduces rules that relate to the free movement of personal data within and outside the EU. For more information, see the [IBM privacy statement](https:\/\/www.ibm.com\/privacy\/).\n\n\n\n\n\n HIPAA \n\nIBM Cloudant, when deployed on dedicated hardware on IBM Cloud, meets the required IBM controls that are commensurate with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) Security and Privacy Rule requirements. These requirements include the appropriate administrative, physical, and technical safeguards required of Business Associates in 45 CFR Part 160 and Subparts A and C of Part 164. HIPAA must be requested at the time of provisioning and applies to the IBM Cloudant Enterprise plan, IBM Cloudant on IBM Cloud Dedicated plan, and IBM Cloudant Dedicated Hardware plan on IBM Cloud. Contact your sales representative to sign a Business Associate Addendum (BAA) agreement with IBM.\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nIBM Cloudant and IBM Cloudant Dedicated Cluster are audited by a third-party security firm and meet ISO 27001, ISO 27017, and ISO 27018 requirements. For more information, see the [IBM Cloudant Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the IBM Cloudant Compliance page cover the IBM Cloudant service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-compliance"},{"document_id":"ibmcld_02776-2010-4574","score":10.5583270183,"text":"\n* Technically Identifiable Personal Information (such as device IDs, usage-based identifiers, static IP address, and so on. - when linked to an individual)\n* Healthcare Information (data related to physical or mental health of an individual, or which otherwise reveals information about his or her health status)\n\n\n\n\n\n\n\n Usage Data \n\nWhen engaging in the Permitted Uses of the Service, Developer may collect certain information automatically, including, but not limited to the following (collectively \"Usage Data\"):\n\n\n\n* The types of devices being used for testing or development\n* IP addresses\n* Operating systems\n* The types of Internet browsers used\n* Unique device identifiers and other diagnostic data\n\n\n\n\n\n\n\n\n\n Use Of Data \n\nDeveloper uses the collected data for various purposes:\n\n\n\n* To perform development and testing of applications\n* To provide analysis or valuable information to improve development and testing\n* To monitor usage in development and testing\n* To detect, prevent, and address technical issues\n\n\n\n\n\n\n\n Transfer Of Data \n\nInformation, including Personal Data, may be transferred to \u2014 and maintained on \u2014 computers located outside of Developer\u2019s state, province, country or other governmental jurisdiction where the data protection laws may differ than those from Developer\u2019s jurisdiction.\n\nDeveloper will take all steps reasonably necessary to ensure that Personal Data is treated securely and in accordance with this Privacy Policy and applicable law. Developer will also ensure no transfer of Personal Data will take place to an organization or a country, unless there are adequate authorizations and controls in place including obtaining consent where necessary and ensuring the security of Personal Data.\n\n\n\n\n\n Disclosure Of Data \n\n\n\n Legal Requirements \n\nDeveloper may disclose Personal Data in the good faith belief that such action is necessary:\n\n\n\n* To comply with a legal obligation\n* To protect and defend the rights or property of Developer\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_07578-289590-291746","score":9.8774555757,"text":"\nWhen the IBM code version is updated, the VMware software and service versions that are already installed for the instance remain unchanged.\n\nIBM does not provide ongoing updates to add-on services such as Zerto or Veeam\u00ae. Obtaining and installing these updates is your responsibility.\n\nNewly deployed VMware ESXi\u2122 servers and clusters are patched with recent, but not necessarily the most recent, VMware ESXi updates.\n\nFor all other VMware component updates, you must ensure that newly deployed ESXi servers and clusters have the most recent updates that you require. IBM Cloud for VMware Solutions does not offer support for applying updates and patches for VMware components. You must monitor and apply these updates yourself.\n\nTo download ESXi updates from VMware, you can configure VMware Update Manager (VUM), which is integrated into your vCenter Server. For more information, see [VMware Support](https:\/\/www.vmware.com\/support.html).\n* Does the management services NSX Edge pose a security risk?\n\nAlthough the VMware NSX Edge\u2122 for management services is on a public subnet, the following security measures are in place to ensure that it does not pose a security risk:\n\n\n\n* The NSX Edge firewall is configured to allow only outgoing HTTPS (TCP port 443) traffic that is initiated by the management virtual machines.\n* SNAT (Source Network Address Translation) is used so that private IP addresses are not visible outside the private network.\n* Remote access for the management services NSX Edge appliance is disabled.\n* Passwords for accessing the management services NSX Edge from the private network are randomized and encrypted.\n\n\n\n* Does the customer-managed NSX Edge pose a security risk?\n\nAlthough the customer-managed NSX Edge is connected to the public VLAN, security measures are in place to ensure that it does not pose a security risk. The following security measures are in place:\n\n\n\n* A firewall rule is in place to allow only outgoing traffic from the private subnet range of IP addresses.\n* A SNAT rule (disabled by default) is in place to convert all IP addresses from the private subnet to a single IP address on the public subnet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-289564-291720","score":9.8774555757,"text":"\nWhen the IBM code version is updated, the VMware software and service versions that are already installed for the instance remain unchanged.\n\nIBM does not provide ongoing updates to add-on services such as Zerto or Veeam\u00ae. Obtaining and installing these updates is your responsibility.\n\nNewly deployed VMware ESXi\u2122 servers and clusters are patched with recent, but not necessarily the most recent, VMware ESXi updates.\n\nFor all other VMware component updates, you must ensure that newly deployed ESXi servers and clusters have the most recent updates that you require. IBM Cloud for VMware Solutions does not offer support for applying updates and patches for VMware components. You must monitor and apply these updates yourself.\n\nTo download ESXi updates from VMware, you can configure VMware Update Manager (VUM), which is integrated into your vCenter Server. For more information, see [VMware Support](https:\/\/www.vmware.com\/support.html).\n* Does the management services NSX Edge pose a security risk?\n\nAlthough the VMware NSX Edge\u2122 for management services is on a public subnet, the following security measures are in place to ensure that it does not pose a security risk:\n\n\n\n* The NSX Edge firewall is configured to allow only outgoing HTTPS (TCP port 443) traffic that is initiated by the management virtual machines.\n* SNAT (Source Network Address Translation) is used so that private IP addresses are not visible outside the private network.\n* Remote access for the management services NSX Edge appliance is disabled.\n* Passwords for accessing the management services NSX Edge from the private network are randomized and encrypted.\n\n\n\n* Does the customer-managed NSX Edge pose a security risk?\n\nAlthough the customer-managed NSX Edge is connected to the public VLAN, security measures are in place to ensure that it does not pose a security risk. The following security measures are in place:\n\n\n\n* A firewall rule is in place to allow only outgoing traffic from the private subnet range of IP addresses.\n* A SNAT rule (disabled by default) is in place to convert all IP addresses from the private subnet to a single IP address on the public subnet.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00542-6107-8245","score":9.8433972396,"text":"\nCertification details and attestation reports (that is, ISO and SOC2) can be provided to the customer upon request.\n\n\n\n\n\n Technical and Organizational Measures \n\nTechnical and Organizational Measures (TOMs) are employed by IBM Cloudant to ensure the security of Personal Data. IBM Cloudant holds externally audited certifications for the controls IBM Cloudant employs. Certification details and attestation reports (that is, ISO and SOC2) can be provided to the customer upon request.\n\n\n\n\n\n Service access to data \n\nIBM Cloudant operations and support staff have access to customer data and can access it during routine operations. This access is only done as required in order to operate and support the service. Access is also limited to a need to know basis and is logged, monitored, and audited.\n\n\n\n\n\n\n\n Deletion of data \n\n\n\n Deleting a document \n\nWhen a document is deleted, the database creates a \"tombstone.\" What the tombstone includes depends on how you delete it:\n\n\n\n* If you make a DELETE call, the tombstone includes the _id, _rev, and _deleted fields.\n* If you delete by updating the document with a _deleted: true field and add a PUT or POST request to it, the tombstone includes what you set in the document body. This practice can be useful in some circumstances, for example, when recording why a document was deleted in its tombstone.\n\n\n\nFor more information, see [Simple removal of \"tombstone\" documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentstombstone-documents).\n\n\n\n\n\n When is a deleted document removed? \n\nCompaction runs automatically and periodically removes old revisions (deleted or otherwise) from the database, by writing out only \"leaf\" revisions to a new file. IBM Cloudant keeps a history of _id and _rev to enable replication, but not old document bodies.\n\nIBM Cloudant doesn't expose the CouchDB compaction API.\n\nIBM Cloudant doesn't guarantee that a database is compacted in a specific time. Compaction is done as a background process across the storage tier. Databases are always being compacted. It isn't guaranteed that the data compacted is the data that you deleted or changed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-general-data-protection-regulation-gdpr-"},{"document_id":"ibmcld_00523-7-2476","score":9.7607553238,"text":"\nDisaster recovery and backup for IBM Cloudant \n\nYour data is important and valuable. You want to protect your data to help ensure it's secure, available, and maintains integrity. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae provides several ways to protect your data and help keep your applications operational.\n\nSome of these protection features are automatic. For other forms of protection, IBM Cloudant provides you with supported tools that help you to create your own high availability and disaster recovery capabilities.\n\nThe IBM Cloud\u00ae Service has Business Continuity plans in place to provide for the recovery of the Cloud Service within hours if a disaster occurs. You are responsible for your data backup, and associated recovery of your content.\n\nThis document provides an overview of the automatic capabilities and supported tools that are offered by IBM Cloudant.\n\n\n\n Types and levels of protection \n\nThe type of protection you might want depends on the problem you're trying to solve.\n\nFor example, you might want to have a high level of data availability so that you can still access your data, even if a limited amount of hardware within the system failed. This requirement is necessary for \"High Availability\" (HA). It means that you provide the best possible continuous data availability after a hardware failure. Different HA techniques tolerate different levels of failure before operations are affected.\n\nYou might want to have quick and easy ways of backing up and restoring data. For example, after a severe or extensive hardware failure, you want the ability to make all the data available on an alternative system as quickly as possible. This requirement is necessary for \"Disaster Recovery\" (DR). A disaster generally means that a database is no longer available in one or more locations. For example, a power outage might cause all systems in a database cluster to fail. Or a large-scale network failure might mean systems in a cluster can't be contacted, even though they continue to work correctly.\n\nAddressing your HA or DR requirements often begins by simplifying the problem into more generic requirements. When you identify your requirements, you can apply the tools and features that help solve the generic needs. Together, the tools and features can address your HA or DR requirements.\n\nDifferent tools and features provide different levels of protection. The different features might be more or less suitable for your specific HA or DR requirement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07498-0-1649","score":22.0617185423,"text":"\n\n\n\n\n\n\n  Enterprise account architecture \n\nLarge enterprises that allow an account structure, cross account networking, resource deployment, and billing to develop organically run the risk of encountering governance, scaling, security, and accounting issues. This document provides a recommendation for how to address these concerns across accounts so that a robust, compliant, and scalable solution can be achieved.\n\nThis recommendation extends and compliments the account and resource level guidance that is found in the [IBM Cloud Framework for Financial Services](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-about) and other IBM Cloud best practices such as:\n\n\n\n*  [Cloud best practices for IT executives](https:\/\/www.ibm.com\/downloads\/cas\/NYWPPW6K)\n*  [Best practices for setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-best-practices)\n*  [Best practices for organizing resources and assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setup)\n*  [Best practices for organizing users, teams, and applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)\n*  [Best practices for working with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-best-practices)\n*  [Best practices for billing and usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-best-practices)\n*  [Advanced networking for IBM Cloud VPC](https:\/\/www.ibm.com\/cloud\/architecture\/content\/course\/advanced-networking-for-vpc)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-about"},{"document_id":"ibmcld_14774-18795-21198","score":21.4945413533,"text":"\nWhile this design has only one backup server instance, it is recommended to deploy Enterprise Manager when encryption is used for backup or backup copy jobs. It is advised to install the Enterprise Manager server on the recovery site so it is available for disaster recovery.\n* Proxy server - This proxy is used for management components that are located in the recovery region.\n* Repository - A location used to store backup files for the management components in the recovery region and also the target for backup copy jobs from the protected region.\n* SFTP\/SMB server - These servers are not Veeam services but native Windows services that are used for file-level backups of some of the management components. A Veeam file copy job copies files to the protected region for extra protection.\n\n\n\nReview the following Veeam design decisions:\n\n\n\n* For optimal performance and availability, placing the Veeam components on separate virtual and physical servers is considered best practice. However, this practice increases complexity in smaller environments. Therefore, the all-in-one deployment scenario for use case 1 is selected.\n* As the total number of protected VMs is low, the embedded database option for the database for use case 1 is selected.\n* The bare metal servers with direct attached storage option are used as it provides a backup infrastructure that is separated from the virtualized infrastructure compute and storage.\n* In a two-site environment, it is best practice to install the Veeam Backup server component in the DR site. In a disaster situation, Veeam Backup server is available to start the recovery.\n* Deploy Enterprise Manager to use password loss protection. Enterprise Manager administrators can unlock backup files by using a challenge-response mechanism.\n* It is recommended that the proxy is as close as possible to the source data with a high-bandwidth connection. The traffic from the source to the proxy is not yet optimized, meaning that 100% of the backup data is transferred over this link. A good connection is required between proxy and repository as optimized data (normally 50% of the source data size) is transferred across this link. Therefore, place proxies in both the protected and recovery regions.\n* Proxies can be hosted on Windows Server or Linux OS with almost no performance differences. For the all-in-one deployment scenario, a Windows OS is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_04113-7-2190","score":21.3940364555,"text":"\nBest practices for CIS setup \n\nBecause IBM Cloud\u00ae Internet Services is positioned at the edge of your network, you\u2019ll need to take a few steps to guarantee a smooth integration with your CIS services. Here are some recommended best practices for integrating CIS with your origin servers.\n\nYou can do these steps either before or after you change your DNS and activate our proxy service. These recommendations allow CIS to connect to your origin servers properly. They\u2019ll help you prevent any issues with API or HTTPS traffic, and help your logs capture the correct IP addresses of your customers, rather than the protective CIS IP addresses.\n\nHere\u2019s what you\u2019ll need to set up:\n\n\n\n* Restore the originating IPs of your customers\n* Incorporate CIS IP addresses\n* Make sure your security settings don't interfere with API traffic\n* Configure your security settings as strictly as possible\n\n\n\n\n\n Best practice 1: Know how to restore the originating IPs of your customers \n\nAs a reverse proxy, CIS provides the origination IP in these headers:\n\n\n\n* CF-Connecting-IP\n* X-Forwarded-For\n* True-Client-IP (optional)\n\n\n\nYou can restore user IP addresses using a variety of tools, for infrastructures such as Apache, Windows IIS, and NGINX.\n\n\n\n\n\n Best practice 2: Incorporate CIS IP addresses to make integration smoother \n\nHere are the two steps to take:\n\n\n\n* Remove any rate limiting of CIS IP addresses\n* Set up your ACLs to allow only CIS IP addresses and other trusted parties\n\n\n\nYou can find the updated list of IP ranges for IBM CIS [at this location](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses).\n\n\n\n\n\n Best practice 3: Review your security settings to make sure they don\u2019t interfere with API traffic \n\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04178-7-2164","score":20.9007134523,"text":"\nManaging your CIS deployment for best performance \n\nIBM Cloud\u00ae Internet Services (CIS) can provide the fastest experience for your customers because it optimizes your images, and it stores your web content as near as possible to your end-users. Your content is loaded from proxied edge servers (which reduces latency).\n\nWith CIS, you can enhance your site's performance further by using best practices to speed up the loading of your web content. Here are some specific best practices for enhancing the performance of your web content within CIS.\n\nRecommended and best practices:\n\n\n\n* Cache as much of your static and semi-static web content as possible\n* For event-driven content, purge your cache using the API\n\n\n\n\n\n Best practice 1: Cache as much static and semi-static content as possible \n\n\n\n* Enable Cache Everything for static HTML web pages\n* Use conservative Time-to-live (TTL) for your content that changes occasionally\n\n\n\n\n\n Utilize conservative TTLs (Time-to-Lives) for content that changes occasionally \n\nIf content rarely changes, you can set a conservative TTL to utilize our cache as much as possible. If you have a high percentage of re-validation requests, you could increase the TTLs of your content without negatively affecting your customers. By using the cache more effectively, you'll increase performance because you'll revalidate less often.\n\n\n\n\n\n How do I tell if items are being cached? \n\nCIS adds the response header CF-Cache-Status when it attempts to cache an object. If caching is successful, the value of this header indicates its status with one of these keywords:\n\n\n\n* MISS: The asset was not yet in the cache or the TTL had expired (that is, it had reached the cache-control maximum age of 0).\n* HIT: The asset was delivered from the cache.\n* EXPIRED: This asset was delivered from cache, but the next request requires revalidation.\n* REVALIDATED: The asset was delivered from cache. The TTL was expired, but an If-Modified-Since request to the origin indicated that the asset had not changed. Therefore, the version in cache is considered valid again.\n\n\n\n\n\n\n\n\n\n Best practice 2: For event-driven content, purge your cache","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment-for-best-performance"},{"document_id":"ibmcld_07984-3902-5502","score":20.3728585193,"text":"\nDesign your application for high availability (recommended)](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-high-availability)\n* [14. Use endpoint detection and remediation (EDR) tooling to detect malicious code](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-endpoint-detection-remediation)\n* [15. Regularly scan for open ports \/ protocols](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-network-threat-detection)\n* [16. Secure and manage secrets and certificates](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-secrets-management)\n* [17. Tag all IBM Cloud resources with security attributes](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-security-attributes)\n* [18. Monitor for security and compliance against a baseline configuration](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-security-compliance-monitoring)\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-next-steps)\n\n\n\n[Best practices and requirements for software](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practices-softwarebest-practices-software)\n\n\n\n* [1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-sitemap"},{"document_id":"ibmcld_07984-2706-4346","score":19.8898484661,"text":"\nEnsure all operator actions are executed through a bastion host](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-bastion-host)\n* [8. Capture audit events and forward to a SIEM](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-audit-logs)\n* [9. Ensure operational logging and monitoring is implemented](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-operational-logging-and-monitoring)\n* [10. Follow secure development processes and ensure software integrity](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-development-processes)\n* [11. Encrypt consumer data at rest and in transit](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-encryption)\n* [12. Implement business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-bcdr)\n* [13. Design your application for high availability (recommended)](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-high-availability)\n* [14. Use endpoint detection and remediation (EDR) tooling to detect malicious code](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-endpoint-detection-remediation)\n* [15.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-sitemap"},{"document_id":"ibmcld_14375-6433-7293","score":19.2185228139,"text":"\nIt is a security best practice to replace user-facing certificates with certificates that are signed by a third-party or enterprise certificate authority (CA). Certificates for machine-to-machine communication can remain as VMCA\u2013signed certificates. However, it is recommended that you follow best practices for your organization, which typically involve the use of an identified enterprise CA.\n\nYou can use the Windows AD servers within this design to create certificates that are signed by the local instance. However, you can also choose to configure CA services if needed.\n\n\n\n\n\n Related links \n\n\n\n* [Physical infrastructure design](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-design_physicalinfrastructure)\n* [Virtual infrastructure design](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-design_virtualinfrastructure)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-design_commonservice"},{"document_id":"ibmcld_12453-9092-11379","score":19.2097849598,"text":"\nWhen you update a root CA certificate, the change impacts your entire public-key infrastructure. To minimize impact, it is recommended that you set a long validity period for your root CA certificate. In Secrets Manager, the default TTL for root certificates is 10 years.\n\n\n\n\n\n\n\n Choosing an algorithm for generating keys \n\nBefore you create a certificate authority in Secrets Manager, you must choose a key algorithm for generating the public and private keys for your CA. The public and private key-pair is used to authenticate an SSL\/TLS connection. If you're not sure where to start, you can use the following suggested guide for selecting a key algorithm.\n\n\n\n1. Choose an algorithm family.\n\nThe key algorithm that you select determines the encryption algorithm and key size to use to generate keys and sign certificates. As a best practice, use the same algorithm family for all certificates that belong to a certificate chain. Secrets Manager supports the following families of algorithms.\n\n\n\nTable 2. Supported algorithm families and key sizes\n\n Algorithm family Description Supported key sizes \n\n RSA Widely used and compatible with most browsers and servers, RSA is the industry standard for public-key cryptography. 2048 bits <br>4096 bits \n Elliptic curve (EC) Generates stronger keys and smaller certificates. For example, a 256-bit EC key is equivalent in encryption strength to a 3072-bit RSA key. 224 bits <br>256 bits <br>384 bits <br>521 bits \n\n\n\n2. Choose a key size.\n\nThe key size or length that you select determines the encryption strength. The larger the key size for an algorithm family, the more difficult it is to break. Keep in mind that longer key lengths results in more data to store and transmit, which can impact the performance of your certificate. As a best practice, choose a key size that is appropriate for the TTL or validity period of your certificate.\n\nFor longer living certificates, it is recommended to use longer key lengths to provide more encryption protection.\n\n\n\n\n\n\n\n\n\n Using certificate authority unauthenticated endpoints \n\nIf you're using leaf certificates that are issued by a CA in Secrets Manager for your applications, use the following API calls to gain access to the issuing CA Certificate Revocation List (CRL) and CA certificate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-create-certificates"},{"document_id":"ibmcld_03836-0-316","score":18.9419144705,"text":"\n\n\n\n\n\n\n  Best practices for application development \n\nInformation previously contained on this page has been refreshed and merged into the [Creating Applications tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app). For the most up to date recommendations, refer to that tutorial.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-best-practices-app"},{"document_id":"ibmcld_09109-8993-10845","score":18.6680468419,"text":"\nTo encode your key material, first you should download and install [OpenSSL](https:\/\/github.com\/openssl\/opensslfor-production-use).\n\nOnce OpenSSL has been downloaded and installed, there are two recommended commands for encoding the key material. Both methods are equivalent, in that they convert a string , whether <key_material_string> or , as you can see below, into a base64 string. If your material is in a file (for example, you might have a file with credentials, not just an encrypted key, that you want to store in Key Protect), the best option is to issue:\n\n {: pre}\nopenssl base64 -in <infile> -out <outfile>\n\nReplace the variables in the example request according to the following table.\n\n\n\nTable 2. Describes the variables that are needed to base64-encode your key material.\n\n Variable Description \n\n infile The name of the binary file where your key material string resides. <br> <br>Ensure that the file is not larger than 7,500 bytes. \n outfile The name of the file where your base64-encoded key material will be created once the command has run. \n\n\n\nIf you want to output the base64 material in the command line directly rather than a file, run the command openssl enc -base64 <<< '<key_material_string>', where key_material_string is the key material input for your imported key.\n\nIf you want to base 64 encode key material which is not in a file, you can issue:\n\n {: pre}\necho -n <password> | base64\n\nWhere \"password\" is the key material you want to use.\n\nTo avoid extra characters, for example an extra new line, it is a best practice to copy the base64 to the clipboard, especially when the base64 string is going to be posted in the console.\n\n\n\n\n\n Using OpenSSL to create and encode new key material \n\nUse this process to create a random base64-encoded key material with a specific byte length. 32 bytes (256 bits) is recommended.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-4-2033","score":18.7419094346,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03270-3352-5135","score":18.4253911931,"text":"\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03113-6206-7586","score":18.3185271944,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03113-4996-6502","score":18.1894609,"text":"\n[UI location where the code that is triggered by named event handlers is authored](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03273-11911-13556","score":17.9841172717,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03113-7328-8943","score":17.9649050034,"text":"\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)\n\nIn addition to creating node_9, the service automatically updates the previous_sibling property of node_6 so that it points to the new node.\n\n\n\n\n\n Moving a node to a different parent \n\nLet's move node_5 to a different parent by using the POST \/dialog_nodes\/node_5 method with the following body:\n\n{\n\"parent\": \"node_1\"\n}\n\nThe specified value for parent must be valid:\n\n\n\n* It must refer to an existing node.\n* It must not refer to the node being modified (a node cannot be its own parent).\n* It must not refer to a descendant of the node being modified.\n* It must not refer to a node of type response_condition or event_handler.\n\n\n\nThis results in the following changed structure:\n\n![Example dialog 4](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_4.png)\n\nSeveral things have happened here:\n\n\n\n* When node_5 moved to its new parent, node_7 went with it (because the parent value for node_7 did not change). When you move a node, all descendants of that node stay with it.\n* Because we did not specify a previous_sibling value for node_5, it is now the first sibling under node_1.\n* The previous_sibling property of node_4 was updated to node_5.\n* The previous_sibling property of node_9 was updated to null, because it is now the first sibling under node_2.\n\n\n\n\n\n\n\n Resequencing siblings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02952-1632-3754","score":17.8791264361,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02952-3289-5462","score":17.7235106967,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02882-27313-29495","score":17.6777848237,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03188-1732-3801","score":17.6514803641,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14984-4-2041","score":35.0777971784,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot \n\nRestoring from a backup snapshot creates a fully provisioned boot or data volume that you can use to boot an instance or attach as auxiliary storage. You can restore volumes during instance creation or when you want to create stand-alone boot or data volumes to be used later. You can restore a data volume to add more storage to an existing instance. You can use backup snapshots to restore volumes in a different region for business continuity purposes or geographic expansion. You can restore volumes from backup snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a backup snapshot \n\nWhen you restore a volume from a backup, the service creates another volume. The restored volume inherits the same [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata as the original volume. However, you can choose a different profile and capacity if you prefer. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the new volume inherits that encryption.\n\nRestoring a volume from a backup snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable. The volume appears first as pending while it's being created. During the restoration, your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC. After the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_14996-4-1904","score":34.9628305603,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot \n\nRestoring from a backup snapshot creates a fully provisioned boot or data volume that you can use to boot an instance or attach as auxiliary storage. You can restore volumes during instance creation or when you want to create stand-alone boot or data volumes to be used later. You can restore a data volume to add more storage to an existing instance. You can use backup snapshots to restore volumes in a different region for business continuity purposes or geographic expansion. You can restore volumes from backup snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a backup snapshot \n\nWhen you restore a volume from a backup, the service creates another volume. The restored volume inherits the same [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata as the original volume. However, you can choose a different profile and capacity if you prefer. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the new volume inherits that encryption.\n\nRestoring a volume from a backup snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable. The volume appears first as pending while it's being created. During the restoration, your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC. After the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-performance-considerations).\n\nFor best performance, use backups with fast restore.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_16024-9702-11722","score":34.6558253662,"text":"\nFor more information, see [Creating Block Storage for VPC volumes with customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-encryption). \n Encryption Instance Optional. A link to the provisioned KMS instance for a customer-managed encryption volume. \n Key Optional. The name and copiable ID of the root key that is used to encrypt the passphrase, which secures a customer-managed encryption volume. \n Backup policies The number of backup policies that are associated with the volume. Click the number link to go to the backup policies tab. \n Snapshots The number of snapshots that were created of the volume. Click the number link to go to the Snapshots and Backups tab. \n Attached virtual server Volumes attached to a virtual server instance are listed here. Click Attach to select an instance to attach this volume. For more information, see [Attaching a volume to an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storage). \n Status Tracks the overall lifecycle state of the volume, which ranges from volume creation to volume deletion. Attachment status, for example, attached when the volume is attached to an instance and attaching when in progress. \n Name Click the name of the virtual server instance to see instance details. \n Auto delete When enabled, the volume is automatically deleted when you delete the instance. Click the toggle to enable automatic deletion. \n Backup policies Shows backup policies that are associated with this volume. To associate backup policies, you can add a backup policy's tags for target resources to this volume. Click Apply to select a backup policy, then apply its tags for the target resource to the volume. \n\n\n\nTable 4 shows Actions menu options from the volume details page.\n\n\n\nTable 4. Actions menu options one the volume details page.\n\n Action Description \n\n Create snapshot Create a snapshot from a data volume or a \"bootable snapshot\" from a boot volume. Data volumes must be attached to a virtual server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-viewing-block-storage&interface=ui"},{"document_id":"ibmcld_15926-4-1908","score":34.6472771724,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore"},{"document_id":"ibmcld_15934-4-1908","score":34.6472771724,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=api"},{"document_id":"ibmcld_15937-4-1908","score":34.6472771724,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=cli"},{"document_id":"ibmcld_15938-4-1908","score":34.6472771724,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=terraform"},{"document_id":"ibmcld_15939-4-1908","score":34.6472771724,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=ui"},{"document_id":"ibmcld_15869-7-1976","score":34.4592647317,"text":"\nAbout Block Storage Snapshots for VPC \n\nBlock Storage Snapshots for VPC are a regional offering that is used create a point-in-time copy of your Block Storage for VPC boot or data volume. The initial snapshot that you take is a full backup of the volume. Subsequent snapshots of the same volume are incremental, so only the changes since the last snapshots are captured. You can restore data to a new volume during instance provisioning, from an existing instance, and when you create an unattached volume.\n\n\n\n Snapshots concepts \n\nA snapshot is a copy of your volume that you take manually in the UI or from the CLI, or create programmatically with the API, or Terraform. You can take a snapshot of a boot or data volume that is attached to a running virtual server instance or from an unattached data volume. A \"bootable\" snapshot is a snapshot of a boot volume. A \"nonbootable\" snapshot is of a data volume. You can take snapshots as often as you want. However, you cannot take a snapshot of a volume that's in a degraded state.\n\nDo you want to automatically create snapshots of your Block Storage for VPC volumes? With Backup for VPC, you can create backup policies to schedule regular volume backups. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n\nThe first time that you take a snapshot of a volume, all the volume's contents are copied. The snapshot has the same encryption as the volume (customer-managed or provider-managed). Snapshots are stored and retrieved from IBM Cloud\u00ae Object Storage. Data is encrypted while in transit and stored in the same region as the original volume.\n\nWhen you take a second snapshot, it captures only the changes that occurred since the last snapshot was taken. As such, the size of the snapshots can grow or shrink, depending on what is being uploaded to IBM Cloud\u00ae Object Storage. The number of snapshots increases with each successive snapshot that you take.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about"},{"document_id":"ibmcld_15883-7-1976","score":34.4592647317,"text":"\nAbout Block Storage Snapshots for VPC \n\nBlock Storage Snapshots for VPC are a regional offering that is used create a point-in-time copy of your Block Storage for VPC boot or data volume. The initial snapshot that you take is a full backup of the volume. Subsequent snapshots of the same volume are incremental, so only the changes since the last snapshots are captured. You can restore data to a new volume during instance provisioning, from an existing instance, and when you create an unattached volume.\n\n\n\n Snapshots concepts \n\nA snapshot is a copy of your volume that you take manually in the UI or from the CLI, or create programmatically with the API, or Terraform. You can take a snapshot of a boot or data volume that is attached to a running virtual server instance or from an unattached data volume. A \"bootable\" snapshot is a snapshot of a boot volume. A \"nonbootable\" snapshot is of a data volume. You can take snapshots as often as you want. However, you cannot take a snapshot of a volume that's in a degraded state.\n\nDo you want to automatically create snapshots of your Block Storage for VPC volumes? With Backup for VPC, you can create backup policies to schedule regular volume backups. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n\nThe first time that you take a snapshot of a volume, all the volume's contents are copied. The snapshot has the same encryption as the volume (customer-managed or provider-managed). Snapshots are stored and retrieved from IBM Cloud\u00ae Object Storage. Data is encrypted while in transit and stored in the same region as the original volume.\n\nWhen you take a second snapshot, it captures only the changes that occurred since the last snapshot was taken. As such, the size of the snapshots can grow or shrink, depending on what is being uploaded to IBM Cloud\u00ae Object Storage. The number of snapshots increases with each successive snapshot that you take.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=api"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7598336331}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07765-0-1628","score":23.9516665374,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_07787-0-1608","score":19.2271576006,"text":"\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"},{"document_id":"ibmcld_02746-7-1681","score":17.9239658218,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_00708-54925-56282","score":17.771681692,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-54925-56282","score":17.771681692,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-54906-56263","score":17.771681692,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_00708-32460-34303","score":17.1194247208,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-32460-34303","score":17.1194247208,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-32441-34284","score":17.1194247208,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_03638-1509-3624","score":16.7874386201,"text":"\nYou can record these details for both an individual device and for all devices associated with your account:\n\n\n\n* View individual device IPs from the Device List.\n* View individual device root passwords in the Snapshot View for the device.\n* View multiple device IPs by using the Download CSV option from the Device List. Then, select Download CSV from the Settings cog to download a full list of devices and details in spreadsheet format.\n\n\n\n4. Update the credentials for operating systems and other software. All of the software that was loaded onto your device during the provisioning process was assigned temporary credentials. You can view and manage these credentials on the Passwords tab of each device in the IBM Cloud\u00ae console. Use these temporary credentials to access your software for the first time. Then, change the password to your software by following strong password practices. Create a password that consists of a combination of letters, numbers, and symbols. Optionally, you can store password updates on the Passwords tab for each device. However, when you store passwords, any person with access to the account and appropriate permissions can view the passwords that are stored on the Passwords screen.\n5. Access your server on the private network. You can use the IBM Cloud infrastructure private network to interact with your devices through remote desktop (RDP) by using SSH and KVM over IP. You can use the VPN Access tool for private network connection to either the closest SSL VPN endpoint or to the endpoint of your choice. VPN access is also required to interact with several services. To access the private network, edit the user\u2019s VPN access from the User List. To access the User List, click Account > Users > User list. Use the [Virtual Private Network](https:\/\/www.ibm.com\/cloud\/vpn-access) page to connect to one of the various VPN options.\n6. After you have your infrastructure and environments up and running, you are ready to set up your monitoring service. IBM Cloud Monitoring gives you insight into the performance and health of your applications, services, and platforms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-set-up"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03435-20211-22413","score":16.4730935772,"text":"\nAccount usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-at_events_acc_mgt"},{"document_id":"ibmcld_02379-22602-24722","score":16.2204838972,"text":"\nEnterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated) \n\nThis section explains events that are generated when you configure the IAM account settings from the Access (IAM) > Settings dashboard.\n\n\n\n Configuring MFA \n\nWhen you set on MFA in your account by configuring the Account Login section in the Access (IAM) > Settings dashboard, you get 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.\n* Event with action billing.account-mfa.set-on that indicates that MFA is enabled in the account.\n\n\n\nWhen you set off MFA, you get the following 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"},{"document_id":"ibmcld_12553-4545-5875","score":15.8555937421,"text":"\n-H \"Authorization: Bearer <IAM_Token>\"\n-H 'Content-Type: application\/json'\n-d '{\n\"parent\": \"crn:v1:bluemix:public:enterprise::a\/$ENTERPRISE_ACCOUNT_ID::enterprise:$ENTERPRISE_ID\",\n\"name\": \"Example Account Group\",\n\"primary_contact_iam_id\": \"$PRIMARY_CONTACT_IAM_ID\"\n}'\n\nCreateAccountGroupOptions createAccountGroupOptions = new CreateAccountGroupOptions.Builder()\n.parent(parentCRN)\n.name(\"Example Account Group\")\n.primaryContactIamId(enterpriseAccountIamId)\n.build();\n\nResponse<CreateAccountGroupResponse> response = service.createAccountGroup(createAccountGroupOptions).execute();\nCreateAccountGroupResponse createAccountGroupResponse = response.getResult();\n\nSystem.out.println(createAccountGroupResponse);\n\ncreate_account_group_response = enterprise_management_service.create_account_group(\nparent=parent_crn,\nname='Example Account Group',\nprimary_contact_iam_id=enterprise_account_iam_id,\n).get_result()\n\nprint(json.dumps(create_account_group_response, indent=2))\n\ncreateAccountGroupOptions := enterpriseManagementService.NewCreateAccountGroupOptions(\nparentCRN,\n\"Example Account Group\",\nenterpriseAccountIamID,\n)\n\ncreateAccountGroupResponse, response, err := enterpriseManagementService.CreateAccountGroup(createAccountGroupOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(createAccountGroupResponse, \"\", \" \")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-organize"},{"document_id":"ibmcld_02379-20817-23063","score":15.4708324989,"text":"\nThis section explains events that are generated when a user looks at the information that is provided through the Manage > Billing and usage > Usage section, or request an export of the data.\n\nYou can get events with reason.reasonCode = 404 that are generated when there is no usage data available for the request. The severity is set to normal.\n\n\n\n requestData fields \n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-summary.read, billing.account-summary.download, and billing.account-instances-usage-report.download:\n\n\n\nTable 16. Account usage summary requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-usage-report.read:\n\n\n\nTable 17. Account usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"},{"document_id":"ibmcld_12791-62190-64524","score":15.0779229721,"text":"\nEditor View network zones<br><br>Create network zones<br><br>Update network zones<br><br>Remove network zones \n Administrator View network zones<br><br>Create network zones<br><br>Update network zones<br><br>Remove network zones \n\n\n\n\n\n\n\n Enterprise \n\nYou can use the Enterprise service to assign users access to manage an enterprise by creating accounts within the enterprise, assigning accounts to account groups, naming account groups, and more. This type of policy works only if it is assigned within the enterprise account.\n\n\n\nTable 7. Roles and example actions for the Enterprise service\n\n Roles Actions \n\n Viewer View the enterprise, account groups, and accounts \n Operator Not applicable \n Editor View and update the enterprise name and domain, create accounts and account groups, view usage reports, and import accounts. \n Administrator View and update the enterprise name and domain, create accounts and account groups, move accounts between account groups, import existing accounts, and view usage reports \n Usage report viewer View the enterprise, accounts, and account groups and view usage reports for all accounts in the enterprise. \n\n\n\n\n\n\n\n Global catalog \n\nYou can give users access to view private products in the catalog or change the visibility of private products for other users in the account.\n\n\n\nTable 8. Roles and example actions for the Global Catalog service\n\n Roles Actions \n\n Viewer View private services \n Operator Not applicable \n Editor Change object metadata but can't change visibility for private services \n Administrator Change object metadata or visibility for private services, and restrict visibility of a public service \n\n\n\n\n\n\n\n IAM Access Groups \n\nYou can give users access to view, create, edit, and delete access groups in the account by using the IAM Access Groups service.\n\n\n\nTable 9. Roles and example actions for the IAM access groups service\n\n Roles Actions \n\n Viewer View access groups and members \n Operator Not applicable \n Editor View, create, edit, and delete groups<br><br>Add or remove users from groups \n Administrator View, create, edit, and delete groups<br><br>Add or remove users<br><br>Assign access to a group<br><br>Manage access for working with access groups<br><br>Enable or disable public access to resources at the account level \n\n\n\n\n\n\n\n IAM Access Management service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_12791-83226-85560","score":15.0779229721,"text":"\nEditor View network zones<br><br>Create network zones<br><br>Update network zones<br><br>Remove network zones \n Administrator View network zones<br><br>Create network zones<br><br>Update network zones<br><br>Remove network zones \n\n\n\n\n\n\n\n Enterprise \n\nYou can use the Enterprise service to assign users access to manage an enterprise by creating accounts within the enterprise, assigning accounts to account groups, naming account groups, and more. This type of policy works only if it is assigned within the enterprise account.\n\n\n\nTable 6. Roles and example actions for the Enterprise service\n\n Roles Actions \n\n Viewer View the enterprise, account groups, and accounts \n Operator Not applicable \n Editor View and update the enterprise name and domain, create accounts and account groups, view usage reports, and import accounts. \n Administrator View and update the enterprise name and domain, create accounts and account groups, move accounts between account groups, import existing accounts, and view usage reports \n Usage report viewer View the enterprise, accounts, and account groups and view usage reports for all accounts in the enterprise. \n\n\n\n\n\n\n\n Global catalog \n\nYou can give users access to view private products in the catalog or change the visibility of private products for other users in the account.\n\n\n\nTable 7. Roles and example actions for the Global Catalog service\n\n Roles Actions \n\n Viewer View private services \n Operator Not applicable \n Editor Change object metadata but can't change visibility for private services \n Administrator Change object metadata or visibility for private services, and restrict visibility of a public service \n\n\n\n\n\n\n\n IAM Access Groups \n\nYou can give users access to view, create, edit, and delete access groups in the account by using the IAM Access Groups service.\n\n\n\nTable 8. Roles and example actions for the IAM access groups service\n\n Roles Actions \n\n Viewer View access groups and members \n Operator Not applicable \n Editor View, create, edit, and delete groups<br><br>Add or remove users from groups \n Administrator View, create, edit, and delete groups<br><br>Add or remove users<br><br>Assign access to a group<br><br>Manage access for working with access groups<br><br>Enable or disable public access to resources at the account level \n\n\n\n\n\n\n\n IAM Access Management service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_12791-37352-39384","score":14.9165106086,"text":"\nTo create a context-based restriction rule for a service, you must be assigned an IAM policy with the Administrator role the service you are creating a rule against. For example, if you want to create a rule to protect a Key Protect instance, you must be assigned the Administrator role on the Key Protect service and the Viewer role or higher on the Context-based restrictions service.\n\nThe Viewer role on the Context-based restrictions service allows you to add network zones to your rule.\n\n\n\nTable 6. Roles and example actions for the context-based restrictions service\n\n Roles Actions role_ID value \n\n Viewer View network zones crn:v1:bluemix:public:iam::::role:Viewer \n Editor View network zones<br><br>Create network zones<br><br>Update network zones<br><br>Remove network zones crn:v1:bluemix:public:iam::::role:Editor \n Administrator View network zones<br><br>Create network zones<br><br>Update network zones<br><br>Remove network zones crn:v1:bluemix:public:iam::::role:Administrator \n\n\n\nYou can give users access to view, create, update, and remove context-based restrictions and network zones.\n\n\n\n\n\n Enterprise \n\nYou can use the Enterprise service to assign users access to manage an enterprise by creating accounts within the enterprise, assigning accounts to account groups, naming account groups, and more. This type of policy works only if it is assigned within the enterprise account.\n\n\n\nTable 7. Roles and example actions for the Enterprise service\n\n Roles Actions role_ID value \n\n Viewer View the enterprise, account groups, and accounts crn:v1:bluemix:public:iam::::role:Viewer \n Operator Not applicable \n Editor View and update the enterprise name and domain, create accounts and account groups, view usage reports, and import accounts. crn:v1:bluemix:public:iam::::role:Editor \n Administrator View and update the enterprise name and domain, create accounts and account groups, move accounts between account groups, import existing accounts, and view usage reports crn:v1:bluemix:public:iam::::role:Administrator","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_12559-4953-7138","score":14.3813899914,"text":"\nTo import an existing account, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Enterprise and Billing account management services within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\nComplete the following steps to import the example UX-UI account to the Design account group:\n\n\n\n1. From the enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, click Add > Import account.\n3. Select UX-UI from the Account list.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. Select Design as the parent of the UX-UI account. This determines where in the enterprise hierarchy the account exists.\n5. Review the information about the impacts to your account, and select I understand the impact to my account. Then, click Import.\n\n\n\nRepeat the steps to import more accounts.\n\n\n\n\n\n Step 4: Create new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\nComplete the following steps to create the example Web account in your enterprise:\n\n\n\n1. From the Enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter Web as the name of the account.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"},{"document_id":"ibmcld_12573-4001-5682","score":14.1829529193,"text":"\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group. This option is exclusive with --parent-account-group and --parent-enterprise.\n\n--parent-enterprise (required)\n: Set enterprise as the parent. This option is exclusive with --parent-account-group and --parent-account-group-id.\n\n\n\n\n\n\n\n ibmcloud enterprise account-show \n\nDisplay details of an account.\n\nibmcloud enterprise account-show (-n, --name NAME | --id ID)\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of the account. This option is exclusive with --id.\n\n\n\n\n\n\n\n ibmcloud enterprise accounts \n\nList accounts.\n\nibmcloud enterprise accounts [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID] [--recursive]\n\n\n\n Command options \n\n--parent-account-group ACCOUNT_GROUP_NAME (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant accounts.\n\n\n\n\n\n\n\n ibmcloud enterprise account-import \n\nImport a stand-alone account.\n\nibmcloud enterprise account-import (--account-id ID) [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID]\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_12573-2772-4341","score":14.09828471,"text":"\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.\n\n--parent-account-group ACCOUNT_GROUP_NAME (optional).\n: Name of the parent account group. If omitted, the parent would be the current enterprise.\n\n\n\n\n\n\n\n ibmcloud enterprise account-delete \n\nDelete an account.\n\nibmcloud enterprise account-delete (-n, --name NAME | --id ID) [-q, --quiet]\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME\n: Name of the account group. This option is exclusive with --id.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud enterprise account-move \n\nMove an account under different parent.\n\nibmcloud enterprise account-move (-n, --name NAME | --id ID) (--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID | --parent-enterprise)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":44.8988579577,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":43.6748837046,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16368-7-2072","score":43.5548479832,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-4-1877","score":43.4948467456,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-7-1721","score":42.7171119557,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-12876-14604","score":41.9304643838,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03421-1518-3290","score":41.3881362402,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-1365-2938","score":40.6566205988,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03196-30333-32476","score":40.5635994828,"text":"\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03166-4-2012","score":40.2167909333,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01377-8075-10005","score":21.5289809186,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":21.5289809186,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01377-13470-15034","score":20.3442366777,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-13496-15060","score":20.3442366777,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01388-10517-12258","score":17.5807591484,"text":"\nList the policies for User B by running the following command.\n\nibmcloud iam user-policies <user.b@example.com>\n\nFind the policies that you created and note the Policy IDs.\n3. Delete the policies that you created by running the following command, where <Policy_ID> is the Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 3: Create a service ID and grant access to a resource \n\nConfigure a service ID and grant it access to your IBM Cloud Container Registry namespace.\n\n\n\n1. Set up a service ID with access to IBM Cloud Container Registry and create an\n\nAPI keyfor it.\n\n\n\n1. Log in to User A's account by running the following command.\n\nibmcloud login\n2. Create a service ID named cr-roles-tutorial with the description \"Created during the access control tutorial for Container Registry\" by running the following command.\n\nibmcloud iam service-id-create cr-roles-tutorial --description \"Created during the access control tutorial for Container Registry\"\n3. Create a service policy for the service ID that grants the Reader role on namespace_a by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_a --roles Reader\n4. Create a second service policy that grants the Writer role on namespace_b by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_b --roles Writer\n5. Create an API key for the service ID by running the following command.\n\nibmcloud iam service-api-key-create cr-roles-tutorial-apikey cr-roles-tutorial\n\n\n\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_05256-22076-24099","score":17.2562427709,"text":"\nIf you have a Service ID that you want to use, select it. If not, select Create, enter a name and description, and click Create.\n4. From the Service ID page, from the Access policies section, select Assign access.\n5. From the Assign service ID additional access section,\n\n\n\n1. Select Container Registry for type of access. Click Next.\n2. Select the type of access: All resources or Specific resources. If you specify Specific resources, you can add attributes based on resource group, geography, region, resource type, resource ID, or resource name to further restrict access. If you select a certain resource group, make sure to select Viewer access for Resource group access. Click Next.\n3. In the Roles and Actions section, select the type of access you want to grant. If you plan to use only images for your applications and jobs, select Reader. If you want to push the source code and images to Container Registry, then also select Writer. Click Review.\n4. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 2 Enabling Container Registry discovery \n\nTo allow the Code Engine console to automatically discover Container registry, you must authenticate the service ID to the IAM Identity Service.\n\n\n\n1. From the Service ID page, from the Access policies section, select Assign access.\n2. From the Assign service ID additional access section,\n\n\n\n1. Select IAM Identity Service for type of access. Click Next.\n2. Select Specific resources for resource scope. Select Resource type as attribute type, keep string equals as operator and enter serviceid as value. Click Add a condition.\n3. Select Resource ID as attribute type, keep string equals as operator and put the identifier of your service ID. You can find your service ID on the Details page for the service ID or in the browser URL when configuring it. Click Next.\n4. In the Roles and Actions section, select Platform Operator access. Click Review\n5. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 3 Creating an API key for a service ID \n\nCreate an API key for a service ID.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_01530-1294-3025","score":17.2414444501,"text":"\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinviamuserinv).\n\nIf you want users to create clusters in IBM Cloud Kubernetes Service, ensure that you assign the IBM Cloud Container Registry Administrator role to those users, and don't assign a resource group. For more information, see [Preparing to create clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusterscluster_prepare).\n\n\n\nTo create policies for IBM Cloud Container Registry, the service name field must be container-registry.\n\nIf you want to access resources, you must assign roles to users or service IDs. If you want to grant access to everything, don't specify a resource type or a resource. If you want to grant access to a specific namespace, specify the resource type as namespace and use the namespace name as the resource.\n\n\n\n* To create a policy for users, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n* To create a policy for service IDs, run the ibmcloud iam service-policy-create command or use the IBM Cloud console to bind roles to your service IDs. To create policies, you must have the Administrator role. You automatically have the Administrator role on your own account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user"},{"document_id":"ibmcld_01388-2747-4448","score":17.0994197937,"text":"\nibmcloud cr quota-set --traffic=4000\n\nThe command fails because User B doesn't have the correct access.\n\n\n\n3. Grant User B the Manager role so that User B can configure IBM Cloud Container Registry.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. Create a policy that grants the Manager role to User B by running the following command.\n\nibmcloud iam user-policy-create <user.b@example.com> --service-name container-registry --roles Manager\n\n\n\n4. Prove that User B can now change quotas in User A's account.\n\n\n\n1. Log in as User B, targeting User A's account by running the following command.\n\nibmcloud login -c <YourAccountID>\n2. Try to edit your registry quota to 4 GB of traffic by running the following command.\n\nibmcloud cr quota-set --traffic=4000\n\nIt works because User B has the correct type of access.\n3. Now change the quota back by running the following command.\n\nibmcloud cr quota-set --traffic=5120\n\n\n\n5. Clean up.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. List the policies for User B, find the policy that you created by running the following command, and note the ID.\n\nibmcloud iam user-policies <user.b@example.com>\n3. Delete the policy by running the following command, where <Policy_ID> is your Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 2: Authorize a user to access specific namespaces \n\nCreate some\n\nnamespaceswith sample images, and grant access to them. You create policies to grant different roles to each namespace, and show what effect that has.\n\n\n\n1. Create three new namespaces in User A's account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01494-31513-33000","score":17.0303939131,"text":"\n* [Enforce security in your cluster](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_enforce_security)\n* [Resolve vulnerabilities in your image](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_resolve_vulnerabilities)\n\n\n\n* [Deploying to nondefault Kubernetes namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_deploy_nondefault_namespaces)\n\n\n\n\n\n\n\n Granting access to Container Registry resources tutorial \n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access_prereq)\n* [Authorize a user to configure the registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessconfigure_registry)\n* [Authorize a user to access specific namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessaccess_resources)\n* [Create a service ID and grant access to a resource](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessservice_id)\n* [Cleaning up your account](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessclean_up)\n\n\n\n\n\n\n\n Solution tutorials \n\n[Moving a VM based app to Kubernetes](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-vm-to-containers-and-kubernetesvm-to-containers-and-kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_16729-71418-73421","score":17.0152133701,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00953-7-2042","score":9.450890009,"text":"\nTroubleshooting for Pipeline Private Workers \n\nGeneral problems with using Pipeline Private Workers might include Kubernetes cluster and kubectl version issues. In many cases, you can recover from these problems by following a few easy steps.\n\n\n\n Why is my Delivery Pipeline Private Worker inactive? \n\nPrivate workers within a pool of workers can be in one of the following states:\n\n\n\n* Active with the current, supported version of private workers\n* Inactive with an unsupported version of private workers\n* Inactive\n\n\n\n What\u2019s happening \n\nYour private worker is inactive. Inactive private workers cannot handle incoming run requests. Pipeline stages that use an inactive private worker cannot complete.\n\n Why it\u2019s happening \n\nThere is an issue with your Kubernetes cluster and the worker cannot be contacted. Or, the version of the private worker that you are running is no longer supported.\n\n How to fix it \n\nTo activate your Delivery Pipeline private worker, [install](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workersinstall_pw) the private worker again. Then, [register](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workersregister_pw) the Delivery Pipeline private worker on the Kubernetes cluster again.\n\n\n\n\n\n I tried to install support for Delivery Pipeline Private Workers in Kubernetes. Why did the installation fail? \n\nIf there is an issue with the version of kubectl that you are running on the client machine, the Delivery Pipeline Private Worker installation fails.\n\n What\u2019s happening \n\nAfter you try to install support for private workers in Kubernetes, an error message is displayed to indicate that there is a schema mismatch and the installation fails.\n\nSchemaError(io.k8s.apimachinery.pkg.apis.meta.v1.APIGroup): invalid object doesn't have additional properties\n\n Why it\u2019s happening \n\nThere is a mismatch between the versions of kubectl that you are running on the Kubernetes server and the Kubernetes client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-troubleshoot-pipeline-private-workers"},{"document_id":"ibmcld_05736-9216-10856","score":9.0826675852,"text":"\nUnsupported:kubectl apply --server-dry-run removed The deprecated --server-dry-run option is removed from the kubectl apply command. If your scripts rely on this option, update them to use the --dry-run=server option instead. \n Unsupported:kubectl get --export removed The deprecated --export option is removed from the kubectl get command. If your scripts rely on this option, refer to the [Deprecate --export option from get command pull request](https:\/\/github.com\/kubernetes\/kubernetes\/pull\/73787) issue for discussion and references to scripts that handle various use cases. \n kubectl --output jsonpath format changes The kubectl get--o jsonpath (or -o jsonpath) option now returns a JSON object for complex types such as structs, arrays, and slices. Previously, the option returned output in go format. If you use kubectl get to retrieve such fields using --output jsonpath, update your scripts to handle JSON objects. You might try using the -o go-template option to maintain compatibility with the previous behavior. \n Temporary kubectl latency RBAC operations are now performed asynchronously. After you run ibmcloud ks cluster config for the first time after the update, kubectl commands might fail for a few seconds while RBAC synchronizes for the first time. Afterward, kubectl commands perform as expected. If you use automation to access the cluster with kubectl commands, add retry logic for kubectl commands after a kubeconfig file is successfully retrieved. \n Unsupported: Select kubelet metrics The following kubelet metrics that were available via the \/metrics and \/metrics\/resource endpoints are unsupported and removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_119"},{"document_id":"ibmcld_08848-0-1791","score":9.0644403189,"text":"\n\n\n\n\n\n\n  How can I resolve the network error when working with the Kubernetes Service provider? \n\n  What\u2019s happening \n\nDuring the cluster upgrade from Kubernetes Service older version to new version. The Terraform apply fails with the TCP connection error message.\n\nError: Get \"http:\/\/localhost\/api\/v1\/\": dial tcp [::1]:80: connect: connection refused\n\nOr\n\nError: {{site.data.keyword.containershort_notm}} cluster unreachable: invalid configuration: no configuration has been provided\n\n  Why it\u2019s happening \n\nYou are combining the cluster provisioning and working with the Kubernetes Service provider at the same time in your Terraform template in the IBM Cloud Schematics workspace or in your localhost. You make a change in the cluster configuration that leads to the cluster re-create. When you run terraform refresh command, you view strange errors such as, network or namespace issues.\n\n  How to fix it \n\nTo troubleshoot this error you need to ensure:\n\n\n\n*  You don't combine the Kubernetes Service provider with the cluster resource at the same time in the Terraform template.\n*  The resources should not be created in the same Terraform template or module where Kubernetes Service provider resources are in use.\n*  The Terraform provider evaluates the provider blocks versus actual resource, and the order in which the resources are defined. For more information, see [Provider configuration](https:\/\/developer.hashicorp.com\/terraform\/language\/providers\/configurationprovider-configuration).\n\n\n\nIf you cannot resolve this issue, contact support by opening a support case for the service that you want to work with. Make sure to include the incident ID. For more information, see [Using the Support Center](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-ks-network-error"},{"document_id":"ibmcld_05838-13761-15409","score":9.0240748664,"text":"\nupdate_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Setting up IBM Cloud\u00ae Monitoring alerts \n\nWhen you set up alerts, make sure to allow your cluster enough time to self-heal. Because Kubernetes has self healing capabilities, configure your alerts only for the issues that arise over time. By observing your cluster over time, you can learn which issues Kubernetes can resolve itself and which issues require alerts to avoid downtime.\n\nOn 15 June 2022, the naming convention for IBM Cloud\u00ae Monitoring alerts is changing to a Prometheus compatible format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_04083-33184-35372","score":8.9157979115,"text":"\n* If another application in a cluster with constrained resources is in a pending state, and is prioritized higher than the blockchain component, the blockchain pod cannot restart because the resources are consumed by the pending application.\n* If the blockchain component needs to restart, but is on a worker node that has been \"cordoned\", meaning no new components can be brought to that node, it cannot restart. A blockchain pod becomes unschedulable when the Kubernetes scheduler is unable to find a node that can accommodate the resource requirements of the pod.\n* If there is a timeout between the kubelet, the node agent that runs on each node, and the Kubernetes master node, a pod restart can fail.\n* The pod restart itself can time out when its worker node restarts and takes too long to mount the persistent volume claim (PVC).\n\n\n\n How to fix it \n\nTo enable the blockchain pod to restart successfully, you need to address the underlying cluster issues:\n\n\n\n* Ensure there are adequate resources available on worker nodes in the cluster. If not, deploy a new worker node with increased resources.\n* After you resolve the cluster issues, delete the failing blockchain pod. When Kubernetes restarts the pod, it will attempt to move the pod workload to another node with sufficient resources.\n* If the timeout between a kubelet and the master node cannot be resolved, open a support ticket with your cluster provider.\n\n\n\n\n\n\n\n What is the proper way to clean up a failed node deployment? \n\n What\u2019s happening \n\nSometimes a node can fail to deploy, for example, due to lack of resources in your Kubernetes cluster. After you understand the cause of the node deployment failure, you need to clean up the failed node in your cluster.\n\n How to fix it \n\nDo not attempt to use Kubernetes commands to remove the node. Instead, it is extremely important that you use the IBM Blockchain Platform console or the APIs to remove the failed node to ensure that the associated metadata and storage are also cleaned up.\n\n\n\n\n\n How can I view my smart contract container logs? \n\n What\u2019s happening \n\nYou may need to view your smart contract, or chaincode, container logs to debug a smart contract issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_11912-11244-11866","score":8.7542795499,"text":"\nAlternatively, you can follow the NetApp documentation for [uninstalling the Trident operator](https:\/\/netapp-trident.readthedocs.io\/en\/stable-v20.07\/kubernetes\/operations\/tasks\/managing.htmluninstalling-with-the-trident-operator)\n5. Optional: List your storage configurations and remove your Trident configuration.\n\nibmcloud sat storage config ls\n\nibmcloud sat storage config rm --config <config_name>\n\n\n\n\n\n\n\n\n\n Getting help and support for NetApp Trident \n\nIf you run into an issue with NetApp Trident, you can visit the [NetApp support page](https:\/\/netapp-trident.readthedocs.io\/en\/stable-v20.04\/support\/support.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-netapp-trident"},{"document_id":"ibmcld_09785-9585-11685","score":8.6946153049,"text":"\n: V2.4.5 is supported which fixes an issue when using --verbose with --format json resulting in corrupted JSON output.\n\n\n\n\n\n 28 July 2021 \n\nSecure support for Inline Scanner\n: V2.4.4 is supported including the following updates:\n\n\n\n* Security fixes.\n* Adding a retry mechanism when pulling images from registries.\n* Adding the ability to write a JSON log to a file.\n* Fixed a malware scan issue.\n* Fixed issue when getting images for registries not supporting tag listing.\n\n\n\n\n\n\n\n 27 July 2021 \n\nSecure support for Kubernetes Audit functionality\n: General available support of Kubernetes Audit functionality as part of the Admission Controller.\n\n\n\n\n\n 2 July 2021 \n\nSecure support for Inline Scanner\n: V2.4.3 is supported including security fixes and a problem with incorrect version detection for Apache Struts 2.\n\n\n\n\n\n 1 July 2021 \n\nSecure support for Node Image Analyzer\n: V0.1.13 is available.\n\n\n\n\n\n 14 June 2021 \n\nSecure support for RedHat OpenShift Container Platform v4 benchmark\n: You can now scan and validate compliance with the controls included in the CIS benchmark requirements.\n\n\n\n\n\n 9 June 2021 \n\nSecure change improvements to navigation and activity audit\n: Updates include:\n\n\n\n* Moving Network from under Policies in the menu.\n* Grouping Activity Audit and Captures into the Investigation menu item.\n* Runtime scope moved in Activity Audit to allow more space for activity data.\n* Activity types can be filtered directly from the graph.\n* Displayed element attributes can be filtered from the list.\n\n\n\n\n\n\n\n 4 June 2021 \n\nSecure changes to Kubernetes network security configuration and user experience\n: Changes include:\n\n\n\n* New configuration panel allowing you to include or exclude a set of labels for a cluster or namespace.\n* Adding the ability to label IPs not mapped to Kubernetes or OpenShift entities.\n* Adding the ability to to configure internal subnets for clusters.\n* Adding additional information when hovering over a network connection or network node.\n* Adding unresolved IP filtering.\n* Adding Network as an item in the navigation.\n\n\n\n\n\n\n\n 1 June 2021 \n\nPromQL library","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitoring-release-notes"},{"document_id":"ibmcld_10189-3187-5240","score":8.5572491964,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-3185-5238","score":8.5572491964,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10510-65064-67302","score":8.5478073777,"text":"\n* Compute resource limitation: To ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) for every namespace. Resource quotas determine the deployment constraints for a project, such as the number of Kubernetes resources that you can deploy, and the amount of CPU and memory that can be consumed by those resources. After you set a quota, users must include resource requests and limits in their deployments.\n* Shared cluster resources: If you run multiple tenants in one cluster, some cluster resources, such as the Red Hat OpenShift router, Ingress application load balancer (ALB) or available portable IP addresses are shared across tenants. Smaller services might have a hard time using shared resources if they must compete against large services in the cluster.\n* Updates: You can run one Red Hat OpenShift API version at a time only. All apps that run in a cluster must comply with the current Red Hat OpenShift API version independent of the team that owns the app. When you want to update a cluster, you must ensure that all teams are ready to switch to a new Red Hat OpenShift API version and that apps are updated accordingly. This also means that individual teams have less control over the Red Hat OpenShift API version they want to run.\n* Changes in cluster setup: If you want to change the cluster setup or reschedule workloads onto new worker nodes, you must roll out this change across tenants. This roll out requires more reconciliation and testing than in a single-tenant cluster.\n* Communication process: When you manage multiple tenants, consider setting up a communication process so that tenants know where to go when an issue with the cluster exists, or when they need more resources for their services. This communication process also includes informing your tenants about all changes in the cluster setup or planned updates.\n\n\n\nAlthough single-tenant and multi-tenant clusters come with roughly the same costs, single-tenant clusters provide a higher level of isolation than the projects in a multi-tenant cluster. For better workload isolation, use single-tenant clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-10086-11557","score":32.0444075094,"text":"\nCPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr ) \n Hourly cost: IBM Cloud Kubernetes cluster $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) \n Hourly cost: Storage $0.06 USD <br>340GB <br>[Bronze](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>2 IOPS\/GB $0.09 USD <br>420GB <br>[Silver](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>4 IOPS\/GB \n Total hourly cost $0.71 USD $1.19 USD \n\n\n\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_03994-15948-17676","score":31.943375481,"text":"\nIf you do not want to use the default File Storage that is pre-selected for you when you provision a Kubernetes cluster in IBM Cloud, you can provision storage of your choice. See this topic on [Persistent storage considerations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-storage) to learn more.\n* If you decide to include IBM Cloud multi-zone support in your Kubernetes cluster on IBM Cloud, you must provision your own storage. See [Using Multizone (MZR) clusters with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-mzr) for more details.\n* You can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance will be limited by throughput, storage and functionality. IBM Cloud will delete your cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster. If you choose a paid Kubernetes cluster instead of the limited free cluster, you will incur charges for the Kubernetes service to your IBM Cloud account.\n* Kubernetes clusters that are configured with private VLANs are not supported.\n\n\n\n\n\n\n\n License and pricing \n\nIBM Blockchain Platform for IBM Cloud introduces a new hourly pricing model based on virtual processor core (VPC) usage. The simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_04031-7-2093","score":30.046130861,"text":"\nPricing for IBM Blockchain Platform for IBM Cloud \n\nATTENTION!! IBM Blockchain Platform SaaS Edition is being replaced by IBM Support for Hyperledger Fabric!! IBM Blockchain Platform SaaS Edition will no longer be supported after July 31, 2023. Customers have been directed to migrate their networks by July 31, 2023. After this date, IBM Blockchain Platform SaaS networks that are not migrated to IBM Support for Hyperledger Fabric will be at risk for potential security vulnerabilities. A migration tool is provided from your console, and the disruption to your network is minimal. See [Migrating to IBM Support for Hyperledger Fabric](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-migrating-to-hlf-support) for details.\n\nThis guide helps you understand the pricing model for IBM\u00ae Blockchain Platform for IBM Cloud, and how much you will pay when you develop and grow your blockchain network of peers, ordering nodes, and Certificate Authorities components, which are based on Hyperledger Fabric v2.2.10.\n\n\n\n Pricing model \n\nIBM Blockchain Platform introduces a new hourly pricing model that is based on virtual processor core (VPC) allocation. This simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes are allocated on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour.\n\nA VPC is a unit of measurement that is used to determine the licensing cost of IBM products. It is based on the number of virtual cores (vCPUs) that are available to the product. A vCPU is a virtual core that is assigned to a virtual machine or a physical processor core. For IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-6179-7910","score":27.8770340577,"text":"\n[Elements of pricing](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/elements-of-pricing.svg)\n\nFigure 1. Elements of pricing\n\n\n\n* IBM Blockchain Platform: Based on a flat rate of $0.29 USD\/VPC-hour. This fee represents the charge for your blockchain component VPC allocation in your Kubernetes cluster.\n* IBM Cloud Kubernetes Service: While you can link your IBM Blockchain Platform service instance to either an IBM Cloud Kubernetes service cluster or an OpenShift cluster, this pricing model is based on the usage of an IBM Cloud Kubernetes service cluster. The IBM Cloud Kubernetes service uses a tiered pricing model that is visible in IBM Cloud when you provision your paid cluster. This includes the charges for your compute, that is, CPU and memory. IBM Cloud Kubernetes Services are priced on a tiered model that is based on the number of hours of usage per month. Therefore, when you examine pricing plans, consider that 24x7 usage is equivalent to 720 hours per month. Refer to the table on the [Kubernetes Service Catalog page](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about) for more details on cluster pricing. Customers who are interested in pricing OpenShift clusters can review [Red Hat OpenShift on IBM Cloud Pricing](https:\/\/www.ibm.com\/cloud\/openshift\/pricing).\n* Storage: Choose the storage plan that works for your needs. See [Understanding Kubernetes storage basics](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptskube_concepts) to learn more about your storage class options and how much they [cost](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing). The IBM Blockchain Platform nodes use the default storage class for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-8842-10444","score":27.8047825524,"text":"\nBoth examples assume an IBM Cloud Kubernetes service cluster and the default CouchDB database is used as the peer database. It also assumes peers are deployed with Fabric v2.x images instead of Fabric v1.4 images.\n\n\n\n* The Test network scenario is suitable for getting started with your first use case with IBM Blockchain and testing smart contracts.\n* The Join a network scenario includes two peers, and a Certificate Authority (CA) that is required for organization membership.\n\n\n\n* These peers can join a production IBM Blockchain Platform network that is hosted elsewhere.\n* Nodes can always be dialed back to a minimal utilization state (0.001 CPU) when they are not in use to [lower costs](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern-components).\n* Because this scenario could be used for a production environment:\n\n\n\n* The default compute resources have been doubled to provide greater capacity.\n* The [Silver](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storagefile_storageclass_reference) storage class is chosen for faster performance.\n\n\n\n\n\n\n\n\n\nTable 1. Pricing examples for a test network and joining a network\n\n Pricing options** (1 VPC = 1 CPU = 1 vCPU) Test Network Join a Network \n\n CPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr )","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_03994-17349-19158","score":26.6144462346,"text":"\nThe simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started \n\nFor information about how to deploy IBM Blockchain Platform for IBM Cloud, see [Getting started with IBM Blockchain Platform for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-v2-deploy-iks).\n\nFor more information about how to use the console to start deploying nodes and building consortium, see the [Building your network](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) tutorial. This tutorial guides you through the process of using the console to create a sample network with three organizations, one ordering organization, two peer organizations, and a channel with two peers joined to it. You can use this sample network to for demos or proofs of concept or adjust and expand the steps in the tutorial to create your own custom blockchain configuration.\n\n\n\n\n\n Architecture reference \n\nThe following illustrations show the components of your blockchain network and how they interact with your cluster.\n\n\n\n IBM Blockchain Platform on IBM Cloud Kubernetes Service Architecture \n\nZoom\n\n![IKS Sample network structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/cloudkubernetes.svg)\n\nFigure 1. Architecture diagram of IBM Blockchain Platform on IBM Cloud Kubernetes Service\n\nNotice how a single instance of the console, also known as Operational Tooling, is created for each IBM Blockchain Platform Service Instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_04031-4820-6435","score":24.1961063454,"text":"\n3. Launch IBM Blockchain Platform in the [IBM Cloud Catalog](https:\/\/cloud.ibm.com\/catalog\/services\/blockchain-platform).\n4. Under Select a pricing plan, ensure that the Standard plan is selected and then click Create.\n5. On the Welcome and pre-requisites panel that opens, click I have a Cluster (Skip to Link a cluster).\n6. In the Select an IBM Kubernetes Service cluster drop-down list, select your free cluster. Note: If your free cluster is not listed, ensure sure you are not using the ESR version of Firefox. If you are, switch to another browser such as Chrome and retry.\n7. Click Deploy to cluster.\n8. When the platform is ready, you can click Launch the IBM Blockchain Platform to open the blockchain console UI and get started. Watch the [video](http:\/\/ibm.biz\/BlockchainPlatformSeries2) to learn how to Deploy a peer on the IBM Blockchain Platform, or try out the getting started tutorial [Build a network](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-network).\n\n\n\nAfter 30 days, your Kubernetes cluster is deleted along with all of your blockchain nodes and data.\n\n\n\n\n\n\n\n Key elements of cost \n\nBecause your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice, each of the following elements forms your total cost.\n\nZoom\n\n![Elements of pricing](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/elements-of-pricing.svg)\n\nFigure 1. Elements of pricing\n\n\n\n* IBM Blockchain Platform: Based on a flat rate of $0.29 USD\/VPC-hour.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-1609-3779","score":21.0945804786,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_03883-1323-2791","score":20.4705984659,"text":"\nIBM Blockchain Platform provides different offerings that allow you to deploy your network in the environment of your choice. You need to decide if you want to deploy the IBM Blockchain Platform 2.5.4 or if you want to use the IBM Blockchain Platform for IBM Cloud.\n\n\n\nTable 1. Which offering is right for your business?\n\n IBM Blockchain Platform for anywhere (2.5.4) IBM Blockchain Platform for IBM Cloud \n\n Where do you want to deploy the platform? Multiple Kubernetes distributions on a private, public, or hybrid multicloud <br> <br>See [Supported Platforms](https:\/\/www.ibm.com\/docs\/en\/blockchain-platform\/2.5.4?topic=started-about-blockchain-platform-254console-ocp-about-prerequisites)) A Kubernetes cluster on IBM Cloud <br> <br>See [Supported configuration](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-supported-cfg) \n What are my deployment options? <br><br> * Full platform<br> * [Only IBM Blockchain images](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-get-started-ibpget-started-ibp-images)<br><br><br> <br><br> * Full platform<br><br><br> \n How is it billed? Contact us for [pricing](https:\/\/www.ibm.com\/docs\/en\/blockchain-platform\/2.5.4?topic=253-pricing) [$0.29 USD per allocated CPU hour](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) \n Can I connect with peers in other clouds? Yes Yes \n Can my data center be<br><br>on-prem<br><br>and behind a firewall? Yes No","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-get-started-ibp"},{"document_id":"ibmcld_03806-1323-2838","score":20.3009005111,"text":"\nIBM Blockchain Platform provides different offerings that allow you to deploy your network in the environment of your choice. You need to decide if you want to deploy the IBM Blockchain Platform 2.5.4 or if you want to use the IBM Blockchain Platform for IBM Cloud.\n\n\n\nTable 1. Which offering is right for your business?\n\n IBM Blockchain Platform for anywhere (2.5.4) IBM Blockchain Platform for IBM Cloud \n\n Where do you want to deploy the platform? Multiple Kubernetes distributions on a private, public, or hybrid multicloud <br> <br>See [Supported Platforms](https:\/\/www.ibm.com\/docs\/en\/blockchain-platform\/2.5.4?topic=started-about-blockchain-platform-254console-ocp-about-prerequisites)) A Kubernetes cluster on IBM Cloud <br> <br>See [Supported configuration](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-supported-cfg) \n What are my deployment options? <br><br> * Full platform<br> * [Only IBM Blockchain images](https:\/\/cloud.ibm.com\/docs\/blockchainget-started-ibp-images)<br><br><br> <br><br> * Full platform<br><br><br> \n How is it billed? Contact us for [pricing](https:\/\/www.ibm.com\/docs\/en\/blockchain-platform\/2.5.4?topic=253-pricing) [$0.29 USD per allocated CPU hour](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) \n Can I connect with peers in other clouds? Yes Yes \n Can my data center be<br><br>on-prem<br><br>and behind a firewall? Yes No \n Can I use a console UI to deploy and manage my blockchain components? Yes Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1231511944}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-6287-8401","score":24.6764034632,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-1733-3996","score":23.7142255866,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16321-7-1807","score":23.3458356921,"text":"\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16337-10301-11908","score":22.8685333661,"text":"\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n{\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}\n},\n\"channels\":\n{\n\"channel\": \"voice_telephony\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n end_session \n\nSends a command to the channel ending the session. This response type instructs the phone integration to hang up the call.\n\n\n\n Integration channel support \n\n\n\n Phone SMS \n\n ![Yes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/checkmark-icon.svg) \n\n\n\n\n\n* The SMS integration supports ending a session by using the terminateSession action command.\n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_16321-1374-3426","score":22.8267220603,"text":"\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:\n\n\n\n* [Define a sequence of phone commands](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sequence)\n\n\n\nYou can also perform the following phone-specific actions:\n\n\n\n* [Inject custom values into CDR log events](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-cdr-custom-data)\n* [Access phone integration context variables from your action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-access-context-variables)\n\n\n\nFor reference information about response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\n Adding phone-specific responses to your assistant \n\nTo initiate a voice-specific interaction from a an action step, add a response within the generic array using the appropriate response type. For more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-assistant-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from an action step, you can dynamically change the Speech to Text configuration during a conversation.\n\nBy default, any Speech to Text configuration changes you make persist for the remainder of the conversation, or until you update them again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03165-4477-6547","score":22.7984592459,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03179-4-1759","score":22.5190358673,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16288-7905-9593","score":21.8541827065,"text":"\nWhen search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.\n\n\n\nFor more information about using the search integration, see [Leveraging existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add).\n\nFor more information about how to implement common actions from your dialog, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n\n\n\n\n Setting up a SIP trunk \n\nIf you do not use the option to generate a free phone number, you are responsible for setting up the SIP trunk that will be used by the phone integration. Find a provider and create a SIP trunk account. Your account will be charged for the phone integration's use of the SIP trunk.\n\nYou can set up a SIP trunk in the following ways:\n\n\n\n* [Creating a Twilio SIP trunk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-twilio-setup)\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup)\n* [Bring your own SIP trunk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-byost)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16337-9125-10721","score":21.5918224458,"text":"\nName Type Description Required? \n\n response_type string date Y \n\n\n\n\n\n\n\n Example \n\nThis example sends a text response asking the user to specify a date, and then shows an interactive date picker.\n\n{\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"What day will you be checking in?\"\n},\n{\n\"response_type\": \"date\"\n}\n]\n}\n\n\n\n\n\n\n\n dtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Integration channel support \n\n\n\n Phone \n\n ![Yes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=phone-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_16290-4708-6492","score":21.3358110139,"text":"\n[Genesys simulate call](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/phone-genesys-simulate-call.png)\n16. Go to Phone Management and click Create new. Specify the following information:\n\n\n\n* In the Phone Name field, specify a descriptive name.\n* In the Base Settings field, select WebRTCPhone.\n* In the Site field, select the site you want to use.\n* In the Person field, select yourself.\n\n\n\n17. In the Watson Assistant user interface, [create a new phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phonedeploy-phone-setup). Specify the following information:\n\n\n\n* When prompted, select Use an existing phone number with an external provider.\n* Specify the phone number you assigned in the Genesys Number Plans setting. This is not necessarily a real phone number; it is just the identifier you assigned.\n* Complete the phone integration setup process. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone).\n* After the phone integration is set up, go to the SIP trunk tab and uncheck the Don't place callers on hold while transferring to a live agent option.\n\n\n\n18. In the Genesys Cloud console, click the circle in the upper left corner. Select Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to a live agent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10916-16473-18734","score":22.5238966736,"text":"\nSee also [image](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2024928), [registry](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2064940), [layer](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2028320).\n\n\n\n\n\n context \n\nEnvironmental or conditional information that can be used to define when rules that restrict access to resources should be applied. A context can be a set of properties or attributes like client IP addresses, office hours, time of day, or multi-factor authentication.\n\n\n\n\n\n context-based restriction \n\nAn access management method that defines and enforces access for resources based on the network location of the access request.\n\n\n\n\n\n control \n\nA technical, administrative, or physical safeguard designed to meet a set of defined security and privacy requirements. Controls exist to prevent, detect, or lessen the ability of a threat to exploit a vulnerability.\n\n\n\n\n\n control assessment \n\nThe evaluation of a configuration for compliance with applicable standards.\n\n\n\n\n\n control library \n\nA collection of similar predefined or custom controls.\n\n\n\n\n\n control specification \n\nA statement that defines the specific security and privacy requirements that a control must meet.\n\n\n\n\n\n coreference \n\nA relationship between two words or phrases in which both refer to the same person or thing and one stands as a linguistic antecedent of the other. For example, there is a coreference between the two pronouns in the phrase \"She taught herself\" but not in the phrase \"She taught her\". A coreference links two equivalent entities in the same text.\n\n\n\n\n\n coreference chain \n\nA list of entities that were annotated as coreferences. When a mention is annotated as a coreference, the system creates a coreference chain. The coreference chain provides a way to view all of the mentions in context and verify that all of the occurrences belong together under the same entity type.\n\n\n\n\n\n corpus \n\nA collection of source documents that are used to train a machine learning model.\n\n\n\n\n\n credential \n\nInformation acquired during authentication that describes a user, group associations, or other security-related identity attributes, and that is used to perform services such as authorization, auditing, or delegation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_12395-4-2044","score":20.574605211,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Importing SSL\/TLS certificates \n\nYou can use IBM Cloud\u00ae Secrets Manager to import SSL\/TLS certificates that you can use for your apps or services.\n\nAn SSL\/TLS certificate is a type of digital certificate that is used to establish communication privacy between a server and a client. Certificates are issued by\n\ncertificate authorities (CA)and contain information that is used to create trusted and secure connections between endpoints. After you add a certificate to your Secrets Manager instance, you can use it to secure network communications for your cloud or on-premises deployments. Your certificate is stored securely in your dedicated Secrets Manager service instance, where you can centrally manage its lifecycle.\n\nIn Secrets Manager, certificates that you import to the service are imported certificates (imported_cert). Certificates that you order through Secrets Manager from a third-party certificate authority are [public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificatesorder-public-certificates) (public_cert). Certificates that you create by using a private certificate authority are [private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-private-certificates) (private_cert).\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret).\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nBefore you import a certificate, be sure that you:\n\n\n\n* Create an X.509 compliant certificate with a matching private key (optional).\n* Convert your files into Privacy-enhanced electronic mail (PEM) format.\n* Keep the private key unencrypted to ensure that it can be imported into Secrets Manager.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates&interface=ui"},{"document_id":"ibmcld_10916-69092-70947","score":20.1946496001,"text":"\nA catalog in which approvals for publishing and lifecycle actions are bypassed so that it can be used for testing APIs under development.\n\n\n\n\n\n scale \n\nTo increase platform (or system) capacity by adding more application or service instances\n\n\n\n\n\n SCM \n\nSee [source control management](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx3579285).\n\n\n\n\n\n scope \n\nA grouping of resources that can be validated or evaluated for security and compliance. See also [rule](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2037526), [profile](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2034950).\n\n\n\n\n\n secret \n\nA type of sensitive information, such as a password or an API key, that is used by an application to access a protected resource. See also [dynamic secret](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx9968958).\n\n\n\n\n\n secret group \n\nThe environment and constraints that contained secrets in an instance must adhere to. A user can be associated with a secret group to enable access and collaboration.\n\n\n\n\n\n secrets engine \n\nA component that serves as a back end for a specific type of secret, such as a password or an API key, within a secrets management service. Depending on its type, a secrets engine can store data, generate secrets on demand, and more. See also [dynamic secret](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx9968958).\n\n\n\n\n\n Secure Shell (SSH) \n\nA network protocol for secure data exchange between two networked devices. The client can use public-key and private-key authentication, or password authentication, to access the remote server.\n\n\n\n\n\n Secure Sockets Layer (SSL) \n\nA security protocol that provides communication privacy. With SSL, client\/server applications can communicate in a way that is designed to prevent eavesdropping, tampering, and message forgery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_12361-1556-3484","score":20.0181274034,"text":"\nA user must also have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add only network zones to a rule.\n\nAny IBM Cloud Activity Tracker or audit log events that are generated come from the context-based restrictions service, not Secrets Manager. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started with protecting your Secrets Manager resources with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n\n\n How Secrets Manager integrates with context-based restrictions \n\nTo restrict access, you must create [zones](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-create&interface=uinetwork-zones-create) and [rules](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-create&interface=uicontext-restrictions-create-rules).\n\nFirst, create a zone with the appropriate details for network or resource definitions. Then, attach that zone to the specified resource to restrict access. You can create zones and rules by using a RESTful [API](https:\/\/cloud.ibm.com\/apidocs\/context-based-restrictionsintroduction) or with [context-based restrictions](https:\/\/cloud.ibm.com\/context-based-restrictions\/overview). After you create or update a zone or a rule, it might take a few minutes for the change to take effect.\n\nCBR rules do not apply to provisioning or deprovision processes.\n\n\n\n\n\n Limitations \n\nWhen a user has instance level IAM access, CBR rules that are applied to specific secret groups do not take effect. To work around this limitation, set the user's IAM access policies to only secret groups.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-access-control-cbr"},{"document_id":"ibmcld_12397-20364-22014","score":19.035370733,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-cli"},{"document_id":"ibmcld_12358-20397-22058","score":18.9858188972,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/secrets-manager-cli-plugin?topic=secrets-manager-cli-plugin-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager-cli-plugin?topic=secrets-manager-cli-plugin-secrets-manager-cli"},{"document_id":"ibmcld_04519-20259-21874","score":18.9828134834,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-secrets-manager-cli"},{"document_id":"ibmcld_10016-2630-4454","score":18.8226315572,"text":"\nYou can also [create an allowlist for the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusterprivate-se-allowlist) to limit access to your cluster from only the allowed subnets. For more information, see the different service architecture setups for [classic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-archarchitecture_classic) or [VPC](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-archarchitecture_vpc) clusters.\n* Classic network: See [Network segmentation and privacy for classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation).\n* VPC network: See [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation_vpc).\n\n\n\n\n\n\n\n Kubernetes resources within the cluster \n\n\n\n* Pod-to-pod network traffic control: Consider using [Kubernetes network policies and Calico](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies).\n* Red Hat OpenShift resources for pod-level control: See [Configuring security context constraints (SCCs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_sccoc_sccs).\n\n\n\n\n\n\n\n\n\n\n\n Understanding IAM access policies and roles \n\nAccess policies determine the level of access that users in your IBM Cloud account have to resources across the IBM Cloud platform. A policy assigns a user one or more roles that define the scope of access to a single service or to a set of services and resources that are organized together in a resource group. Each service in IBM Cloud might require its own set of access policies.\n\n\n\n Pick the correct access policy and role for your users \n\nYou must define access policies for every user that works with Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overview"},{"document_id":"ibmcld_12348-1227-2514","score":18.6556212908,"text":"\n(https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/secrets-manager\/\/images\/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https:\/\/www.youtube.com\/watch?v=rOp7aGyavnk)\n\n Latest updates \n\n[View more](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-release-notes)17 April 2023 | Now available: new API and CLI versions\n\nThe new API, SDK, Terraform, and CLI versions offer more options to manage your Secrets Manager instance. The Secrets Manager API v1 has been deprecated in favor of v2.\n\n3 March 2023 | Now available: Terraform support\n\nSecrets Manager now supports Terraform.\n\n11 December 2022 | Support for context-based restrictions (CBR)\n\nManage user and service access to your Secrets Manager resources by using context-based restrictions.\n\n14 November 2022 | Manually configure your own DNS provider\n\nYour DNS provider isn't integrated with the service? You can now manually configure it by using the UI.\n\n18 October 2022 | Add custom metadata to your secret versions and auto-rotate IAM credentials\n\nDo you need more space to log details about your secret versions? Add relevant information as metadata.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager"},{"document_id":"ibmcld_13616-12161-13939","score":18.5282351972,"text":"\nAny vulnerabilities found by these scans must be resolved before product release or submitted through IBM's Product Security Incident Response Team (PSIRT) process for resolution via defect (IBM Authorized Program Analysis Report or APAR)\n* IBM TRIRIGA development uses Rational Team Concert for development (management of tasks, stories, epics, version control, test management, etc) Selenium and TestNG for test automation, Jenkins for deployment automation, and Rational Performance Tester (RPT) for performance load testing.\n\n\n\n\n\n\n\n Data Security & Privacy (DS&P) \n\n\n\n* IBM Data Security and Privacy Principles for IBM Cloud services can be found at the link below:\n\n\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=data-security](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=data-security)\n\n\n\n* IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services can be found below. This is applicable to EU-US and Swiss-US customers:\n\n\n\n[https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\n\n\n* Data Responsibility at IBM\n\n\n\n[https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\n\n\n* Data Processing Addendum (GDPR)\n\n\n\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08867-20399-21926","score":22.7309697136,"text":"\n+-------------------------------------------+\nSubscription Name: 30 Day Self-Supported Red Hat OpenShift Container Platform, 2-Core Evaluation\nProvides: Red Hat Ansible Engine\nRed Hat Software Collections (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise Infrastructure\nRed Hat JBoss Core Services\nRed Hat Enterprise Linux Fast Data path\nRed Hat OpenShift Container Platform for Power\nJBoss Enterprise Application Platform\n:\nRed Hat OpenShift Container Platform Client Tools for Power\nRed Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise JBoss EAP add-on\nRed Hat OpenShift Container Platform\nRed Hat Gluster Storage Management Console (for RHEL Server)\nRed Hat OpenShift Enterprise JBoss A-MQ add-on\nRed Hat Enterprise Linux for Power, little endian Beta\nRed Hat OpenShift Enterprise Client Tools\n:\nRed Hat OpenShift Enterprise Application Node\n:\nRed Hat OpenShift Service Mesh\n:\nRed Hat OpenShift Enterprise JBoss FUSE add-on\nSKU: SER0419\nContract: 123456789\nPool ID: 1a2345bcd6789098765abcde43219bc3\nProvides Management: Yes\nAvailable: 10\nSuggested: 1\nService Level: Self-Support\nService Type: L1-L3\nSubscription Type: Stackable\nStarts: 12\/03\/2018\nEnds: 01\/02\/2019\nSystem Type: Physical\n7. Exit the secure shell to return to your OpenShift installation directory inside your container.\n\nexit\n\nExample output:\n\nlogout\nConnection to 169.47.XXX.XX closed.\n\/go\/bin\/terraform-ibm-openshift \n\n\n\n2. Finish setting up and registering the nodes with the Red Hat Network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"},{"document_id":"ibmcld_14491-1340-3282","score":22.6333557009,"text":"\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"},{"document_id":"ibmcld_10422-7-1877","score":22.4567985282,"text":"\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_14492-10142-11408","score":22.4021032519,"text":"\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [VMware Solutions and Red Hat OpenShift overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro)\n* [Red Hat OpenShift Container Platform 4.7 documentation](https:\/\/docs.openshift.com\/container-platform\/4.7\/welcome\/index.html)\n* [Red Hat OpenShift Container Platform 4.7 release notes](https:\/\/docs.openshift.com\/container-platform\/4.7\/release_notes\/ocp-4-7-release-notes.html)\n* [What's new in Red Hat OpenShift](https:\/\/www.openshift.com\/learn\/whats-new)\n* [Succeeding with Red Hat OpenShift and VMware\u2019s Software-Defined Datacenter (SDDC)](https:\/\/blog.openshift.com\/red-hat-openshift-and-vmware-better-together\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10702-7-1940","score":22.329426273,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10422-1393-2886","score":22.3087410604,"text":"\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.10\/release_notes\/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https:\/\/github.com\/kubernetes\/kubernetes\/tree\/master\/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_07968-7-1612","score":22.2712277895,"text":"\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial).\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"},{"document_id":"ibmcld_14497-11060-12784","score":22.2453149488,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14492-7-1792","score":22.2375319549,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10203-7-1859","score":22.2240049173,"text":"\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-7-2257","score":34.798750816,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":34.798750816,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":34.1439574457,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":34.11952564,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":34.0530981676,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-4-2366","score":33.8465348884,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":33.8465348884,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":32.873199157,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":32.873199157,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01471-5654-7396","score":32.4996402753,"text":"\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12573-2772-4341","score":5.3050702307,"text":"\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.\n\n--parent-account-group ACCOUNT_GROUP_NAME (optional).\n: Name of the parent account group. If omitted, the parent would be the current enterprise.\n\n\n\n\n\n\n\n ibmcloud enterprise account-delete \n\nDelete an account.\n\nibmcloud enterprise account-delete (-n, --name NAME | --id ID) [-q, --quiet]\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME\n: Name of the account group. This option is exclusive with --id.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud enterprise account-move \n\nMove an account under different parent.\n\nibmcloud enterprise account-move (-n, --name NAME | --id ID) (--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID | --parent-enterprise)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_12573-1474-3115","score":5.2944456937,"text":"\nibmcloud enterprise account-group-update \n\nUpdate an account group.\n\nibmcloud enterprise account-group-update (-n, --name NAME | --id ID) (--new-name NEW_NAME)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account group. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account group. This option is exclusive with --id.\n\n--new-name NEW_NAME (required)\n: New name of target account group.\n\n\n\n\n\n\n\n ibmcloud enterprise account-group \n\nDisplay details of account group.\n\nibmcloud enterprise account-group (-n, --name NAME | --id ID)\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of the account group. This option is exclusive with --id.\n\n\n\n\n\n\n\n ibmcloud enterprise account-groups \n\nList account groups.\n\nibmcloud enterprise account-groups [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID] [--recursive]\n\n\n\n Command options \n\n--parent-account-group ACCOUNT_GROUP_NAME (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"},{"document_id":"ibmcld_12559-4953-7138","score":5.161650686,"text":"\nTo import an existing account, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Enterprise and Billing account management services within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\nComplete the following steps to import the example UX-UI account to the Design account group:\n\n\n\n1. From the enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, click Add > Import account.\n3. Select UX-UI from the Account list.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. Select Design as the parent of the UX-UI account. This determines where in the enterprise hierarchy the account exists.\n5. Review the information about the impacts to your account, and select I understand the impact to my account. Then, click Import.\n\n\n\nRepeat the steps to import more accounts.\n\n\n\n\n\n Step 4: Create new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\nComplete the following steps to create the example Web account in your enterprise:\n\n\n\n1. From the Enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter Web as the name of the account.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"},{"document_id":"ibmcld_12546-10144-11384","score":5.1284145362,"text":"\n\"name\": \"Example Account\",\n\"owner_iam_id\": \"$OWNER_IAM_ID\"\n}'\n\nCreateAccountOptions createAccountOptions = new CreateAccountOptions.Builder()\n.parent(parentCRN)\n.name(\"Example Account\")\n.ownerIamId(enterpriseAccountIamId)\n.build();\n\nResponse<CreateAccountResponse> response = service.createAccount(createAccountOptions).execute();\nCreateAccountResponse createAccountResponse = response.getResult();\n\nSystem.out.println(createAccountResponse);();\n\ncreate_account_response = enterprise_management_service.create_account(\nparent=parent_crn,\nname='Example Account',\nowner_iam_id=enterprise_account_iam_id,\n).get_result()\n\nprint(json.dumps(create_account_response, indent=2))\n\ncreateAccountOptions := enterpriseManagementService.NewCreateAccountOptions(\nparentCRN,\n\"Example Account\",\nenterpriseAccountIamID,\n)\n\ncreateAccountResponse, response, err := enterpriseManagementService.CreateAccount(createAccountOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(createAccountResponse, \"\", \" \")\nfmt.Println(string(b))\n\nconst params = {\nparent: parentCrn,\nname: 'Example Account',\nownerIamId: enterpriseAccountIamId,\n};\n\nenterpriseManagementService.createAccount(params)\n.then(res => {\nconsole.log(JSON.stringify(res.result, null, 2));\n})","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-add"},{"document_id":"ibmcld_12546-7171-9158","score":5.1184592805,"text":"\nAfter you finish building your configuration file, initialize the Terraform CLI. For more information, see [Initializing Working Directories](https:\/\/www.terraform.io\/cli\/init).\n\nterraform init\n3. Provision the resources from the main.tf file. For more information, see [Provisioning Infrastructure with Terraform](https:\/\/www.terraform.io\/cli\/run).\n\n\n\n1. Run terraform plan to generate a Terraform execution plan to preview the proposed actions.\n\nterraform plan\n2. Run terraform apply to create the resources that are defined in the plan.\n\nterraform apply\n\n\n\n\n\n\n\n\n\n\n\n Creating new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\n\n\n Creating accounts in the console \n\n\n\n1. From the Enterprise dashboard, click Accounts to view accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter a name for the account that's unique within the enterprise. Because it's one of many accounts, a unique, descriptive name helps you understand the purpose of the account at a glance.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. If you want to add the account to an account group, select the account group to be its parent. The parent that you choose determines where in the enterprise hierarchy the account exists.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\n\n\n\n\n Creating accounts by using the CLI \n\n\n\n1. If you want to add the account to an account group, find the names and IDs of existing account groups.\n\nibmcloud enterprise account-groups --recursive\n2. Create the account by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-add"},{"document_id":"ibmcld_12553-4545-5875","score":5.1151743541,"text":"\n-H \"Authorization: Bearer <IAM_Token>\"\n-H 'Content-Type: application\/json'\n-d '{\n\"parent\": \"crn:v1:bluemix:public:enterprise::a\/$ENTERPRISE_ACCOUNT_ID::enterprise:$ENTERPRISE_ID\",\n\"name\": \"Example Account Group\",\n\"primary_contact_iam_id\": \"$PRIMARY_CONTACT_IAM_ID\"\n}'\n\nCreateAccountGroupOptions createAccountGroupOptions = new CreateAccountGroupOptions.Builder()\n.parent(parentCRN)\n.name(\"Example Account Group\")\n.primaryContactIamId(enterpriseAccountIamId)\n.build();\n\nResponse<CreateAccountGroupResponse> response = service.createAccountGroup(createAccountGroupOptions).execute();\nCreateAccountGroupResponse createAccountGroupResponse = response.getResult();\n\nSystem.out.println(createAccountGroupResponse);\n\ncreate_account_group_response = enterprise_management_service.create_account_group(\nparent=parent_crn,\nname='Example Account Group',\nprimary_contact_iam_id=enterprise_account_iam_id,\n).get_result()\n\nprint(json.dumps(create_account_group_response, indent=2))\n\ncreateAccountGroupOptions := enterpriseManagementService.NewCreateAccountGroupOptions(\nparentCRN,\n\"Example Account Group\",\nenterpriseAccountIamID,\n)\n\ncreateAccountGroupResponse, response, err := enterpriseManagementService.CreateAccountGroup(createAccountGroupOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(createAccountGroupResponse, \"\", \" \")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-organize"},{"document_id":"ibmcld_12571-37602-39455","score":5.0653571982,"text":"\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all access policies under the current account:\n\nibmcloud iam access-policies\n\nList all user access policies under the current account:\n\nibmcloud iam access-policies --type user\n\nList all service ID access policies under the current account:\n\nibmcloud iam access-policies --type service_id\n\nList all access group access policies under the current account:\n\nibmcloud iam access-policies --type access_group\n\nList all trusted profile access policies under the current account:\n\nibmcloud iam access-policies --type trusted_profile\n\nList all trusted profile access policies sorted by created_at in ascending order under the current account:\n\nibmcloud iam access-policies --type trusted_profile --sort-by created_at\n\nList all trusted user policies sorted by last_modified_at in descending order under the current account:\n\nibmcloud iam access-policies --type user --sort-by -last_modified_at\n\n\n\n\n\n\n\n ibmcloud iam account-policies \n\nList all account policies under current account:\n\nibmcloud iam account-policies [-t, --type access | auth] [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]\n\n\n\n Command options \n\n-t, --type access | auth\n: List all policies under current account filtered by policy type. Valid options are: access | auth\n\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-q, --quiet\n: Suppress verbose output.\n\n--api-version\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all account policies under current account:\n\nibmcloud iam account-policies\n\nList all authorization policies under current account. Provides the same list as ibmcloud iam authorization-policies:\n\nibmcloud iam account-policies -t auth\n\nList all access policies under current account. Provides the same list as ibmcloud iam access-policies:\n\nibmcloud iam account-policies -t access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"},{"document_id":"ibmcld_00696-1740-4173","score":5.0535298248,"text":"\nWhen you log in, any of the following types of accounts might be associated with your user credentials:\n\n\n\n* Personal account\n* Corporate account\n* Corporate individual account\n\n\n\n\n\n Personal accounts \n\nTypically, each user has their own account that is their personal account. You can easily identify your personal account because it usually contains your name, for example, John Smith's Account.\n\nYou have full rights over all objects that are created in your personal account. You can invite other users to join your account, assign them rights over objects that you create, and assign them rights to create objects in your account. Because of these rights, the personal data of other users might be in your account, and your personal data might be in other user's accounts.\n\nIf you have permission to create an object in an account, you also have the right to modify and delete it, regardless of which account the object is stored in. When two users collaborate, they often share a personal account.\n\n\n\n\n\n Corporate accounts \n\nA corporate account is set up by your company. Typically, you are added automatically to the account, rather than being invited. Although corporate accounts provide users with a place to work, communicate, and share resources and charging, this set up is just a convention. A corporate account is really no different than a personal account. Objects that are created in a corporate account are associated with the account and users can be invited to the account.\n\nTeams of people who work for a corporation often collaborate by using a corporate account.\n\n\n\n\n\n Corporate individual accounts \n\nWhen you work for a corporation, the work in your account might be legally owned by the corporation. Many users who work for a corporation have a corporate individual account. If you log in to your account by using credentials that contain your corporation's name and also have what appears to be a personal account, the work within your personal account might belong to the corporation.\n\nA corporate individual account is no different from any other account. You can invite users to a corporate individual account and objects that are created in a corporate individual account are owned by the account.\n\nIf you work for a corporation that owns your work, a personal account that usually contains your name is considered a corporate individual account.\n\n\n\n\n\n\n\n Modifying, exporting, and deleting personal data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_personal_data"},{"document_id":"ibmcld_00330-1604-3194","score":4.9702494124,"text":"\ncdn-powered-by-akamai.origin-path.create Create an origin path. \n cdn-powered-by-akamai.origin-path.update Update an origin path. \n cdn-powered-by-akamai.origin-path.delete Delete an origin path. \n\n\n\n\n\n\n\n List of Time To Live events \n\nThe following table lists the actions taken related to TTL. With each of these actions, an event is generated:\n\n\n\nTable 3. Tive to Live events\n\n Action Description \n\n cdn-powered-by-akamai.ttl.create Create TTL. \n cdn-powered-by-akamai.ttl.update Update TTL. \n cdn-powered-by-akamai.ttl.delete Delete TTL. \n\n\n\n\n\n\n\n List of Purge events \n\nThe following table lists the actions taken related to purge. With each of these actions, an event is generated:\n\n\n\nTable 4. Purge events\n\n Action Description \n\n cdn-powered-by-akamai.purge.create Create purge. \n cdn-powered-by-akamai.purge.save Save purge. \n cdn-powered-by-akamai.purge.unsave Unsave purge. \n\n\n\n\n\n\n\n List of CDN Account events \n\nThe following table lists the actions taken related to CDN account. With each of these actions, an event is generated:\n\n\n\nTable 5. CDN Account events\n\n Action Description \n\n cdn-powered-by-akamai.account.create Create CDN account. \n cdn-powered-by-akamai.account.cancel Cancel CDN account. \n cdn-powered-by-akamai.account.delete Delete CDN account. \n\n\n\n\n\n\n\n List of Geolocation events \n\nThe following table lists the actions taken related to geolocation. With each of these actions, an event is generated:\n\n\n\nTable 6. Geolocation events\n\n Action Description \n\n cdn-powered-by-akamai.geo.create Create Geo location. \n cdn-powered-by-akamai.geo.update Update Geo location.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-at_events"},{"document_id":"ibmcld_02379-9575-11799","score":4.9411072549,"text":"\nrequestData.request_body.old_restrict_create_platform_apikey Reports the original value for the Restrict API key creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.new_restrict_create_platform_apikey Reports the new value for the Restrict API key creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.old_restrict_create_service_id Reports the original value for the Restrict service ID creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.new_restrict_create_service_id Reports the new value for the Restrict service ID creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.old_allowed_ip_addresses Reports the original value for the Restrict IP address access setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.new_allowed_ip_addresses Reports the new value for the Restrict IP address access setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.team_directory_enabled Reports the boolean value that is set when the Restrict user list visibility setting is modified. \n\n\n\nThe following table lists the deprecated actions that generate an event when an account setting that is controlled from the Manage > Access IAM > Settings dashboard is modified:\n\n\n\nTable 11. Actions that generate events when the account settings are changed\n\n Action Description \n\n billing.account-traits.update An event is generated when an account setting is modified. \n billing.account-mfa.set-on An event is generated when the Account Login setting sets on multifactor authentication in the account. \n billing.account-mfa.set-off An event is generated when the Account Login setting sets off multifactor authentication in the account. \n\n\n\n\n\n\n\n Events for managing organizations \n\nThe following table lists the actions that generate an event:\n\n\n\nTable 12. Actions that generate events\n\n Action Description \n\n billing.account-org.create An event is generated when you add an organization to the account. \n\n\n\n\n\n\n\n Events for managing software instances \n\nThe following table lists the actions that generate an event for software instances:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16669-7-2101","score":32.2755869402,"text":"\nIngesting data from object storage bucket \n\nIn this tutorial, you learn to move data into a data lake or an object storage bucket and load the data files to Presto. You will also learn to optimize the file format to choose the table format and run complex SQL query in IBM\u00ae watsonx.data.\n\nSample Scenario : You need to run SQL query on data files that is in your object storage bucket. For this, you must attach the data files in your object storage bucket to Presto. You can also convert data into an optimized analytical format in Parquet or ORC to enhance query performance and reduce server and storage resource consumption. Now, you can run SQL query against the table you created.\n\n\n\n Objective \n\n\n\n* Creating infrastructure within the watsonx.data service.\n* Establishing connection with the customer data bucket.\n* Querying from the bucket\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* Subscription of watsonx.data on cloud.\n* The configuration details of data bucket that you bring in. This is required for establishing connection with the watsonx.data.\n* Ensure that the data bucket has data.\n\n\n\n\n\n\n\n Step 1: Uploading data into an object storage bucket and attaching to Presto \n\nIn this section of the tutorial, you are going to manage data in an object storage bucket and attach the bucket to HMS and associate with Presto engine.\n\n\n\n1. Access any one of the object storage access tools like S3 Browser, AWS S3 console, direct S3 APIs, and various CLI\/UI object storage tools.\n2. Load data files to your object storage bucket by using the tool.\n3. Register and attach the object storage bucket to HMS and associate with Presto engine by using watsonx.data UI.\n4. Alternatively, you can also register and attach an object storage bucket with pre-existing data to HMS.\n\nORC, Parquet, Avro, RCFile, SequenceFile, JSON, Text (CSV) are the Hive supported file formats.\n\n\n\n\n\n\n\n Step 2: Load data files into Presto \n\nAfter attaching the object storage bucket to HMS, you need to load data files into Presto by creating schema and external tables through the Hive connector.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_ingest_osbckt"},{"document_id":"ibmcld_09984-0-1283","score":31.2779710417,"text":"\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity"},{"document_id":"ibmcld_13497-1510-3518","score":30.116782337,"text":"\nExisting instances still work but will be fully deprecated on 31 October.\n\n\n\n\n\n May 2022 \n\nRebranding\n: IBM Cloud SQL Query was rebranded to IBM Cloud Data Engine.\n\nHive\n: Data Engine provides an external [Hive metastore (HMS) service](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore).\n\n\n\n\n\n November 2021 \n\nAdd columns to Catalog tables\n: You can add columns to existing Catalog tables with the newly supported ALTER TABLE ... ADD COLUMNS statement.\n\n\n\n\n\n July 2021 \n\nStream landing tutorial\n: A detailed [getting started tutorial](https:\/\/www.ibm.com\/cloud\/blog\/stream-landing-from-event-streams-kafka-service-to-ibm-cloud-data-lake-on-object-storage) for stream landing with Data Engine is now available.\n\nNew region for stream landing\n: The stream landing capability is now also available in Frankfurt, in addition to Dallas.\n\n\n\n\n\n June 2021 \n\nStream landing support\n: Data Engine now supports stream landing that enables you to stream your data in real time from a topic to a bucket of your choice. This capability enables efficient analytics on the new objects created.\n\nConnect to data lakes with Cloud Pak for Data\n: IBM Cloud Pak\u00ae for Data now comes with an integrated connector to Data Engine that allows to connect to cloud data lakes and import data assets into projects and catalogs in Cloud Pak for Data. For more information, see [Connecting to a Cloud Data Lake with IBM Cloud Pak for Data](https:\/\/www.ibm.com\/cloud\/blog\/connecting-to-a-cloud-data-lake-with-ibm-cloud-pak-for-data).\n\n\n\n\n\n December 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-query-relnotes"},{"document_id":"ibmcld_16729-326786-328759","score":30.1152288734,"text":"\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web application and API with Code Engine](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-webapp)Serverless web application and API with Code Engine\n\nIn this tutorial, you will create a serverless web application using a bucket in Object Storage and implementing the application backend using IBM Cloud Code Engine and IBM Cloudant as JSON document database.\n\nCode Engine Cloudant\n\n+1\n\nObject Storage\n\n\n\n* 1 hour\n* 2023-06-16\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\n[Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn)Accelerate delivery of static files using a CDN\n\nThis tutorial walks you through how to host and serve website assets (images, videos, documents) and user generated content in a IBM Cloud Object Storage, and how to use a IBM\u00ae Content Delivery Network (CDN) for fast and secure delivery to users around the world.\n\nContent Delivery Network (CDN) Object Storage\n\n\n\n* 2 hours","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_00029-7-2023","score":30.1063989088,"text":"\nUsing IBM Cloud Data Engine as external metastore \n\nIBM Cloud Data Engine is IBM Cloud's central service for data lakes. It provides stream ingestion, data preparation, ETL, and data query from IBM Cloud Object Storage and Kafka. It also manages tables and views in a catalog that is compatible with Hive metastore and other big data engines and services can connect to it. See [Overview of IBM Cloud Data Engine](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview).\n\nEach instance of IBM Cloud Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud Object Storage. Catalog syntax is compatible with Hive metastore syntax. You can use IBM Cloud Data Engine to externalize metadata outside the IBM Analytics Engine Spark cluster.\n\n\n\n Pre-requisites \n\nThe following are the pre-requisites:\n\n\n\n* Creating IBM Cloud Data Engine instance\n* Storing data in Cloud Object Storage\n* Creating schema\n\n\n\n\n\n Creating IBM Cloud Data Engine instance \n\n{: metastore-prerequisite_line1}\n\nCreate an IBM Cloud Data Engine instance by using the Standard plan.\u00a0See [Data Engine](http:\/\/cloud.ibm.com\/catalog\/services\/data-engine-previously-sql-query).\n\nAfter you have provisioned the Data Engine instance:\n1. Make a note of the CRN of the instance.\n1. Create an account-level API key or service ID level API key with access to the instance.\n1. This service ID should be granted access to both the Data Engine instance as well as the IBM Cloud Object Storage bucket.\n\nYou can then configure your IBM Analytics Engine instance to use the default metastore configuration either at instance level or at application level as needed.\n\nIBM Cloud Data Engine supports creating instances for different endpoints(location). Within an instance, different IBM Cloud Object Storage buckets are created to store data. The data buckets can be created for different end points(region). The endpoints for the data engine instance(thrift) and the data bucket are different.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13162-7-1878","score":29.5904107145,"text":"\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16729-11586-13439","score":29.4477596534,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_13498-108109-110305","score":28.7785852806,"text":"\nnew partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage. This allows you to reexecute the automatic schema detection when the underlying data is extended with new objects containing more columns. You can also use this method to remove columns from the schema that you do not want to appear in the catalog.\n\n\n\n\n\n\n\n Describe table \n\n\n\n describeTable \n\nReturn the schema (column names and data types) of a table or view definition. If the table or view does not exist, you receive an error.\n\n-- returns detailed information about the customer table\nDESCRIBE TABLE customers_partitioned\n\n\n\n\n\n\n\n Show tables \n\n\n\n showTables \n\nReturns the list of the defined tables and views in the catalog. The LIKE option allows to filter for an indicated pattern. Use * as wildcard character.\n\n-- returns all defined tables in the catalog for this instance\nSHOW TABLES\n\n\n\n\n\n\n\n Show Partitions \n\n\n\n showPartitions \n\nList the defined partitions of a table when a table was created as partitioned. You can filter the returned partitions by using the partitionSpec option.\n\n-- returns all partitions for the table customers_partitioned\nSHOW PARTITIONS customers_partitioned\n\n\n\n\n\n\n\n\n\n Index management \n\nWith the following commands, you can create indexes for data skipping during SQL execution to improve performance and lower the costs of your SQL queries. The indexes store summary metadata for each partition of your table to avoid scanning data that is not needed for the query execution. For more information, see [index management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management).\n\n\n\n Create index \n\n\n\n createIndex \n\nCreate an index on the objects in the specified Object Storage location or on the specified table. Define the required index type for each column that you want to calculate the summary metadata for.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-106506-108540","score":28.5943822772,"text":"\nIf the partition location is not specified, it is inferred from the location of the table and the value(s) of the partitioning column(s). ADD PARTITION does not validate the specified or inferred location.\n\n-- alter the table partitions by adding a partition\nALTER TABLE customers_partitioned ADD IF NOT EXISTS PARTITION ( COUNTRY = 'Spain') LOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\/COUNTRY=Spain\n-- alter the table partitions by dropping a partition\nALTER TABLE customers_partitioned DROP IF EXISTS PARTITION ( COUNTRY = 'Nowhere')\n\nThe SET LOCATION option can be used to change the location of an existing partition.\n\n-- modify the location of an existing partition\nALTER TABLE customers_partitioned PARTITION (country = 'Spain') SET LOCATION cos:\/\/eu-de\/sql\/customers_partitioned.csv\/COUNTRY=Spain\n\nUse the EXISTS option to avoid getting errors during ADD or DROP.\n\n\n\n\n\n\n\n Alter table columns \n\n\n\n alterTableColumns \n\nUse alter table to add new columns to the schema of a catalog table.\n\nAdding columns to the schema has no effect on the objects in Object Storage for the table. If some or all of these objects do not contain a column, values for the corresponding rows are treated as NULL. You can add new objects to the table location (for nonpartitioned tables) or new partitions (for partitioned tables) that contain the new columns to evolve the table schema.\n\n-- create a partitioned sample table in PARQUET format\nCREATE TABLE customers_addcol USING PARQUET LOCATION cos:\/\/us-geo\/sql\/customers_partitioned.parquet\n-- add a new column that does not yet occur in existing partitions. new partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13486-0-612","score":28.5194750614,"text":"\n\n\n\n\n\n\n  Log analysis \n\nLearn how to use the Aspera high-speed upload feature of IBM Cloud\u00ae Object Storage and how to analyze statistical data in CSV format with [Build a data lake by using Object Storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake).\n\nLearn how to revive your archives to work on log data from IBM\u00ae Log Analysis by using IBM Cloud\u00ae Data Engine with [Analyze LogDNA log data on IBM Cloud Object Storage by using IBM Cloud Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/analyze-logdna-log-data-on-ibm-cloud-object-storage-using-ibm-cloud-sql-query).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-loganalysis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16306-8539-10329","score":49.9604320859,"text":"\nIf no utterance is received before the timeout occurs, the phone integration sends a message to the assistant that includes the post_response_timeout_occurred property set to true. \n cdr_custom_data Object A JSON object containing key\/value pairs to be stored in the CDR record for the call. Each time this object is sent, its contents are merged with data sent previously during the call. \n turn_settings.timeout_count Integer The time (in milliseconds) to wait for Watson Assistant to finish processing each conversation turn. \n\n\n\n\n\n\n\n Example request JSON \n\n\"voice_telephony\" : {\n\"post_response_timeout_count\":10000,\n\"final_utterance_timeout_count\":30000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\" : {\n\"custom_data_1\": \"data 1\",\n\"custom_data_2\": \"data 2\"\n}\n}\n\n\n\n\n\n\n\n text_messaging \n\nIncluded only if the SMS with Twilio integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the text_messaging object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation. \n private.user_phone_number String The phone number from which the customer's SMS message originated. \n\n\n\n\n\n\n\n Example JSON \n\n\"text_messaging\": {\n\"private\":{\n\"user_phone_number\":\"+18595553456\"\n},\n\"assistant_phone_number\":\"+18885556789\"\n}\n\n\n\n\n\n\n\n whatsapp \n\nIncluded only if the WhatsApp integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the whatsapp object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_03363-4-2165","score":49.3823866172,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16322-7-2220","score":48.2510360164,"text":"\nPhone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-context"},{"document_id":"ibmcld_03367-1712-3458","score":47.9252537029,"text":"\nIf this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"Hello\"\n}\n]\n},\n\"context\": {\n\"integrations\": {\n\"voice_telephony\": {\n\"post_response_timeout_count\": 10000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_03112-4-2069","score":47.8225643298,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Accessing context data in dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Accessing context data \n\nThe context is an object containing variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation; the context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each end user who interacts with the assistant. For user-based plans, this ID is used for billing purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_16261-12076-14011","score":47.7581242751,"text":"\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input\/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16262-7-2107","score":47.5313510535,"text":"\nAccessing context data in dialog \n\nThe context is an object that contains variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation. The context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each user who interacts with the assistant. For user-based plans, this ID is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n\nThere are two types of context:\n\n\n\n* Global context: context variables that are shared by all skills that are used by an assistant, including internal system variables that are used to manage conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_16261-10613-12744","score":46.7080858239,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_03423-14168-15303","score":45.4451690744,"text":"\nThe assistant_interaction_summaries object contains the following keys:\n\n\n\nKeys for the assistant_interaction_summaries object\n\n Key Type Description \n\n assistant_id string The unique identifier of the assistant. \n session_id string The unique identifier of the session. \n turns JSON array An array of the Watson Assistant transactions that took place during the conversation. \n\n\n\nThe turn object contains the following keys:\n\n\n\nKeys for the turn object\n\n Key Type Description \n\n assistant.log_id string A unique identifier for the logged transaction. Can be used to correlate between message logs and CDR events. \n assistant.start_timestamp string. Time in the ISO format yyyy-MM-ddTHH:mm:ss.SSSZ Time when the request was sent to Watson Assistant. \n assistant.response_milliseconds number Time between when the request was sent and when the response was received from Watson Assistant. \n request JSON object A request sent to Watson Assistant. \n response JSON array An array of the response objects associated with the request. \n\n\n\nThe request object contains the following keys:\n\n\n\nKeys for the request object\n\n Key Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log"},{"document_id":"ibmcld_03367-2935-4844","score":44.7369362294,"text":"\nprivate.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF). \n speech_to_text_result object The final response from the Speech to Text service in JSON format, including the transcript and confidence score for the top hypothesis and any alternatives. The format matches exactly the format that is received from the Speech to Text service. (For more information, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-textrecognize).) \n\n\n\n\n\n Example \n\n{\n\"input\": {\n\"text\": \"agent \",\n\"integrations\": {\n\"voice_telephony\": {\n\"speech_to_text_result\": {\n\"result_index\": 0,\n\"stopTimestamp\": \"2021-09-29T17:43:31.036Z\",\n\"transaction_ids\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":24.7005911143,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":24.4802156238,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_03618-1804-3397","score":22.7399012212,"text":"\nThe TPM device is integrated within the server system and provides a range of Intel TXT security-related functions.\n\n\n\n\n\n What does Intel TXT does for you \n\nIntel TXT is especially advantageous for large enterprises subject to compliance and audit regulations, such as healthcare, financial services, and government organizations. It helps assure that tracking of all trusted resources can be integrated, managed, and reported on with the relevant compliance organizations (HIPAA, PCI, FedRAMP, ISO, FISMA, and SSAE 16). For the first time, these organizations are able to certify that a cloud computing system is secured for workloads such as\n\n\n\n* Governance and enterprise risk\n* Information and lifecycle management\n* Compliance and audit\n* Application security\n* Identity and access management\n* Incident response\n\n\n\nFor more information about Intel TXT on IBM Cloud Bare Metal Servers, see [Intel\u00ae Trusted Execution Technology](https:\/\/www.ibm.com\/cloud\/bare-metal-servers\/intel-txt).\n\n\n\n\n\n Special technical notice \n\nIntel TXT is provided by Intel\u00ae and operates on the IBM Cloud Bare Metal Servers that require specific technical knowledge to support and manage. The IBM Cloud current delivery model can turn Intel\u00ae TXT either on or off. IBM Cloud can't assist with configuration of Intel TXT settings because of the sensitivity of customer environments and data. The recommendation is that you either include staff who is trained in Intel TXT technologies or engage with a consulting firm with expertise in orchestrating root of trust and measured launch environment (MLE) architecture.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-hardware-monitroing-security-controls"},{"document_id":"ibmcld_07679-0-891","score":20.9444630491,"text":"\n\n\n\n\n\n\n  AU-14 - Session Audit \n\n\n\n  Control requirements \n\nAU-14 - 0\n:   The information system provides the capability for authorized users to select a user session to capture\/record or view\/hear.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Running operator actions through a bastion host](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion)\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nSession audits include, for example, monitoring keystrokes, tracking websites visited, and recording information and\/or file transfers. Session auditing activities are developed, integrated, and used in consultation with legal counsel in accordance with applicable federal laws, Executive Orders, directives, policies, regulations, or standards.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-au-14"},{"document_id":"ibmcld_14708-2831-4126","score":19.0747669492,"text":"\nThis action allows data to be received from the proxy servers during backup and restore processes.\n\nufw status\nStatus: active\nTo Action From\n-- ------ ----\n6162\/tcp ALLOW 10.38.207.157 Allow Veeam Mgmt from Veeam BUR server\n2500\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n6162\/tcp ALLOW OUT Anywhere Veeam transport rule\n2500\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n\nZoom\n\n![Veeam backup](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/veeam-cr-sa-lhbr-proxy.svg)\n\nFigure 2. Veeam backup\n\n\n\n Best practices for a Linux hardened repository \n\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_06104-3423-5552","score":18.2743546296,"text":"\nFor data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.\n: Cold data: Data that is rarely accessed, if at all. Common use cases are archives, long-term backups, historical data.\n: Frozen data: Data that is not accessed and that you need to keep due to legal reasons.\n\nIf you can't predict the frequency or the frequency does not follow a strict pattern, determine whether your workloads are read-heavy, write-heavy, or balanced. Then, look at the storage option that fits your workload and investigate what storage tier gives you the flexibility that you need. For example, IBM Cloud Object Storage provides a flex storage class that considers how frequent data is accessed in a month and takes into account this measurement to optimize your monthly billing.\n\nInvestigate if your data must be shared across multiple app instances, zones, or regions.\n: Access across pods: When you use Kubernetes persistent volumes to access your storage, you can determine the number of pods that can mount the volume at the same time. Some storage solutions can be accessed by one pod at a time only. With other storage solutions, you can share volume across multiple pods.\n: Access across zones and regions: You might require your data to be accessible across zones or regions. Some storage solutions, such as file and block storage, are data center-specific and can't be shared across zones in a multizone cluster setup.\n\nIf you want to make your data accessible across zones or regions, make sure to consult your legal department to verify that your data can be stored in multiple zones or a different country.\n\nUnderstand other storage characteristics that impact your choice.\n: Consistency: The guarantee that a read operation returns the latest version of a file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan"},{"document_id":"ibmcld_10545-3427-5556","score":18.2743546296,"text":"\nFor data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.\n: Cold data: Data that is rarely accessed, if at all. Common use cases are archives, long-term backups, historical data.\n: Frozen data: Data that is not accessed and that you need to keep due to legal reasons.\n\nIf you can't predict the frequency or the frequency does not follow a strict pattern, determine whether your workloads are read-heavy, write-heavy, or balanced. Then, look at the storage option that fits your workload and investigate what storage tier gives you the flexibility that you need. For example, IBM Cloud Object Storage provides a flex storage class that considers how frequent data is accessed in a month and takes into account this measurement to optimize your monthly billing.\n\nInvestigate if your data must be shared across multiple app instances, zones, or regions.\n: Access across pods: When you use Kubernetes persistent volumes to access your storage, you can determine the number of pods that can mount the volume at the same time. Some storage solutions can be accessed by one pod at a time only. With other storage solutions, you can share volume across multiple pods.\n: Access across zones and regions: You might require your data to be accessible across zones or regions. Some storage solutions, such as file and block storage, are data center-specific and can't be shared across zones in a multizone cluster setup.\n\nIf you want to make your data accessible across zones or regions, make sure to consult your legal department to verify that your data can be stored in multiple zones or a different country.\n\nUnderstand other storage characteristics that impact your choice.\n: Consistency: The guarantee that a read operation returns the latest version of a file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan"},{"document_id":"ibmcld_05088-40304-41974","score":18.1769537052,"text":"\nAdd or remove a legal hold to or from a protected object \n\nThe object can support 100 legal holds:\n\n\n\n* A legal hold identifier is a string of maximum length 64 characters and a minimum length of 1 character. Valid characters are letters, numbers, !, _, ., , (, ), - and \\.\n* If the addition of the given legal hold exceeds 100 total legal holds on the object, the new legal hold will not be added, a 400 error is returned.\n* If an identifier is too long, it will not be added to the object and a 400 error is returned.\n* If an identifier contains invalid characters, it will not be added to the object and a 400 error is returned.\n* If an identifier is already in use on an object, the existing legal hold is not modified and the response indicates that the identifier was already in use with a 409 error.\n* If an object does not have retention period metadata, a 400 error is returned and adding or removing a legal hold is not allowed.\n\n\n\nThe user making adding or removing a legal hold must have Manager permissions for this bucket.\n\ndef add_legal_hold_to_object(bucket_name, object_name, legal_hold_id):\nprint(\"Adding legal hold {0} to object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.add_legal_hold(\nBucket=bucket_name,\nKey=object_name,\nRetentionLegalHoldId=legal_hold_id\n)\n\nprint(\"Legal hold {0} added to object {1} in bucket {2}!n\".format(legal_hold_id, object_name, bucket_name))\n\ndef delete_legal_hold_from_object(bucket_name, object_name, legal_hold_id):\nprint(\"Deleting legal hold {0} from object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.delete_legal_hold(\nBucket=bucket_name,\nKey=object_name,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_14708-3638-5837","score":18.1575413767,"text":"\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_05070-23003-24661","score":17.6176521058,"text":"\nCopySource: sourceBucketName + '\/' + sourceObjectName,\nRetentionDirective: 'Copy'\n}).promise()\n.then((data) => {\nconsole.log(Protected object copied from ${sourceBucketName}\/${sourceObjectName} to ${destinationBucketName}\/${newObjectName});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\nShow more\n\n\n\n\n\n Add or remove a legal hold to or from a protected object \n\nThe object can support 100 legal holds:\n\n\n\n* A legal hold identifier is a string of maximum length 64 characters and a minimum length of 1 character. Valid characters are letters, numbers, !, _, ., , (, ), - and \\.\n* If the addition of the given legal hold exceeds 100 total legal holds on the object, the new legal hold will not be added, a 400 error will be returned.\n* If an identifier is too long it will not be added to the object and a 400 error is returned.\n* If an identifier contains invalid characters, it will not be added to the object and a 400 error is returned.\n* If an identifier is already in use on an object, the existing legal hold is not modified and the response indicates the identifier was already in use with a 409 error.\n* If an object does not have retention period metadata, a 400 error is returned and adding or removing a legal hold is not allowed.\n\n\n\nThe user making adding or removing a legal hold must have Manager permissions for this bucket.\n\nfunction addLegalHoldToObject(bucketName, objectName, legalHoldId) {\nconsole.log(Adding legal hold ${legalHoldId} to object ${objectName} in bucket ${bucketName});\nreturn cos.client.addLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03704-3030-4892","score":30.6060724736,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":30.5833128338,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":30.5833128338,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03776-5228-7163","score":30.1680955641,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03704-4411-6289","score":28.2493849713,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1045891-1047755","score":28.2493849713,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1045762-1047626","score":28.2493849713,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03765-4100-6125","score":27.0981962645,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars \n\nDue to current banking regulations, recurring credit card transactions might be unsuccessful for India-based customers with accounts that are billed in US Dollars. You can use one of the following methods to make a payment:\n\n\n\n* [Make a one-time payment](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagemakepayment)\n* Request to migrate your account to be billed in India Rupees. To make a request, provide a credit card that is billed in India Rupees on the [Payment Method](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. Specify that India Rupees are in the Payment Currency section. Additional information might be requested through a Support case during the migration process.\n\n\n\n\n\n\n\n Making a one-time payment \n\nYou can use a credit card to make a one-time payment at any time for any amount, whether it's for the full balance or a partial sum. The details that you enter for the one-time payment aren't recorded for future use, and aren't populated with a default amount.\n\nTo make a one-time payment, in the IBM Cloud console, go to Manage > Billing and usage, and select Payments. Click Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03765-5710-7263","score":26.5300088353,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03765-2725-4571","score":25.6933780273,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08316-13384-14296","score":5.834507665,"text":"\n\"name\": \"remote_cidr_blocks\",\n\"secure\": false,\n\"value\": \"\"169.252.0.0\/18\"]\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"ibm_customer_number\",\n\"secure\": false,\n\"value\": \"12345\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"compute_cluster_gui_username\",\n\"secure\": false,\n\"value\": \"admin\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"compute_cluster_gui_password\",\n\"secure\": false,\n\"value\": \"P@ssw0rd\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"storage_cluster_gui_username\",\n\"secure\": false,\n\"value\": \"admin\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"storage_cluster_gui_password\",\n\"secure\": false,\n\"value\": \"P@ssw0rd\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"storage_cluster_key_pair\",\n\"secure\": false,\n\"value\": \"scale-hpcc-key\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"compute_cluster_key_pair\",\n\"secure\": false,\n\"value\": \"scale-hpcc-key\",\n\"type\": \"\",\n\"description\": \"\"\n}\n],\n\"has_githubtoken\": true","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-creating-workspace"},{"document_id":"ibmcld_08317-13395-14307","score":5.834507665,"text":"\n\"name\": \"remote_cidr_blocks\",\n\"secure\": false,\n\"value\": \"\"169.252.0.0\/18\"]\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"ibm_customer_number\",\n\"secure\": false,\n\"value\": \"12345\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"compute_cluster_gui_username\",\n\"secure\": false,\n\"value\": \"admin\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"compute_cluster_gui_password\",\n\"secure\": false,\n\"value\": \"P@ssw0rd\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"storage_cluster_gui_username\",\n\"secure\": false,\n\"value\": \"admin\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"storage_cluster_gui_password\",\n\"secure\": false,\n\"value\": \"P@ssw0rd\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"storage_cluster_key_pair\",\n\"secure\": false,\n\"value\": \"scale-hpcc-key\",\n\"type\": \"\",\n\"description\": \"\"\n},\n{\n\"name\": \"compute_cluster_key_pair\",\n\"secure\": false,\n\"value\": \"scale-hpcc-key\",\n\"type\": \"\",\n\"description\": \"\"\n}\n],\n\"has_githubtoken\": true","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-creating-workspace&interface=api"},{"document_id":"ibmcld_12571-73966-75419","score":5.622927698,"text":"\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-f, --force\n: Force failure if multiple profiles are found.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n Examples \n\nCreate link named my_link for trusted profile my-profile for an IKS_SA compute resource with service account name default, default namespace, and my_compute_resource_crn CRN:\n\nibmcloud iam trusted-profile-link-create my_profile --name my_link --cr-type IKS_SA --link-name default --link-namespace default --link-crn my_compute_resource_crn\n\nCreate link named my_link for trusted profile ID Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 for an IKS_SA compute resource with service account name default in the namespace my_namespace and with a CRN of my_resource_crn:\n\nibmcloud iam trusted-profile-link-create Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 --name my_link --cr-type IKS_SA --link-name default --link-namespace my_namespace --link-crn my_resource_crn\n\nCreate link named my_link for trusted profile ID Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 for a VSI compute resource with a CRN of my_resource_crn:\n\nibmcloud iam trusted-profile-link-create Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 --name my_link --cr-type VSI --link-crn my_resource_crn\n\n\n\n\n\n\n\n ibmcloud iam trusted-profile-links \n\nList all links to compute resources for a specified trusted profile\n\nibmcloud iam trusted-profile-links (NAME|ID) [--id | --output FORMAT] [-f, --force] [-q, --quiet]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"},{"document_id":"ibmcld_12571-72885-74325","score":5.6150483201,"text":"\nDelete policy ID bdf62c30-35dd-4852-bcb8-2f0dd3929701 from my-profile without confirmation:\n\nibmcloud iam trusted-profile-policy-delete my-profile bdf62c30-35dd-4852-bcb8-2f0dd3929701 -f\n\n\n\n\n\n\n\n ibmcloud iam trusted-profile-link-create \n\nCreate a link to a compute resource for a trusted profile\n\nibmcloud iam trusted-profile-link-create (NAME|ID) --name LINK_NAME --cr-type CR_TYPE --link-crn CRN [--link-namespace NAMESPACE --link-name NAME] [--output FORMAT] [-q, --quiet] [-f, --force]\n\n\n\n Command options \n\nNAME|ID (required)\n: Name or ID of the profile to link the compute resource to.\n\n--name\n: Name for the link.\n\n--cr-type (required)\n: The compute resource type. VSI for Virtual Service Instance on VPC, IKS_SA for Service Accounts on Kubernetes clusters, or ROKS_SA for managed Red Hat OpenShift.\n\n--link-crn (required)\n: CRN of the VSI instance \/ cluster instance.\n\n--link-namespace\n: Namespace of the service account for IKS_SA or ROKS_SA, required if IKS_SA or ROKS_SA.\n\n--link-name\n: Name of the service account for IKS_SA or ROKS_SA, required if IKS_SA or ROKS_SA.\n\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-f, --force\n: Force failure if multiple profiles are found.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n Examples \n\nCreate link named my_link for trusted profile my-profile for an IKS_SA compute resource with service account name default, default namespace, and my_compute_resource_crn CRN:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"},{"document_id":"ibmcld_14496-10412-11775","score":5.4528310739,"text":"\nEND_OF_WORKER_IGNITION\nShow more\n\nThe terraform.tfvars file is created.\n\n\n\n1. In the SSH session to the bastion node, with root privileges, use the following command to open the file; vi \/opt\/ocpinstall\/installer\/upi\/vsphere\/terraform.tfvars.\n2. Type i to enter insert mode, paste the file contents.\n3. Press Esc, then type :wq to save the file and exit the vi editor.\n\n\n\n\n\n\n\n main.tf - Remove the DNS section \n\nRemove the dns module section as the file expects to use AWS route 53 for DNS. The main.tf file is updated.\n\n\n\n1. In the SSH session to the bastion node, with root privileges, use the following command to open the file: vi \/opt\/ocpinstall\/installer\/upi\/vsphere\/main.tf\n2. Type i to enter insert mode.\n3. Scroll down the file until you reach the DNS module section.\n4. Delete the entire section shown in \"File 3: Section to be removed\".\n5. Press Esc, then type :wq to save the file and exit the vi editor.\n\n\n\nmodule \"dns\" {\nsource = \".\/route53\"\n\nbase_domain = \"${var.base_domain}\"\ncluster_domain = \"${var.cluster_domain}\"\nbootstrap_count = \"${var.bootstrap_complete ? 0 : 1}\"\nbootstrap_ips = [\"${module.bootstrap.ip_addresses}\"]\ncontrol_plane_count = \"${var.control_plane_count}\"\ncontrol_plane_ips = [\"${module.control_plane.ip_addresses}\"]\ncompute_count = \"${var.compute_count}\"\ncompute_ips = [\"${module.compute.ip_addresses}\"]\n}\n\n\n\n\n\n\n\n Run Terraform","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro"},{"document_id":"ibmcld_13967-6311-8229","score":5.3090298257,"text":"\nDue to the level of CPU oversubscription that is allowed on the hosts for variable compute server instances, CPU performance levels might be less than other public profiles with the same number of cores, while RAM and storage remain consistent. These variable compute profiles are a lower-cost alternative. For example, you can use this function to test a new feature without incurring the higher cost of a full-performance virtual server instance.\n\nThe offering is available in the following profiles:\n\n\n\nTable 11. Variable compute profiles\n\n Profile vCPU RAM Storage Type \n\n U1.1x2 1 2 GB SAN \n U1.2x4 2 4 GB SAN \n U1.4x8 4 8 GB SAN \n\n\n\n\n\n Storage notes \n\n\n\n* SAN primary boot disk (25 or 100 GB) with an extra disk available, up to 2 TB. You can add one extra secondary disk to your variable compute instance.\n* Pricing for public virtual servers that use SAN storage includes virtual CPU, memory, and minimum primary boot disk. Extra disk prices depend on the disk size and quantity that you select.\n\n\n\nSupported operating systems (such as RHEL, CentOS, Ubuntu, and others), databases that are supported, and software add-ons are also available with this offering.\n\n\n\n\n\n\n\n Compute \n\nCompute profiles are best for workloads with intensive CPU demands, such as high web traffic workloads, production batch processing, and front-end web servers.\n\nThe offering is available in the following profiles:\n\n\n\nTable 12. Compute profiles\n\n Profile vCPU RAM Storage Type \n\n C1.1x1 1 1 GB SAN \n C1.2x2 2 2 GB SAN \n C1.4x4 4 4 GB SAN \n C1.8x8 8 8 GB SAN \n C1.16x16 16 16 GB SAN \n C1.32x32 32 32 GB SAN \n\n\n\n\n\n Storage notes \n\n\n\n* SAN primary boot disk (25 or 100 GB) with extra disks available, up to 2 TB each (five total disks allowed).\n* Pricing for public virtual servers that use SAN storage includes virtual CPU, memory, and minimum primary boot disk. Extra disk prices depend on the disk size and quantity that you select.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profiles"},{"document_id":"ibmcld_12571-77439-78913","score":5.2699069682,"text":"\nTo specify mutiple conditions, specify the flag multiple times --conditions \"claim:CLAIM1,operator:OPERATOR1,value:VALUE1\" --conditions \"claim:CLAIM2,operator:OPERATOR2,value:VALUE2\".\n\n--expiration\n: Specify an expiration in seconds for SAML rules. Must not be provided for trusts established to Compute Resources (type = Profile-CR).\n\n--name\n: Name for the rule.\n\n--cr-type\n: The compute resource type the rule applies to, required only if type is specified as 'Profile-CR'. Values are VSI for Virtual Service Instance on VPC, IKS_SA for Service Accounts on Kubernetes clusters, or ROKS_SA for managed Red Hat OpenShift.\n\n--realm-name\n: Issuer Id for trusts established via IBMid with federation, or appid:\/\/ for trusts established via App ID federation. Must not be provided for trusts established to Compute Resources (type = Profile-CR).\n\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-f, --force\n: Force failure if multiple profiles are found.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n Examples \n\nCreate a Profile-SAML rule with rule name my-rule, realm name set to https:\/\/w3id.sso.ibm.com\/auth\/sps\/samlidp2\/saml20, expiration set to 1200 seconds for trusted profile my-profile with the rule conditions: cn EQUALS my_user\n\nibmcloud iam trusted-profile-rule-create my-profile --name my-rule --type Profile-SAML --conditions claim:cn,operator:EQUALS,value:my_user --realm-name https:\/\/w3id.sso.ibm.com\/auth\/sps\/samlidp2\/saml20 --expiration 1200","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"},{"document_id":"ibmcld_00119-1275-3294","score":5.22211217,"text":"\nIt is expected - proceed by sending the form.\n\n\n\n\n\n\n\n Adding a vSphere backup job \n\n\n\n1. On the navigation, click Computers. The computers page shows the registered computers and environments.\n2. Click Jobs.\n3. In the Select job Task menu, click Create New VMware\u00ae vCenter Job.\n4. Specify the following information.\n\n\n\n* In the Name field, type a name for the backup job.\n* In the Description field, optionally type a description for the backup job.\n* In the Destination list, select the vault where you want to save the backup data.\n* In the Password and Confirm Password fields, type an encryption password. You can also type a password hint in the Password Hint field.\n\n\n\nA vault appears in the list only if it is assigned to the user, or if the user added it to the computer\u2019s Vault Settings. For new backup jobs, the encryption method is AES 256 bit. Existing jobs can have other encryption methods.\n5. In the Include in Backup field, take one or more of the following steps until the Backup Set field shows the VMs that you want to include in the backup job.\n\n\n\n* To add specific VMs to the backup job, select each VM, and then click Include.\n* To exclude specific VMs from the backup job, select each VM, and then click Exclude.\n* To add VMs to the backup job by name, check the virtual machines box, and then click Include.\n* To remove an inclusion or exclusion record from the Backup Set box, click Delete next to the record.\n\n\n\n6. Click Apply Now to consolidate and simplify records in the Backup Set box, if changes need to be applied.\n7. Click Create Job.\n\n\n\n\n\n\n\n Setting up a schedule \n\nAfter the backup job is created, you can add one or more schedules for running the job automatically.\n\n\n\n1. When you click Create Job, the Schedule window appears and gives you an option to create a custom schedule for the backup job.\n\nBy default Daily retention is selected for the job. Retention and Job schedule can be changed in this window, and multiple Retention schemes can also be assigned to the backup job.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-ConfigureVRA"},{"document_id":"ibmcld_16652-0-1194","score":5.1409453121,"text":"\n\n\n\n\n\n\n  Creating an engine \n\nTo create an engine, complete the following steps.\n\n\n\n1.  Log in to watsonx.data console.\n2.  From the navigation menu, select Infrastructure manager.\n3.  To provision an engine, click Add component and select Create engine.\n4.  In the Create engine window, provide the following details to a sign up new compute to work with your data.\n\n\n\nTable 1. Provision engine\n\n Field                           Description                                                                                   \n\n Type                            Select the engine type from the list.                                                         \n Display name                    Enter your compute engine name.                                                               \n Configuration mode              Select Quick for predefined engine sizes or Custom for customized engine configuration.       \n Size                            Select the engine size. For all sizes, coordinator and worker nodes are storage-optimized.    \n Catalogs associated (optional)  Associate the available catalogs with the engine if necessary.                                \n\n\n\n5.  Click Create.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-prov_engine"},{"document_id":"ibmcld_09898-40601-43860","score":5.0317263652,"text":"\ntechnology and computing enterprise technology customer relationship management \n technology and computing enterprise technology data management \n technology and computing enterprise technology enterprise resource planning \n technology and computing hardware computer desktop computer \n technology and computing hardware computer portable computer laptop \n technology and computing hardware computer portable computer palmtops and pdas \n technology and computing hardware computer portable computer tablet \n technology and computing hardware computer portable computer \n technology and computing hardware computer servers \n technology and computing hardware computer \n technology and computing hardware computer components chips and processors \n technology and computing hardware computer components disks \n technology and computing hardware computer components graphics cards \n technology and computing hardware computer components memory portable \n technology and computing hardware computer components memory \n technology and computing hardware computer components motherboards \n technology and computing hardware computer components sound cards \n technology and computing hardware computer networking router \n technology and computing hardware computer networking wireless technology \n technology and computing hardware computer peripherals computer monitors \n technology and computing hardware computer peripherals printers, copiers and fax copiers \n technology and computing hardware computer peripherals printers, copiers and fax fax machines \n technology and computing hardware computer peripherals printers, copiers and fax printers \n technology and computing hardware computer peripherals printers, copiers and fax scanners \n technology and computing hardware computer peripherals \n technology and computing hardware \n technology and computing internet technology chat \n technology and computing internet technology ecommerce \n technology and computing internet technology email \n technology and computing internet technology internet cafes \n technology and computing internet technology isps \n technology and computing internet technology social network \n technology and computing internet technology web clip art \n technology and computing internet technology web design and html \n technology and computing internet technology web search people search \n technology and computing internet technology web search \n technology and computing internet technology \n technology and computing mp3 and midi \n technology and computing networking network monitoring and management \n technology and computing networking vpn and remote access \n technology and computing networking \n technology and computing operating systems linux \n technology and computing operating systems mac os \n technology and computing operating systems unix \n technology and computing operating systems windows \n technology and computing operating systems \n technology and computing programming languages c and c++ \n technology and computing programming languages java \n technology and computing programming languages javascript \n technology and computing programming languages visual basic \n technology and computing programming languages \n technology and computing software databases","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy-v1"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03042-1241-3131","score":28.7940553852,"text":"\n* [Skills](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-addskill-add-limits)\n* [Versions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versionsversions-limits)\n\n\n\n\n\n\n\n User information \n\nA unique user is recognized by the user ID that is associated with the person that interacts with your assistant. It is your responsibility to pass the user ID information to the service. Watson Assistant checks for the following information from API requests in this order:\n\n1. user_id: A property defined in the API that is sent in the context object of a \/message API call. Using this property is the best way to ensure that you accurately attribute \/message API calls to unique users. For more information about the user ID property, see the API reference documentation:\n\n- context.global.system.user_id: [v2 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2message)\n- context.metadata.user_id: [v1 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1message)\n\n1. session_id (v2 only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes integration or after the inactivity time limit is reached.\n\nIf you use the stateless v2 \/message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_16252-3899-5971","score":28.7474782843,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03107-3801-5605","score":28.1561564143,"text":"\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16262-7-2107","score":27.9930610655,"text":"\nAccessing context data in dialog \n\nThe context is an object that contains variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation. The context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each user who interacts with the assistant. For user-based plans, this ID is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n\nThere are two types of context:\n\n\n\n* Global context: context variables that are shared by all skills that are used by an assistant, including internal system variables that are used to manage conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_03037-7-1971","score":27.513949285,"text":"\nAdvanced tasks \n\nLearn about APIs and other tools you can use to access and analyze log data.\n\n\n\n API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03112-4-2069","score":27.3482308903,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Accessing context data in dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Accessing context data \n\nThe context is an object containing variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation; the context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each end user who interacts with the assistant. For user-based plans, this ID is used for billing purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_03037-1358-3485","score":27.0190143799,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03042-2711-4616","score":26.5746243205,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_03364-6793-8946","score":26.5296799228,"text":"\nSee [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_16261-12076-14011","score":26.1303698728,"text":"\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input\/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10702-7-1940","score":26.3806608339,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10203-7-1859","score":26.3201858611,"text":"\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10228-4-1670","score":26.3188608702,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started"},{"document_id":"ibmcld_10229-4-1670","score":26.3188608702,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started&interface=ui"},{"document_id":"ibmcld_14492-7270-9227","score":26.2864800651,"text":"\n* If the cluster is not attached to a subscription, a message is displayed with a link that you can use to find this cluster in the Red Hat customer portal. Use the link to assign the appropriate subscription and entitlement to the cluster.\n\n\n\nIf you do not have enough subscriptions and entitlements, contact a Red Hat Sales representative.\n\n\n\nFor more information, see [Red Hat OpenShift subscriptions information and known issues](https:\/\/access.redhat.com\/articles\/4105561).\n\n\n\n\n\n Configuring authentication \n\nBy default, the Red Hat OpenShift installer creates a kubeadmin user that you can use to log in to the cluster. Create authentication backends or more users, as needed, for security purposes.\n\nFor more information about how to configure Red Hat OpenShift authentication, see [Understanding authentication](https:\/\/docs.openshift.com\/container-platform\/4.7\/authentication\/understanding-authentication.html).\n\n\n\n\n\n Updating your Red Hat OpenShift cluster \n\nFor more information about updating Red Hat OpenShift, see:\n\n\n\n* [Updating a cluster within a minor version using the web console](https:\/\/docs.openshift.com\/container-platform\/4.7\/updating\/updating-cluster-within-minor.html).\n* [Updating a cluster within a minor version using the CLI](https:\/\/docs.openshift.com\/container-platform\/4.7\/updating\/updating-cluster-cli.html).\n\n\n\n\n\n\n\n Considerations when you install Red Hat OpenShift for VMware \n\n\n\n* Before the service is installed in your environment, a check is completed against the available capacity of the target cluster in the environment to ensure that the service components can fit. The storage capacity check applies only to vSAN storage. For NFS clusters, a new NFS datastore, dedicated to Red Hat OpenShift, is added.\n* The cluster is associated with the Red Hat account from the pull secret that is provided.\n* The Latency Sensitivity setting of the Red Hat OpenShift cluster VMs can affect Kubernetes scheduling performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_16729-104404-106143","score":26.2468941278,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10527-7-1958","score":26.2313153286,"text":"\nArchitecture and dependencies of the service \n\nReview sample architectures, components, and dependencies for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nIn Red Hat OpenShift on IBM Cloud, your clusters comprise an IBM-managed master that secures components such as the API server and etcd, and customer-managed worker nodes that you configure to run you app workloads, as well as Red Hat OpenShift-provided default components. The default components within the cluster, such as the Red Hat OpenShift web console or OperatorHub, vary with the Red Hat OpenShift version of your cluster.\n\n\n\n Classic Red Hat OpenShift version 4 architecture \n\nReview the architecture diagram and then scroll through the following tables for a description of master and worker node components in Red Hat OpenShift on IBM Cloud clusters that run version 4 on classic infrastructure. For more information about the OpenShift Container Platform architecture, see the [Red Hat OpenShift docs](https:\/\/docs.openshift.com\/container-platform\/4.11\/architecture\/architecture.html).\n\nWhen you run oc get nodes, you might notice that the ROLES of your worker nodes are marked as both master,worker. These nodes are worker nodes in IBM Cloud, and don't include the master components that are managed by IBM. Instead, these nodes are marked as master because they run OpenShift Container Platform components that are required to set up and manage default resources within the cluster, such as the OperatorHub and internal registry.\n\nZoom\n\n![Red Hat OpenShift on IBM Cloud cluster architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/\/images\/cs_org_ov_both_ses_roks4.png)\n\nFigure 1. Red Hat OpenShift version 4 master components\n\n\n\n Red Hat OpenShift version 4 master components \n\nReview the following components in the IBM-managed master of your Red Hat OpenShift on IBM Cloud cluster.\n\nYou can't modify these components.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecture"},{"document_id":"ibmcld_10489-7-1763","score":26.0895010381,"text":"\nSetting up the Red Hat Marketplace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nWith [Red Hat\u00ae Marketplace](https:\/\/marketplace.redhat.com\/en-us), you can deploy certified Red Hat software from an operator-based catalog to your OpenShift Container Platform clusters, including Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nRequired permissions:\n\n\n\n* The IAM Operator platform access role for the cluster in Kubernetes Service.\n* The IAM Manager service access role in all namespaces (cluster-admin RBAC) for the cluster in Kubernetes Service.\n\n\n\nRed Hat Marketplace is available for clusters that run Red Hat OpenShift version 4 only.\n\nBefore you begin:\n\n\n\n* Register for a [Red Hat Marketplace account](https:\/\/marketplace.redhat.com\/en-us\/registration\/redhat-marketplace).\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that the Operator Lifecycle Manager (OLM) pods in the openshift-operator-lifecycle-manager project and marketplace pods in the openshift-marketplace project are ready and running. You might have to restart a pod to return the pod to a healthy state.\n\noc get pods -n openshift-operator-lifecycle-manager\n\noc get pods -n openshift-marketplace\n\n\n\nTo set up your cluster with Red Hat Marketplace:\n\n\n\n1. Follow the [Red Hat Marketplace instructions](https:\/\/marketplace.redhat.com\/en-us\/workspace\/clusters\/add\/register) to create a namespace, operator, and global pull secret for the Red Hat Marketplace.\n2. Verify that the global pull secret for the cluster is updated with the registry.marketplace.redhat.com secret.\n\noc get secret pull-secret -n openshift-config --output=\"jsonpath={.data..dockerconfigjson}\" | base64 --decode | grep \"marketplace\" -A4\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rh-marketplace"},{"document_id":"ibmcld_14492-8686-10586","score":25.9785805761,"text":"\n* Before the service is installed in your environment, a check is completed against the available capacity of the target cluster in the environment to ensure that the service components can fit. The storage capacity check applies only to vSAN storage. For NFS clusters, a new NFS datastore, dedicated to Red Hat OpenShift, is added.\n* The cluster is associated with the Red Hat account from the pull secret that is provided.\n* The Latency Sensitivity setting of the Red Hat OpenShift cluster VMs can affect Kubernetes scheduling performance. By default, the setting is set to Normal, but it can be set to High if you encounter Kubernetes performance issues.\n\n\n\n\n\n\n\n Considerations when you delete Red Hat OpenShift for VMware \n\n\n\n* Before you delete Red Hat OpenShift for VMware, you must remove any additional VMs that you created in the ocp directory on VMware. The VMware Solutions automation removes only the items that were deployed during the initial installation of Red Hat OpenShift (VMs, storage, and NSX). Any node that is deployed after the installation is not cleaned up.\n* The VXLAN, DLR, and the Edge Gateway that were created during the initial deployment of Red Hat OpenShift for VMware is deleted. The VMs that you deployed on VXLAN will lose connectivity after the removal of Red Hat OpenShift for VMware starts.\n* If your cluster uses NFS storage, deleting Red Hat OpenShift deletes the NFS datastore that was added during installation.\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_14492-5755-7781","score":25.9664808732,"text":"\nThe installer program, named openshift-install, is used to install Red Hat OpenShift and can also be used to generate fresh ignition files.\n\nThe bastion also holds a file that is named auth\/kubeconfig, needed for authentication. This file holds the initial kubeadmin credentials that are created during installation. Before you initially use the oc or kubectl tools, you must set the KUBECONFIG environment variable with the path to this file. For example, export KUBECONFIG=auth\/kubeconfig.\n\nAfter that is done, any commands you run will be as the kubeadmin user. You can verify the user account by running the command .\/oc whoami.\n\nAfter you configure your authentication and any additional users, you no longer need to source this file, and you can log in as the user that you created.\n\n\n\n\n\n Red Hat subscriptions \n\nThe Red Hat OpenShift cluster is associated with the Red Hat account from the pull secret that was provided during installation. To assign subscriptions or manage the cluster, you can view the cluster in the Red Hat portal under Systems or Clusters.\n\n\n\n\n\n\n\n Assigning Red Hat subscriptions and entitlements to your Red Hat OpenShift cluster \n\n\n\n1. Log in to your Red Hat OpenShift cluster web console.\n2. Click Home > Dashboards. Make a note of the cluster ID that is displayed.\n3. Click Administration > Cluster Settings.\n4. Click OpenShift Cluster Manager under the channel, version, and update information.\n\n\n\n* Ensure that the cluster ID that is displayed matches the cluster ID from step 2.\n* If the cluster is not attached to a subscription, a message is displayed with a link that you can use to find this cluster in the Red Hat customer portal. Use the link to assign the appropriate subscription and entitlement to the cluster.\n\n\n\nIf you do not have enough subscriptions and entitlements, contact a Red Hat Sales representative.\n\n\n\nFor more information, see [Red Hat OpenShift subscriptions information and known issues](https:\/\/access.redhat.com\/articles\/4105561).\n\n\n\n\n\n Configuring authentication","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-7173-9446","score":18.24970446,"text":"\nWhen specified in combination with PARTITIONED BY, it sorts the rows within each partition by the sort order that is specified in the SORT BY clause. When specified in combination with PARTITIONED INTO, the same is done, which is often referred to as clustering the rows by the specified columns into the fixed number of partitions specified by PARTITIONED INTO. When specified without the PARTITIONED clause, it is equivalent to an ORDER BY clause specified at the top level of the SQL SELECT statement. If PARTITIONED INTO is specified, the ORDER BY clause is ignored.\n\n\n\n Partition by columns \n\nWhen you use the PARTITIONED BY (column-list) clause without specifying INTO x BUCKETS\/OBJECTS, you can store the query result by using Hive-style partitioning, which is to create partitions that contain only rows that have certain values for one or more columns. Choose this physical layout if the stored object is further analyzed by using SQL queries that specify predicates on the partition columns.\n\nFor example, a result object that contains worldwide order data has a column country to represent the country that the order is initiated from. Partitioning the result object by the column PARTITIONED BY (country), would create a result object with a partition for each country present in the query result.\n\nWhen the result object is stored this way on Cloud Object Storage, each SQL query that contains a predicate, such as country = 'USA' or country in ('MALTA', 'ITALY', 'VATICAN CITY'), benefits from this physical layout. The reason is that during SQL query execution partitions must be read only if they contain data for the countries of interest. This layout tremendously cuts down the I\/O traffic of the SQL query.\n\nSee the following extra remarks on Hive-style partitioning.\n\n\n\n* Hive-style partitions have an eye-catching naming scheme because the column names that are used for partitioning are part of the partition object prefix, for example, \/order\/COUNTRY=USA\/part-m-00000.snappy.parquet.\n* Hive-style partitions do not contain any values for partition columns since their values are stored in the object prefix of the partition. Thus, if you copy a HIVE-style partition and rename the object prefix by removing the partition column values, you lose data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13480-4908-6825","score":17.3240714411,"text":"\nIncorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.\n\nTo clean up catalog entries for unused data, use the DROP TABLE statement. This statement removes the table definition from the catalog without affecting the actual data on Object Storage:\n\nDROP TABLE customers\n\n\n\n\n\n Partitioned tables \n\nYou can manage a table in the catalog that references data that is organized in multiple partitions on Object Storage. The naming of the objects must adhere to the Hive-style partition naming convention: The object names must include the structure \/columm=value\/. The column must be a column name that is included in the schema definition of the CREATE TABLE statement. You can also have more than one partitioning columns in the object names, such as \/columm1=value\/column2=value\/.\n\nFollowing is an example list of object names on Object Storage that is partitioned on the country column with the Hive-style partition naming convention:\n\ncustomers_partitioned.csv\/country=Germany\/cust-1.csv\ncustomers_partitioned.csv\/country=Germany\/cust-2.csv\ncustomers_partitioned.csv\/country=Spain\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_00576-8941-10714","score":15.809219443,"text":"\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)\n* [Partitioned databases - data design](https:\/\/blog.cloudant.com\/2019\/03\/05\/Partition-Databases-Data-Design.html)\n\n\n\n\n\n\n\n Making the most of the primary index \n\nIBM Cloudant has a primary index on the document's _id attribute. This index allows documents to be retrieved by _id (GET \/db\/id) or a range of _ids (GET \/db\/_all_docs?startkey=\"a\"&endkey=\"z\"). By storing data in the primary key and ensuring that each _id is unique, the primary index can be used to fetch documents and ranges of documents without secondary indexing. See the following list of ideas:\n\n\n\n* If you have something unique in your object that would be useful to query against, use it as your _id field, for example, bob.smith@gmail.com, isbn9780241265543, or oakland,ca.\n* If your objects contain a hierarchy, model that in your _id: usa:ca:oakland or books:fiction:9780241265543. The hierarchy goes from largest to smallest, so you can use the primary index to find all the cities in usa or all the cities in usa:ca, without secondary indexing.\n* If you're storing time-series data, encoding time at the start of your _id sorts the primary index by time, for example, 001j40Ox1b2c1B2ubbtm4CsuLB4L35wQ.\n* Partitioned databases group documents that share a partition key together. A partition key must have many values and must not include hot spots to avoid directing a large proportion of your application's traffic to a few partitions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00381-3303-3948","score":15.0538268929,"text":"\nSierra Leone,\nSan Marino,\nSenegal,\nSomalia,\nSuriname,\nSao Tome and Principe,\nEl Salvador,\nSint Maarten,\nSyrian Arab Republic,\nSwaziland,\nTurks and Caicos Islands,\nChad,\nFrench Southern Territories,\nTogo,\nThailand,\nTajikistan,\nTokelau,\nTurkmenistan,\nTunisia,\nTonga,\nEast Timor,\nTurkey,\nTrinidad and Tobago,\nTuvalu,\nTaiwan,\nTanzania, United Republic of,\nUkraine,\nUganda,\nUSA Minor Outlying Islands,\nUnited States,\nUruguay,\nUzbekistan,\nVatican City State,\nSt Vincent and the Grenadines,\nVenezuela,\nVirgin Islands, British,\nVirgin Islands, U.S.,\nViet Nam,\nVanuatu,\nWallis and Futuna,\nSamoa,\nYemen,\nMayotte,\nSouth Africa,\nZambia,\nZimbabwe\n]\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-geoblocking-class"},{"document_id":"ibmcld_13480-6528-8270","score":14.8828206668,"text":"\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table \n\nThis data partitioning is reflected in the PARTITIONED BY clause of the following CREATE TABLE statement:\n\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (country)\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nAutomatic schema detection also recognizes partitioned tables from the structure of the object names, so the same table definition is created from the following statement:\n\nCREATE TABLE customers\nUSING CSV\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nIf your data on Object Storage does not adhere to this naming convention, you can convert it to a Hive-partitioned layout by using Data Engine in a data preparation step. Use SELECT * to copy the data to a new location and specify [PARTITION BY](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencepartitionedClause) in the INTO clause:\n\nSELECT * FROM cos:\/\/us-geo\/sql\/customers.csv\nINTO cos:\/\/us-geo\/mybucket\/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13118-27377-28138","score":14.3672984016,"text":"\nnull 7634piweba3y.prodigy.comGET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null25218 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 4441 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 1414 ntigate.nt.comGET \/images\/const... 20001\/Jul\/1995:04:1...\n null45308line03.pm1.abb.mi...GET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null 669 source.iconz.co.nzGET \/images\/WORLD... 20001\/Jul\/1995:04:1...\n null 234 source.iconz.co.nzGET \/images\/USA-l... 20001\/Jul\/1995:04:1...\n null 363 source.iconz.co.nzGET \/images\/MOSAI... 20001\/Jul\/1995:04:1...\n null13372 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n+---------------------------+-----+--------------------+--------------------+------------+--------------------+\n\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"},{"document_id":"ibmcld_00530-9526-10355","score":13.1261378979,"text":"\n\"Person_name\": \"Robert De Niro\",\n\"Movie_year\": map[string][]interface{}{\n\"$in\": []interface{}{1978, 2009},\n},\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a392eb9f2\",\n\"_rev\": \"1-9faa75d7ea524448b1456a6c69a4391a\",\n\"Movie_runtime\": 183,\n\"Movie_rating\": \"R\",\n\"Person_name\": \"Robert De Niro\",\n\"Movie_genre\": \"DW\",\n\"Movie_name\": \"Deer Hunter, The\",\n\"Person_pob\": \"New York, New York, USA\",\n\"Movie_year\": 1978,\n\"Person_dob\": \"1943-08-17\"\n}\n],\n\"bookmark\": \"g2w ... c2o\"\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-example-movies-demo-database"},{"document_id":"ibmcld_00530-4127-5130","score":12.7458545222,"text":"\nservice = CloudantV1.new_instance()\n\nresponse = service.post_find(\ndb='my-movies',\nselector={'Person_name': 'Zoe Saldana'}\n).get_result()\n\nprint(response)\n\npostFindOptions := service.NewPostFindOptions(\n\"my-movies\",\nmap[string]interface{}{\n\"Person_name\": \"Zoe Saldana\",\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a3941110b\",\n\"_rev\": \"1-556aec0e89fa13769fbf59d651411528\",\n\"Movie_runtime\": 162,\n\"Movie_rating\": \"PG-13\",\n\"Person_name\": \"Zoe Saldana\",\n\"Movie_genre\": \"AVYS\",\n\"Movie_name\": \"Avatar\",\n\"Movie_earnings_rank\": \"1\",\n\"Person_pob\": \"New Jersey, USA\",\n\"Movie_year\": 2009,\n\"Person_dob\": \"1978-06-19\"\n}\n],\n\"bookmark\": \"g2wA ... Omo\"\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-example-movies-demo-database"},{"document_id":"ibmcld_10067-2911-4724","score":12.6231176122,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various oc commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr-tutorial"},{"document_id":"ibmcld_05595-2977-4795","score":12.6231176122,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various kubectl commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr-tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16324-3229-5312","score":37.114679244,"text":"\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_03330-4-2191","score":36.2077015891,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16233-7-2298","score":35.7979430699,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_07148-7-2060","score":35.1815584086,"text":"\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question\/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https:\/\/medium.com\/ibm-watson\/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-covidkit"},{"document_id":"ibmcld_07080-6045-7467","score":34.8708739802,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a Conversational Search project. [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"},{"document_id":"ibmcld_03330-3253-5192","score":34.2135037535,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_13160-7-1812","score":33.895045064,"text":"\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson\/tree\/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_01090-0-821","score":33.8426619752,"text":"\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https:\/\/community.ibm.com\/community\/user\/hybriddatamanagement\/blogs\/jordan-hodges1\/2020\/01\/15\/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SS6NHC\/com.ibm.swg.im.dashdb.apdv.porting.doc\/doc\/c_compat_dcw.html).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dcw"},{"document_id":"ibmcld_01018-0-821","score":33.8426619752,"text":"\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https:\/\/community.ibm.com\/community\/user\/hybriddatamanagement\/blogs\/jordan-hodges1\/2020\/01\/15\/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFMBX\/com.ibm.swg.im.dashdb.apdv.porting.doc\/doc\/c_compat_dcw.html).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-dcw"},{"document_id":"ibmcld_13160-14797-16607","score":33.2721734643,"text":"\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http:\/\/localhost](http:\/\/localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/Slackbot_event.png)\n\nSlack with the eventbot","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-3583-5403","score":24.3559583682,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":24.2001643182,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_11602-14697-16534","score":17.6405025967,"text":"\nFor more information about these systems and how they're used inside the IBM Power Systems Virtual Server service, see the following data sheets:\n\nData sheets:\n\n\n\n* [IBM Power System S922 (9009-22A)](https:\/\/www.ibm.com\/downloads\/cas\/KQ4BOJ3N)\n* [IBM Power System E980 (9080-M9S)](https:\/\/www.ibm.com\/downloads\/cas\/VX0AM0EP)\n\n\n\nFor further information, see [hardware specifications for IBM Power Systems Virtual Servers](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-about-virtual-serverhardware-specifications).\n\n\n\n\n\n\n\n VMware Software-Defined Data Center \n\nIBM Cloud and VMware partner to bring the capabilities of VMware for SAP into Cloud by using VMware vSphere installed to IBM Cloud\u00ae Bare Metal Servers.\n\nThis enables secure single-tenant compute with full root control to the hypervisor, providing optimized performance with high agility, resiliency, and elastic compute costs. Since Dec-2007, when VMware first announced support for SAP, there has been continuous improvement to VMware-SAP capabilities, which provide flexible delivery of SAP project implementations and easier maintenance of SAP Systems; all these capabilities are available with VMware and IBM Cloud.\n\nIn short, IBM Cloud provides two levels of VMware, which are both SAP-certified:\n\n\n\n* Intel Bare Metal and VMware vSphere (ESXi OS), requires manual VMware setup and configuration\n* IBM Cloud for VMware Solutions Dedicated, fully automated VMware SDDC setup and configuration\n\n\n\n* includes optional BYOL and access to advanced VMware capabilities, such as VMware HCX for seamless bidirectional network extension and connection to existing VMware clusters on-premises\n\n\n\n\n\nFor more information about IBM Cloud for VMware on Classic Infrastructure, see [IBM Cloud for VMware](https:\/\/www.ibm.com\/cloud\/vmware). Additional information is available on:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offerings"},{"document_id":"ibmcld_03027-6555-8367","score":17.0398849946,"text":"\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right), RTL (right-to-left), or Auto (which automatically chooses the text direction based on your system settings). The None option displays left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/bidi-options.png)\n3. Click the X to close the page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03353-6854-8737","score":17.0398849946,"text":"\nSave the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right) or RTL (right-to-left), or select Auto which will automatically choose the text direction based on your system settings. The None option will display left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the \"Try it out\" panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_13429-70586-72538","score":16.9950587783,"text":"\nNew beta next-generation language models and low_latency parameter\n: The service now supports a growing number of next-generation language models. The next-generation multimedia and telephony models improve upon the speech recognition capabilities of the service's previous generation of broadband and narrowband models. The new models leverage deep neural networks and bidirectional analysis to achieve both higher throughput and greater transcription accuracy. At this time, the next-generation models support only a limited number of languages and speech recognition features. The supported languages, models, and features will increase with future releases. The next-generation models are beta functionality.\n\nMany of the next-generation models also support a new low_latency parameter that lets you request faster results at the possible expense of reduced transcription quality. When low latency is enabled, the service curtails its analysis of the audio, which can reduce the accuracy of the transcription. This trade-off might be acceptable if your application requires lower response time more than it does the highest possible accuracy.The low_latency parameter is beta functionality.\n\nThe low_latency parameter impacts your use of the interim_results parameter with the WebSocket interface. Interim results are available only for those next-generation models that support low latency, and only if both the interim_results and low_latency parameters are set to true.\n\n\n\n* For more information about the next-generation models and their capabilities, see [Next-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ng).\n* For more information about language support for next-generation models and about which next-generation models support low latency, see [Supported next-generation language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ngmodels-ng-supported).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_07279-0-1798","score":16.3216090262,"text":"\n\n\n\n\n\n\n  Setting up Bidirectional Forwarding Detection (BFD) \n\nBidirectional Forwarding Detection (BFD) quickly detects faults in a network between two routers or switches connected by a link. It provides a single, standardized method for failover detection at any protocol layer over any media. BFD also provides a way for network administrators to detect forwarding-path failures at a uniform rate, rather than the variable rates of different routing protocol hello mechanisms. Network profiling and planning is easier, and reconvergence time is predictable, consistent, and significantly faster.\n\nBFD support comes pre-enabled with your direct link. However, BFD doesn\u2019t start working until you activate the feature during direct link creation, or on an existing direct link. No prerequisites are required. Simply configure this feature with the following values:\n\n\n\n*  Interval \u2013 The interval is the minimum time (in milliseconds) expected to occur between when the local routing device sends BFD hello packets and the reply from its neighbor. This value can range from 300 to 255,000 milliseconds.\n*  Multiplier \u2013 The multiplier is the number of times that a hello packet is missed before BFD declares the neighbor down. This value can range from 1 to 255. The default multiplier value is 3.\n\n\n\nWhen using BFD, avoid using graceful restart on the Direct Link BGP session. Graceful restart helper is configured on the Direct Link router. If the customer side of the BGP session is configured with graceful restart, then the routes that the IBM router receives remain in the routing table for 300 seconds, even if BFD is triggered.\n\n\n\n  Related link \n\n[Activating and deactivating Bidirectional Forwarding Detection (BFD)](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-activate-deactivate-bfd)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-bfd"},{"document_id":"ibmcld_13416-7-2114","score":16.1297817799,"text":"\nNext-generation languages and models \n\nThe IBM Watson\u00ae Speech to Text service supports a growing collection of next-generation models that improve upon the speech recognition capabilities of the service's previous-generation models. The model indicates the language in which the audio is spoken and the rate at which it is sampled. Next-generation models have higher throughput than the previous-generation models, so the service can return transcriptions more quickly. Next-generation models also provide noticeably better transcription accuracy.\n\nWhen you use next-generation models, the service analyzes audio bidirectionally. Using deep neural networks, the model analyzes and extracts information from the audio. The model then evaluates the information forwards and backwards to predict the transcription, effectively \"listening\" to the audio twice.\n\nWith the additional information and context afforded by bidirectional analysis, the service can make smarter hypotheses about the words spoken in the audio. Despite the added analysis, recognition with next-generation models is more efficient than with previous-generation models, so the service delivers results faster and with more accuracy. Most next-generation models also offer a low-latency option to receive results even faster, though low latency might impact transcription accuracy.\n\nIn addition to providing greater transcription accuracy, the models have the ability to hypothesize words that are not in the base language model and that it has not encountered in training. This capability can decrease the need for customization of domain-specific terms. A model does not need to contain a specific vocabulary term to predict that word.\n\n\n\n* For an overview of the next-generation models and their technology, see [Next-Generation Watson Speech to Text](https:\/\/medium.com\/ibm-watson-speech-services\/next-generation-watson-speech-to-text-650fd66d95d0).\n* For more information about the technology that underlies the next-generation models, see [Advancing RNN Transducer Technology for Speech Recognition](https:\/\/arxiv.org\/abs\/2103.09935).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ng"},{"document_id":"ibmcld_03353-5263-7331","score":15.9486872311,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_14410-1474-2881","score":15.9366360673,"text":"\nHCX Syslog User configured Connection between HCX (the client) and the Syslog server. Values for the Syslog port and protocol are specified in the vSphere Web Client. For example, port 514 for UDP protocol. \n HCX HCX-IX 8123 TCP Send host-based replication service instructions to the HCX-IX. HTTP \n HCX HCX-IX 9443 TCP Send management instructions to the local HCX-IX by using the REST API. HTTP <br>HTTPS \n HCX-IX HCX-NE 443 TCP Send management instructions from HCX-IX to HCX-NE when HCX-NE uses the same path as the HCX-IX. HTTP <br>HTTPS \n HCX-IX HCX-NE 8443 TCP Bidirectional management instructions from HCX-IX to HCX-NE, when HCX-NE uses an alternative data path. HTTP <br>HTTPS \n HCX-NE HCX-NE (remote) 443 TCP Bidirectional management instructions from HCX-IX to HCX-NE, when HCX-NE uses an alternative data path. HTTP <br>HTTPS \n HCX-IX ESXi hosts 80, 902 TCP Management and OVF deployment Internal \n ESXi Hosts HCX-IX 31031, 44046 TCP Internal host-based replication traffic Internal \n HCX-IX ESXi hosts 8000 TCP vMotion (zero downtime migration) \n HCX-IX (local) HCX-IX <br>(remote) 4500 UDP Internet Key Exchange (IKEv2) to encapsulate workloads for the bidirectional tunnel IPsec \n HCX-IX (local) HCX-IX <br>(remote) 500 UDP Internet Key Exchange (ISAKMP) for the bidirectional tunnel IPsec \n\n\n\n\n\n Related links \n\n\n\n* [VMware HCX ports and protocols](https:\/\/ports.vmware.com\/home\/VMware-HCX)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-hcx-archi-port-req"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.7095272045,"ndcg_cut_10":0.8270433092}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06320-2897-4555","score":31.3039037462,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-1330-3318","score":24.588171424,"text":"\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https:\/\/docs.datastax.com\/en\/devapp\/doc\/devapp\/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_03870-4661-6102","score":19.073793764,"text":"\n[Install the operator in the openshift-operators namespace](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/allnamespace-install-operator.png)\n\nFigure 1. Install the operator in the openshift-operators namespace\n8. The Console and Fabric components can be installed in any namespace.\n\nZoom\n\n![Console and Fabric components can be installed in any namespace](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/allnamespace-installed-operators.png)\n\nFigure 2. Console and Fabric components can be installed in any namespace\n9. Next, update the Security Context Constraint command settings to use the Fabric and Console namespaces.\n\nZoom\n\n![Update Security Context Constraint command settings to use the Fabric and Console namespaces.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/allnamespace-ibp-consoles.png)\n\nFigure 3. Update Security Context Constraint command settings to use the Fabric and Console namespaces.\n10. If your OpenShift cluster is behind a firewall, see [Deploy from Red Hat Marketplace (airgap installation)](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-deploy-ocp-rhm-fw).\n11. Continue to [Step one: Apply the Security Context Constraint](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-deploy-ocp-rhmdeploy-ocp-rhm-scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-deploy-ocp-rhm"},{"document_id":"ibmcld_03916-46686-48366","score":18.8939720754,"text":"\nConnecting to your network by using low-level Fabric SDK APIs \n\nIf you are interested in preserving your existing application code, or by using Fabric SDKs for languages other than Node.js, you can still connect to your network by using lower-level Fabric SDK APIs. Use the console to [download your connection profile](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-profile). You can then import the endpoints of the peers and ordering nodes of your channel directly from the connection profile, or use the node endpoint information to manually add peer and orderer objects. You will also need to use your CA to [create an application identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-identities), and then use the CA endpoint information enroll on the client side, or generate certificates using your console.\n\nThe [Fabric Node SDK](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/index.html) documentation provides a tutorial on how to [connect to your network using a connection profile](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/tutorial-commonconnectionprofile.html). The tutorial uses the CA endpoint information in your connection profile to generate keys using the SDK. You can also use your console to generate a signing certificate and private key and convert the keys into PEM format. You can then set a user context by passing your keys directly to the SDKs' [Fabric Client class](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/Client.html) using the following code:\n\nfabric_client.createUser({\nusername: 'admin',\nmspid: 'org1',\ncryptoContent: {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_16729-11586-13439","score":18.7695461505,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_03837-1503-3686","score":18.7494469165,"text":"\nFor the purposes of this overview, we focus just on certificate authorities (CAs), orderers, peers, smart contracts, and applications. As you can see from the [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network), this sequence is not arbitrary; it reflects the proper order in which components in a network based on Fabric are deployed.\n\n\n\n Peers \n\nAt a conceptual level, a blockchain network is comprised mainly of organizations (as organizations decide on how a network is structured, as well as owning nodes and managing identities). At a physical level, however, a blockchain network is comprised primarily of peer nodes that are owned and administered by organizations. Peers are the fundamental elements of the network because they host ledgers and smart contracts (which are contained in [chaincode](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/developapps\/chaincodenamespace.html)), and are therefore where transactions are executed and validated.\n\nMore accurately, the peer hosts instances of the ledger, and instances of smart contracts. Because smart contracts and ledgers are used to encapsulate the shared processes and shared information in a network, these aspects of a peer make them a good starting point to understand what a Fabric network does.\n\nTo learn more about peers specifically, check out [Peers](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/peers\/peers.html) from the Fabric community documentation.\n\nThe IBM Blockchain Platform console allows you to create peers, join them to channels, create anchor peers, install smart contracts, and seamlessly upgrade your peers.\n\n\n\n\n\n Certificate Authorities (CAs) \n\nYou can think of a blockchain network as a series of managed interactions between nodes to serve a defined business use case. For these interactions to be verifiable (to ensure, in other words, who is who) requires identities and a system of permissions that can be checked during each interaction. You can think of the kind of identity that is needed as being similar to a credit card in that it identifies someone within a particular context.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-component-overview"},{"document_id":"ibmcld_03837-3210-5419","score":18.3040426421,"text":"\nCertificate Authorities (CAs) \n\nYou can think of a blockchain network as a series of managed interactions between nodes to serve a defined business use case. For these interactions to be verifiable (to ensure, in other words, who is who) requires identities and a system of permissions that can be checked during each interaction. You can think of the kind of identity that is needed as being similar to a credit card in that it identifies someone within a particular context. Credit cards identify an individual in terms of banking transactions, while Fabric identities allow users to be identified in a blockchain context.\n\nIn Hyperledger Fabric, as well as the IBM Blockchain Platform, this component is the Certificate Authority (CA), which creates identities in the form of x509 certificates as well defining of an organization through the creation of a Membership Services Provider (MSP), which defines the permissions of identities at a component and channel level. These identities can include attributes about them, for example, by linking them to a particular organization or organizational unit (OU).\n\nAn organization MSP, for example, has an MSP subfolder called admins. Any user whose certificate is inside that admin folder is an admin of the organization. Because this MSP defines the organization, it is listed in the configuration on every channel of which the organization is a member. As a result, whenever an admin of the organization tries to perform an action, the signing certificate of the admin (which is attached to all of its interactions) is checked against the certificates listed in the MSP. Does the certificate match the one listed in the channel configuration? If it does, the other organizations will validate it and the action can be performed. If not, the request to execute the transaction is rejected.\n\nIBM Blockchain Platform CAs are based on the [Hyperledger Fabric CA](https:\/\/hyperledger-fabric-ca.readthedocs.io\/en\/release-1.4\/), though it is possible to use another CA if it uses a PKI based on x.509 certificates. Because non-Fabric CAs are not configured to create properly formatted MSPs, users who want to use this kind of CA must create the MSP for themselves.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-component-overview"},{"document_id":"ibmcld_03870-5750-7207","score":18.1813755134,"text":"\nIf your OpenShift cluster is behind a firewall, see [Deploy from Red Hat Marketplace (airgap installation)](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-deploy-ocp-rhm-fw).\n11. Continue to [Step one: Apply the Security Context Constraint](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-deploy-ocp-rhmdeploy-ocp-rhm-scc).\n\n\n\n\n\n\n\n Step one: Apply the Security Context Constraint \n\nThe IBM Blockchain Platform requires specific security and access policies to be added to your project. The ibp-scc.yaml file is provided here for you to copy and edit to define the security policies for your project. Before attempting this step, you should be logged in to the oc CLI.\n\nCopy and save the following security context constraint object to your local system as ibp-scc.yaml. Edit the file and replace <PROJECT_NAME> with the name of your project.\n\nallowHostDirVolumePlugin: false\nallowHostIPC: false\nallowHostNetwork: false\nallowHostPID: false\nallowHostPorts: false\nallowPrivilegeEscalation: true\nallowPrivilegedContainer: true\nallowedCapabilities:\n- NET_BIND_SERVICE\n- CHOWN\n- DAC_OVERRIDE\n- SETGID\n- SETUID\n- FOWNER\napiVersion: security.openshift.io\/v1\ndefaultAddCapabilities: []\nfsGroup:\ntype: RunAsAny\ngroups:\n- system:serviceaccounts:<PROJECT_NAME>\nkind: SecurityContextConstraints\nmetadata:\nname: <PROJECT_NAME>\nreadOnlyRootFilesystem: false\nrequiredDropCapabilities: []\nrunAsUser:\ntype: RunAsAny\nseLinuxContext:\ntype: RunAsAny","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-deploy-ocp-rhm"},{"document_id":"ibmcld_04066-6776-8657","score":17.6482827806,"text":"\nIf you do not have an account:\n\n\n\n1. Click the Sign up button.\n2. After you create a free trial account, upgrade it to a Pay-As-You-Go type by going to Manage > Billing and Usage > Billing in the IBM Cloud console, and clicking Add Credit Card.\n3. Ensure that the user has both Administrator and Manager roles for the Kubernetes cluster that they will link to their blockchain service instance. See these steps on [how to assign Kubernetes access roles](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks-icibp-v2-deploy-iks-k8x-access-roles) for more information.\n\n\n\n\n\nWhen you plan to use the service instance in the context of a broader organization-wide solution, it is recommended that the participating organizations use a functional email address to create their network. In this case, access to the network does not depend on any single individual's availability.\n\n\n\n* If you plan to use an existing Kubernetes cluster on IBM Cloud, ensure the version of Kubernetes it is running is between v1.24 - v1.26. For more information about how to determine what version of Kubernetes your cluster is running and how to upgrade the version, see [Updating the Kubernetes version of your cluster](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks-icibp-v2-deploy-iks-updating-kubernetes).\n* If you plan to use a Hardware Security Module (HSM) to generate and store the private key for your peer and ordering nodes, you can configure the HSM before you deploy the platform. Along with deploying the HSM device itself, in order for the blockchain components to access the HSM partition, you also need to publish an HSM client image to a container registry. If you decide to publish an HSM client image to a container registry, you can enable HSM support for the platform by providing the image URL when you link the service to your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks"},{"document_id":"ibmcld_06320-4083-5561","score":17.4599401974,"text":"\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration. For more information, see [DSBULK documentation](https:\/\/docs.datastax.com\/en\/dsbulk\/doc\/dsbulk\/reference\/dsbulkCmd.html).\n\n\n\n\n\n\n\n Resource configurations \n\n\n\n* The recommended configuration for a node is:\n\n\n\n* 16 CPUs\n* 32 GB to 64 GB RAM\n* 16 K disk IOPS (16 k IOPS == 1.6 TB disk)\n\n\n\n\n\n\n\n\n\n\n\n Next steps \n\nDetailed information on CQL, the Cassandra Query Language, can be found by consulting [CQL for DSE Documentation](https:\/\/docs.datastax.com\/en\/dse\/6.0\/cql\/).\n\nLooking to administer your deployment? Consult DataStax's documentation on using the [stand-alone CQLSH client](https:\/\/docs.datastax.com\/en\/astra\/docs\/connecting-to-databases-using-standalone-cqlsh.html).\n\nYou can manage your deployment with [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli), the [Cloud Databases CLI plug-in](https:\/\/cloud.ibm.com\/docs\/databases-cli-plugin?topic=databases-cli-plugin-cdb-reference), or by using the [Cloud Databases API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05873-73055-74805","score":13.7528305453,"text":"\n: All istio-monitoring support is deprecated in version 1.7 of the Istio add-on and is automatically removed in version 1.8 of the Istio add-on. To use monitoring with Istio, you must install the components separately from the Istio add-on.\n: For more information, see the [Istio documentation](https:\/\/istio.io\/latest\/docs\/ops\/integrations\/).\n: The istio-ingressgateway-public-(n)-enabled and istio-ingressgateway-zone-(n) options in the [managed-istio-custom ConfigMap resource](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize) are generally available for production use.\n\n\n\n\n\n\n\n Version 1.6 (unsupported) \n\nVersion 1.6 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.6 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.6 of the managed IBM Cloud Kubernetes Service Istio and version 1.6 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n meshConfig.enablePrometheusMerge=true and values.telemetry.v2.enabled=true In the managed Istio add-on, support for telemetry with IBM Cloud Monitoring is enabled by default. This support can be disabled by [customizing the Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize). \n istio-ingressgateway and istio-egressgateway In the managed Istio add-on, placement of gateways on edge worker nodes is preferred, but not required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_05873-80552-82182","score":13.6672576328,"text":"\n* [CVE-2020-1752](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-1752).\n\n\n\n: For more information, see the [Istio security bulletin 2020-008](https:\/\/istio.io\/latest\/news\/security\/istio-security-2020-008\/)\n\n\n\n\n\n Change log for 1.6, released 08 July 2020 \n\nReview the changes that are in version 1.6 of the managed Istio add-on.\n\nPrevious version\n: 1.5.7\n\nCurrent version\n: 1.6\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.6](https:\/\/istio.io\/latest\/news\/releases\/1.6.x\/announcing-1.6\/).\n: Support is added for the istio-knative-cluster-local-gateway-enabled and istio-monitoring-telemetry options in the [managed-istio-custom ConfigMap resource](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize). You can use these options to manage inclusion of Knative apps in the service mesh and the Istio telemetry enablement. Support for IBM Cloud Monitoring is enabled for Istio by default.\n\n\n\n\n\n\n\n Version 1.5 (unsupported) \n\nVersion 1.5 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.5 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_05873-81662-83420","score":13.0193811065,"text":"\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n egressGateways[name: istio-egressgateway].enabled: true In the managed Istio add-on, the egress gateway is enabled by default. \n istiod, istio-ingressgateway, and istio-egressgateway In the managed Istio add-on, istiod and all Istio ingress and egress gateways are set up for basic high availability support. High availability support on these components includes the following settings by default: node anti-affinity, HorizontalPodAutoscaler, PodDisruptionBudget, and automatic scaling of replicas. \n prometheus.enabled: false In the managed Istio add-on, the Prometheus, Grafana, Jaeger, and Kiali monitoring components are disabled by default due to current security concerns in the community release of Istio that can't be adequately addressed for a production environment. \n values.global.pilot.enableProtocolSniffingForInbound and values.global.pilot.enableProtocolSniffingForOutbound In the managed Istio add-on, protocol sniffing is disabled by default until the feature becomes more stable in the community Istio. \n\n\n\n\n\n\n\n Change log for 1.5.10, released 1 September 2020 \n\nReview the changes that are in version 1.5.10 of the managed Istio add-on.\n\nPrevious version\n: 1.5.9\n\nCurrent version\n: 1.5.10\n\nUpdates in this version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_03369-1415-3586","score":12.7139809533,"text":"\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https:\/\/cldr.unicode.org\/index\/downloads\/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16302-0-1237","score":12.438914011,"text":"\n\n\n\n\n\n\n  Publishing dialog and actions \n\nIf the dialog feature is enabled, the publishing and deployment processes remain the same. However, some slight differences in functionality exist.\n\nTo learn about the overall publishing and deployment model for Watson Assistant, see the [Publishing and deploying your assistant overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview). For more information about the Publish page and how the publishing process works, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). The following slight differences exist when the dialog feature is enabled in an assistant:\n\n\n\n*  On the Publish page, the information in the Content type column lists whether your content changes contain a dialog.\n*  The version tiles on the Publish and Environments pages show whether the published content contains actions, or actions and a dialog. For example, if the dialog feature is enabled in your assistant, the version tile displays Contains actions & dialog.\n*  When you export a version of your content from the Publish page, two JSON files are downloaded. One file is for actions and one file is for the dialog.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-publish"},{"document_id":"ibmcld_06941-0-1401","score":12.1320880914,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nFind answers to questions that are commonly asked about migrating from Discovery v1 to v2.\n\nDo the two versions have all the same features?\n:   There are many feature differences between the two versions. For a full feature comparison, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nHow do I know which version I'm using now?\n:   When you open the product user interface in v2, the following page is displayed:\n\nZoom\n\n![Shows the main My Projects page with a single Sample Project tile.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/gs-home-page.png)\n\nFigure 1. Home page from the Sample Project\n\nHow long will the migration take?\n:   The time you need to set aside for the migration differs based on the amount of data you want to retain in your existing v1 service instance.\n\nDo I need to update my existing applications for them to work with v2?\n:   Yes. You will need to edit any existing applications to account for changes that are introduced with Discovery v2. For more information, see the [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\nTo get started, see [Migrating to Discovery v2](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data--migration-faq"},{"document_id":"ibmcld_07067-1816-3544","score":12.1080660403,"text":"\n* For more information about feature differences, see [the feature comparison table](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-chooseversion-choose-comparison).\n* For more information about detailed API differences, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\nDiscovery v2 is available for all users of Plus or Enterprise plan instances, or Premium plan instances that were created after 15 July 2020. v2 is also available for IBM Watson\u00ae Discovery Cartridge for IBM Cloud Pak\u00ae for Data users.\n\n\n\n Migration overview \n\nMigrating from Discovery v1 to v2 is a multistep process that you can do independently.\n\nThe two versions of the Discovery service have many differences, but you can adopt techniques and utilities that were applied to a v1 instance for use with your new v2 instance.\n\nTo migrate from v1 to v2, you must complete the following high-level steps:\n\n\n\n1. [Plan the migration](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-plans).\n2. [Transfer your documents](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-docs).\n3. [Update your application to use the v2 API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-difs).\n4. Regression test and deploy the updated application.\n5. [Delete your v1 plan service instance](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-delete).\n\n\n\nSome steps require you to make programmatic changes by using the API and others involve changes that you can make from the product user interface.\n\n\n\n\n\n Plan the migration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_10534-328324-329702","score":11.8811801861,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-service-compliance)\n* [What else can I do to increase the security and compliance of my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-what-else)\n\n\n\n* [Running the worker node CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-worker-test)\n\n\n\n[Comparing the CIS Kubernetes and the Compliance Operator benchmarks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison)\n\n\n\n* [Major differences](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-major)\n* [Minor differences](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-minor)\n\n\n\n\n\n Version 4.13 \n\n[4.13 version information and update actions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_413cs_versions_413)\n\n\n\n* [Release timeline](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_413release_timeline_413)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07068-7-1672","score":11.7598409896,"text":"\nAPI version comparison \n\nFor most API methods, the request parameters and response bodies differ between v1 and v2. Learn about the equivalent or alternative v2 methods that you can use to do actions that are supported by the v1 API.\n\nThe comparison information assumes you are using the latest version of the v1 API (version 2019-04-30) and compares it to the latest version of the v2 API (version 2020-08-30).\n\n\n\n Environments \n\nThere is no concept of an environment in v2. The deployment details such as size and index capacity are managed based on the service plan type. In v2, collections are organized in projects. You can create different types of projects to apply default configuration settings to the collections that you add to the projects.\n\nThere are no equivalent methods in v2 for the v1 environment methods. However, the following table shows v2 methods that serve similar functions to the corresponding v1 methods. The supported parameters and response bodies that are returned for each method differ also.\n\n\n\nEnvironment API action support details\n\n Action v1 API Related v2 API \n\n Create an environment [POST \/v1\/environments](https:\/\/cloud.ibm.com\/apidocs\/discoverycreateenvironment) [POST \/v2\/projects](https:\/\/cloud.ibm.com\/apidocs\/discovery-datacreateproject) \n List environments [GET \/v1\/environments](https:\/\/cloud.ibm.com\/apidocs\/discoverylistenvironments) [GET \/v2\/projects](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistprojects) \n Get environment info [GET \/v1\/environments\/{environment_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverygetenvironment) [GET \/v2\/projects\/{project_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagetproject)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_14105-0-1469","score":11.6180566177,"text":"\n\n\n\n\n\n\n  Differences between versions of XenServer \n\nLicensing is the only difference between versions of XenServer that are installed on the system. If you want to upgrade your license to a higher class license after installation, you experience no downtime to reinstall your server. Contact IBM Cloud\u00ae sales for pricing information.\n\nNote: Not all available features are supported.\n\nThe following lists of features are included for each of the different licenses that are offered (as of XenServer 6.0):\n\nXenServer free, advanced, enterprise license features\n\n\n\n*  XenServer Hypervisor\n*  Conversion Tools\n*  Management integration with Microsoft System Center VMM\n*  Resilient distributed management architecture\n*  VM disk snapshot and revert\n*  XenCenter Management Console\n*  XenMotion Live Migration\n\n\n\nXenServer advanced and enterprise license features\n\n\n\n*  Automated VM protection and recovery (Automated VM protection and recovery is only available for the Advanced and Enterprise editions in the 6.0 release and later.)\n*  Distributed virtual switching\n*  Heterogeneous Pools\n*  High Availability\n*  Memory Optimization\n*  Performance alerting and reporting\n\n\n\nXenServer Enterprise license features\n\n\n\n*  Dynamic workload balancing\n*  GPU pass-thru\n*  Host power management\n*  IntelliCache\n*  Live memory snapshot and revert\n*  Provisioning Services (virtual)\n*  Role-based administration\n*  StorageLink\n*  Web management console with delegated admin\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-differences-between-versions-of-xenserver"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01041-2429-3846","score":19.7170329928,"text":"\nAfter you grant your Db2 on Cloud deployments permission to use your keys, you supply the key name or CRN in [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-keys) when you provision a deployment. The deployment uses your encryption key to encrypt your data.\n\nIf you provision a deployment through the CLI or API, the key needs to be identified by its full CRN, not just its ID. A CRN is in the format crn:v1:<...>:key:<id>.\n\n\n\n\n\n Deleting the deployment \n\nIf you delete a deployment that is protected with a key, the deployment remains registered against the key for the duration of the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you have to force delete the key using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys). After the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-management-services"},{"document_id":"ibmcld_01034-2639-4203","score":18.5168234996,"text":"\n\"target\": \"blue-us-south\",\n\"resource_group\": \"5g9f447903254bb58972a2f3f5a4c711\",\n\"resource_plan_id\": \"databases-for-x-standard\",\n\"disk_encryption_key_crn\": \"crn:v1:<...>:key:<id>\"\n}'\n\nIf you provision a deployment through the CLI or API, the HPCS key needs to be identified by its full CRN, not just its ID. An HPCS CRN is in the format crn:v1:<...>:key:<id>.\n\n\n\n\n\n Key Rotation \n\nHPCS offers manual and automatic [key rotation](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-rotation-policy) and key rotation is supported by Cloud Databases deployments. When you rotate a key, the process initiates a Syncing KMS state task, and your deployment is reencrypted with the new key. The task is displayed on the Tasks panel on your deployment's Overview and the associated HPCS and Cloud Databases events are sent to Activity Tracker.\n\n\n\n\n\n Deleting the Deployment \n\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 7 days). If you need to delete the key in the soft-deletion period, you must [force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_01034-3831-4923","score":17.6798201325,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_08493-38549-39733","score":16.9321516458,"text":"\nGenerateRandomRequest := &pb.GenerateRandomRequest{\nLen: (uint64)(ep11.AES_BLOCK_SIZE),\n}\nGenerateRandomResponse, err := cryptoClient.GenerateRandom(context.Background(), GenerateRandomRequest)\nif err != nil {\nreturn nil, fmt.Errorf(\"GenerateRandom error: %s\", err)\n}\niv := GenerateRandomResponse.Rnd[:ep11.AES_BLOCK_SIZE]\nfmt.Println(\"Generated IV\")\n\nEncryptInitRequest := &pb.EncryptInitRequest{\nMech: &pb.Mechanism{Mechanism: ep11.CKM_AES_CBC_PAD, Parameter: util.SetMechParm(iv)},\nKey: GenerateKeyResponse.KeyBytes,\n}\n\nEncryptInitResponse, err := cryptoClient.EncryptInit(context.Background(), EncryptInitRequest)\nShow more\n* JavaScript code snippet\n\nclient.EncryptInit({\nMech: {\nMechanism: ep11.CKM_AES_CBC_PAD,\nParameterB: iv\n},\nKey: key\n}, (err, data={}) => {\ncb(err, data.State);\n});\n\n\n\n\n\n\n\n Encrypt \n\nThe Encrypt function encrypts single-part data. You don't need to perform the EncryptUpdate and EncryptFinal suboperations for a single-part encryption. Before you call this function, make sure to run EncryptInit first.\n\nEnterprise PKCS #11 over gRPC\n\nEnterprise PKCS #11\n\nPKCS #11\n\n\n\n\n\n Description Binds to EP11 m_Encrypt, which is an implementation of PKCS #11 C_Encrypt.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-grep11-api-ref"},{"document_id":"ibmcld_06341-2428-3641","score":16.9242151533,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":16.9242151533,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":16.9242151533,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":16.9242151533,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":16.9242151533,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_09559-3849-5260","score":16.8389370714,"text":"\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you must [force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-hpcs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.1666666667,"recall_5":0.1666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.1695801026,"ndcg_cut_10":0.4510502357}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-112397-114109","score":35.3796788013,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-447531-449109","score":35.258785702,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":35.258785702,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":35.1807287939,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_07578-448564-450242","score":34.8518328659,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-448546-450224","score":34.8518328659,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00558-1499-3456","score":33.477943582,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-1535-3460","score":33.3326251559,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00532-0-1979","score":33.2766547336,"text":"\n\n\n\n\n\n\n  Availability zones FAQ \n\nYou can create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance on IBM Cloud in a multi-zone or single-zone region.\n\nThe following tutorials demonstrate how to create an instance:\n\n\n\n*  Using the dashboard. For more information, see [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant).\n\n\n\nIf you want to create an IBM Cloudant Dedicated Hardware plan instance, follow the [Creating and leveraging an IBM Cloudant Dedicated Hardware plan instance on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloudcreating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud) tutorial.\n\n\n\n  What is an availability zone? \n\nWhen you create an instance, after you select the IBM Cloudant tile, you must select a region. These locations are called availability zones. An availability zone is an IBM Cloud\u00ae Public location that hosts your data. All Lite and Standard plans automatically deploy into a multi-zone region. Dedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/).\n\n\n\n\n\n  What is the difference between a single-zone and a multi-zone region? \n\nA multi-zone region includes three availability zones that can be used by an instance that is deployed to that region. The multi-zone regions available with IBM Cloudant include the following regions:\n\n\n\n*  Dallas\n*  Frankfurt\n*  London\n*  Osaka\n*  Sydney\n*  Tokyo\n*  Washington DC\n\n\n\nA single-zone region offers only one availability zone for that region. The single-zone regions available with IBM Cloudant include the following regions:\n\n\n\n*  Seoul\n*  Chennai\n\n\n\nFor more information, see [Plans and provisioning](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclocations-and-tenancy).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-availability-zones"},{"document_id":"ibmcld_07578-449817-451754","score":33.2372204297,"text":"\nFor more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n* Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant?\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n* Who do I contact if I have questions?\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n* Modeling data to scale FAQ\n\n Modeling data to scale FAQ \n\nThe way you model data on IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae significantly impacts how your application can scale. The underlying data model differs substantially from a relational model, and ignoring this distinction can be the cause of performance issues down the road.\n\nAs always, successful modeling involves achieving a balance between ease of use versus the performance characteristics you're hoping to achieve.\n\n(The FAQ for modeling data to scale is based on a blog article by Mike Rhodes, My top five tips for modeling your data to scale.)\n\n\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16487-4539-6619","score":29.0050866827,"text":"\nAs another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the .zip file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations. A human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance.\n\n\n\n\n\n UIMA CAS XMI files \n\nTo help train a model, you can upload documents that were pre-annotated by a UIMA analysis engine. The pre-annotated files must be in XMI serialization of UIMA Common Analysis Structure (UIMA CAS XMI) format and combined into a .zip file. For example, you can upload documents that were annotated in an IBM Watson Explorer collection.\n\nA human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance. For more information about how to create these files and requirements for uploading them, see [Uploading pre-annotated documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_uima).\n\n\n\n\n\n Anonymizing data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation"},{"document_id":"ibmcld_16468-3297-5708","score":28.4954522205,"text":"\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.\n* Dictionaries of terms that are to be treated as equivalent terms in your domain content.\n\n\n\n* Creating a corpus of documents that are representative of your domain content.\n* Pre-annotating documents based on the dictionaries that you add to a Knowledge Studio workspace. After you create a machine learning model, you can use the model to pre-annotate new documents that you add to the corpus. Pre-annotation is a process of machine-annotating a document to the extent possible before a machine learning model is available to do so. Pre-annotation can reduce human-annotation labor by replacing some human annotation creation with mere verification of the correctness of machine annotation.\n* Dividing documents among human annotators, who then use the IBM Watson\u00ae Knowledge Studio ground truth editor tool to manually add annotations to small sets of documents.\n* Comparing the human annotation results and resolving conflicts. Adjudication in this phase is needed to ensure accurate and consistently annotated documents are promoted to ground truth, where they can be used to train and test a machine learning model.\n\n\n\n\n\n\n\n Model development \n\nThis stage refers to the use of Knowledge Studio tools to create a model. After establishing ground truth, the human annotation results can be used to train an algorithm for automatically adding annotations to large collections of documents, such as collections that include millions of documents.\n\n\n\n\n\n Model evaluation \n\nThis stage refers to the use of Knowledge Studio tools to refine the model and improve performance. The results generated by the model are evaluated against a test set of ground truth documents. Accuracy analysis identifies the causes of annotation errors. Headroom analysis helps you assess which errors require focus and where model refinements can yield the greatest impact.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16423-4898-6946","score":28.3709332553,"text":"\nAn option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations. A human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance.\n\n\n\n\n\n UIMA CAS XMI files \n\nTo help train a model, you can upload documents that were pre-annotated by a UIMA analysis engine. The pre-annotated files must be in XMI serialization of UIMA Common Analysis Structure (UIMA CAS XMI) format and combined into a ZIP file. For example, you can upload documents that were annotated in an IBM Watson Explorer collection.\n\nA human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance. For details about how to create these files and requirements for uploading them, see [Uploading pre-annotated documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_uima).\n\n\n\n\n\n Anonymizing data \n\nIf you want to build a model that is optimized for your data, but do not want to upload the data as-is to Knowledge Studio for privacy reasons, you can strip the documents of any personally identifiable information (PII) first, and then use those anonymized documents to train the model. Do not redact the information or replace it wholesale with variables. For best results, replace the real information with fake information of the same type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_16451-1641-3812","score":28.1615745159,"text":"\nFor more information about which ratios to apply, see [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.\n\nThe document sets must contain at least 10 annotated documents.\n8. After the model is created, select one of the following actions:\n\nTable 1. Document options\n\n\n\n Option Description \n\n Log View the log file to see whether any problems occurred. \n Details View the annotation performance statistics, change the document sets that you want to use for training and testing the model, and create snapshot versions of the model artifacts. \n Export If you have a Standard plan or a Premium plan, you can export a ZIP file to your local system that contains the components that are required for the model to run in a machine learning runtime environment, such as Watson Explorer. \n\n\n\n\n\n\n\n\n\n\n\n Evaluating annotations added by the model \n\nYou can compare the ground truth view for annotations added by human annotators to the annotations added by the model.\n\n\n\n Procedures \n\nTo evaluate the annotations added by the model:\n\n\n\n1. Select Machine Learning Model > Performance > Train and evaluate. The Training\/Test\/Blind Sets page is displayed.\n2. Click View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16507-16696-18884","score":28.0463921126,"text":"\nA document that overlaps between a selected document set and an unselected document will appear pre-annotated in both document sets.\n\n\n\n\n\n\n\n\n\n Uploading pre-annotated documents \n\nYou can jump-start the training of your model by uploading documents that were pre-annotated through an Unstructured Information Management Architecture (UIMA) analysis engine.\n\nThe pre-annotated documents must be in the XMI serialization form of UIMA Common Analysis Structure (UIMA CAS XMI). The .zip file that you upload must include the UIMA TypeSystem descriptor file and a file that maps the UIMA types to entity types in your Knowledge Studio type system.\n\nUIMA CAS XMI is a standard format of Apache UIMA. Guidelines are provided for how to create files in the correct format from analyzed collections in IBM Watson Explorer. If you use another Apache UIMA implementation, adapt these guidelines for your purposes. Regardless of how you create the XMI files, the requirements for creating the type system mapping file and .zip file are the same for everyone.\n\nIf you assign the imported documents to human annotators, the documents appear pre-annotated in the ground truth editor and a number of mentions might already be annotated. The human annotator thus has more time to focus on applying the annotation guidelines to unmarked mentions. Alternatively, you can bypass the human annotation step and use the pre-annotated documents to immediately start training and evaluating a machine learning model.\n\n\n\n Exporting analyzed documents from Watson Explorer Content Analytics \n\nYou can export documents that were crawled and analyzed in IBM Watson Explorer Content Analytics, and upload the analyzed documents as XMI files into a Knowledge Studio workspace.\n\n\n\n Procedure \n\nTo get analyzed documents from a Watson Explorer Content Analytics collection, follow these steps:\n\n\n\n1. Open the Content Analytics administration console in a web browser.\n2. On the Collections view, expand the collection that you want to export documents from. In the Parse and Index pane, ensure that the parse and index process is running, and then click the arrow icon for Export analyzed document content and metadata.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16516-17782-19845","score":27.7637775002,"text":"\nAdded Performance page\n: Added a Performance page for model quality evaluation and guidance about how to improve quality.\n\n\n\n\n\n\n\n November 2017 \n\n\n\n Changes \n\nBug fixes\n: Fixed an issue where some relation annotations were missing in the downloaded corpus.\n: Fixed an issue where a model could not be withdrawn from deployment if its status was None.\n: Fixed an issue where the model could not be evaluated for Korean.\n\n\n\n\n\n\n\n October 2017 \n\n\n\n Changes \n\nExport issue fixed\n: Fixed the issue with the Export button not being enabled until you refreshed the browser window in the IBM Cloud [experimental](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks-faqsexperimental) release.\n\nButton label issue fixed\n: Fixed the button labels and tooltips to match the changes for the terms upload and download in the IBM Cloud [experimental](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks-faqsexperimental) release. These terms are used instead of import and export when referring to type systems, documents, and dictionaries.\n\nDescription delay issue fixed\n: Fixed the delay in updating the descriptions on the Knowledge Studio User Account Management page in the IBM Cloud [experimental](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks-faqsexperimental) release.\n\nUI changes to pre-annotation interface\n: In the pre-annotation section of the interface, made a couple GUI changes to clarify the functionality of the machine learning model, the rule-based model, the dictionary, and IBM\u00ae AlchemyLanguage. Changed the button label from Run to Pre-annotate, changed the title of the window from Run Annotator to Run Pre-annotation, and changed the error message to clarify that you can't add automated annotations after humans annotated the documents.\n\nDictionary-based tokenizer fix\n: For projects or workspaces that use dictionary-based tokenizers, fixed an issue that showed empty sentences if you imported documents without ground truth.\n\n\n\n\n\n\n\n September 2017","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_16524-1630-3793","score":27.7540646023,"text":"\nSee [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.\n\n> Note: The document sets must contain at least 10 annotated documents.\n8. After the model is created, select one of the following actions:\n\n\n\n\n\nDocument options\nEach row in this table describes one option for a choice.\n\n Option Description \n\n Log View the log file to see whether any problems occurred. \n Details View the annotation performance statistics, change the document sets that you want to use for training and testing the model, and create snapshot versions of the model artifacts. \n Export If you have a Standard plan or a Premium plan, you can export a ZIP file to your local system that contains the components that are required for the model to run in a machine learning runtime environment, such as Watson Explorer. \n\n\n\n\n\n\n\n\n\n Evaluating annotations added by the model \n\nYou can compare the ground truth view for annotations added by human annotators to the annotations added by the model.\n\n\n\n Procedure \n\nTo evaluate the annotations added by the model:\n\n\n\n1. Select Machine Learning Model > Performance > Train and evaluate. The Training\/Test\/Blind Sets page is displayed.\n2. Click View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_16451-3317-5174","score":27.5776901738,"text":"\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16524-3358-5215","score":27.5776901738,"text":"\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_16447-1597-3270","score":27.0607135365,"text":"\nIn large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Export models \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02143-0-1216","score":34.2687167578,"text":"\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondlite"},{"document_id":"ibmcld_07578-1076793-1078629","score":33.0085260651,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":33.0085260651,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05013-2864-3381","score":32.2713638832,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_16729-112397-114109","score":32.229964213,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-1091444-1093417","score":31.6318898282,"text":"\n* Can I move an org to another account?\n\nCurrently, you can't move an org to a different account. However, you can re-create the org with the same credentials in a different account to mimic this functionality. For more information, see [Adding orgs and spaces](https:\/\/cloud.ibm.com\/docs\/account?topic=account-orgsspacesuserscreateorg).\n* Why can't I create a Lite account?\n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n* How do I see who created a service instance and when?\n\nFrom the [Resource list](https:\/\/cloud.ibm.com\/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https:\/\/cloud.ibm.com\/docs\/account?topic=account-audit-log).\n* What are IBM Cloud Context-based restrictions?\n\nAs an account owner or administrator, you can define and enforce access restrictions for IBM Cloud\u00ae resources based on the network location of access requests by enabling context-based restrictions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1093930-1095903","score":31.6318898282,"text":"\n* Can I move an org to another account?\n\nCurrently, you can't move an org to a different account. However, you can re-create the org with the same credentials in a different account to mimic this functionality. For more information, see [Adding orgs and spaces](https:\/\/cloud.ibm.com\/docs\/account?topic=account-orgsspacesuserscreateorg).\n* Why can't I create a Lite account?\n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n* How do I see who created a service instance and when?\n\nFrom the [Resource list](https:\/\/cloud.ibm.com\/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https:\/\/cloud.ibm.com\/docs\/account?topic=account-audit-log).\n* What are IBM Cloud Context-based restrictions?\n\nAs an account owner or administrator, you can define and enforce access restrictions for IBM Cloud\u00ae resources based on the network location of access requests by enabling context-based restrictions.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12904-1535-3460","score":31.5227089933,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01660-7085-8964","score":31.4998218645,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00558-1499-3456","score":31.4697579471,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03709-0-1479","score":24.6230723345,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03704-7496-9340","score":23.8378324303,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1048947-1050776","score":23.8378324303,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1048818-1050647","score":23.8378324303,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03732-0-1673","score":23.5824463968,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03711-0-822","score":23.2228920635,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cant-create-service-feature-code"},{"document_id":"ibmcld_03699-7-2091","score":21.9319038728,"text":"\nApplying promo codes \n\nPromotions are limited-time credits toward your IBM Cloud\u00ae account and services that you can get by applying promo codes. Each promo code can be used one time and is valid only for a certain amount of time. Promo codes are provided on a limited basis by IBM Cloud sales to customers with billable accounts.\n\nPromo codes are typically based on short phrases, like PROMO200. If you have an alphanumeric code, such as a1b2c3def456, it's a different type of code that is referred to as a feature code. You can apply these codes on the Manage > Account > Account settings page or when you register for a new account. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\nPromotions are one type of credit for your account. For example, if you have a Pay-As-You-Go or Subscription account, you can use promo codes for limited-time credits toward your account and IBM Cloud products. Promo codes are different from feature codes that provide access to Trial accounts, or subscriptions that add credits as discounts to your account.\n\n\n\n Types of available promotion credits \n\nBoth one-time credit promotions and recurring dollar credit promotions are available for all IBM Cloud products.\n\n\n\n1. One-time credit promotion\n\n\n\n* Credit promotions can be used only one time, for a set time period, and you can't remove them after you apply them. Credit promotions use the following format: $X off for Y days.\n\n\n\n2. Recurring dollar credit promotion\n\n\n\n* Recurring dollar credits are offered for a set time period. For example, you can have a promotion of $100 USD value that is recurring every 30 days for 6 months. Recurring dollar credit promotions use the following format: $X every Y months, repeats Z times.\n* Promo credit expires at the end of the committed term. Any credit that isn't used doesn't roll over to the next term.\n\nWith a recurring credit, if the amount of credit that is allocated to a client is not used within the allocated time, the credit expires.\n\n\n\n\n\n\n\n\n\n Applying promo codes to your account","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes"},{"document_id":"ibmcld_03704-10459-12479","score":21.5090807292,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1051890-1053900","score":21.5090807292,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1051761-1053771","score":21.5090807292,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":23.4439194498,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":23.2370111195,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_01660-16615-18504","score":23.1844019249,"text":"\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/account\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_13429-166159-168045","score":22.8352192909,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_07642-0-563","score":22.3791160634,"text":"\n\n\n\n\n\n\n  AC-19 (5) - Full Device \/ Container-based Encryption \n\n\n\n  Control requirements \n\nAC-19 (5) - 0\n:   The organization employs [IBM Assignment: file level, full disk\/device, or both] to protect the confidentiality and integrity of information on [Assignment: organization-defined mobile devices].\n\n\n\n\n\n  NIST supplemental guidance \n\nContainer-based encryption provides a more fine-grained approach to the encryption of data\/information on mobile devices, including for example, encrypting selected data structures such as files, records, or fields.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-19.5"},{"document_id":"ibmcld_16727-1086316-1088349","score":22.2891978991,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1083825-1085863","score":22.2463062736,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14390-16273-17983","score":21.5595944301,"text":"\n* At the end of the documented process, your vCenter Server instance is running vSphere 7.0 Update 1c with N-VDS distributed switches. This configuration is different than the currently supported [Software BOM for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_bomvc_bom-software), which is vSphere 7.0 Update 3c with Distributed vSwitch 7.0.0.\n* For more information about the migration of N-VDS to VDS switches for vSphere 7.0 or later and NSX-T Data Center 3.0 and later, see [Migrate host switch to vSphere Distributed Switch](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-1039A36F-F55E-4A0A-B6C6-2C383F4A716D.html). Currently, this procedure is not verified on a VMware Solutions vCenter Server instance.\n* IBM Cloud is undertaking an assessment of the N-VDS to VDS conversion and the required changes to the automation database to allow this in-place upgrade.\n* Currently, Day 2 automation workflows such as add host or add cluster, are not tested against VMware Solutions vCenter Server instances that are upgraded from vSphere 6.7 to 7 and still using N-VDS distributed switches. Customers must assume that this automation might fail and that if this automation is required then the lift and shift migration approach used. If this automation is not needed, you can use the upgrade process that is documented.\n* A workaround for the add nodes and add cluster features is to use the VMware vSphere offering. For more information, see [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview). You must complete a number of manual tasks after the automated deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-v2t-migration"},{"document_id":"ibmcld_10852-44214-45420","score":21.1299445875,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_00959-2830-5215","score":20.8023803099,"text":"\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-7-2257","score":32.3268274836,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":32.3268274836,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":31.8374864116,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":31.8164351636,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":31.7671301602,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":31.7671301602,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":31.6592308049,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-8109-9900","score":31.3478091413,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":31.3478091413,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":30.9557815275,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.8318724637}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07191-7-2252","score":15.1124425759,"text":"\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07178-6197-7974","score":14.5871074713,"text":"\n[Example query structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/query_structure2.png)\n\nOperators that evaluate a field (<= , >=, <, >) require a number or date as the value. Using quotations around a value always makes it a string. Therefore score>=0.5 is a valid query and score>=\"0.5\" is not. See [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators) for a complete list of operators.\n\nConsiderations:\n\n\n\n* Not sure when to query on an entity, concept, or keyword? See [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).\n\n\n\nAfter you click Run query and open the JSON tab, query highlighting is turned on, by default. The setting adds a highlight field to your query results. Within the highlight field, the words that match your query are wrapped in HTML <em> (emphasis) tags. For more information, see the [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight).\n\n\n\n\n\n\n\n Building combined queries \n\nYou can combine query parameters together to build more targeted queries. For example, you can use the both the filter and query parameters together. For more information about filtering vs. querying, see [Differences between the filter and query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfiltervquery).\n\n\n\n\n\n How to structure an aggregation \n\nAggregations return a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see [Aggregations](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_02590-7911-9371","score":14.3903181211,"text":"\nTo prevent [dangerous client bugs and backward-compatibility hazards](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-robustnesssanitation-and-validation), unrecognized query parameters SHOULD and invalid parameter values MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Case insensitivity \n\nQuery parameter names SHOULD NOT be case-normalized to support case insensitivity; a parameter that does not match the case of a defined parameter but otherwise matches its name SHOULD be treated as any other extraneous input\n\n[4].\n\nHowever, parameter name case normalization MAY be supported for backward compatibility with existing clients.\n\n\n\n\n\n Parameter duplication \n\nRequests that provide a query string with duplicate single-value\n\n[5]query parameters of the same name and differing values[6] MUST result in a 400 status and appropriate error response model. For backward compatibility with existing clients, query strings containing duplicate query parameters of the same name and with the same value MAY be supported [7].\n\nIf a service supports parameter name [case insensitivity](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uriscase-insensitivity), parameter names MUST be normalized prior to validating uniqueness.\n\nSupport for array input in query parameters SHOULD use comma-separated values within a single parameter (for example, foo=1,2,3) instead of duplicated\n\n[8]parameters ( foo=1&foo=2&foo=3).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uris"},{"document_id":"ibmcld_07191-1691-3739","score":14.0825749949,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_13406-1732-4088","score":13.8411830855,"text":"\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_07098-7-2215","score":13.5761836371,"text":"\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataquery). For an overview of query concepts, see the [Query overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07067-26099-28206","score":13.3059144968,"text":"\nIf false, ranks the passages from all of the documents by passage quality regardless of the document quality and returns them in a separate passages field in the response.\n* When passages are returned for a query, you can also enable answer finding. When true, answer objects are returned as part of each passage in the query results. When find_answers and per_document are both set to true, the document search results and the passage search results within each document are reordered by using the answer confidences. The goal of this reordering is to place the best answer as the first answer of the first passage of the first document. Similarly, if the find_answers parameter is set to true and per_document parameter is set to false, then the passage search results are reordered in decreasing order of the highest confidence answer for each document and passage.\n* Both v1 and v2 support custom stop words. However, there are a few differences in how custom stop words are used:\n\n\n\n* There is no default custom stop words list for Japanese collections in v2.\n* When you define custom stop words in v1, your stop words list replaces the existing stop words list. In v2, your list augments the default list. You cannot replace the list, which means you cannot remove stop words that are part of the default list in v2.\n\n\n\n\n\n\n\n Update how your application handles query results \n\nThe way that your application shows query results might need to be updated due to the following differences between the query results document syntax between the v1 and v2 queries:\n\n\n\n* At the entity enrichment level, the following information is not supported in v2:\n\n\n\n* Disambiguation\n* Emotion\n* Sentiment\n\n\n\nThe Part of Speech enrichment is applied automatically to documents in most project types in v2, but the index fields that are generated by the enrichment are not displayed in the JSON representation of the document.\n\nZoom\n\n![Difference in entities data structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/compare-result-syntax.png)\n\nFigure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_13446-15041-17074","score":13.1504745286,"text":"\nAvailability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Generally available or beta for next-generation models that support low latency. For more information, see [Supported next-generation language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ngmodels-ng-supported). \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n max_alternatives \n\nAn optional integer that specifies the maximum number of alternative hypotheses that the service returns. By default, the service returns a single final hypothesis. For more information, see [Maximum alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metadatamax-alternatives).\n\n\n\nTable 17. The max_alternatives parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n model \n\nAn optional model that specifies the language in which the audio is spoken and the rate at which it was sampled: broadband\/multimedia or narrowband\/telephony. By default, en-US_BroadbandModel is used. For more information, see [Using a model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-use).\n\n\n\nTable 18. The model parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n processing_metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_03285-5746-7932","score":13.0260527174,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":13.0260527174,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3692678015}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09685-5899-7847","score":34.0885135117,"text":"\nFor more information, see [Collecting metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-about-collect-metrics).\n\n\n\n\n\n Sending metrics \n\nYou can send metrics via the public or the private endpoints by using the appropriate ingestion URL. Details can be found in the [endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints) section.\n\n\n\n\n\n Viewing metrics \n\nYou can monitor and manage metrics through the Monitoring Web UI. For more information, see [Viewing metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitoring).\n\nNotice that there is a delay showing metric data for new time series. Data is not ready until the initial indexing of a new metric source is completed. Therefore, new sources such as clusters, platform metrics, or systems that you configure, all take some time to become visible through the Monitoring UI.\n\n\n\n\n\n Sending notifications \n\nYou can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on.\n\nFor example, you can set up Monitoring to send alert notifications to IBM Cloud Event Notifications.\n\n\n\n* [Sending email notifications to IBM Cloud Event Notifications](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-tutorial)\n* [Sending SMS notifications to IBM Cloud Event Notifications](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-tutorial-en-sms)\n\n\n\nFor more information, see [Working with alerts and events](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts).\n\n\n\n\n\n Data location \n\nMetric data is hosted on the IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-about-monitor"},{"document_id":"ibmcld_14503-4971-7126","score":31.4767705309,"text":"\nThe client can also configure their compute VMs to uses these forwarders, if required.\n* VMware Update Manager (VUM) provides updating of vSphere hosts and VM hardware and tools. VUM uses the Proxy to gain access to the internet repositories.\n\n\n\nVMware Aria Operations collects data from objects in the environment. Each piece of data that is collected is called a metric observation or value. VMware Aria Operations uses the vCenter adapter to collect raw metrics from vCenter. In addition to the metrics it collects, VMware Aria Operations calculates capacity metrics, badge metrics, and metrics to monitor the health of your system. Alert definitions are a combination of symptoms and recommendations that identify problem areas and generate alerts on which you act for those areas.\n\n\n\n\n\n Monitored components \n\n\n\n Monitoring of vCenter \n\nThe monitoring of vCenter is accomplished with VMware Aria Operations and the VMware SDDC Health Management Pack. VMware Aria Operations for Logs collects the log data from vCenter and the Content Pack for vSphere adds specific understanding to the logs and in turn sends alerts to VMware Aria Operations.\n\nThe VMware SDDC Health Management Pack monitors the SDDC Management stack and provides badges for health and alerts related to configuration and compliance of SDDC product components that include vCenter.\n\n\n\n\n\n Monitoring of vSphere hosts \n\nMonitoring of the vSphere hosts is accomplished with VMware Aria Operations through vCenter and the collection of logs through VMware Aria Operations for Logs.\n\n\n\n\n\n Monitoring of vSAN \n\nTo monitor vSAN, VMware Aria Operations, and VMware Aria Operations for Logs are used. In vCenter, you can use an extra set of vSAN Health Checks. Installation of the Management Pack for vSAN provides more dashboards to aid with the monitoring of vSAN.\n\nVMware Aria Operations generates an alert if a problem occurs in the SDDC product components in the storage area network that the VMware vSAN adapter is monitoring. An alert that is related to configuration compliance and health is passed through VMware SDDC Health Solution management pack from VMware vSAN Management Pack.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-arch"},{"document_id":"ibmcld_09703-1640-3664","score":31.3160016689,"text":"\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts"},{"document_id":"ibmcld_09148-8939-9806","score":31.2591914103,"text":"\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"},{"document_id":"ibmcld_01044-0-937","score":31.0947063276,"text":"\n\n\n\n\n\n\n  Logging and monitoring \n\nMonitoring and logging is part of the service. However, it is not directly displayed to the user. Instead, the infrastructure is used by IBM operational staff to address issues.\n\nYou can connect with a Db2 command-line client, such as CLPPlus, to access detailed information and diagnostics.\n\n\n\n  A basic overview: \n\nThe following are two basic types of checking your system status:\n\n\n\n*  External health and uptime checks\n*  Metric-based monitoring\n\n\n\nIBM monitors hundreds of metrics and stores those metrics historically. Based on the values of these metrics, alerts are generated. These alerts are sent to IBM operations staff to ensure that the alerts are seen and addressed. In addition, IBM also sends archived operating system and diagnostic logs for rapid diagnosis. Db2 on Cloud complies with GDPR, and IBM EU Cloud options provide an even higher level of adherence to GDPR, if needed.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-log_mon"},{"document_id":"ibmcld_10246-2935-4501","score":30.7253730393,"text":"\nThe following metrics can be monitored for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\n\n\n* kubelet_volume_stats_available_bytes\n* kubelet_volume_stats_capacity_bytes\n* kubelet_volume_stats_inodes\n* kubelet_volume_stats_inodes_free\n* kubelet_volume_stats_inodes_used\n\n\n\nWant to set up storage monitoring alerts for platforms such as email or Slack? See [Sending notifications to external systems](https:\/\/docs.openshift.com\/container-platform\/4.10\/monitoring\/managing-alerts.htmlsending-notifications-to-external-systems_managing-alerts) in the Red Hat OpenShift documentation.\n\nBefore monitoring metrics for Block Storage for VPC, you must have a cluster with the Block Storage for VPC add-on enabled and you must have a Block Storage for VPC volume attached to a worker node. Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae Storage Metrics are populated only for mounted storage volumes.\n\n\n\n1. Navigate to the Red Hat OpenShift web console and select Monitoring and then Metrics.\n2. Input the metric you want to monitor in the dialog box and select Run queries.\n\nkubelet_volume_stats_used_bytes{persistentvolumeclaim=\"NAME OF PVC\"} \/ kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"NAME OF PVC\"}\n\nExample output\n\nendpoint instance job metrics_path namespace node persistentvolumeclaim prometheus service value\nhttps-metrics 11.111.1.1:XX kubelet \/metrics default 11.111.1.1 PVC-NAME openshift-monitoring\/k8s kubelet 0.003596851526321722\n\n\n\nFor more information, see [Monitoring](https:\/\/docs.openshift.com\/container-platform\/4.11\/monitoring\/monitoring-overview.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_09794-9435-11301","score":30.1480706664,"text":"\n[Panel options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/platform\/images\/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: This field is set to the metric that you have selected from the panel. Check that the metric and aggregation are the ones that you need.\n\nScope: This field is set to the scope that you have defined for the metric in the panel. Check that the scope is the one that you need.\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n\n\n Configuring an alert from the Alerts section \n\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working"},{"document_id":"ibmcld_09276-3243-4933","score":30.0068401455,"text":"\nSMS You can send an SMS to notify of an alert either through the PagerDuty channel or through the IBM Cloud Monitoring channel. For more information, see [Integrating with SMS](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-sms). \n Slack You can configure a slack channel. \n Webhook You can configure a web hook URL. \n PagerDuty You can configure connection details to your PagerDuty system, and select a service. Use this channel when you require call times and escalation management processes. For more information, see [Integrating with PagerDuty](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-pagerduty). \n IBM Cloud Monitoring You can configure a Monitoring instance. When you need alerts on log data alongside your system health metrics, configure a Monitoring notification channel. For more information, see [Integrating with IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-monitoring). \n\n\n\n\n\n\n\n Creating alerts \n\nYou can choose any of the following options to create an alert:\n\n\n\n* Create a preset and attach the preset to the view\n* Create a specific alert on a view.\n\n\n\nYou can configure alerts graphically through the Log Analysis UI, or programmatically.\n\n\n\n* For more information on how to configure an alert, see [Creating alerts through the UI](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-create_alert_ui).\n* For more information on how to create alerts programmatically, see [Managing views and alerts programmatically](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-config_api).\n\n\n\n\n\n\n\n Deleting alerts \n\nYou can delete alerts graphically through the Log Analysis UI, or programmatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts"},{"document_id":"ibmcld_09794-8223-9780","score":29.9695857052,"text":"\nTo save the scope, you must click Save at the panel level.\n\n\n\n\n\n\n\n Configuring an alert on a platform metric \n\n\n\n Configuring an alert from a panel \n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert. If you need multiple notification channels, check they are available.\n3. Navigate to the Dashboards section (![dashboard section](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/dashboards.png)) in the Web UI.\n4. Select a custom dashboard in the My Dashboards section.\n5. Select the panel for which you want to define the alert.\n\nBefore you create the alert, check the scope of the metric that is configured in the panel. This scope is automatically included in the alert definition.\n6. Click the Actions icon ![Three dots icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/actions.png) and select Create Alert.\n\nZoom\n\n![Panel options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/platform\/images\/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working"},{"document_id":"ibmcld_09700-7-1797","score":29.8811974128,"text":"\nConfiguring an alert by using the legacy alert editor \n\nIn the IBM Cloud Monitoring service, you can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on. [Learn more](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts).\n\nComplete the following steps to configure an alert:\n\n\n\n Step 1. Select the alert type \n\nFrom the Alert section of the UI, select Add Alert. Then, choose the alert type.\n\n\n\n\n\n Step 2. Name the alert \n\nEnter a name for the alert.\n\nYou can also add a description for the alert and the name of an alert group if you want to group you alerts. If an alert group is not specified, the alert will be created in the default group.\n\n\n\n\n\n Step 3. Define the severity \n\nAdd a severity level. Valid severity values are info, low, medium, and high.\n\n\n\n\n\n Step 4. Define the metric section \n\n\n\n1. Select a metric (entity) that you want to monitor.\n2. Define the alert condition. Choose any of the following options:\n\nOption 1: Choose a metric and a single condition such as average, sum, minimum or maximum.\n\nOption 2: Choose Create multi-condition alerts. Enter the condition, for example, min(min(cpu.used.percent)) < = 50 OR max(max(cpu.used.percent)) >= 80.\n\nZoom\n\n![Multi-condition alert](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/multi-condition-alerts.png)\n\nMulti-condition alert","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert-config"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03966-3327-5475","score":19.2643947339,"text":"\n* Org admins: When you join a consortium that is hosted by an ordering service, you provide the signing certificates of identities that will become the administrators for your organization. You can use these identities to create or edit channels.\n* Peer or orderer admins: IBM Blockchain Platform nodes are deployed with the signing certificates of component administrators identities inside of them. These certificates allow the admins to operate the component from a remote client or by using the console.\n* Applications: Your applications need to sign their transactions before submitting them to be validated by the network. You need to create identities you can use to sign transactions from your client applications.\n\n\n\nYou can use the console to create these identities by using the [registration process](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-register). After you register your admin identities, you need to issue each identity a signing certificate and private key, provide the signing certificate to your organization MSP definition, and add the identity to your console wallet. You can complete these steps for one admin identity when you [create your organization MSP](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizationsconsole-organizations-create-msp). You can use separate identities as org admins or node admins, or you can use one identity to do both tasks. The [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) uses one identity to be an admin for each organization created in the tutorial.\n\n\n\n\n\n Associating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_03893-74275-75877","score":18.8816114122,"text":"\nConfigure an HSM client image[See Build a Docker image](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-hsm-build-docker).\n3. Configure the node to use HSM. From the APIs or the console, when you deploy a peer, CA, or ordering node, you can select the advanced option to use an HSM. See [Configure the node to use the HSM](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-cfg-hsm-node).\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* The Kubernetes CLI is required to configure the HSM. If you are using a Kubernetes cluster on IBM Cloud see [Getting started with IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) or [Installing the OpenShift CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-cli).\n* You need access to a container registry, such as Docker or the [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-started).\n\n\n\n\n\n\n\n Build a Docker image \n\nConfigure HSM on your blockchain network by publishing an HSM client image to a container registry, as described below.\n\nBuild an HSM client image\n\nNext we build a Docker file that contains the HSM client image. These instructions assume that you have successfully configured your HSM appliance and HSM client. Use these steps to generate an image that is consumable by the IBM Blockchain Platform operator.\n\n\n\n* Step one: Modify the HSM client configuration.\n* Step two: Build the HSM client image.\n* Step three: Push the Docker image to your container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_16281-0-376","score":18.8440019239,"text":"\n\n\n\n\n\n\n  Integrating with a custom client app \n\nIBM Cloud\n\nIf the available integration channels do not meet your needs, you can build your own client application as the interface between the assistant and your customers.\n\nFor more information, see [Building a custom client using the API](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-custom-app"},{"document_id":"ibmcld_02998-8791-9815","score":18.5204775549,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03982-9793-12132","score":18.1160347429,"text":"\nBecause an MSP is the representation of an organization in the network, you select the MSP definition when you deploy your nodes (identifying the organization the node belongs to), are joined to the consortium (by an ordering service admin), create a channel, join a channel, edit a channel, or perform any action where you have to specify the organization that is performing the action.\n\n\n\n\n\n Downloading a connection profile \n\nAfter you create an organization MSP definition and create peers with that organization MSP definition, you can download a connection profile that can be used by a client application to connect to your network via one or more gateway peers. The gateway peers are the peers that are specified in the connection profile, and they are used to perform service discovery to find all of the endorsing peers in the network that will endorse transactions.\n\nClick the Organization MSP tile for the organization that your client application interacts with. Click Create connection profile to open a side panel where you can build and download your connection profile.\n\n![Create connection profile panel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/create-connx-profile.png)\n\nIf you plan to use the client application to register and enroll users with the organization CA, you need to include the Certificate Authority in the connection profile definition.\n\nSelect the peers to include in the connection profile definition. When a peer is not available to process requests from a client application, service discovery ensures that the request is automatically sent to a different peer. Therefore, to accommodate for peer downtime during a maintenance cycle for example, it is recommended that you select more than one peer for redundancy. In addition to peers created by using the console or APIs, imported peers that have been imported into the console are eligible to be selected as well.\n\nThe list of channels that the selected peers have joined is also provided for your information. If a channel is missing from the list, it is likely because the peer joined to it is currently unavailable.\n\nYou can then download the connection profile to your local file system and use it with your client application to generate certificates and invoke smart contracts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizations"},{"document_id":"ibmcld_05070-7-1814","score":17.8059749269,"text":"\nUsing Node.js \n\nThe IBM Cloud\u00ae Object Storage SDK for Node.js provides modern capabilities that make the most of IBM Cloud Object Storage.\n\n\n\n Installing the SDK \n\n[Node.js](https:\/\/cloud.ibm.com\/docs\/node?topic=node-getting-started) is an excellent way to build [web applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-mean-stack), and customize your instance of Object Storage for your end users. The preferred way to install the Object Storage SDK for Node.js is to use the [npm](https:\/\/www.npmjs.com) package manager for Node.js. Type the following command into a command line:\n\nnpm install ibm-cos-sdk\n\nTo download the SDK directly, the source code is hosted on [GitHub](https:\/\/github.com\/IBM\/ibm-cos-sdk-js).\n\nMore detail on individual methods and classes can be found in [the API documentation for the SDK](https:\/\/ibm.github.io\/ibm-cos-sdk-js\/).\n\n\n\n\n\n Getting Started \n\n\n\n Minimum requirements \n\nTo run the SDK, you need Node 4.x+.\n\n\n\n\n\n Creating a client and sourcing credentials \n\nTo connect to COS, a client is created and configured by providing credential information (API Key, Service Instance ID, and IBM Authentication Endpoint). These values can also be automatically sourced from a credentials file or from environment variables.\n\nAfter generating a [Service Credential](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials), the resulting JSON document can be saved to \/.bluemix\/cos_credentials. The SDK will automatically source credentials from this file unless other credentials are explicitly set during client creation. If the cos_credentials file contains HMAC keys the client authenticates with a signature, otherwise the client uses the provided API key to authenticate with a bearer token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_02680-7025-8620","score":17.7761153441,"text":"\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Integrate Kotlin to your Java project with these steps:\n\n\n\n* Add the Kotlin Gradle plug-in to the Module level build.gradle\n\ndependencies {\nclasspath \"com.android.tools.build:gradle:4.1.1\"\nclasspath \"org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version\"\n}\n* Add kotlin-android plugin to the App level build.gradle\n\nplugins {\nid 'com.android.application'\nid 'kotlin-android'\n}\n\n\n\n4. Initialize the SDK.\n\nAppConfiguration appConfiguration = AppConfiguration.getInstance();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_03916-19063-21128","score":17.7414177151,"text":"\nIf you manually built your organization MSP with certificates from an external CA, the connection profile will not include any information in the \"certificateAuthorities\": section.\n\n\n\n\n\n Service discovery \n\nService discovery allows your applications to dynamically find the peer and ordering endpoints of your network. If you do not use service discovery, you need to manually add the endpoint information of peer and ordering nodes on your channel to your connection profile or your application. You would need to edit your connection profile or update your application each time a node is added or removed from your network.\n\nBefore you can take advantage of the [Service Discovery](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/discovery-overview.html) feature of Hyperledger Fabric, you must configure anchor peers on the channel. Service discovery allows your application to learn which peers on the channel outside your organization need to endorse a transaction. Without service discovery, you will need to get the endpoint information of these peers out of band from other organizations and add them to your connection profile. For more information, see [Configuring anchor peers](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-governibp-console-govern-channels-anchor-peers).\n\nLater in this topic, we use the connection profile to build a Fabric gateway that is configured for [service discovery](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-sd-cfg).\n\n\n\n\n\n Enrolling by using the SDK \n\nOnce the network operator provides the enroll ID and secret of the application identity and the network connection profile, an application developer can use the Fabric SDKs or the Fabric CA client to generate client-side certificates. You can use the following steps to enroll an application identity by using the [Fabric SDK for Node.js](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/index.html).\n\n\n\n1. Save the connection profile to your local system and rename it connection.json.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_02998-7662-9256","score":17.4029079245,"text":"\n[An ending node was added to the dialog also.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs. Let's see how well it works.\n\n\n\n1. Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/try-it.png) icon to open the Try it out pane. There's that reassuring welcome message.\n2. In the text field, type Hello and press Enter. The output indicates that the General_Greetings intent was recognized, and the appropriate response (Good day to you.) is displayed.\n3. Try the following input:\n\n\n\n* bye\n* howdy\n* see ya\n* good morning\n* sayonara\n\n\n\n\n\nWatson can recognize your intents even when your input doesn't exactly match the examples that you included. The dialog uses intents to identify the purpose of the user's input regardless of the precise wording used, and then responds in the way you specify.\n\n\n\n\n\n Result of building a dialog \n\nThat's it. You created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03916-39203-41294","score":17.2546701315,"text":"\nSuccessfully enrolled client \"user1\" and imported it into the wallet\n\nYou can find the wallet that was created in the identity folder of the magnetocorp directory.\n\n\n\n\n\n Step four: Use the connection profile to build a Fabric gateway \n\nThe Hyperledger Fabric [Transaction Flow](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/txflow.html) spans multiple components, with the client applications playing a unique role. Your application needs to connect to the peers that need to endorse the transaction and needs to connect to the ordering service that will order the transaction and add it into a block. You can provide the endpoints of these nodes to your application by using your connection profile to construct a Fabric gateway. The gateway then conducts the low-level interactions with your Fabric network. To learn more, visit the [Fabric gateway](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/developapps\/gateway.html) topic in the Fabric documentation.\n\nYou have already downloaded your connection profile and used it to connect to your organization's Certificate Authority. Now we use the connection profile to build a gateway.\n\nOpen the file issue.js in a text editor. Before you edit the file, notice that it imports the FileSystemWallet and Gateway classes from fabric-network library.\n\nconst { FileSystemWallet, Gateway } = require('fabric-network')\n\nYou will need to import the path class to build the gateway from the connection profile you downloaded from your console. Add the following line to the file to import the path class:\n\nconst path = require('path');\n\nThe Gateway class is used to construct a gateway that you will use to submit your transaction.\n\nconst gateway = new Gateway()\n\nThe FileSystemWallet class is used to load the wallet you created in the previous step. Edit the following line if you changed the location of the wallet on your file system.\n\nconst wallet = new FileSystemWallet('..\/identity\/user\/isabella\/wallet');\n\nAfter you import your wallet, use the following code to pass your connection profile and wallet to the new gateway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3433743194}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14546-2844-4906","score":10.9866087516,"text":"\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.\n\n\n\n\n\n\n\n VMware Shared on-demand billing plan \n\nVMware Shared on-demand virtual data center resources are allocated as needed. Pricing is hourly based on the resource usage in the virtual data center. The following metrics are part of this plan.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 2. VMware Shared Solutions On-demand billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_BASE_COST Monthly Virtual data center price, which includes the edge gateway with five IP addresses. \n TOTAL_VCPU_HOURS Hourly The peak vCPU usage over the period of an hour. \n TOTAL_RAM_GB_HOURS Hourly The peak memory usage over the period of an hour. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of an hour. This value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_14546-4405-6573","score":10.9757607587,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_16007-6455-7960","score":10.8713327449,"text":"\nYou have limited control of what is generated.\n\nThe following sections describe these solutions in more detail.\n\nExample virtual server setup:\n\n\n\n* Two virtual servers (Virtual-server-1 and Virtual-server-2) where both virtual servers belong to the same VPC.\n* Each virtual server has two interfaces from two subnets:\n\n\n\n* Virtual-server-1 has interface eth0 from net_1_0, and interface eth1 from net_1_1.\n* Virtual-server-2 has interface eth0 from net_2_0, and interface eth1 from net_2_1.\n\n\n\n* Each virtual server's net__0 is set up with a default route.\n* Each subnet's gateway IP and CIDR are known.\n\nAlphabetic names are used here. The real gateway ID would be similar to 192.168.100.1, the CIDR 192.168.100.0\/24, and the IP address 192.168.100.6.\n\n\n\n\n\nTable 1. Example of a virtual server instance with multiple interfaces\n\n Subnet Gateway IP Subnet CIDR Interface IP \n\n net_1_0 gw_ip_1_0 cidr_1_0 ip_1_0 \n net_1_1 gw_ip_1_1 cidr_1_1 ip_1_1 \n net_2_0 gw_ip_2_0 cidr_2_0 ip_2_0 \n net_2_1 gw_ip_2_1 cidr_2_1 ip_2_1 \n\n\n\n\n\n Adding a static route for the second interface \n\nThis solution makes one subnet the default gateway (automatically by virtual server instance creation), and adds a static route for the second subnet:\n\n\n\n* On Virtual-server-1:\n\nip route add cidr_2_1 via gw_ip_1_1 dev eth1\n* On Virtual-server-2:\n\nip route add cidr_1_1 via gw_ip_2_1 dev eth1\n\n\n\n\n\n\n\n Adding a separate routing table for the second interface \n\n\n\n* On Virtual-server-1:\n\n\n\necho 201 eth1tab >> \/etc\/iproute2\/rt_tables","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-instance-vnics"},{"document_id":"ibmcld_07578-221033-223165","score":10.8517933863,"text":"\nIn some regions, dedicated hosts have a limitation on the number of virtual server instances that can be placed on them at one time. You can try to provision the cluster with a smaller number of virtual server instances to overcome this.\n* Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation?\n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffice from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a range of multiple IP addresses.\n* Does the Spectrum Symphony offering support multiple key pairs to establish SSH to all of the nodes?\n\nYes, the Spectrum Symphony offering supports multiple single key pairs that can be provided for access to all of the nodes that are part of the cluster. In addition, Spectrum Symphony has a feature where each node of the cluster can be accessed through passwordless SSH.\n* What storage types are available through this offering?\n\nIn the Spectrum Symphony offering, you can use Spectrum Scale scratch storage or persistent storage. A scratch storage configuration uses virtual server instances with instance storage. A persistent storage configuration uses bare metal servers with locally attached NVMe storage.\n* Which Linux operating system is supported for worker nodes?\n\nThe solution supports custom images based on RHEL 8.6 for virtual server instance worker nodes, and it supports the use of the stock RHEL 8.6 VPC images for bare metal worker nodes. At this time, custom images are not supported for use with VPC bare metal servers.\n* Can I use a custom resolver that is already associated with a VPC?\n\nYes, the solution supports the use of a custom resolver that is already associated to a VPC. If a VPC already has a custom resolver, the automation makes uses of it and the DNS service and associates the new DNS domain that is created from the solution for hostname resolution.\n* Can I associate a single VPC with multiple DNS zones that have the same name?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-221007-223139","score":10.8517933863,"text":"\nIn some regions, dedicated hosts have a limitation on the number of virtual server instances that can be placed on them at one time. You can try to provision the cluster with a smaller number of virtual server instances to overcome this.\n* Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation?\n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffice from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a range of multiple IP addresses.\n* Does the Spectrum Symphony offering support multiple key pairs to establish SSH to all of the nodes?\n\nYes, the Spectrum Symphony offering supports multiple single key pairs that can be provided for access to all of the nodes that are part of the cluster. In addition, Spectrum Symphony has a feature where each node of the cluster can be accessed through passwordless SSH.\n* What storage types are available through this offering?\n\nIn the Spectrum Symphony offering, you can use Spectrum Scale scratch storage or persistent storage. A scratch storage configuration uses virtual server instances with instance storage. A persistent storage configuration uses bare metal servers with locally attached NVMe storage.\n* Which Linux operating system is supported for worker nodes?\n\nThe solution supports custom images based on RHEL 8.6 for virtual server instance worker nodes, and it supports the use of the stock RHEL 8.6 VPC images for bare metal worker nodes. At this time, custom images are not supported for use with VPC bare metal servers.\n* Can I use a custom resolver that is already associated with a VPC?\n\nYes, the solution supports the use of a custom resolver that is already associated to a VPC. If a VPC already has a custom resolver, the automation makes uses of it and the DNS service and associates the new DNS domain that is created from the solution for hostname resolution.\n* Can I associate a single VPC with multiple DNS zones that have the same name?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11622-24554-26341","score":10.1783763981,"text":"\nansible-playbook --connection=local -i \"localhost,\" powervs-rhel.yml -e @ filesystem_creation_variables\n* For SLES\n\nansible-playbook --connection=local -i \"localhost,\" powervs-sles.yml -e @ filesystem_creation_variables\n\n\n\n\n\nAfter successful execution, file systems that are required for HANA installations are available.\n\n\n\n\n\n Preparing for SAP installation \n\nPreparation for SAP installation is needed for SAP HANA and SAP NetWeaver and not required on Power Systems Virtual Server instance for SAP shared file systems.\n\n\n\n Using saptune on SLES for SAP \n\nUse the saptune tool to apply recommended operating system settings for SAP HANA or SAP NetWeaver on SUSE Linux\u00ae Enterprise Server. On IBM Power Systems Virtual Servers, the same SUSE Linux\u00ae Enterprise Server image is used for SAP NetWeaver and SAP HANA.\n\nThe following workflow shows how you can use the saptune tool to apply the SAP solution to your server. For more information about saptune, see [SAP Note 1275776 - Linux: Preparing SLES for SAP environments](https:\/\/launchpad.support.sap.com\/\/notes\/1275776).\n\n\n\n1. Verify that the package status is current.\n\nzypper info saptune\n2. Verify that the saptune version is at least 3.\n\nsaptune version\n3. List all available solutions. Numbered entries represent integrated SAP Notes for each of the solutions.\n\nsaptune solution list\n4. Get an overview of saptune options.\n\nsaptune --help\n5. Enable and start the saptune.service. This command also disables sapconf and tunes, which isn't used since saptune version 3.\n\nsaptune service takeover\n6. Simulate the changes before you apply them. (optional)\n\nFor SAP HANA:\n\nsaptune solution simulate HANA\n\nFor SAP NetWeaver:\n\nsaptune solution simulate NETWEAVER\n7. Apply the saptune solution.\n\nFor SAP HANA:\n\nsaptune solution apply HANA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-power-vs-set-up-power-instances"},{"document_id":"ibmcld_12769-1676-2596","score":10.0927328554,"text":"\nSecurity scenario: Customers want granular control over traffic at an instance level (apart from network-level firewalls). However, at the same time, the costs of a shared hardware firewall can add up quickly if you need to protect multiple servers in different data centers.\n\nSolution: You do not incur extra charges for using security groups. You can use security groups for all virtual servers that need protection in any of our global data centers.\n\n\n\n\n\n Globally scalable and easily manageable firewall \n\nSecurity scenario: You want to avoid configuring firewall rules on each server separately. Instead, you want an easily manageable firewall solution that spans servers in different global data centers.\n\nSolution: Define N security groups for N different types of servers in your cloud workload. Manage all rules for a security group in one place. Manage the security group associations with the virtual servers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-groups?topic=security-groups-getting-started"},{"document_id":"ibmcld_11581-45443-46511","score":9.9244030956,"text":"\nch1-140x7000 IBM Power Virtual Server <br><br> * [OLAP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2373)<br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2455)<br><br><br> \n mh1-8x1440 IBM Power Virtual Server <br><br> * [OLAP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2404)<br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2444)<br><br><br> \n mh1-10x1800 IBM Power Virtual Server <br><br> * [OLAP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2405)<br><br><br> \n mh1-25x4500 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2447)<br><br><br> \n mh1-50x9000 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2448)<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-faq-profile-specs"},{"document_id":"ibmcld_11581-44697-45723","score":9.8786790939,"text":"\nbh1-140x14000 IBM Power Virtual Server <br><br> * [OLAP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2387)<br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2453)<br><br><br> \n ch1-60x3000 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2445)<br> * [OLAP Scale-Out Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2357)<br><br><br> \n ch1-100x5000 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2454)<br><br><br> \n ch1-140x7000 IBM Power Virtual Server <br><br> * [OLAP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2373)<br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2455)<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-faq-profile-specs"},{"document_id":"ibmcld_11581-46176-47132","score":9.8688908711,"text":"\nmh1-25x4500 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2447)<br><br><br> \n mh1-50x9000 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2448)<br><br><br> \n mh1-80x14400 IBM Power Virtual Server <br><br> * [OLAP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2403)<br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2450)<br><br><br> \n mh1-125x22500 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2540)<br><br><br> \n umh-4x960 IBM Power Virtual Server <br><br> * [OLTP Record](https:\/\/www.sap.com\/dmc\/exp\/2014-09-02-hana-hardware\/enEN\/\/solutions?filters=iaas&id=s:2385)<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-faq-profile-specs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00033-7-2292","score":59.4490261747,"text":"\nFAQs \n\n\n\n What is IBM Analytics Engine serverless? \n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n\n\n\n\n\n What are the advantages of IBM Analytics Engine serverless instances? \n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n\n\n Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop? \n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n\n\n\n\n\n Can I change the instance home storage of a serverless instance? \n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n\n\n\n\n\n How is user management and access control managed in a serverless instance? \n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n\n\n\n\n\n How do I define the size of the cluster to run my Spark application? \n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"},{"document_id":"ibmcld_07578-107943-110247","score":59.2142723411,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-107922-110226","score":59.2142723411,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00042-4304-6393","score":58.708390782,"text":"\nFor details on how to use the log_forwarding_config API, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n\n\n 13 May 2022 \n\nSupport for Python 3.9\n: You can now run Spark applications using Python 3.9. on your IBM Analytics Engine serverless instances.\n\n\n\n\n\n 04 April 2022 \n\nLimitation on how long Spark applications can run\n: Spark applications can run for a maximum period of 3 days (72 hours). Any applications that run beyond this period will be auto-cleaned in order to adhere to the security and compliance patch management processes for applications in Analytics Engine.\n\n\n\n\n\n 30 March 2022 \n\nStart using the Analytics Engine serverless CLI\n: Use this tutorial to help you get started quickly and simply with provisioning an Analytics Engine serverless instance, and submitting and monitoring Spark applications. See [Create service instances and submit applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli).\n\n\n\n\n\n 9 September 2021 \n\nIntroducing IBM Analytics Engine Standard serverless plan for Apache Spark\n: The IBM Analytics Engine Standard serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nNew: The IBM Analytics Engine Standard serverless plan for Apache Spark is now GA in the Dallas IBM Cloud service region.\n: This plan offers a new consumption model using Apache Spark whereby resources are allocated and consumed only when Spark workloads are running.\n\nCapabilities available in the IBM Analytics Engine Standard serverless plan for Apache Spark include:\n\n\n\n* Running Spark batch and streaming applications\n* Creating and working with Jupyter kernels for interactive use cases\n* Running Spark batch applications through an Apache Livy like interface\n* Customizing instance with your own libraries\n* Autoscaling Spark workloads\n* Aggregating logs of your Spark workloads to the Log Analysis server","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes"},{"document_id":"ibmcld_00042-5803-6591","score":55.5320547931,"text":"\n: This plan offers a new consumption model using Apache Spark whereby resources are allocated and consumed only when Spark workloads are running.\n\nCapabilities available in the IBM Analytics Engine Standard serverless plan for Apache Spark include:\n\n\n\n* Running Spark batch and streaming applications\n* Creating and working with Jupyter kernels for interactive use cases\n* Running Spark batch applications through an Apache Livy like interface\n* Customizing instance with your own libraries\n* Autoscaling Spark workloads\n* Aggregating logs of your Spark workloads to the Log Analysis server\n\n\n\nTo get started using the serverless plan, see [Getting started using serverless IBM Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes"},{"document_id":"ibmcld_00007-7-2159","score":53.135927385,"text":"\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00033-3440-5507","score":52.4018656962,"text":"\nCurrently, you can monitor Spark applications in the following ways:\n\n\n\n* By tracking the state of the Spark application. For details, see [Getting the state of a submitted application](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-apispark-app-status).\n* By viewing the Spark history events that are forwarded to the IBM Cloud Object Storage instance that you specified as instance home. You can download these events and view them in the Spark history server UI installed on your desktop. At a later stage, you will be able to launch Spark history server UI from within the IBM Analytics Engine service instance details UI page.\n\n\n\n\n\n\n\n How do I set up autoscaling policies for my serverless instance? \n\nYou can enable autoscaling for all applications at instance level at the time you create an instance of the Analytics Engine Standard serverless plan for Apache Spark or per application at the time you submit the application. For details, see [Enabling application autoscaling](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-appl-auto-scaling).\n\n\n\n\n\n Can I connect to a serverless instance with the Apache Livy API? \n\nYes, the IBM Analytics Engine Standard serverless plan for Apache Spark provides an API interface similar to Livy batch API. For details, see [Livy API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-livy-api).\n\n\n\n\n\n Where can I find the logs for my Spark applications? \n\nYou can aggregate the logs from your Spark applications to Log Analysis. For details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n How can I track actions performed by users on a serverless Spark instance? \n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"},{"document_id":"ibmcld_07578-111385-113433","score":52.4018656962,"text":"\nCurrently, you can monitor Spark applications in the following ways:\n\n\n\n* By tracking the state of the Spark application. For details, see [Getting the state of a submitted application](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-apispark-app-status).\n* By viewing the Spark history events that are forwarded to the IBM Cloud Object Storage instance that you specified as instance home. You can download these events and view them in the Spark history server UI installed on your desktop. At a later stage, you will be able to launch Spark history server UI from within the IBM Analytics Engine service instance details UI page.\n\n\n\n* How do I set up autoscaling policies for my serverless instance?\n\nYou can enable autoscaling for all applications at instance level at the time you create an instance of the Analytics Engine Standard serverless plan for Apache Spark or per application at the time you submit the application. For details, see [Enabling application autoscaling](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-appl-auto-scaling).\n* Can I connect to a serverless instance with the Apache Livy API?\n\nYes, the IBM Analytics Engine Standard serverless plan for Apache Spark provides an API interface similar to Livy batch API. For details, see [Livy API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-livy-api).\n* Where can I find the logs for my Spark applications?\n\nYou can aggregate the logs from your Spark applications to Log Analysis. For details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-111364-113412","score":52.4018656962,"text":"\nCurrently, you can monitor Spark applications in the following ways:\n\n\n\n* By tracking the state of the Spark application. For details, see [Getting the state of a submitted application](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-apispark-app-status).\n* By viewing the Spark history events that are forwarded to the IBM Cloud Object Storage instance that you specified as instance home. You can download these events and view them in the Spark history server UI installed on your desktop. At a later stage, you will be able to launch Spark history server UI from within the IBM Analytics Engine service instance details UI page.\n\n\n\n* How do I set up autoscaling policies for my serverless instance?\n\nYou can enable autoscaling for all applications at instance level at the time you create an instance of the Analytics Engine Standard serverless plan for Apache Spark or per application at the time you submit the application. For details, see [Enabling application autoscaling](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-appl-auto-scaling).\n* Can I connect to a serverless instance with the Apache Livy API?\n\nYes, the IBM Analytics Engine Standard serverless plan for Apache Spark provides an API interface similar to Livy batch API. For details, see [Livy API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-livy-api).\n* Where can I find the logs for my Spark applications?\n\nYou can aggregate the logs from your Spark applications to Log Analysis. For details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00064-7-2200","score":51.6363420626,"text":"\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":29.8500100656,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":27.5699817071,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":24.0330873963,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-35313-36062","score":20.2212606136,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":19.6342236961,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-1603-3385","score":19.5118381651,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-2946-5057","score":19.5118381651,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04111-34153-35639","score":18.529220488,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_16286-1338-3308","score":18.0657647324,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_04170-7-2189","score":17.9435401698,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02734-7-2170","score":34.8743797718,"text":"\nAnonymous authentication \n\nWith IBM Cloud\u00ae App ID, you can allow users to anonymously browse your application under an anonymous user profile. If the user chooses to sign in, you can allow them to still access their anonymous attributes by attaching their anonymous profile to their user identity with App ID.\n\n\n\n Understanding progressive authentication \n\nWhen a user chooses not to sign in immediately, they are considered an anonymous user. For example, say you're an online retailer and you want to allow users to add objects to their shopping cart without signing in. However, you ask them to sign in to complete their purchase. If a user chooses to sign in, you can allow them to access the same objects that were in their shopping carts before they signed in.\n\nYou can use App ID to gather information about anonymous users into an anonymous user profile, which you can use to help personalize their experience of your application. If the user chooses to signs in, you can attach the user attributes that are part of the anonymous profile to their user identity that is stored in App ID. Anonymous profiles are temporarily valid. While you develop your app, you can [configure the lifetime](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpidp-token-lifetime) of anonymous tokens.\n\nWhen a user signs in, they become an identified user. If an existing identified user profile does not exist, you can create a new identified user profile. After a user is identified, App ID issues new access and identity tokens and their anonymous token becomes invalid. However, an identified user can still access the attributes of their anonymous profile because they are accessible with the new access and identity tokens.\n\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_16304-7-2130","score":32.7806010607,"text":"\nDynamic options \n\nAn options response presents customers with a list of choices to select from. You can use the dynamic setting to generate the list from options that might be different each time.\n\nDynamic options are generated based on the data stored in a variable, which must be available to the step asking the question. The source variable must contain an array of values, each of which represents one of the options that will be presented to the customer. The items in the array can be simple values such as strings or numbers (for example, [ \"Raleigh\", \"Boston\", \"New York\" ]) or compound JSON objects.\n\nA common scenario for dynamic options is when an array is returned from an external API that you call using a custom extension. For example, you might use a custom extension to retrieve a list of credit cards associated with a customer's account. You can then use dynamic options to ask the customer which card to use during the conversation. (For more information about custom extensions, see [Calling a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extension).)\n\nYour actions might also populate the source variable using expressions. For example, you might use a session variable to build a shopping cart containing items the customer has decided to purchase. An action for removing an item from the cart could then use dynamic options to show the items in the cart so the customer can select which one to remove. (For more information about using expressions for variable values, see [Using an expression to assign a value to a session variable](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expressionsexpression-variable).)\n\n\n\n Defining dynamic options \n\nTo define a dynamic options customer response:\n\n\n\n1. In a step, click Define customer response.\n2. Choose the Options response type.\n3. Click the Dynamic toggle.\n4. In the Source variable field, choose the variable that contains the array that defines the dynamic options (for example, the variable containing the response from a custom extension that you called in a previous step).\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dynamic-options"},{"document_id":"ibmcld_02734-1732-3794","score":26.9564259841,"text":"\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.\n\nIf the user chooses to sign in from the first tab, then they have access only to the t-shirt they added to their cart before they signed in. In this case, App ID attaches only the attributes of the anonymous profile on the first tab to the user's identity. The service does not merge the anonymous profile that is created on the second tab to the user's identity stored in App ID. But the user can still access the shorts anonymously on the second tab because they are still accessible with the anonymous profile that was created on the second tab. While you develop your app, you can configure how to attach anonymous attributes to identified user profiles.\n\n\n\n What does the progressive authentication flow look like? \n\nIn the following image, you can see the direction of communication that defines the progressive authentication flow between the user, your application, App ID, and the identity provider.\n\nZoom\n\n![The path to becoming an identified user when they start as anonymous](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/auth-anon-user.svg)\n\nFigure 1. Progressive authentication flow of anonymous user\n\n\n\n1. The user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_12890-5431-6703","score":26.9366134352,"text":"\nNow consider whether they would even notice when it takes a few seconds for a database update to propagate throughout the application.\n\nAvailability trumps consistency more than you might expect. Online shopping cart systems, HTTP caches, and DNS are a few more examples. Organizations must consider the cost of downtime such as user frustration, productivity loss, and missed opportunities.\n\n\n\n\n\n From theory to implementation \n\nAddressing high availability is vital for cloud applications. Otherwise, global database consistency stays a major bottleneck as you scale. Highly available applications need to maintain constant contact with their data, even if that data isn't up to date. That's the concept of eventual consistency, and it's nothing to be scared of. Sometimes, with a large scale, it's better to serve answers that aren't perfectly correct than to not serve them at all.\n\nDatabase systems hide the complexities of availability versus consistency in different ways, but they always exist. IBM Cloudant, CouchDB, and other NoSQL database teams believe that the best policy requires developers to address these complexities early in the design process. By doing the hard work up front, you reduce surprises because applications are ready to scale from day one.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-cap-theorem"},{"document_id":"ibmcld_04105-5067-6335","score":24.0508125657,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_16261-12076-14011","score":22.3329992618,"text":"\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input\/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_10169-11782-14185","score":22.315175713,"text":"\nFor example they provide a free appetizer at the chef's restaurant and an extra incentive to buy the ingredients for the demonstrated meal (for example, $20 off $150 cart).\n\nThe solution is made up of the following primary components.\n\n\n\n1. INVENTORY ANALYSIS: the in-store events (recipes, ingredient lists, and product locations) are tailored to market the slow-moving inventory.\n2. LOYALTY MOBILE APP provides targeted marketing with digital coupons, shopping lists, product inventory (prices, availability) on a store map, and social sharing.\n3. SOCIAL MEDIA ANALYTICS provides personalization by detecting customers\u2019 preferences in terms of trends: cuisines, chefs, and ingredients. The analytics connect regional trends with an individual\u2019s Twitter, Pinterest, and Instagram activity.\n4. DEVELOPER-FRIENDLY TOOLS accelerate roll-out of features and bug fixes.\n\n\n\nBack-end inventory systems for product inventory, store replenishment, and product forecasting have a wealth of information, but modern analytics can unlock new insights about how to better move high-end products. By using a combination of IBM Cloudant and IBM Streaming Analytics, the CMO can find the sweet spot of ingredients to match to custom in-store events.\n\nIBM\u00ae Event Streams for IBM Cloud\u00ae acts as the just-in-time events platform to bring in the rapidly changing information from the inventory systems to IBM Streaming Analytics.\n\nSocial media analytics with Watson Discovery (personality and tone insights) also feed in trends to the inventory analysis to improve product forecasting.\n\nThe loyalty mobile app provides detailed personalization information, especially when customers use its social sharing features, such as posting recipes.\n\nIn addition to the mobile app, the Developers are busy with building and maintaining the existing loyalty app that\u2019s tied to traditional checkout coupons. In short, they need to focus on coding instead of managing the infrastructure. Thus, they chose Red Hat OpenShift on IBM Cloud because IBM simplifies infrastructure management.\n\n\n\n* Managing Kubernetes master, IaaS, and operational components, such as Ingress and storage\n* Monitoring health and recovery for worker nodes\n* Providing global compute, so Developers aren't responsible for infrastructure setup in data centers\n\n\n\nCompute, storage, and event management that run in public cloud with access to back-end ERP systems","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_retail"},{"document_id":"ibmcld_16471-161976-164079","score":22.278614469,"text":"\nLikewise, the GetEnd function returns the end offset of its input span.\n\nThe following example illustrates the use of the GetBegin and GetEnd function.\n\ncreate view PersonOffsets as\nselect GetBegin(P.name) as offsetBegin, GetEnd(P.name) as offsetEnd\nfrom Person P;\n\nFor both of these functions, if the argument is null, the function returns null.\n\n\n\n\n\n GetLanguage \n\nThe GetLanguage function takes a single span argument and returns the two-letter language code of the source text of the span. If the argument is null, the function returns null.\n\nThis statement produces meaningful results only if the data source is tagging text fields with the appropriate languages.\n\n\n\n\n\n GetLemma \n\nThe GetLemma function takes a single Span or Text object as an argument and returns a string that contains the lemmatized form of the input span. If the argument is null, the function returns null. With dictionary entries for lemma match, this function can determine the lemmatized form of various tokens as returned by the tokenizer. For example, for the span went shopping GetLemma returns the lemma string go shop.\n\nThe results of this function follow these rules:\n\n\n\n* If the input span starts at the beginning of a token and ends at the end of a token, the result contains the sequence of lemmas that begins with the lemma of the first token, followed by a white space, followed by the lemma of the second token, followed by a white space, and so on (for example, dog cat fish bird ...). If the lemma for a token consists of white spaces, escape the white space by using the backslash character ( \\ ).\n* If the input span starts or ends with white space (for example, it starts between two tokens or ends between two tokens), the function ignores the beginning and trailing white space.\n* If the input span starts in the middle of a token or ends in the middle of a token, then the output consists of the following content, in this order, and separated by a white space:\n\n\n\n* The surface form of the first partial token if it exists.\n* The sequence of lemmas that correspond to the first to last complete tokens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_09898-29905-32638","score":21.4465182286,"text":"\nscience physics nanotechnology \n science physics optics \n science physics space and astronomy \n science physics thermodynamics \n science physics \n science social science anthropology \n science social science history ancient history \n science social science history archaeology \n science social science history genealogy \n science social science history heraldry \n science social science history medieval history \n science social science history modern history \n science social science history prehistory \n science social science history \n science social science linguistics translation \n science social science linguistics \n science social science pedagogy \n science social science philosophy ethics \n science social science philosophy \n science social science sociology \n science social science \n science weather meteorological disaster flood \n science weather meteorological disaster hurricane \n science weather meteorological disaster tornado \n science weather meteorological disaster \n science weather \n science \n shopping auctions \n shopping classifieds \n shopping gifts flowers \n shopping gifts greeting cards \n shopping gifts party supplies \n shopping gifts \n shopping resources comparisons engines \n shopping resources consumer protection \n shopping resources contests and freebies \n shopping resources coupons \n shopping resources loyalty programs \n shopping resources product reviews \n shopping resources warranties and service contracts \n shopping retail department stores \n shopping retail online stores \n shopping retail outlet stores \n shopping retail second-hand market \n shopping retail wholesalers \n shopping retail \n shopping toys action figures \n shopping toys dolls \n shopping toys puppets \n shopping toys stuffed animals \n shopping toys \n shopping \n society crime drug trafficking \n society crime organized crime \n society crime personal offense assault \n society crime personal offense hate crime \n society crime personal offense homicide \n society crime personal offense human trafficking \n society crime personal offense kidnapping \n society crime personal offense torture \n society crime property crime arson \n society crime property crime bribery \n society crime property crime burglary \n society crime property crime embezzlement \n society crime property crime fraud \n society crime property crime larceny \n society crime property crime piracy \n society crime property crime robbery \n society crime property crime smuggling \n society crime property crime usury \n society crime sexual offense pedophilia \n society crime sexual offense prostitution \n society crime sexual offense rape \n society crime sexual offense \n society crime \n society dating \n society gay life \n society racism \n society senior living","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy-v1"},{"document_id":"ibmcld_12890-3573-6000","score":20.6003772748,"text":"\nAs a result, some responses might include old data while the new data propagates through the system.\n\n\n\n\n\n Changing the approach \n\nMaintaining one consistent view of data is logical and easy to understand because a relational database does this work for you. The expectation is that web-based services that interact with database systems behave in this way. But that expectation doesn't mean that they do work this way. Consistency isn't a given, and it takes a little work to change the approach.\n\nIn fact, consistency isn't necessarily essential for many enterprise cloud services. Large, heavily used systems bring with them a high probability that a portion of the system might fail. A database that is engineered around the need to prioritize availability and eventual consistency is better suited to keeping your application online. The consistency of application data can be addressed after the fact.\n\n\n\n\n\n Application availability versus consistency in the enterprise \n\nA look at popular web-based services shows that people already expect high availability, and happily trade this availability for eventually consistent data, often without realizing they're doing so.\n\nMany applications mislead users for the sake of availability. Consider ATMs: inconsistent banking data is why it's still possible to overdraft money without realizing it. It's unrealistic to present a consistent view of your account balance throughout the entire banking system if every node in the network must halt and record this figure before operations continue. A better choice is to make the system highly available.\n\nThe banking industry figured it out back in the 1980s, but many IT organizations are still worried about sacrificing consistency for the sake of availability. Think about the number of support calls placed when your sales team can't access their CRM app. Now consider whether they would even notice when it takes a few seconds for a database update to propagate throughout the application.\n\nAvailability trumps consistency more than you might expect. Online shopping cart systems, HTTP caches, and DNS are a few more examples. Organizations must consider the cost of downtime such as user frustration, productivity loss, and missed opportunities.\n\n\n\n\n\n From theory to implementation \n\nAddressing high availability is vital for cloud applications. Otherwise, global database consistency stays a major bottleneck as you scale.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-cap-theorem"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16365-12876-14604","score":47.1038415493,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16295-7-1721","score":46.3926903158,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":44.8988579577,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":43.6748837046,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_03166-6034-7833","score":43.6537711944,"text":"\nYou add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n\n\n\n\n\n\n\n Deploy your assistant in production \n\n\n\n1. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n2. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-7-2072","score":43.5548479832,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-4-1877","score":43.4948467456,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16384-7-2422","score":43.0483627079,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03421-1518-3290","score":41.3881362402,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03422-13387-15045","score":41.1923308306,"text":"\nconnect-src *.watsonplatform.net *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watsonplatform.net .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements, such as <script> and <style> tags, to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'nonce- ';connect-src *.watsonplatform.net *.watson.appdomain.cloud\"\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03471-7-1807","score":25.7130780505,"text":"\nIBM Cloud services that generate events that are managed through Activity Tracker hosted event search \n\nList of IBM Cloud\u00ae services that generate auditing events in an IBM Cloud account that you can only manage through Activity Tracker hosted event search instances.\n\nActivity Tracker hosted event search routes location-based auditing events to an Activity Tracker hosted event search instance in the region where they are generated and routes global auditing events to the Activity Tracker instance that is provisioned in Frankfurt. Some exceptions may apply, see [IBM Cloud services that generate Activity Tracker events by location](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-cloud_services_locations).\n\n\n\n Analytics services \n\nThe following table lists analytics services that send auditing events:\n\n\n\nTable 1. List of analytics services\n\n Service CRN service name Events \n\n [IBM\u00ae Analytics Engine](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-getting-started) ibmanalyticsengine [Location-based events](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless) \n [IBM Cloud\u00ae Data Engine](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewoverview) sql-query [Location-based events](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-activitytrackeractivitytracker) \n [Watson Query](https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-getting-started) data-virtualization [Location-based events](https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-activity-tracker) \n\n\n\n\n\n\n\n Compute serverless services \n\nThe following table lists serverless compute services that send auditing events:\n\n\n\nTable 2. List of serverless compute services\n\n Service CRN service name Events","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-cloud_services_other"},{"document_id":"ibmcld_02377-4304-6397","score":23.2175891041,"text":"\nIn addition, consider the following information:\n\n\n\n* You must have the manager role to configure archiving in the IBM Cloud Activity Tracker instance. This role includes the logdna.dashboard.manage IAM action role that allows a user to perform admin tasks such as configure archiving.\n* When you configure archiving, the Activity Tracker instance and the IBM Cloud Object Storage (COS) instance must be provisioned in the same account.\n* The credential that Activity Tracker uses to write data into a COS bucket must have writer role.\n\n\n\n\n\n\n\n Monitor archiving \n\nTo monitor archiving, you can use the following services:\n\n\n\n* IBM Cloud Monitoring service:\n\nIBM Cloud Object Storage is integrated with the Monitoring service. Monitoring provides a default template that you can customize to monitor the bucket that you configure to store data for long term.\n\nFor more information, see [Monitoring archiving by using IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving-monitor).\n* IBM Cloud Activity Tracker:\n\nArchiving generates Activity Tracker events with the action logdnaat.archiving.send to notify of failures sending data to Event Streams. There are different reasons for failure such as invalid credentials and topic deleted.\n\nFor more information, see [Configuring an alert to monitor archiving](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving-at-monitor).\n\n\n\n\n\n\n\n Viewing archived events by using the SQL Query service \n\nData Engine provides a serverless, no-ETL solution to easily query data stored in COS. [Learn more](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview).\n\nYou can use this service to analyze data from archived files in COS.\n\nOnce you have SQL Query running on IBM Cloud, you can immediately start querying your data using the SQL Query user interface, programmatically by using either the REST API or the Python ibmcloudsql library, or write a serverless function by using Cloud Functions.\n\nWhen you query events:\n\n\n\n* You must provision an instance of the Data Engine service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving-ov"},{"document_id":"ibmcld_00033-4979-5757","score":23.0096675471,"text":"\nFor details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n How can I track actions performed by users on a serverless Spark instance? \n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"},{"document_id":"ibmcld_02400-2954-4354","score":22.354399415,"text":"\n[Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Location-based events](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-at-eventsbm-at-events) \n\n\n\n\n\n\n\n Compute serverless services \n\nThe following table lists serverless compute services that send auditing events:\n\n\n\nTable 3. List of serverless compute services\n\n Service CRN service name Activity Tracker hosted event search offering Events \n\n [IBM Cloud\u00ae Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) functions ![Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Location-based events](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-at_events) \n [IBM Cloud\u00ae Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started) codeengine ![Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Location-based events](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-at_events) \n\n\n\n\n\n\n\n Container services \n\nThe following table lists container platform services that send auditing events:\n\n\n\nTable 4. Container events\n\n Service CRN service name Activity Tracker hosted event search offering Events","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-cloud_services"},{"document_id":"ibmcld_02400-1969-3370","score":22.1799266377,"text":"\n[Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Location-based events](https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-activity-tracker) \n\n\n\n\n\n\n\n Classic services \n\nThe following table lists services that send auditing events:\n\n\n\nTable 2. List of classic services\n\n Service CRN service name Activity Tracker hosted event search offering Events \n\n [IBM Cloud\u00ae Virtual Servers (Classic)](https:\/\/cloud.ibm.com\/docs\/vsi?topic=virtual-servers-about-virtual-serversabout-virtual-servers) audit-log ![Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Location-based events](https:\/\/cloud.ibm.com\/docs\/vsi?topic=virtual-servers-at_eventsat_events) \n [IBM Cloud\u00ae Bare Metal Servers (Classic)](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-about-bmabout-bm) audit-log ![Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Location-based events](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-at-eventsbm-at-events) \n\n\n\n\n\n\n\n Compute serverless services \n\nThe following table lists serverless compute services that send auditing events:\n\n\n\nTable 3. List of serverless compute services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-cloud_services"},{"document_id":"ibmcld_03470-7-1746","score":21.6323435924,"text":"\nIBM Cloud services that generate events that are managed through Activity Tracker Event Routing \n\nList of IBM Cloud\u00ae services that generate auditing events that you can manage through IBM Cloud Activity Tracker Event Routing.\n\nActivity Tracker Event Routing routes events based on the location that is specified in the logSourceCRN field included in the event. You can define a target, the resource where events are routed to, in any Activity Tracker Event Routing supported region. However, the target resource can be located in any region where that type of target is supported, in the same account or in a different account. You can define rules to determine where auditing events are to be routed by configuring 1 or more routes in the account. You can define rules for managing global events and location-based events that are generated in regions where Activity Tracker Event Routing is supported.\n\n\n\n Classic services \n\nThe following table lists services that send auditing events:\n\n\n\nTable 1. List of classic services\n\n Service CRN service name Events \n\n [IBM Cloud\u00ae Virtual Servers (Classic)](https:\/\/cloud.ibm.com\/docs\/vsi?topic=virtual-servers-about-virtual-serversabout-virtual-servers) audit-log [Location-based events](https:\/\/cloud.ibm.com\/docs\/vsi?topic=virtual-servers-at_eventsat_events) \n [IBM Cloud\u00ae Bare Metal Servers (Classic)](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-about-bmabout-bm) audit-log [Location-based events](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-at-eventsbm-at-events) \n\n\n\n\n\n\n\n Compute serverless services \n\nThe following table lists serverless compute services that send auditing events:\n\n\n\nTable 2. List of serverless compute services\n\n Service CRN service name Events","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-cloud_services_atracker&interface=cli"},{"document_id":"ibmcld_02418-1762-3039","score":21.5943426551,"text":"\n[Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Classic services \n\nAmericas\n\nAsia Pacific\n\nEurope\n\n\n\nTable 3. Compute infrastructure services integration in Americas locations\n\n Service Dallas (us-south) Washington (us-east) Toronto (ca-tor) Sao Paulo (br-sao) \n\n IBM Cloud\u00ae Virtual Servers ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) \n IBM Cloud\u00ae Bare Metal Servers ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Compute serverless services \n\nAmericas\n\nAsia Pacific\n\nEurope\n\n\n\nTable 4. Compute serverless services integration in Americas locations\n\n Service Dallas (us-south) Washington (us-east) Toronto (ca-tor) Sao Paulo (br-sao) \n\n Cloud Functions !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-cloud_services_locations"},{"document_id":"ibmcld_02497-9519-10919","score":21.0902009075,"text":"\n* Users are responsible for downloading files to EU-supported locations.\n\n\n\nTo learn how to configure archiving for your auditing instance, see [Archiving logs](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-archiving).\n\n\n\n\n\n Step 8. Querying archived events with SQL Query service \n\nData Engine provides a serverless, no-ETL solution to easily query data stored in COS. [Learn more](https:\/\/cloud.ibm.com\/docs\/services\/sql-query?topic=sql-query-overview).\n\nYou can use this service to analyze data from archived files in COS.\n\nOnce you have SQL Query running on IBM Cloud, you can immediately start querying your data using the SQL Query user interface, programmatically by using either the REST API or the Python ibmcloudsql library, or write a serverless function by using Cloud Functions.\n\nWhen you query events, consider the following information:\n\n\n\n* You must provision an instance of the Data Engine service in Frankfurt.\n* You must restrict user access to work with that instance. Users need the platform viewer role to launch the UI, and the service writer role to run queries.\n* When you open the UI, the Data Engine service automatically generates a unique COS bucket that will store all of the results as CSV files from your SQL queries. To make sure that you are using an EU-supported bucket, create one. You can specify your custom bucket to store results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-manage_eu_acc"},{"document_id":"ibmcld_02522-1317-3277","score":20.7788790992,"text":"\nUse the Data Engine user interface (UI) to develop and test your queries, and the [SQL Query REST API](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlqueryrestapi) to automate them.\n\nThe Data Engine service provides a serverless, no-ETL solution to easily query data stored in Object Storage. Underneath, SQL Query uses Apache Spark SQL as its underlying query engine.\n\nYou can use the Data Engine to run SQL queries (that is, SELECT statements) to analyze, transform structured and semi-structured data, or clean up rectangular data. You cannot run actions such as CREATE, DELETE, INSERT, and UPDATE.\n\nThe Data Engine service can process input data that is read from CSV, JSON, ORC, Parquet, or AVRO files. The archive files from an IBM Cloud Activity Tracker instance contain data in JSON format.\n\nEach query result can be written to a CSV, JSON, ORC, PARQUET, or AVRO file in a Object Storage instance of your choice.\n\nWhen you query an IBM Cloud Activity Tracker archive file, you must convert the JSON formatted file into PARQUET format to be able to query the contents successfully.\n\n\n\n Prerequisites \n\nTo be able to use the Data Engine service to query archived event files, check the following prerequites:\n\n\n\n* You must have access to a COS instance in your account.\n\nYou must have access to a bucket that contains the IBM Cloud Activity Tracker archive files and a bucket to use to store results from your queries.\n* You must have an IBM Cloud Activity Tracker instance provisioned in your account that has [archiving configured to a bucket in the COS instance in your account](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-archiving).\n\nEvents are archived daily to a file in a COS bucket.\n\nNotice that if archiving is not configured, you must wait at least 24 hours before an archive file is available after archiving is configured.\n* You must have 1 or more archive files uploaded in the bucket.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_03471-1366-2755","score":20.6352905757,"text":"\n[Watson Query](https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-getting-started) data-virtualization [Location-based events](https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-activity-tracker) \n\n\n\n\n\n\n\n Compute serverless services \n\nThe following table lists serverless compute services that send auditing events:\n\n\n\nTable 2. List of serverless compute services\n\n Service CRN service name Events \n\n [IBM Cloud\u00ae Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) functions [Location-based events](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-at_events) \n\n\n\n\n\n\n\n Database services \n\nThe following table lists database services that send auditing events:\n\n\n\nTable 3. List of database services\n\n Service CRN service name Events \n\n [IBM Cloud\u00ae Databases for EnterpriseDB](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-getting-started) databases-for-enterprisedb-group [Location-based events](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-activity-tracker) \n [IBM Cloud\u00ae Databases for DataStax](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started) databases-for-cassandra-group [Location-based events](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-activity-tracker)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-cloud_services_other"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-14455-16070","score":31.6745921071,"text":"\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.\n\nFor more information about how user identity information is specified and how it is used, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\n\n\n\n\n Security and administration \n\nSecuring the web chat\n: To secure the web chat, you can use JSON Web Token (JWT) to authenticate users and encrypt private data. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\nControlling the web chat version\n: The web chat code hosted by IBM Cloud is regularly updated with improvements and new features. By default, the embed script automatically uses the latest version of the web chat. To avoid unexpected changes that might affect your website, you might want to control which version of the web chat your website uses, giving you an opportunity to test each new version before you deploy in in production., in order to avoid unexpected changes when a new version is released.\n\nFor more information about web chat versioning, see [Controlling the web chat version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16368-13121-14853","score":29.8778205031,"text":"\n[development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial showing how to render a custom response type as a replacement for the default options response, see [Tutorial: implementing custom option buttons in the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-custom-buttons).\n\nImplementing a contact center integration\n: You can use one of the web chat starter kits to integrate with a contact center (service desk) platform other than the ones available in as built-in Watson Assistant integrations. Fully functional reference implementations are available for several contact center platforms; in addition, you can use a starter kit to develop a custom integration with the platform of your choice.\n\nFor more information, see [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa).\n\n\n\n\n\n Managing data \n\nManaging user identity information\n: The web chat associates a user ID with each message it sends to the assistant; this user ID is used for user-based billing and other purposes. You can either allow the web chat to generate an anonymous ID for each user, or you can control the user ID yourself.\n\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03080-5624-7473","score":29.081506388,"text":"\nFor more information about how to customize it, see [HTML content](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhtml).\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-set-context)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16365-15662-16934","score":29.0117819041,"text":"\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03421-5573-7330","score":28.8218068947,"text":"\nFor more information about the home screen, see [Adding a home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen). For more information about how to customize it, see [HTML content](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhtml)\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_02855-13982-15842","score":28.6996299535,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16385-1806-3819","score":28.6359371398,"text":"\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nWith web chat security enabled, you can optionally implement additional security measures as needed:\n\n\n\n* You can use JWTs to securely [authenticate customers](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-authenticate) by user ID, which makes it possible for your assistant to control access to functions that require authorization.\n\nWithout web chat security enabled, each customer who uses your assistant is identified only by the user_id property that is part of the message request. This is sufficient for identifying unique users for billing purposes, but it is not secure, because it could be modified.\n\nBy encoding user identity information as part of the JWT payload, you can authenticate users securely. The JWT is signed and cannot be modified by the user.\n\nFor more information about using JWTs for secure authentication, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-authenticate).\n* You can [prevent unauthorized access](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt) to sensitive customer information by encrypting it and including it as part of the JWT user payload.\n\nThe user payload is a part of the JWT you can use to send information you want your assistant to have access to, but that you do not want customers to see. This information is stored only in private variables, which cannot be seen by customers and are never included in logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_16382-7-1870","score":28.4435150242,"text":"\nManaging user identity information \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nIf you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\nIf you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration. Choose a non-human-identifiable ID. For example, do not use a person's email address as the user ID.\n\nIn addition, the ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. (For more information about deleting user data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecuring-gdpr-wa).)\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nTo support these user-based capabilities, add the [updateUserID() method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIf you enable security, you set the user ID in the JSON Web Token instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid"},{"document_id":"ibmcld_16386-7-2009","score":28.4250522492,"text":"\nAuthenticating users \n\nWith web chat security enabled, you can securely authenticate customers by user ID.\n\nThe default behavior of the web chat integration is to identify unique users by setting the value of the user_id property that is sent as part of each message to the assistant. (For more information, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).)\n\nThis approach is sufficient for tracking unique users for billing purposes, but it is not secure and should not be used for access control. If you enable web chat security, you can use JSON Web Tokens (JWTs) to securely authenticate your users and control access to functions of your assistant that require authorization.\n\n\n\n Authenticating with the sub claim \n\nTo use this method for authenticating users, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nWhen you create a JWT for the web chat, you must specify a value for the sub (subject) claim, which identifies the user. (For anonymous users, you can use a generated unique ID.)\n\nWhen you generate a user ID for an anonymous user, be sure to save the generated ID in a cookie to prevent being billed multiple times for the same customer.\n\nWhen the web chat integration receives a message signed with this JWT, it stores the user ID from the sub claim as context.global.system.user_id. For user-based plans, this user ID is used for billing purposes. (You cannot use the updateUserID() instance method to set the user ID if web chat security is enabled.) The same user ID is also used as the customer ID, which can be used to make requests to delete user data. Because the customer ID is sent in a header field, the ID you specify must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-authenticate"},{"document_id":"ibmcld_16368-7-2072","score":27.9994607405,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00436-0-941","score":17.5069552431,"text":"\n\n\n\n\n\n\n  Updating CDN configuration details \n\nAfter your CDN is running, you can update CDN configuration details. Follow these steps.\n\n\n\n1.  On the CDN page, select your CDN, which takes you to the Overview page.\n2.  Select the Settings tab. Your CDN configuration details are displayed.\n\nYou only see SSL Certificate if your CDN was configured with HTTPS.\n\nFor Server, the following fields can be changed:\n\n\n\n*  Host header\n*  Origin server address\n*  HTTP\/HTTPS Port\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\nFor Object Storage, the following fields can be changed:\n\n\n\n*  Host header\n*  Endpoint\n*  Bucket name\n*  HTTPS Port\n*  Allowed file extensions\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\n3.  Update the Origin or Other Options details if needed, then click the Save button in the lower right corner to update your CDN configuration details.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-updating-cdn-configuration-details"},{"document_id":"ibmcld_15263-5634-7460","score":16.8406301629,"text":"\nibmcloud is instance-delete $vsi\n\nThe status of the instance changes to deleting immediately, but it still appears in a list query result. The deletion of an instance can take up to 30 minutes.\n\nYou can request other subnet resources to be deleted in parallel while you wait for the instance to be deleted. However, the subnet cannot be deleted until the instance and all other resources in the subnet no longer appear in the list query results.\n\nIf a secondary network interface exists in the subnet you are trying to delete, you must delete the instance. A network interface cannot be deleted from the instance without deleting the instance.\n\n\n\n\n\n Delete the subnet \n\nAfter all the resources inside the subnet were deleted, which means that they are not returned in a list query result, run the following command to delete the subnet:\n\nibmcloud is subnet-delete $subnet\n\nThe status of the subnet changes to deleting immediately, but it might take a few minutes until the subnet is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Step 3: Delete all public gateways in the VPC, if any \n\nTo list all public gateways in your account, run the following command:\n\nibmcloud is public-gateways\n\nFor each public gateway in the VPC you want to delete, run the following command to delete the public gateway, where $gateway is the public gateway ID.\n\nibmcloud is public-gateway-delete $gateway\n\n\n\n\n\n Step 4: Delete the VPC \n\nAfter all subnets and public gateways in the VPC are deleted, run the following command to delete the VPC, where $vpc is the ID of the VPC you are deleting.\n\nibmcloud is vpc-delete $vpc\n\nThe status of the VPC changes to deleting immediately, but it might take a few minutes until the VPC is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Deleting a VPC by using the REST APIs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-vpc-resources"},{"document_id":"ibmcld_16666-11924-13606","score":16.8092820105,"text":"\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_16670-5968-7639","score":16.541720509,"text":"\nYou must link the Db2 and Netezza databases to the Presto engine that is used to process the data.\n\nTo associate Db2 with the Presto engine, do the following steps:\n\n\n\n1. From the Infrastructure manager, select Db2 database. Click the overflow menu icon at the end of the row and click Associate.\n2. In the Associate with engine form, select the Presto engine that you want to use to process the data.\n3. Click Associate and restart engine. The Db2 database is associated with the Presto engine.\n\n\n\nSimilarly, select the Netezza database and link it to the Presto engine.\n\n\n\n\n\n Step 6: Combine data \n\nYou can also navigate to the Query workspace to create SQL queries to query your data.\n\nTo run the SQL query to join two tables, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to join the details from Db2 and Netezza:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"Db2\".\"default\".\"order_detail\" AS details\nLEFT JOIN \"Netezza\".\"gosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_join_data"},{"document_id":"ibmcld_02522-7188-8827","score":16.3801773553,"text":"\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1. In the IBM Cloud dashboard, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/icons\/icon_hamburger.svg) > Resource list > Storage.\n2. Select the Data Engine instance that has the bucket with the archive files.\n\nContact your IBM Cloud Activity Tracker administrator to get the COS information.\n3. Select Buckets.\n4. Select the bucket name. You can see the list of archive files in the bucket.\n5. Identify the file that you want to query.\n\nNotice that the file name has the name of your IBM Cloud Activity Tracker instance and the date, in UTC format, of the events that are included.\n\nIf you get a file of 20 bytes, that file does not have any data.\n6. For that file, select SQL URL.\n\nA window opens that shows the URL.\n7. Copy the URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_02547-1335-2984","score":16.3654034205,"text":"\nSelect Everything to see all the events, or a view.\n\n\n\nYou can view events through the view that you have selected.\n\n\n\n\n\n View a subset of the events by applying a search query \n\nYou can select the events that are displayed through a view by applying a search query. You can save that view for reuse later. [Learn more](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-viewsviews_step2).\n\n\n\n\n\n View a subset of the events by applying a timeframe \n\nYou can select the events that are displayed through a view by applying a timeframe.\n\nYou can apply a timestamp by specifying an absolute time, a relative time, or a time range.\n\nComplete the following steps to jump to a specific time:\n\n\n\n1. [Go to the web UI](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-launchlaunch).\n2. Click the Views icon ![Views icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/views.png).\n3. Select Everything or a view.\n4. Enter a time query. Choose any of the following options:\n\n\n\n* Enter an abosute time to jump to a point in time in your events such as May 20 7:00pm.\n* Enter a relative time such as 2 days ago, today at 12am, or an hour ago.\n* Enter a time range such as yesterday 10am to yesterday 11am, last fri 4:30pm to 11\/12 1 AM, last wed 4:30pm to 23\/05 1 AM, or May 20 10am to May 22 10am. Make sure to include to to separate the initial timestamp from the end timestamp.\n\n\n\n5. Press ENTER.\n\nYou might get the error message: Your request is taking longer than expected, try refreshing your browser in a bit as we try to catch up. Retry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-view_events"},{"document_id":"ibmcld_09437-7403-8993","score":15.9613296656,"text":"\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/icons\/icon_hamburger.svg) > Resource list > Services.\n3. Select an Data Engine instance.\n4. From the Manage tab, select Launch Data Engine UI.\n\n\n\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1. In the IBM Cloud dashboard, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/icons\/icon_hamburger.svg) > Resource list > Storage.\n2. Select the Data Engine instance that has the bucket with the archive files.\n\nContact your Log Analysis administrator to get the COS information.\n3. Select Buckets.\n4. Select the bucket name. You can see the list of archive files in the bucket.\n5. Identify the file that you want to query.\n\nNotice that the file name has the ID of your Log Analysis instance and the date, in UTC format.\n6. For that file, copy the Object Data Engine URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-sqlquery"},{"document_id":"ibmcld_02522-8519-10234","score":15.90664444,"text":"\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format \n\nWhen you query an archive file, the format of the data is JSON. You must transform the format to PARQUET to query successfully the data.\n\nParquet is an open source file format that stores nested data structures into a flat columnar format, and preserves the schema of the original data.\n\nThe Data Engine UI is an editor that lets you immediately start composing SQL queries. Since SQL Query uses Spark SQL, you can use Spark SQL functions and ANSI SQL to compose both simple and complex queries that involve large amounts of data.\n\nComplete the following steps to run the query to transform content from JSON into PARQUET:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT * FROM cleancols(SQL_URL STORED AS JSON)\nINTO RESULTS_BUCKET STORED AS PARQUET\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n* Use [cleancols](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference) to avoid transformation problems into PARQUET format when the name of the columns include special characters or blanks.\n\n\n\nFor example, the following query is used to transform an archive file:\n\nSELECT * FROM cleancols(cos:\/\/ams03\/at-eu-de\/999999d8f1f.2019-06-03.62.json.gz STORED AS JSON)\nINTO cos:\/\/eu-de\/results-at STORED AS PARQUET\n2. Click Run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_02522-5994-7615","score":15.6108729168,"text":"\nChoose any of the following actions to manage IAM policies in the IBM Cloud:\n\n\n\n* To grant permissions to a user, see [Assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesassign-new-access).\n* To revoke permissions, see [Removing access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesremoving-access-console)).\n* To review a user's permissions, see [Reviewing your assigned access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesreview-your-access-console).\n\n\n\n\n\n\n\n Step 3. Running a query through the Data Engine UI \n\nIn SQL, the term query is just another way of saying SELECT statement.\n\nTo run a query, complete the following steps:\n\n\n\n Step 3.1. Launch the Data Engine query UI \n\n\n\n1. [Log in to your IBM Cloud account](https:\/\/cloud.ibm.com\/login).\n\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/icons\/icon_hamburger.svg) > Resource list > Services.\n3. Select an Data Engine instance.\n4. From the Manage tab, select Launch Data Engine UI.\n\n\n\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_16671-4467-6313","score":15.5575683821,"text":"\nWhen you register your own bucket, ensure to provide the correct details for bucket configuration. Quick start wizard does not validate the bucket configuration details and you cannot modify them later.\n\nEnsure that the data bucket contains data.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select Apache Iceberg.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the engine type and size.\n\nDepending on the workload that you have, you can select the type and size of the Presto engine.\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nYou can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to. For more information about creating engines, catalogs, buckets, databases, see Configuring watsonx.data components in the How To section.\n\n--------------------\n\n\n\n\n\n Step 4: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select the catalog. In this scenario, consider the Apache Iceberg catalog, default schema, order_detail table, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_prov_custbckt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":13.5587813814,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":13.5222727171,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02665-1570-3896","score":13.2960261822,"text":"\nStandard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n\n\n\n\n What are the charges to use App Configuration? \n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service. For example, an entity might be an instance of an app that runs on a mobile device, a microservice that runs on the cloud, or a component of infrastructure that runs that microservice. For any entity to interact with App Configuration, it must provide a unique entity ID. This task is most easily accomplished by programming your app or microservice to send the Entity ID by using the App Configuration SDK.\n\nAPI Call - An API call is the invocation of the App Configuration through a programmable interface.\n\nExactly what constitutes an API call varies depending on the entity type (for example, a microservice or a mobile app). For server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_10817-6582-8092","score":11.953177263,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12330-7-2140","score":11.5533142919,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_10817-4371-5701","score":11.5385235916,"text":"\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.\n\n\n\n\n\n Invoke a mobile SDK action \n\nTo invoke a remote action, you can call invokeAction with the action name. Use a dictionary to pass parameters to the action as needed.\n\nExample\n\n\/\/ In this example, we are invoking an action to print a message to the IBM Cloud Functions Console\nvar params = Dictionary<String, String>()\nparams[\"payload\"] = \"Hi from mobile\"\ndo {\ntry whisk.invokeAction(name: \"helloConsole\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: false, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nprint(\"Action invoked!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\nShow more\n\n\n\n\n\n Fire a mobile SDK trigger \n\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7707-9426","score":11.4458615103,"text":"\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate\nlet session = NSURLSession(configuration: NSURLSessionConfiguration.defaultSessionConfiguration(), delegate: NetworkUtilsDelegate(), delegateQueue:NSOperationQueue.mainQueue())\n\/\/ set the SDK to use this urlSession instead of the default shared one\nwhisk.urlSession = session\n\n\n\n Support for qualified names with mobile SDK \n\nAll actions and triggers have a fully qualified name that is made up of a namespace, a package, and an action or trigger name. The SDK can accept these elements as parameters when you are invoking an action or Firing a trigger. The SDK also provides a function that accepts a fully qualified name that looks like \/mynamespace\/mypackage\/nameOfActionOrTrigger. The qualified name string supports unnamed default values for namespaces and packages that all Cloud Functions users have, so the following parsing rules apply:\n\n\n\n* qName = \"foo\" results in namespace = default, package = default, action\/trrigger = \"foo\"\n* qName = \"mypackage\/foo\" results in namespace = default, package = mypackage, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/foo\" results in namespace = mynamespace, package = default, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/mypackage\/foo\" results in namespace = mynamespace, package = mypackage, action\/trigger = \"foo\"\n\n\n\nAll other combinations issue a WhiskError.QualifiedName error.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-45155-46272","score":11.1633862362,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02674-7-1766","score":10.9608960945,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_10852-44214-45420","score":10.194870669,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11652-3001-4951","score":14.5240124355,"text":"\nWithin the Public Subnet, the [SAP router](https:\/\/support.sap.com\/en\/tools\/connectivity-tools\/saprouter.html) and the jump host provide secure connections to the virtual server instances. The SAP router is a software application that provides a remote connection between the customer's network and SAP. The SAP Router and jump host are within a single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional SAP products and analytics solutions and offerings that are acquired from Sybase. For a comprehensive list of which SAP Business Analytics products benefits from SAP router connections, see [SAP Note 1478974](https:\/\/launchpad.support.sap.com\/\/notes\/1478974).\n\nA jump host is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their premises. These SAP virtual server instances can be in a separate security zone but must be on same IBM Cloud region. The customer connection to the jump host follows the same rules as the direct connection from customer premises to the virtual server instance SAP instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. This architecture uses two defined security groups; this arrangement is the simplest method for separating the public and private subnets. You can add more security groups if you require more isolation.\n\n\n\n\n\n Virtual server instances on SAP NetWeaver 7.x APAB stack, JAVA stack, and dual stack (ABAP+JAVA) architectural design on IBM Cloud\u00ae VPC on Unix \n\n\n\n Standard system \n\nIn a standard system, all main instances run on a single virtual server instance within a private subnet. For more information, see [About virtual server instances for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers). The virtual server instance has these components:\n\nZoom\n\n![Figure 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-refarch-nw-db2"},{"document_id":"ibmcld_11654-3229-5138","score":14.257621637,"text":"\nThe SAP Router and jumphost are within a single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional SAP products and analytics solutions and offerings that are acquired from MS SQL Server database. For a comprehensive list of which SAP Business Analytics products benefits from SAP router connections, see [SAP Note 1478974](https:\/\/launchpad.support.sap.com\/\/notes\/1478974).\n\nA jumphost is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their premises. These SAP virtual server instances can be in a separate security zone but should be on same IBM Cloud region. The customer connection to the jumphost follows the same rules as the direct connection from customer premises to the virtual server instance SAP instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. In this architecture, there are two security groups defined; this arrangement is the simplest method for separating the public and private subnets. You can add more security groups if you require more isolation.\n\n\n\n\n\n Virtual server instances on SAP NetWeaver 7.x APAB stack, JAVA stack, and dual stack (ABAP+JAVA) stack on Windows Servers with MS SQL Server DB \n\n\n\n Standard system \n\nIn a standard system, all main instances run on a single virtual server instance within a private subnet. For more information, see [about virtual servers for VPC](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic-vsi?topic=vpc-on-classic-vsi-virtual-private-cloud). The virtual server instance has these components:\n\nZoom\n\n![Figure 2. Standard installation](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/images\/refarch-sap-mssql-std-only.svg)\n\nFigure 2. SAP NetWeaver 7.x MS SQL Server standard installation with AAS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-refarch-nw-mssql"},{"document_id":"ibmcld_14389-1322-3552","score":14.1336431338,"text":"\nThe HTTP proxy server must be configured and available by using Virtual Routing and Forwarding (VRF) before the F5 BIG-IP installation can begin.\n\nThe BigIP Virtual Edition (VE) endpoints must be able to activate their license before they can become operational. After the BigIP VE endpoints are installed, they no longer require the use of the proxy server.\n\nThe F5 BIG-IP service cannot be added without a working proxy server at the time of service installation.\n\n\n\n\n\n F5 BIG-IP service configuration \n\nWhen you order the service, provide the following settings.\n\n\n\n Name \n\nEnter the service name.\n\n\n\n\n\n F5 license activation connection \n\nSelect Public network or Private network for license activation. If the target cluster is configured with private-only network interfaces, only the Private network option is available. This selection determines how the F5 virtual servers contact the F5 license server, and it does not impact the workload data plane.\n\nIf you select Private network, specify the following settings:\n\n\n\n* Proxy IP address The IPv4 address of the proxy server.\n* Proxy port number The port number of the proxy server, usually 8080 or 3128.\n\n\n\nAuthenticated proxy is not supported.\n\n\n\n\n\n Maximum bandwidth \n\nSpecify the maximum throughput of the F5 BIG\u2013IP appliance.\n\n\n\n\n\n License model \n\nThe license model for F5 BIG-IP offers the following options:\n\n\n\n* Good - This offer uses the BIG-IP Local Traffic Manager\u2122 (LTM) VE, operating as a full-proxy architecture, which provides:\n\n\n\n* Intelligent local traffic management\n* Complete SSL traffic visibility\n* Analytics and health monitoring to ensure that application servers are always available to your users.\n\n\n\n* Better - This offer is built on the benefits of the Good option, with the addition of BIG-IP DNS\u2122, BIG-IP Advanced Firewall Manager\u2122 (AFM), and BIG-IP Application Acceleration Manager\u2122 (AAM) modules. It delivers global traffic management services, application performance optimization, and advanced network firewall and Distributed Denial of Service (DDoS) mitigation capabilities.\n* Best - In addition to the Good and Better offers, BIG-IP Application Security Manager\u2122 (ASM) provides:\n\n\n\n* Comprehensive application protection against L7 DDoS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_ordering"},{"document_id":"ibmcld_16094-8464-10265","score":14.0190989331,"text":"\n1. Click Security groups under Network, then click Create.\n2. Enter vpc-secure-private-sg as name and select the VPC you created earlier.\n3. Click Create security group.\n\n\n\n\n\n\n\n Create a virtual server instance \n\nTo create a virtual server instance in the newly created subnet:\n\n\n\n1. Click on the subnet vpc-secure-private-subnet created earlier under Subnets.\n2. Click Attached resources, under Attached instances, click Create.\n3. To configure the instance:\n\n\n\n1. Enter a unique name, vpc-secure-private-vsi and resource group as earlier.\n2. Select the same Location already used by the bastion virtual server.\n3. Select Public type of virtual server.\n4. Set the Operating System to Ubuntu Linux. You can pick any version of the image.\n5. Select Compute (2 vCPUs and 4 GB RAM) as your profile. To check other available profiles, click View all profiles.\n6. For SSH keys pick the SSH key you created earlier for the bastion.\n\n\n\n4. Scroll to Networking and select the VPC your created.\n5. Under Network interfaces, click on the Edit icon\n\n\n\n* Select vpc-secure-private-subnet as the subnet.\n* Uncheck the default security and group and activate vpc-secure-private-sg.\n* Click Save.\n\n\n\n6. Click Create virtual server instance.\n\n\n\n\n\n\n\n Add virtual server instance(s) to the maintenance security group \n\nFor administrative work on the servers, you have to associate the specific virtual servers with the maintenance security group. In the following, you will enable maintenance, log into the private server, update the software package information, then disassociate the security group again.\n\nLet's enable the maintenance security group for the server.\n\n\n\n1. Navigate to Security groups and select vpc-secure-maintenance-sg security group.\n2. Click on theAttached resources tab, then Edit interfaces.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-secure-management-bastion-server"},{"document_id":"ibmcld_13238-8347-10193","score":13.9821188352,"text":"\nClick Create subnet to provision it.\n\n\n\n\n\n\n\n Create a security group \n\nTo create a new security group:\n\n\n\n1. Click Security groups under Network, then click Create.\n2. Enter vpc-secure-private-sg as name and select the VPC you created earlier.\n3. Click Create security group.\n\n\n\n\n\n\n\n Create a virtual server instance \n\nTo create a virtual server instance in the newly created subnet:\n\n\n\n1. Click on the subnet vpc-secure-private-subnet created earlier under Subnets.\n2. Click Attached resources, under Attached instances, click Create.\n3. To configure the instance:\n\n\n\n1. Enter a unique name, vpc-secure-private-vsi and resource group as earlier.\n2. Select the same Location already used by the bastion virtual server.\n3. Select Public type of virtual server.\n4. Set the Operating System to Ubuntu Linux. You can pick any version of the image.\n5. Select Compute (2 vCPUs and 4 GB RAM) as your profile. To check other available profiles, click View all profiles.\n6. For SSH keys pick the SSH key you created earlier for the bastion.\n\n\n\n4. Scroll to Networking and select the VPC your created.\n5. Under Network interfaces, click on the Edit icon\n\n\n\n* Select vpc-secure-private-subnet as the subnet.\n* Uncheck the default security and group and activate vpc-secure-private-sg.\n* Click Save.\n\n\n\n6. Click Create virtual server instance.\n\n\n\n\n\n\n\n Add virtual server instance(s) to the maintenance security group \n\nFor administrative work on the servers, you have to associate the specific virtual servers with the maintenance security group. In the following, you will enable maintenance, log into the private server, update the software package information, then disassociate the security group again.\n\nLet's enable the maintenance security group for the server.\n\n\n\n1. Navigate to Security groups and select vpc-secure-maintenance-sg security group.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-secure-management-bastion-server"},{"document_id":"ibmcld_11664-3334-5110","score":13.9817007448,"text":"\nConvert your IBM Cloud account to use [Virtual routing and forwarding (VRF) on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud), using the steps described in [Converting to virtual routing and forwarding](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process).\n\nEnabling VRF permanently alters networking for your IBM Cloud account. Be sure that you have understood both the benefits and minor tradeoffs, which impact your account and resources. After you enable VRF, it cannot be disabled.\n3. Enable the Cloud Service Endpoints (CSE) to provide a secure and unmetered connection to services on IBM Cloud from the IBM Cloud Classic Infrastructure private network. Follow the steps in [enabling service endpoints](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpointservice-endpoint).\n\nThis is not the same as Virtual Private Endpoints (VPE), which is the upgraded equivalent functionality for IBM Cloud VPC Infrastructure environment; this has more benefits that include IAM access control, endpoint with IP in the Subnet Range of the VPC, and does not require Virtual routing and forwarding (VRF).\n\n\n\n\n\n\n\n Provisioning your VMware Software-Defined Datacenter \n\nThe IBM Cloud\u00ae console requires a unique log-in ID, which is an IBMid. Use the following steps to order your IBM Cloud for VMware Solutions Dedicated. Additional information can be found under [Ordering IBM Cloud for VMware Dedicated, vCenter Server instance and vSphere clusters](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_orderinginstance).\n\n\n\n1. Log in to the [IBM Cloud console](https:\/\/cloud.ibm.com) with your unique credentials.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-vmware-sddc-set-up-infrastructure"},{"document_id":"ibmcld_11655-3315-5222","score":13.8400564455,"text":"\nFor a comprehensive list of which SAP Business Analytics products benefits from SAP router connections, see [SAP Note 1478974](https:\/\/launchpad.support.sap.com\/\/notes\/1478974).\n\nA jumphost is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their premises. These SAP virtual server instances can be in a separate security zone but should be on same IBM Cloud region. The customer connection to the jumphost follows the same rules as the direct connection from customer premises to the virtual server instance SAP instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. In this architecture, there are two security groups defined; this arrangement is the simplest method for separating the public and private subnets. You can add more security groups if you require more isolation.\n\n\n\n\n\n Virtual server instances on SAP NetWeaver 7.x APAB stack, JAVA stack, and dual stack (ABAP+JAVA) architectural design on IBM Cloud\u00ae VPC on Unix \n\n\n\n Standard system \n\nIn a standard system, all main instances run on a single virtual server instance within a private subnet. [about virtual servers for VPC](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic-vsi?topic=vpc-on-classic-vsi-virtual-private-cloud). The virtual server instance has these components:\n\nZoom\n\n![Figure 2. Standard installation](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/images\/refarch-sap-syb-std-only.svg)\n\nFigure 2. SAP NetWeaver 7.x SYB standard installation with AAS\n\nArchitecture of SAP NetWeaver AS for ABAP\n\nSAP tools create a PAS Instance and an ASCS Instance. This method is the standard for Java Stack (System) and is now standard for ABAP Stack.\n\n\n\n1. The Primary Application Server (PAS) - An instance is an administrative unit that contains various components of an SAP system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-refarch-nw-sybase"},{"document_id":"ibmcld_16095-7-1863","score":13.7467804334,"text":"\nUse a VPC\/VPN gateway for secure and private on-premises access to cloud resources \n\nThis tutorial will incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIBM offers a number of ways to securely extend an on-premises computer network with resources in the IBM Cloud. This allows you to benefit from the elasticity of provisioning cloud resources when you need them and removing them when no longer required. Moreover, you can easily and securely connect your on-premises capabilities to the IBM Cloud services.\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular [strongSwan](https:\/\/www.strongswan.org\/) VPN Gateway is used to represent the on-premises VPN gateway.\n\n\n\n Objectives \n\n\n\n* Access a virtual private cloud (VPC) environment from an on-premises data center\n* Securely reach cloud services using private endpoint gateways\n* Use DNS on-premises to access cloud resources over VPN\n\n\n\nThe following diagram shows the resources created by this tutorial\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution46-vpc-vpn\/vpc-site2site-vpn-tutorial.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nA terraform configuration will create the following resources:\n\n\n\n1. The infrastructure (VPC, Subnets, Security Groups with rules, Network ACL and VSIs).\n2. The Object Storage and Databases for PostgreSQL private endpoint gateways to data services.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-site2site-vpn"},{"document_id":"ibmcld_14884-7-2123","score":13.7430651924,"text":"\nAbout virtual server instances for VPC \n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility.\n\nWith virtual server instances for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture. After you provision an instance, you control and manage those infrastructure resources.\n\n\n\n How are virtual server instances for VPC different from other IBM virtual server offerings? \n\nIn the IBM Cloud Virtual Servers for Classic infrastructure offering, instances use native subnet and VLAN networking to communicate to each other within a data center (and single pod). Using subnet and VLAN networking in one pod works well until you must scale up or have large virtual resource demands that require resources to be created between pods. (Adding appliances for VLAN spanning can get expensive and complicated!)\n\nIBM Cloud VPC adds a network orchestration layer that eliminates the pod boundary, creating increased capacity for scaling instances. The network orchestration layer handles all of the networking for all virtual server instances that are within a VPC across regions and zones. With the software-defined networking capabilities that VPC provides, you have more options for multi-vNIC instances and larger subnet sizes.\n\nTo review and start deploying compute resources, see the following topics:\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Virtual Servers for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles) IBM Cloud Virtual Servers for VPC provide the advanced security of a private cloud with the agility and ease of a public cloud. Virtual servers for VPC offer the best network performance (up to 80 Gbps), best security, and fastest provisioning times.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui"},{"document_id":"ibmcld_11554-1776-3838","score":13.6641317214,"text":"\nVPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n\n\n SAP products architecture on IBM Cloud VPC \n\nA [Virtual Private Cloud (VPC)](https:\/\/www.ibm.com\/cloud\/learn\/vpc?mhsrc=ibmsearch_a&mhq=VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with its included virtual server instances. This represents an Infrastructure as a Service (IaaS) within IBM Cloud that offers all of the benefits of isolated, secure, and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering uses virtual instances with native and VLAN networking to communicate to each other within a data center; however, the instances are restricted in one well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods. What\u2019s new with IBM Cloud VPC is a network orchestrator layer concept that eliminates the pod boundaries and restrictions, so this new concept handles all the networking for every virtual instance running within VPC across regions and zones.\n\n\n\n\n\n 1. Highly available system for SAP NetWeaver on IBM Cloud VPC \n\nIn a highly available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the SAP application server consists of two virtual server instances, each of them located in the same zone within the region by using placement groups. Placement groups assure that both cluster resources and cloud resources are also located in different compute nodes as specified in the following placement groups section.\n\nZoom\n\n![Figure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1128451413}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":38.4760263921,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":38.4397413703,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":37.4601829104,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":36.4129984314,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_01533-4-2366","score":35.7414609712,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":35.7414609712,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.200136681}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-47319-49349","score":24.2632984715,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-47304-49334","score":24.2632984715,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13336-7-1965","score":23.5457085643,"text":"\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_13336-3083-5168","score":23.1372162714,"text":"\nAnd, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan? \n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n\n\n\n\n What does \"pricing per minute\" mean? \n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\n\n\n\n\n Do you round up to the nearest minute for every call to the API? \n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_07578-503127-505414","score":22.7395861966,"text":"\nSelect a Pricing plan.\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a Resource group.\n7. Optional: Add Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key: value pairs to help group-related tags, such as costctr: 124.\n8. Optional: Add Access management tags that helps you apply flexible access policies on specific resources.\n9. Accept the licensing agreements and terms by clicking the checkbox.\n10. Click Create. A new service instance is created and the App Configuration service console displayed.\n\n\n\n* What pricing plans are available with App Configuration?\n\nApp Configuration has three pricing plans:\n\n\n\nTable 1. Pricing plans\n\n Plan Inclusions Capabilities \n\n Lite This plan is a free evaluation plan that includes 10 active entity IDs and 5,000 API calls. <br>Lite plan services are deleted after 30 days of inactivity. Includes all App Configuration capabilities for evaluation only. Not to be used for production. \n Standard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n* What are the charges to use App Configuration?\n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-503069-505356","score":22.7395861966,"text":"\nSelect a Pricing plan.\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a Resource group.\n7. Optional: Add Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key: value pairs to help group-related tags, such as costctr: 124.\n8. Optional: Add Access management tags that helps you apply flexible access policies on specific resources.\n9. Accept the licensing agreements and terms by clicking the checkbox.\n10. Click Create. A new service instance is created and the App Configuration service console displayed.\n\n\n\n* What pricing plans are available with App Configuration?\n\nApp Configuration has three pricing plans:\n\n\n\nTable 1. Pricing plans\n\n Plan Inclusions Capabilities \n\n Lite This plan is a free evaluation plan that includes 10 active entity IDs and 5,000 API calls. <br>Lite plan services are deleted after 30 days of inactivity. Includes all App Configuration capabilities for evaluation only. Not to be used for production. \n Standard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n* What are the charges to use App Configuration?\n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12824-7-1978","score":22.4966427471,"text":"\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-migrated-products"},{"document_id":"ibmcld_07214-60873-63067","score":22.3267455601,"text":"\nThese queries can be used as a starting point for writing your own queries. Sample queries are available for both IBM Watson\u2122 Discovery News and private collections.\n\nNew beta visual aggregation builder : Added the beta ability to write aggregations with a visual builder. Click Build in visual mode above the Write an aggregation query using the Discovery Query Language field to try it out. As you build your aggregation visually, the query displays in the Discovery Query Language below it.\n: The visual aggregation builder is currently supported only as a beta capability.\n\n\n\n\n\n 31 July 2017 \n\nNew release of Discovery News : A new version of IBM Watson\u2122 Discovery News was released. The original version is renamed as IBM Watson\u2122 Discovery News Original and is retired, with a removal from service date of 15 January 2018. : If you create a new instance of Discovery, you only have access to the new version of IBM Watson\u2122 Discovery News.\n\nNew pricing structure : A new pricing plan for IBM Watson\u2122 Discovery was released. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details.\n\nUpdate to version string : The version string for all API calls changed to 2017-08-01 from 2017-07-19. This version includes updates for the new pricing plan and the new version of Watson Discovery News. Update the version string to avoid conflicts and possible errors.\n\n\n\n\n\n 19 July 2017 \n\nChange to Pricing plans : Pricing changes will take effect on 1 August 2017. : Users that are currently on the deprecated 30 day free trial plan will be automatically migrated to the Lite plan. As a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_03729-1672-3956","score":22.1992714579,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_00558-2925-4840","score":22.1770246817,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":20.4325745191,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-199697-200931","score":19.1873432957,"text":"\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- <\/section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- <\/section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04183-0-2205","score":18.7777096018,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04186-18298-19703","score":18.7551668652,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-18343-19753","score":18.6683921965,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-198873-200152","score":18.5627223934,"text":"\n<-- <\/section \"id=\"section-set-context-cis-service-examples\" \"> --><-- <\/section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04132-3821-5296","score":18.5427577147,"text":"\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_13139-17831-19468","score":18.4037886992,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-74160-75348","score":18.2597757607,"text":"\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.\n\nibmcloud cis firewall-delete dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall-delete bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Firewall rules \n\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-196613-197723","score":18.2570890389,"text":"\n! ! ! ! ! ! !\n<-- <section \"id=\"section-delete-ratelimit-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.RATELIMIT_RULE_ID: The ID of rate limit rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-ratelimit-rule-options\" \"> --><-- <section \"id=\"section-delete-ratelimit-rule-examples\" \"> --> Examples Delete rate limiting rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis ratelimit-rule-delete 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-ratelimit-rule-examples\" \"> --><-- <\/section \"id=\"section-delete-ratelimit-rule\" \"> --><-- <\/section \"id=\"section-ratelimit\" \"> --><-- <section \"id=\"section-resource-instance\" \"> --> Resource instance Manipulate CIS Service instances by using the following instance commands.<-- <section \"id=\"section-list-cis-service-instances\" \"> --> ibmcloud cis instances List all CIS service instances. ibmcloud cis instances --output FORMAT] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14686-7-2038","score":32.1847838462,"text":"\nSystem context for vCenter Server and Red Hat OpenShift architecture \n\nThe following diagram shows the system context for this reference architecture. A system context diagram is a high-level diagram that provides an initial view of the system. It defines the key elements of a system, the boundary of the system, and the entities that interact with it, along with the interaction.\n\nZoom\n\n![VMware Solutions and Red Hat\u00ae OpenShift\u00ae System Context](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-systemcontext.svg)\n\nFigure 1. IBM Cloud\u00ae for VMware Solutions and Red Hat OpenShift system context\n\n\n\n Actors \n\nThe system context diagram identifies the following actors:\n\n\n\n* VMware administrator - The administrator is responsible for the ongoing deployment and maintenance of the VMware\u00ae environment.\n* Red Hat OpenShift administrator - The administrator is responsible for the ongoing deployment and maintenance of the Red Hat\u00ae OpenShift\u00ae environment.\n* Application user - The users of the applications that are deployed in the VMware and Red Hat OpenShift environment.\n\n\n\n\n\n\n\n Systems \n\nThe system context diagram identifies the following systems:\n\n\n\n* NSX Edge - Virtual appliances that manage north-south traffic into and out of the vCenter Server\u00ae instance.\n* NSX load balancer - Used by Red Hat OpenShift for access to control plane and worker hosts. Load balancing is a function within the NSX\u00ae Edge, providing an L4\/7 application load balancer.\n* IBM Cloud for VMware Solutions Active Directory - Used for vCenter and NSX Manager authentication and can be extended to be used by Red Hat OpenShift.\n* IBM Cloud for VMware Solutions DNS - Used by the VMware and Red Hat OpenShift environment to provide FQDN registration and resolution. DNS is configured to forward lookups to shared IBM DNS servers, allowing the resolution of public endpoints.\n* IBM Cloud shared NTP - Used to maintain time synchronization within the environment.\n* Persistent volumes:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-syscontext"},{"document_id":"ibmcld_10076-23177-24486","score":30.0867274839,"text":"\n5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.6 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.7 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.8 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.9 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-47"},{"document_id":"ibmcld_10077-23179-24488","score":30.0867274839,"text":"\n5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.6 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.7 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.8 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.9 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48"},{"document_id":"ibmcld_10072-23006-24315","score":30.0867274839,"text":"\n5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.6 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.7 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.8 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.9 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410"},{"document_id":"ibmcld_10075-22054-23418","score":30.0015841417,"text":"\n5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set automountServiceAccountToken: false for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set automountServiceAccountToken: false. \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.6 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-46"},{"document_id":"ibmcld_10283-0-1125","score":29.9167141736,"text":"\n\n\n\n\n\n\n  Why can't I use the Red Hat annotations to restrict access to the Red Hat OpenShift Console? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nWhen you use the Red Hat ip_whitelist allowlist annotation to allow only certain source IP addresses to access the Red Hat OpenShift Console, it does not work as expected.\n\n  Why it\u2019s happening \n\nBy default, the source IP address is not preserved from the client (console web browser) through the load balancer and to the router pod. Because the source IP address isn't available when the filtering is done in the router pod, you can't use the ip_whitelist annotation to allow certain IP addresses to access the console.\n\n  How to fix it \n\nDo not use the Red Hat ip_whitelist annotation to restrict Red Hat OpenShift Console access to specific IP address or IP address ranges. Instead, use Context Based Restrictions (CBR) for this purpose.\n\nFor more information, see [Allowing Red Hat OpenShift on IBM Cloud to access other IBM Cloud resources by using CBR](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=uicbr-integrations).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ip_whitelist"},{"document_id":"ibmcld_10078-23549-25012","score":29.4826869241,"text":"\n5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.6 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.7 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.8 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.9 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.3.2 Red Hat OpenShift on IBM Cloud has a set of [default Calico network policies defined](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policiesdefault_policy) and [additional network policies can optionally be added](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policiesadding_network_policies). \n 5.4.1 Red Hat OpenShift on IBM Cloud deploys some system components that could prefer using secrets as files over secrets as environment variables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49"},{"document_id":"ibmcld_10078-22388-23874","score":29.2646572205,"text":"\n5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server) for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server). \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49"},{"document_id":"ibmcld_10064-4-2082","score":29.1717062266,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Protecting Red Hat OpenShift on IBM Cloud resources with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Red Hat OpenShift on IBM Cloud resources can be controlled with context-based restrictions and identity and access management policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the Red Hat OpenShift on IBM Cloud service to create, update, or delete rules. And a user must have either the Editor or Administrator role on the Context-based restrictions service to create, update, or delete network zones.\n\nAny Activity Tracker or audit log events generated come from the context-based restrictions service, and not Red Hat OpenShift on IBM Cloud. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nAttempts to access the cluster control plane, which can be restricted by using the Cluster API type, do not generate Activity Tracker or audit log events.\n\n\n\n How Red Hat OpenShift on IBM Cloud integrates with context-based restrictions \n\nYou can create context-based restrictions (CBR) for Red Hat OpenShift on IBM Cloud resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect Red Hat OpenShift on IBM Cloud resources","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr"},{"document_id":"ibmcld_10065-4-2082","score":29.1717062266,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Protecting Red Hat OpenShift on IBM Cloud resources with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Red Hat OpenShift on IBM Cloud resources can be controlled with context-based restrictions and identity and access management policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the Red Hat OpenShift on IBM Cloud service to create, update, or delete rules. And a user must have either the Editor or Administrator role on the Context-based restrictions service to create, update, or delete network zones.\n\nAny Activity Tracker or audit log events generated come from the context-based restrictions service, and not Red Hat OpenShift on IBM Cloud. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nAttempts to access the cluster control plane, which can be restricted by using the Cluster API type, do not generate Activity Tracker or audit log events.\n\n\n\n How Red Hat OpenShift on IBM Cloud integrates with context-based restrictions \n\nYou can create context-based restrictions (CBR) for Red Hat OpenShift on IBM Cloud resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect Red Hat OpenShift on IBM Cloud resources","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14503-4971-7126","score":31.2354594878,"text":"\nThe client can also configure their compute VMs to uses these forwarders, if required.\n* VMware Update Manager (VUM) provides updating of vSphere hosts and VM hardware and tools. VUM uses the Proxy to gain access to the internet repositories.\n\n\n\nVMware Aria Operations collects data from objects in the environment. Each piece of data that is collected is called a metric observation or value. VMware Aria Operations uses the vCenter adapter to collect raw metrics from vCenter. In addition to the metrics it collects, VMware Aria Operations calculates capacity metrics, badge metrics, and metrics to monitor the health of your system. Alert definitions are a combination of symptoms and recommendations that identify problem areas and generate alerts on which you act for those areas.\n\n\n\n\n\n Monitored components \n\n\n\n Monitoring of vCenter \n\nThe monitoring of vCenter is accomplished with VMware Aria Operations and the VMware SDDC Health Management Pack. VMware Aria Operations for Logs collects the log data from vCenter and the Content Pack for vSphere adds specific understanding to the logs and in turn sends alerts to VMware Aria Operations.\n\nThe VMware SDDC Health Management Pack monitors the SDDC Management stack and provides badges for health and alerts related to configuration and compliance of SDDC product components that include vCenter.\n\n\n\n\n\n Monitoring of vSphere hosts \n\nMonitoring of the vSphere hosts is accomplished with VMware Aria Operations through vCenter and the collection of logs through VMware Aria Operations for Logs.\n\n\n\n\n\n Monitoring of vSAN \n\nTo monitor vSAN, VMware Aria Operations, and VMware Aria Operations for Logs are used. In vCenter, you can use an extra set of vSAN Health Checks. Installation of the Management Pack for vSAN provides more dashboards to aid with the monitoring of vSAN.\n\nVMware Aria Operations generates an alert if a problem occurs in the SDDC product components in the storage area network that the VMware vSAN adapter is monitoring. An alert that is related to configuration compliance and health is passed through VMware SDDC Health Solution management pack from VMware vSAN Management Pack.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-arch"},{"document_id":"ibmcld_08592-8007-9409","score":27.6423187306,"text":"\nYou can scope down your metrics by using the following scope filters.\n\n\n\nTable 4. Describes the scope filters for Hyper Protect Crypto Services metrics.\n\n Attribute Name Description \n\n ibmResourceGroupName The name of the resource group associated with the Hyper Protect Crypto Services service instance. \n ibmScope The account, organization, or space GUID associated with the metric. \n ibmServiceInstanceName The service instance associated with the metric. \n ibmHpcsApi The Hyper Protect Crypto Services API calls associated with the metric. \n\n\n\nBecause of Monitoring limitations, you are able to see the values in the filters for up to 6 hours at a time. You can manually type in value into scope variables to use scope filters for given time periods.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics. To set up alerts, complete the following steps:\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert and select Metric as the alert type.\n3. Select the aggregation and the metric that you would like to be performed on.\n4. Select the scope if applicable.\n5. Set the metric and time requirements for the alert to trigger.\n6. Configure and set up the notification channel and notification interval.\n7. Click CREATE.\n\n\n\nFor more information about configuring metric alerts, see [Metric Alerts](https:\/\/docs.sysdig.com\/en\/metric-alerts.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-operational-metrics"},{"document_id":"ibmcld_14510-3279-5082","score":27.1533600619,"text":"\n* Preconfigured vSphere alarms - The vSphere event and alarm subsystem has a number of default alarms, which monitor the operations of vSphere inventory objects. You must set up actions only for these alarms.\n\n\n\n\n\n\n\n\n\n Alarm setup workflow \n\nVMware provides preconfigured vCenter alarms that are described in the following tables, but they are set with an action to display within the vCenter web client only. Configure the SMTP server details and then set the alert actions to send an email to the system administrators for the following alarms only initially so not to inundate the system administrator team. For more information, see [Send email as an alarm action](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.monitoring.doc\/GUID-1F940DAF-933B-44B7-A200-7A11B5D3E3D5.html).\n\nThe setting alarms workflow is as follows.\n\n\n\n* Configure the SMTP server details.\n* Configure the alert actions for clusters, hosts, datastores, and critical virtual appliances, such as vCenter Server Appliance, PSC, NSX Manager, and controllers.\n\n\n\n* Cluster - a VMware High Availability error.\n* Hosts - CPU status, memory status, storage status, hardware status that is, voltage, temperature, or power status changes.\n* Datastore - low on free disk space.\n* Critical virtual appliance - CPU usage, memory usage, disk latency\n\n\n\n* Use the proactive daily task to review the following information.\n\n\n\n* Review the alerts sent - are the alerts required?\n* Review the alerts that weren't sent - do you need to know about them?\n* Review the metrics - are the metrics correct? For example, confirm that CPU usage must be set to 75% rather than 90% now that you understand your baseline.\n* Do you need to configure your own alarms?\n* Do you need to include virtual machines?\n\n\n\n\n\n\n\n\n\n Typical alarm workflow","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-alarms"},{"document_id":"ibmcld_09701-12088-14157","score":27.1414014731,"text":"\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_03363-4-2165","score":25.8642626923,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_09785-2901-4576","score":24.5544962404,"text":"\nYou can still manage alerts by using the legacy editor. However, notice that new features are only available through the new editor.\n* New configuration settings to help you troubleshoot issues. You can configure a dashboard and a runbook with an alert.\n\n\n\nDeprecated features:\n\n\n\n* Deprecation of the Anomaly Detection and Group Outlier alert types. You can view and manage existing alerts but you cannot define new ones.\n\n\n\nFor more information, see [Configure alerts](https:\/\/docs.sysdig.com\/en\/docs\/sysdig-monitor\/alerts\/configure-alerts\/).\n\n\n\n\n\n 15 June 2022 \n\nIBM Cloud\u00ae Monitoring has made available a proprietary time series database that is designed for storing and serving metrics at scale. [Learn more](https:\/\/docs.sysdig.com\/en\/docs\/release-notes\/enhanced-metric-store\/)\n: The following changes have been made:\n\n\n\n* [Metrics and labels are stored and displayed in a Prometheus compatible naming convention](https:\/\/docs.sysdig.com\/en\/docs\/release-notes\/enhanced-metric-store\/prometheus-compatible-naming-conventions-for-metrics--labels).\n* Some metrics and labels have been deprecated. Deprecated metrics and labels will no longer be available 30 days after this release. See [Discontinued Metrics and Labels](https:\/\/docs.sysdig.com\/en\/docs\/release-notes\/enhanced-metric-store\/discontinued-metrics-and-labels).\n* Classic metrics have been replaced with context-explicit metrics. See [Mapping Classic Metrics with Context-Specific PromQL Metrics](https:\/\/docs.sysdig.com\/en\/docs\/sysdig-monitor\/metrics-dictionary\/metrics-and-label-mapping\/mapping-classic-metrics-with-context-specific-promql-metrics\/mapping-classic-metrics-with-context-specific-promql-metrics).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitoring-release-notes"},{"document_id":"ibmcld_09794-9435-11301","score":24.1529102224,"text":"\n[Panel options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/platform\/images\/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: This field is set to the metric that you have selected from the panel. Check that the metric and aggregation are the ones that you need.\n\nScope: This field is set to the scope that you have defined for the metric in the panel. Check that the scope is the one that you need.\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n\n\n Configuring an alert from the Alerts section \n\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working"},{"document_id":"ibmcld_09148-7815-9285","score":23.749646945,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-dashboard-menu.png)\n\nFigure 2. The dashboard menu that lists the dashboards in your Monitoring instances.\n\nBelow are figures that show the metric views available to you on the default dashboard.\n\nZoom\n\n![An example of a Key Protect metrics dashboard.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-operation-dash1.png)\n\nFigure 3. Some of the metrics available on the Monitoring dashboard.\n\nZoom\n\n![An example of a Key Protect dashboard view.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-operation-view2.png)\n\nFigure 4. Some of the metrics available on the Monitoring dashboard.\n\nYou will not be able to see any metrics in your Monitoring instance until you enable a metrics policy for your Key Protect instance and make API requests to your Key Protect instance.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics.\n\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"},{"document_id":"ibmcld_09703-1640-3664","score":23.6177758851,"text":"\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts"},{"document_id":"ibmcld_09148-8939-9806","score":23.4144795135,"text":"\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1211120-1213024","score":16.6265063251,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":16.6265063251,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09088-9397-11338","score":16.2713464653,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_08695-7-1852","score":16.0843699967,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_16059-9270-11112","score":15.953956637,"text":"\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"},{"document_id":"ibmcld_09192-5368-7014","score":15.7573989075,"text":"\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening \n\nThis key is actively protecting one or more cloud resources, such as a IBM Cloud\u00ae Object Storage bucket or a Cloud Databases deployment.\n\n How to fix it \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. Before you delete a key, [review which resources are encrypted by this key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nYou can get the current list of resources associated with your key by first [synchronizing the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-sync-associated-resources), which might take up to 4 hours. Then, proceed to [viewing associations between root keys and encrypted IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\nAfter using Sync, associations between the key and other resources will be current and up to date. If there are no associations after using Sync, the key can be deleted normally.\n\nIf the associations are still there after Sync:\n\n\n\n* You can use the Key Protect API to [force deletion on the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete).\n* You can delete the resources associated with the key, and then delete the key normally.\n\n\n\n\n\n\n\n Getting help and support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_16045-9337-11274","score":15.7360497843,"text":"\nVolume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_09192-4150-5583","score":15.4784156856,"text":"\nIf the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys \n\nWhen you use the Key Protect user interface or REST API, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou're assigned a Manager access policy for the Key Protect instance. You try to delete a key, but the action fails with the following error message.\n\nConflict: Key could not be deleted. Status: 409, Correlation ID: 160cc463-71d1-4b30-a5f2-d3f7e9f2b75e\n\nYou also try to delete the key by using the Key Protect API, but you receive the following error message.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key could not be deleted. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_07578-1209748-1211682","score":15.1949513916,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1212381-1214315","score":15.1949513916,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-1710-3705","score":51.0521472899,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-3269-5168","score":47.8092397574,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":45.3465021529,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":40.0665108869,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":38.3960172946,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":36.4960641639,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03704-3030-4892","score":35.5190720033,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":35.4394930141,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":35.4394930141,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1069800-1071727","score":34.203309232,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.9047172295,"ndcg_cut_10":0.9047172295}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-4-2033","score":18.8143619633,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03270-3352-5135","score":18.3448834351,"text":"\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03113-6206-7586","score":18.1075293342,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03113-4996-6502","score":18.071851733,"text":"\n[UI location where the code that is triggered by named event handlers is authored](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02882-27313-29495","score":18.0661672205,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02952-3289-5462","score":18.0030590955,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03273-11911-13556","score":17.981031003,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03188-1732-3801","score":17.9314802651,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_02952-1632-3754","score":17.825478302,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03054-27011-29125","score":17.8050935312,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16507-7-2044","score":33.4046671949,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7-2064","score":33.1215287946,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16444-4487-6387","score":33.1174458818,"text":"\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-4382-6307","score":32.8538139096,"text":"\nConfiguring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-1600-3658","score":31.6886295843,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-3099-4772","score":31.1230504106,"text":"\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16463-1457-3136","score":30.8051701169,"text":"\nThen, you can assign the documents to human annotators to finish the annotation work.\n\n\n\n\n\n Lesson 1: Pre-annotating new documents with a machine learning model \n\nIn this lesson, you will learn how to use a machine learning model to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nAfter you train a machine learning model, you can use it to pre-annotate new documents that you add to the corpus.\n\n> Attention: Do not run a pre-annotator on documents that have been annotated by humans, but not been added to the ground truth yet. If you do, all current annotations will be stripped from the documents.\n\nIn this tutorial, you can add a second set of documents by using the documents-ml.csv file. Do not re-add the documents-new.csv file, since this addition would result in duplicate documents in the ground truth. Duplication causes the following problems:\n\n\n\n* If annotations on each document do not match, they lower the quality of the machine learning model.\n* If annotations on each document match, they over-train the machine learning model on the duplicated files.\n\n\n\nFor more information about pre-annotating documents, see [Bootstrapping annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation), which covers additional methods of pre-annotation.\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator.\n2. Upload more documents to the workspace. You can use the [documents-ml.csv![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-ml.csv) file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16552-1519-3329","score":30.7362609634,"text":"\nLesson 1: Pre-annotating new documents with a machine learning model \n\nIn this lesson, you will learn how to use a machine learning model to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nAfter you train a machine learning model, you can use it to pre-annotate new documents that you add to the corpus.\n\nDo not run a pre-annotator on documents that have been annotated by humans, but not been added to the ground truth yet. If you do, all current annotations will be stripped from the documents.\n\nIn this tutorial, you can add a second set of documents by using the documents-ml.csv file. Do not re-add the documents-new.csv file, since this addition would result in duplicate documents in the ground truth. Duplication causes the following problems:\n\n\n\n* If annotations on each document do not match, they lower the quality of the machine learning model.\n* If annotations on each document match, they over-train the machine learning model on the duplicated files.\n\n\n\nFor more information about pre-annotating documents, see [Bootstrapping annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation). You can also read about other pre-annotation methods.\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator.\n2. Upload more documents to the workspace. You can use the [documents-ml.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-ml.csv) file.\n\nFor more information about adding documents to a workspace, see [Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation).\n3. Create an annotation set that uses the documents-ml.csv file as the base set, and assign it to yourself, the administrator.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"},{"document_id":"ibmcld_16516-12409-14637","score":29.9722603164,"text":"\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_16444-3168-4952","score":29.8737904621,"text":"\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.\n\n\n\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7495275801}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10214-13598-15521","score":26.2590235612,"text":"\nFor more information about available bare metal flavors and how bare metal is different from virtual machines, see [Physical machines (bare metal)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm).\n\n\n\n\n\n What is the smallest size cluster that I can make? \n\nYour cluster must have at least 2 worker nodes to run default Kubernetes and OpenShift Container Platform components. You can't have a cluster with 0 worker nodes, and you can't power off or suspend billing for your worker nodes. Additionally, the type of cluster and the number of worker pools that you have can impact the size of your cluster.\n\n\n\n* Single zone clusters: [Create a cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters) with 2 worker nodes in the default worker pool.\n* Multizone clusters: You must [create a cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters) with 1 worker node per zone in the worker pool. Later, you can [remove zones](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_zone_rm) from the worker pool or [remove individual worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_rm) so that your cluster size reduces to the minimum size of 2.\n* Worker pools: For any type of cluster, each worker pool must always have at least 1 worker node. For the smallest size cluster possible, you can have only 1 worker pool.\n\n\n\nKeep in mind that some services such as Ingress might require multiple worker nodes for high availability, and you might not be able to run these services or your apps in the smallest size cluster possible.\n\nClassic clusters only: Initially, you can create a classic cluster with only 1 worker node. This operation is allowed for multizone clusters, so that you are not forced to create 2 worker nodes per zone. If you have a single zone cluster, resize the worker pool to 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10089-6595-8023","score":26.1651423542,"text":"\nNow, the minSize means that the cluster autoscaler does not scale down to fewer than four worker nodes per zone even if you remove the workload that requests the amount.\n\nHow is this behavior different from worker pools that are not managed by the cluster autoscaler?\n: When you [create a worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersadd_pool), you specify how many worker nodes per zone it has. The worker pool maintains that number of worker nodes until you [resize](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [rebalance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_rebalance) it. The worker pool does not add or remove worker nodes for you. If you have more pods than can be scheduled, the pods remain in pending state until you resize the worker pool. When you enable the cluster autoscaler for a worker pool, worker nodes are scaled up or down in response to your pod spec settings and resource requests. You don't need to resize or rebalance the worker pool manually.\n\n\n\n\n\n Following scalable deployment practices \n\nMake the most out of the cluster autoscaler by using the following strategies for your worker node and workload deployment strategies. For more information, see the [Kubernetes Cluster Autoscaler FAQs](https:\/\/github.com\/kubernetes\/autoscaler\/blob\/master\/cluster-autoscaler\/FAQ.md).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc"},{"document_id":"ibmcld_10061-6570-7998","score":26.1651423542,"text":"\nNow, the minSize means that the cluster autoscaler does not scale down to fewer than four worker nodes per zone even if you remove the workload that requests the amount.\n\nHow is this behavior different from worker pools that are not managed by the cluster autoscaler?\n: When you [create a worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersadd_pool), you specify how many worker nodes per zone it has. The worker pool maintains that number of worker nodes until you [resize](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [rebalance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_rebalance) it. The worker pool does not add or remove worker nodes for you. If you have more pods than can be scheduled, the pods remain in pending state until you resize the worker pool. When you enable the cluster autoscaler for a worker pool, worker nodes are scaled up or down in response to your pod spec settings and resource requests. You don't need to resize or rebalance the worker pool manually.\n\n\n\n\n\n Following scalable deployment practices \n\nMake the most out of the cluster autoscaler by using the following strategies for your worker node and workload deployment strategies. For more information, see the [Kubernetes Cluster Autoscaler FAQs](https:\/\/github.com\/kubernetes\/autoscaler\/blob\/master\/cluster-autoscaler\/FAQ.md).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ca"},{"document_id":"ibmcld_10259-9223-10406","score":26.0346642908,"text":"\n* [ibmcloud oc cluster subnet create](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_subnet_create)\n* [ibmcloud oc cluster subnet detach](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_subnet_detach)\n\n\n\n\n\n\n\n\n\n ibmcloud oc worker \n\n[View and modify worker nodes for a cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliworker_node_commands).\n\n\n\n* Deprecated[ibmcloud oc worker add](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_add)\n* [ibmcloud oc worker get](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_get)\n* [ibmcloud oc worker ls](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_workers)\n* [ibmcloud oc worker reboot](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reboot)\n* [ibmcloud oc worker reload](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reload)\n* [ibmcloud oc worker replace](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clicli_worker_replace)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-icks_map"},{"document_id":"ibmcld_10710-7486-8738","score":25.9724100933,"text":"\nIf the worker node remains in this state for an extended period of time even after the Kubernetes master is successfully updated, try to [reload the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reload).\n* You might have another firewall that is protecting your worker nodes, or changed firewall settings recently. Red Hat OpenShift on IBM Cloud requires certain IP addresses and ports to be opened to allow communication from the worker node to the Kubernetes master and vice versa. For more information, see [Firewall prevents worker nodes from connecting](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-firewallvyatta_firewall).\n* The Kubernetes master is down. Contact IBM Cloud support by opening an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n\n\n Warning state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Warning state means that your worker node is reaching the limit for memory or disk space. You can either reduce workload on your worker node or add a worker node to your cluster to help load balance the workload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-reference"},{"document_id":"ibmcld_08879-7-1905","score":25.9043765521,"text":"\nCreating single and multizone Kubernetes and OpenShift clusters \n\nUse this tutorial to create single and multizone clusters with [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iks-overview) or [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview), and deploy your own set of compute hosts in the public cloud where you can run and manage highly available containerized apps.\n\nIn this tutorial, you create a standard classic IBM Cloud Kubernetes Service or Red Hat OpenShift on IBM Cloud cluster with the following configuration:\n\n\n\n* The cluster is created in the us-south region.\n* The cluster is created with the default worker pool.\n* All worker nodes are connected to a private and public VLAN. These public and private VLANs assign public and private IP addresses to the worker nodes.\n* All worker nodes are created with a virtual worker node flavor on shared hardware. If you want to use a different worker node flavor, see the [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes) or [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes) documentation.\n* To allow access to your cluster from the internet and run public-facing app workloads in your cluster, the cluster is set up with both a public and a private service endpoint. For more information, about how network traffic flows when a public and a private service endpoint is enabled, see Worker-to-master and user-to-master communication: Service endpoints in [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_clusters) and [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_clustersworkeruser-master).\n\n\n\nKeep in mind that creating a cluster incurs costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-tutorial-tf-clusters"},{"document_id":"ibmcld_10042-20678-22724","score":25.859066307,"text":"\ncontainers-kubernetes.cluster-worker-pool-zone.list The worker pools for a cluster in a particular zone are listed as part of cluster autoscaler operations. \n containers-kubernetes.cluster-worker-pool-zone.resize A worker node is added to or removed from a zone that the worker pool spans. \n containers-kubernetes.cluster-worker-pool-zone-network.add The networking data, such as public and private VLAN data, is added for a zone that the worker pool spans. \n containers-kubernetes.cluster-worker-pool-zone-worker.list The worker nodes within a zone that a the worker pool spans are listed as part of cluster autoscaler operations. \n containers-kubernetes.worker.delete A worker node is deleted from the cluster. \n containers-kubernetes.worker.get The details of a worker node in the cluster are returned. \n containers-kubernetes.worker.reboot A worker node is rebooted. \n containers-kubernetes.worker.reload A worker node is reloaded. \n containers-kubernetes.worker.replace A worker node is removed and another worker node of the same flavor is created in the cluster. \n containers-kubernetes.worker.update A worker node version is updated. \n\n\n\n\n\n\n\n Viewing your cluster events \n\nTo [view events](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-view_events) that are sent to IBM Cloud Activity Tracker, you select the Activity Tracker instance that matches with the location of your Red Hat OpenShift on IBM Cloud cluster.\n\nThe following table shows the Activity Tracker location where your events are sent to. To view your events, make sure that you have an Activity Tracker instance in the location that matches your cluster location. Note that clusters in the Montreal, Toronto, and Washington, D.C. locations forward all events to the Dallas Activity Tracker location.\n\n\n\nCorresponding Activity Tracker instance and Red Hat OpenShift on IBM Cloud cluster locations.\n\n Red Hat OpenShift on IBM Cloud classic location Activity Tracker event location \n\n Dallas (dal10, dal12, dal13) Dallas \n Montreal (mon01) Washington, D.C.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-at_events"},{"document_id":"ibmcld_10203-3799-5300","score":25.6631649586,"text":"\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.\n\nibmcloud oc worker-pool ls --cluster <cluster_name_or_ID>\n2. List the worker nodes that are in the worker pool, and note one of the Private IP addresses.\n\nibmcloud oc worker ls --cluster <cluster_name_or_ID> --worker-pool <worker_pool_name_or_ID>\n3. Describe the worker node. In the Labels output, note the worker pool ID label, ibm-cloud.kubernetes.io\/worker-pool-id.\n\nThe steps in this topic use a worker pool ID to deploy app pods only to worker nodes within that worker pool. To deploy app pods to specific worker nodes by using a different label, note this label instead. For example, to deploy app pods only to worker nodes on a specific private VLAN, use the privateVLAN= label.\n\noc describe node <worker_node_private_IP>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>\nLabels: arch=amd64\nbeta.kubernetes.io\/arch=amd64\nbeta.kubernetes.io\/instance-type=b3c.4x16.encrypted\nbeta.kubernetes.io\/os=linux\nfailure-domain.beta.kubernetes.io\/region=us-south","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10290-117688-119201","score":25.6477853938,"text":"\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker replace command \n\nibmcloud oc worker replace --cluster my_cluster --worker kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1\n\n\n\n\n\n\n\n ibmcloud oc worker rm \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRemove one or more worker nodes from a cluster. If you remove a worker node, your cluster becomes unbalanced, and [replacing a worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) no longer creates a replacement worker node. You can automatically rebalance your worker pool by running the ibmcloud oc worker-pool rebalance[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_rebalance) after you remove a worker node.\n\nibmcloud oc worker rm --cluster CLUSTER --worker WORKER [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID. To reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker rm command \n\nibmcloud oc worker rm --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10510-17837-19983","score":25.6333883098,"text":"\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0980392858}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00626-3414-5513","score":13.7269528263,"text":"\nThe _replicator database is a special database within your account, where you can PUT or POST replication documents to specify the replications you want.\n\nBefore you start a replication, you must create the _replicator database. To create a database, send a PUT request to:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/_replicator\n\nFor more information, see [Databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases).\n\nTo cancel a replication, you DELETE the replication document. The fields that are supplied in the replication document are described in the [Create or modify a replication operation](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) description under Request information.\n\nAll design documents and _local documents that are added to the \/_replicator database are ignored.\n\n\n\n\n\n Important notes \n\n\n\n* A new and more powerful [replication scheduler](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationthe-replication-scheduler) changes the previous behavior of the IBM Cloudant replication mechanisms. Ensure that your applications are updated.\n* Replications can severely impact the performance of an IBM Cloudant instance. Performance testing helps you understand the impact on your environment under an increasing number of concurrent replications.\n* [Continuous replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicontinuous-replication) can result in many internal calls. Requiring many calls might affect the costs for multi-tenant users of IBM Cloudant systems. By default, continuous replication is not enabled.\n* The target database must exist. It is not automatically created if it does not exist. Add \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-api"},{"document_id":"ibmcld_13144-25047-26967","score":13.604555863,"text":"\nserviceClass: cloudantnosqldb\nplan: standard\n6. Click Create to create a IBM Cloudant database instance. Your context should be Operators > Installed Operators > IBM Cloud Operator in the Administrator perspective with Project: example-health in the Service panel.\n7. Click on the service just created, <your-initials>-cloudant-service and over time the state field will change from provisioning to Online meaning it is good to go.\n8. Create a Binding resource and a Secret resource for the cloudant Service resource just created. Navigate back to Operators > Installed Operators > IBM Cloud Operator > Binding tab. Open the Binding tab, click Create Binding and select YAML View. Create a cloudant-binding associated with the serviceName <your-initials>-cloudant-service, (this is the the name provided for the Service created earlier).\n\napiVersion: ibmcloud.ibm.com\/v1\nkind: Binding\nmetadata:\nname: cloudant-binding\nnamespace: example-health\nspec:\nserviceName: <your-initials>-cloudant-service\n9. Optionally dig a little deeper to understand the relationship between the Red Hat OpenShift resources: Service, service Binding, binding Secret and the IBM Cloud resources: Service, service Instance and the instance's Service credentials. Using the cloud shell:\n\nibmcloud resource service-instances --service-name cloudantnosqldb\n\nYOURINITIALS=<your-initials>\n\nibmcloud resource service-instance $YOURINITIALS-cloudant-service\n\nibmcloud resource service-keys --instance-name $YOURINITIALS-cloudant-service --output json\n\nOutput looks something like this:\n\nyouyou@cloudshell:$ ibmcloud resource service-instances --service-name cloudantnosqldb\nRetrieving instances with type service_instance in all resource groups in all locations under ..\nOK\nName Location State Type\n<your-initials>-cloudant-service us-south active service_instance\nyouyou@cloudshell:$ ibmcloud resource service-instance <your-initials>-cloudant-service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_00626-5090-6346","score":13.5188688022,"text":"\nAdd \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store. For more information, see [replication database maintenance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationreplication-database-maintenance).\n\n\n\nFor security purposes, the IBM Cloudant team recommends that you use IAM API keys or IBM Cloudant legacy authentication [API keys](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountapi-keys) rather than account-level credentials for replication jobs. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication API document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication) and the legacy [Authorization API document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-api"},{"document_id":"ibmcld_00564-5557-7242","score":12.797439893,"text":"\nThe resulting compressed data stream is then redirected and written to a file called backup.gz.\n\nIf the database requires you to supply access credentials, use $SERVICE_URL with the form https:\/\/$USERNAME:$PASSWORD@$ACCOUNT, for example, https:\/\/myusername:mypassword@myhost.cloudant.com.\n\nIt's straightforward to extend the pipeline if you want to transform the data in other ways. For example, you might want to encrypt the data before it's written to disk. You might also want to write the data directly to an object store service by using their command-line tools.\n\n\n\n\n\n Hourly or daily backups that use cron \n\nThe cron scheduling tool can be set up to take snapshots of data at regular intervals.\n\nA useful starting point is to get couchbackup to write a single backup to a file, where the file name includes the current date and time, as shown in the following example:\n\ncouchbackup --url \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\" --db \"animaldb\" > animaldb-backup-date -u \"+%Y-%m-%dT%H:%M:%SZ\".bak\n\nAfter you check the command to ensure it works correctly, it can be entered into a 'cron job':\n\n\n\n1. Install the CouchBackup tools on the server that you want to do the backups.\n2. Create a folder to store the backups.\n3. Create a 'cron entry' that describes the frequency of the backup.\n\n\n\nYou can create a cron entry by using the crontab -e command. See your system documentation for specific details on the 'cron' options.\n\nA cron entry that runs a daily backup looks similar to the following example:\n\n0 5 * * * couchbackup --url \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\" --db \"animaldb\" > \/path\/to\/folder\/animaldb-backup-date -u \"+%Y-%m-%dT%H:%M:%SZ\".bak","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"},{"document_id":"ibmcld_00445-2996-3911","score":12.5020086628,"text":"\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,\n\"database\": \"shards\/00000000-3fffffff\/acceptly\/acceptly_my_chances_logs_live.1321035717\",\n\"design_document\": \"_design\/MyChancesLogCohortReport\",\n\"started_on\": 1363273094,\n\"total_changes\": 26389\n},\n{\n\"user\": \"username\",\n\"updated_on\": 1371118433,\n\"type\": \"search_indexer\",\n\"total_changes\": 5466,\n\"node\": \"dbcore@db7.meritage.cloudant.net\",\n\"pid\": \"<0.29569.7037>\",\n\"changes_done\": 4611,\n\"database\": \"shards\/40000000-7fffffff\/username\/database_name\",\n\"design_document\": \"_design\/lucene\",\n\"index\": \"search1\",\n\"started_on\": 1371118426\n},\n{\n\"view\": 1,\n\"user\": \"acceptly\",\n\"updated_on\": 1363273504,\n\"type\": \"view_compaction\",\n\"total_changes\": 26095,\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.21218.4070>\",\n\"changes_done\": 20000,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks"},{"document_id":"ibmcld_00445-2359-3178","score":12.1881928779,"text":"\n\"checkpointed_source_seq\": \"403-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTRyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmIymg5TXDqSHIBkUj1YUxyaJkNcmvJYgCRDA5AC6tuflZhGrPsgGg9ANAJtzMkCAPFSStc\",\n\"changes_pending\": 134,\n\"pid\": \"<0.1781.4101>\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"docs_written\": 0,\n\"missing_revisions_found\": 0,\n\"replication_id\": \"d0cdbfee50a80fd43e83a9f62ea650ad+continuous\",\n\"revisions_checked\": 0,\n\"source\": \"https:\/\/repl:@tsm.cloudant.com\/tsm-admin\/\",\n\"source_seq\": \"537-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTUyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmI9mg4jXDqSHIBkUj1WTTityWMBkgwNQAqob39WYhextkE0HoBoBNo4MQsAFuVLVQ\",\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks"},{"document_id":"ibmcld_00614-4378-5507","score":11.9475806383,"text":"\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/disk_use?cluster=myclustername&format=json\"\n\nSee an example result after you request disk use data in JSON format:\n\n[\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.used)\",\n\"datapoints\":\n523562172416.0, 1391019360],\n524413976576.0, 1391019420],\n519036682240.0, 1391019480],\n518762102784.0, 1391019540],\n523719393280.0, 1391019600]\n]\n},\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.free)\",\n\"datapoints\":\n6488926978048.0, 1391019360],\n6487768301568.0, 1391019420],\n6493145661440.0, 1391019480],\n6493420257280.0, 1391019540],\n4330660167680.0, 1391019600]\n]\n}\n]\nShow more\n\n\n\n\n\n With format=raw \n\nThe raw format data contains a series of text strings, identifying the name of the metric and associated values.\n\nThe text string (for example sumSeries(net.cloudant.mycustomer001.db.df.srv.used)) is the name of the metric. The next two numbers are the start and end times, expressed as UTC epoch seconds. The final number is the step size in seconds.\n\nThe numbers after the | character contain the metric data that is obtained from your chosen endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"},{"document_id":"ibmcld_00580-24159-25838","score":11.8384195967,"text":"\nCurl comes preinstalled on most Macs and Unix-like operating systems. If it's not present on your computer, Google curl and follow the installation instructions.\n\nLet's first use curl to fetch a web page - Google's home page.\n\n\n\n1. In a command-line terminal, type curl https:\/\/www.google.com.\n\nYou get a pageful of HTML in reply.\nIf this method works, then curl is installed, and you can proceed with the next tasks. Now, we don't want to type the URL of our IBM Cloudant service every time, so let's save the IBM Cloudant URL in an environment variable-called URL.\n2. Run the export URL command to create a variable that is called URL, which we can access later.\n\nexport URL=https:\/\/username:password@host\n3. Create an alias.\n\nalias acurl=\"curl -sgH 'Content-type: application\/json'\"\n\nThis alias is a shortcut that is called acurl that saves us further typing. This acurl command is an alias for curl but with the JSON content-type header and a couple of useful command-line switches.\n4. Test the alias by fetching acurl $URL\/. We get some JSON back from IBM Cloudant.\n\nYou completed your first IBM Cloudant API call. Now, our acurl alias is set up. We can start exploring the API. Let's start with the _all_dbs endpoint, which returns a list of databases.\n5. Type acurl $URL\/_all_dbs to see an array of databases.\n\n\n\nA quick note here on formatting JSON on the command line. We can send the output of our acurl command to another tool, which formats the data nicely on the terminal. The following tools are available for your use:\n\n\n\n* Jq available from the URL on the page, which is more than just a JSON formatter - it allows JSON to be parsed, queried, and manipulated too.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00540-1225-2251","score":11.7921944861,"text":"\nFigure 1. Standard dashboard\n\nIf the Plan tab indicates that you're on the Standard plan, you don't need to read any further. You're already on a paid SLA-backed IBM Cloudant service. No further action is required.\n\n\n\n\n\n\n\n Step 2: Finding your legacy Enterprise plan \n\nYou can find your Enterprise plan in the IBM Cloudant Dashboard by following these steps.\n\n\n\n1. Open the IBM Cloudant Dashboard. For more information, see the [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-navigate-the-dashboard) tutorial.\n2. If you're using a legacy Enterprise cloudant.com account, click Account.\n3. Review your cloudant.com Enterprise account on a dedicated cluster. The view doesn't include a Usage tab and looks like the following example:\n\nZoom\n\n![Review the information about the Enterprise plan in the IBM Cloudant Dashboard under Account.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/cloudantcom_enterpriseplan_account.png)\n\nFigure 2. Enterprise plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan"},{"document_id":"ibmcld_13159-1443-3030","score":11.6236214167,"text":"\n[Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution64-serverless-webapp\/architecture-serverless-api-webapp.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user accesses the application hosted on the bucket in Object Storage\n2. The web application calls a backend API.\n3. The app with the backend API is deployed to Code Engine.\n4. The backend uses IBM Cloudant to store and retrieve guestbook entries.\n\n\n\n\n\n\n\n Step 1: Create the Guestbook database \n\nLet's start by creating a [IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) service instance. IBM Cloudant is a fully managed JSON document database. It is built upon and compatible with Apache CouchDB.\n\n\n\n1. In the [Catalog](https:\/\/cloud.ibm.com\/catalog?category=databasesservices), under Services, go to the Databases category. Click on the IBM Cloudant tile. In the new dialog:\n\n\n\n1. Under Multitenant select a region.\n2. Under Configure Cloudant instance pick a unique name for the service, such as <yourinitials>-guestbook-db.\n3. Select a resource group.\n4. Select IAM as authentication method.\n5. Select the Lite plan. If you already have a Lite plan in your account, select another service plan.\n6. Click Create.\n\n\n\n2. Back in the [IBM Cloud Resource List](https:\/\/cloud.ibm.com\/resources\/), under Services, click on the IBM Cloudant instance you created to open the instance full details page. Note: You may be required to wait until the status of the service changes to Active.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-webapp"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-1324-3123","score":26.3710814665,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":24.5852022803,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-2570-3569","score":23.410456629,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16364-32797-34928","score":22.8360143433,"text":"\n: On the Preview page, you can now upload an image of your organization's website as a background. For more information, see [Previewing and sharing your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share).\n\n\n\n\n\n 16 September 2022 \n\nSession ID information on Analyze page\n: Session ID information for conversations is now displayed on the Conversations tab of the Analyze page. You can also filter customer conversation data by the session ID. From the Conversations tab of the Analyze page, use the Keyword filter to search by session ID. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nThe ability to filter on session ID has limited support for conversations that occurred before this feature release. For all conversations that occurred before 16 September 2022, you can filter only by a single session ID at a time.\n\n\n\n\n\n 9 September 2022 \n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The options response type now has the is any of and is none of operators available. For more information, see [Operators](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nCopy actions to other assistants\n: You can copy an action from one assistant to another. When you copy an action, references to other actions, variables, and saved responses are also copied. For more information, see [Copying an action to another assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-copy-action).\n\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-34499-36597","score":22.3978399614,"text":"\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week. This feature is available with the date response type and the Current date built-in variable.\n\nFor example, you might [define a customer response](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infochoose-type) in step 1 with the date response type. When the customer responds to that step, they choose a date. You can then condition a later step on whether the date that the customer chose is Wednesday.\n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The free text response type now has the contains, does not contain, matches, and does not match operators available. For more information, see [Operators](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nExtensions support for arrays\n: Custom extensions now support passing arrays as parameters and accessing arrays in response variables. For more information, see [Calling a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extension).\n\n\n\n\n\n 26 August 2022 \n\nNew filter on the Analyze page\n: You can now filter customer conversation data by the Greet customer system action. From the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03028-7-1945","score":21.0432326806,"text":"\nImprove your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nThe Analytics page was introduced with version 1.5.0.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nMessage logs are retained for 90 days.\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_03028-1501-3230","score":20.8644813563,"text":"\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/entities_filter.png)\n\nMessages might take some time to update. Allow at least 30 minutes after a user's interaction with your assistant before attempting to filter for that content.\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.\n\nThe time that is shown for each conversation is localized to reflect the time zone of your browser. This time might differ from the timestamp shown if you review the same conversation log via an API call; API log calls are always shown in UTC.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_16364-36153-38148","score":19.9206197138,"text":"\nFrom the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string. Your list of actions filters to match what you enter.\n\n\n\n\n\n 12 August 2022 \n\nActions templates\n: When creating actions, you can choose a template that relates to the problem you\u2019re trying to solve. Templates help tailor your actions to include items specific to your business need. The examples in each template can also help you to learn how actions work. Actions templates include features such as intents, entities, condition-based responses, synonyms, response validations, and agent fallback. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\nChannel name variable\n: The Channel name integration variable lets you add step conditions using these channels: web chat, phone, SMS, WhatsApp, Slack, or Facebook Messenger. For more information, see [Adding conditions to a step](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditions).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_06953-1532-3194","score":19.8537693556,"text":"\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.\n\nThe Emphasize the answer feature is available from instances that are managed by IBM Cloud only.\n\n{\n\"aggregation\": \"\",\n\"sort\": \"\",\n\"count\": 10,\n\"return\": [],\n\"filter\": <custom_filter_specified_in_assistant>\n\"passages\": {\n\"enabled\": \"true\",\n\"fields\": [\n<search_config_body_field_specified_in_assistant>\n],\n\"characters\": 325,\n\"per_document\": true,\n\"max_per_document\": 3,\n\"find_answers\": true,\n\"max_answers_per_passage\": 1\n},\n\"highlight\": false,\n\"spelling_suggestions\": false,\n\"table_results\": {\n\"enabled\": false\n},\n\"suggested_refinements\": {\n\"enabled\": false\n}\n}\nShow more\n\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_03354-1698-3275","score":19.1343962099,"text":"\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days\nTrial | Last 30 days\nLite | Last 7 days\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/entities_filter.png)\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10070-7-1616","score":30.37424439,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05608-7-1899","score":30.3098948509,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05615-17992-19657","score":28.5476754143,"text":"\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05614-18132-19807","score":28.5311181909,"text":"\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123"},{"document_id":"ibmcld_05613-18132-19805","score":28.5311181909,"text":"\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122"},{"document_id":"ibmcld_10534-327288-328620","score":28.0100195217,"text":"\n* [Clusters in Satellite locations without CoreOS enabled](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsos-satellite-without-coreos)\n\n\n\n* [Checking a cluster's Kubernetes server version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsopenshift_server_version)\n* [Release lifecycle](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsrelease_lifecycle)\n* [Archive](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsversion-archive)\n\n\n\n[CIS Kubernetes Benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-benchmark)\n\n\n\n* [Available benchmark versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-benchmark-versions)\n* [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-benchmark-use)\n\n\n\n* [What does the benchmark cover?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-scope)\n* [What do the benchmark recommendations mean?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05616-18044-19639","score":27.9556019934,"text":"\n5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"},{"document_id":"ibmcld_05610-18106-19721","score":27.9197255704,"text":"\n5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119"},{"document_id":"ibmcld_05612-18275-19890","score":27.9197255704,"text":"\n5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_10534-364509-365767","score":27.6867641824,"text":"\n[Red Hat OpenShift on IBM Cloud version 4.10 CIS Kubernetes Benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-410)\n\n\n\n* [1 Master node security configuration](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-1-410)\n\n\n\n* [1.1 Master node configuration files](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-11-410)\n* [1.2 API server](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-12-410)\n* [1.3 Controller manager](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-13-410)\n* [1.4 Scheduler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-14-410)\n\n\n\n* [2 Etcd node configuration](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-section-2-410)\n* [3 Control plane configuration](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-section-3-410)\n\n\n\n* [3.1 Authentication and authorization](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-31-410)\n* [3.2 Logging](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410cis-benchmark-32-410)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-1672-3956","score":44.4525536965,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03729-7-2197","score":44.2026869636,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_14546-4405-6573","score":43.7844069108,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_08056-3796-5774","score":43.1386254303,"text":"\nTo upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https:\/\/cloud.ibm.com\/user\/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n\n\n\n\n How am I charged for support? \n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\n\n\n\n\n How can I upgrade my support plan? \n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\n\n\n\n\n Why can't I see my support cases? \n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-get-supportfaq"},{"document_id":"ibmcld_03729-4932-7001","score":43.0189392401,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_07578-1033424-1035350","score":42.7282687236,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1033295-1035221","score":42.7282687236,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08067-0-1736","score":42.2517645905,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_14546-6172-8106","score":40.9316369043,"text":"\nMetric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges. You can view the charges on the IBM Cloud billing and usage view along with the usage and charges from all other IBM Cloud services.\n\nIn the IBM Cloud Usage view, locate the VMware Solutions service type. Locate the Organization plan to find the Veeam and Zerto usage across all virtual data centers in that organization. The virtual data center usage is located in a separate plan for either VMware Shared on-demand or VMware Shared Reserved.\n\nVeeam\n\nZerto\n\n\n\nTable 5. Licenses and fees for Veeam\n\n Metric Frequency Description \n\n MAX_VEEAM_LICENSES Monthly Veeam license charge for every VM under backup. The monthly charge is for the highest number of VMs under backup at any time period in the month. \n TOTAL_VEEAM_BLOCK_STORAGE_GB_HOURS Hourly Charge per GB of block storage used for all backups. \n TOTAL_VEEAM_OBJECT_STORAGE_GB_HOURS Hourly Charge per GB of object storage used for all backups. \n\n\n\nNo additional Veeam or Zerto usage charges for VMware Shared are incurred.\n\nFor the Veeam service, initially, all backups go to the block storage that is closest to their VM workloads. Backups that are a part of an inactive backup chain are immediately moved to Cloud Object Storage. The restore speed for these inactive backups might be impacted.\n\nYou can change how fast the inactive backup chains are moved to Cloud Object Storage by opening an IBM Cloud for VMware Solutions service ticket.\n\n\n\n\n\n Related links \n\n\n\n* [VMware Shared overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_11730-5345-7171","score":38.936590175,"text":"\nMany extra software packages require access to or from the host, so extra software packages are not allowed to be installed.\n\nMaintenance: IBM provides software updates that you choose when to apply to the host. Because IBM is responsible for providing these updates, you cannot install extra software that is not managed by IBM. Extra software also uses mores CPU, memory, and disk storage resources on the host, which impacts the amount available to your Satellite-enabled IBM Cloud services and applications that run on the hosts.\n\n\n\n\n\n What am I charged for when I use IBM Cloud Satellite? \n\nIBM Cloud Satellite provides a convenient way for you to consume IBM Cloud services in any location that you want, with visibility across your locations. For more information, see [Pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\n\n\n What are the terms of the service level agreement? \n\nSee the [IBM Cloud terms of service](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) and the [Satellite additional service description](http:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm-8913-01).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3154648768}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06836-7-1886","score":25.7994441233,"text":"\nCustom scripts \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. You can use a configuration file (pipeline-config.yaml) to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nWhen any of the custom scripts are started, the complete URL of the custom script file, including the file name and the commit hash, is printed at the beginning of the pipeline logs as follows: The custom script can be viewed using the following link: 'https:\/\/<source repo url>\/<organization name>\/<repository name>\/blob\/<commit hash>\/.pipeline-config.yaml'. This positioning improves traceability.\n\n\n\n Stages \n\nStages in pull request, continuous integration, and continuous deployment pipelines run custom scripts.\n\n\n\n* Pull request pipeline stages: setup, test, and finish. For more information, see [Pull request pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-pr-pipeline).\n* Continuous integration pipeline stages: setup, peer-review, test, static-scan, containerize, sign-artifact, deploy, acceptance-test, scan-artifact, release, and finish. For more information, see [Continuous integration pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-ci-pipeline).\n* continuous deployment pipeline stages: setup, verify-artifact, deploy, acceptance-test, and finish. For more information, see [continuous deployment pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cd-pipeline).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_06858-0-1614","score":25.5197179923,"text":"\n\n\n\n\n\n\n  set-commit-status script \n\nThe script set status checks for commits, either for Pull (or Merge) Requests or already merged commits in a main branch.\n\nThe set-commit-status script is provided by the pipeline. It does not need to be installed. The script has the following dependencies:\n\n\n\n*  bash\n*  libstdc++ shared library\n*  libgcc shared library\n\n\n\nMake sure that the dependencies are installed in the base image that uses this tool for setting Git commit statuses.\n\n\n\n  Usage \n\nThe script set-commit-status requires the following parameters:\n\n\n\n*  --repository\nThe repository URL. Make sure that the repository is added to the toolchain as an integration.\n*  --commit-sha\nThe full SHA hash of the commit to set the status on\n*  --state\nState of the check. The state can be one of the following values: failure, pending, success, or error\n*  --description Short description of the status check\n\n\n\nThe following parameters are optional:\n\n\n\n*  --context\nContext of the check, default is devsecops\/<CUSTOM STAGE NAME>\nFor example: devsecops\/unit-tests\n*  --task-name\nCurrent pipeline task name, default is \"<CUSTOM STAGE NAME>\" For example: unit-tests\n*  --step-name\nCurrent pipeline step name, default is run-stage\n\n\n\nUse the following command to get help:\n\nset-commit-status --help\n\n\n\n  Example usage \n\nset-commit-status   --repository \"https:\/\/url-to.application-repo.git\"   --commit-sha \"49756b0c7e6e89516caa76ebbc697c2d55852fbc\"   --state \"success\"   --description \"Unit tests finished running.\"   --context \"tekton\/code-unit-tests\"   --task-name \"code-unit-tests\"   --step-name \"run-stage\"\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-set-commit-status"},{"document_id":"ibmcld_06861-14970-16613","score":25.5022379594,"text":"\nTo evaluate if you have any failures in your pipeline run, check the final step of your pipeline, which has a pipeline evaluator.\n\n\n\n\n\n Customizing the pipeline \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. Use the pipeline-config.yaml configuration file to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nFor more information on customizing the CI pipelines, see [Custom scripts](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts).\n\n\n\n\n\n Wrapping up \n\nBy completing the CI part of this tutorial, you:\n\n\n\n* Created a DevSecOps CI toolchain for Terraform.\n* Modified some code in the infrastructure code repository.\n* Ran the pr pipeline before you merge your changes.\n* Ran the ci-pipeline to build, test, and deploy your changes to your dev environment.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [Getting started with toolchains](https:\/\/cloud.ibm.com\/devops\/getting-started)\n* [Getting started with Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-getting-started)\n\n\n\n\n\n\n\n Next steps \n\nContinue to [Part 3: Set up a CD toolchain for Infrastructure as Code](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-tutorial-iac-cd).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-tutorial-iac-ci"},{"document_id":"ibmcld_00891-1673-3989","score":25.4057362137,"text":"\nFor more information about managing availability, see [How do I ensure zero downtime?](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-zero-downtime) \n\n\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\n\n Task IBM responsibilities Your responsibilities \n\n Update Delivery Pipeline images. Provide updated Delivery Pipeline job container images. These images might include updates to command tools (such as ibmcloud) that might affect the function of existing pipeline job scripts. Update Delivery Pipeline job scripts to respond to changes in underlying container images, or configure pipeline job scripts to use specific versions of container images instead of the latest version. \n Deploy apps and other workloads by using the Delivery Pipeline. Maintain the Delivery Pipeline service. Maintain the job scripts that are run by the Delivery Pipeline service, the inputs to pipeline job stages (such as source code), and the apps and other workloads that are deployed by job scripts. \n Support Delivery Pipeline private workers to allow pipeline workloads to run on customer infrastructure. Provide and maintain the private worker agent that integrates customer-managed infrastructure into the Delivery Pipeline service. Install the private worker agent into your Kubernetes cluster with enough capacity to run your pipeline workloads. Update the agent as new versions become available. \n\n\n\n\n\n\n\n Identity and access management \n\nIdentity and access management includes tasks such as authentication, authorization, access control policies, and approving, granting, and revoking access.\n\n\n\nTable 3. Responsibilities for identity and access management\n\n Task IBM responsibilities Your responsibilities \n\n Manage access to toolchains in resource groups and their associated IBM-hosted tools, except for Git Repos and Issue Tracking. N\/A Grant, revoke, and manage access to toolchains by using IBM Cloud Identity and Access Management (IAM). For more information about access management, see [Managing user access to toolchains in resource groups](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-toolchains-iam-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-responsibilities-cd"},{"document_id":"ibmcld_06885-16589-17887","score":25.3027155023,"text":"\nUse that url to verify that the app is running.\n\n\n\n\n\n Pipeline customization \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. You can use a configuration file (pipeline-config.yaml) to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nMore detailed information on customizing the CI pipelines can be found [here](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts).\n\n\n\n\n\n Wrapping up \n\nBy completing the CI part of this tutorial, you:\n\n\n\n* Created a DevSecOps CI toolchain\n* Modified some code in the application repository\n* Ran the ci-pr pipeline before you merge your changes\n* Ran the ci-pipeline to build, test, and deploy your changes to your dev environment.\n\n\n\n\n\n\n\n\n\n Next steps \n\nContinue to [Part 3: Set up a Continuous Deployment (CD) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cd-toolchain).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-ci-toolchain"},{"document_id":"ibmcld_12956-4029-5912","score":25.1151887719,"text":"\nYou can get the Git commit ID by using the command sh(returnStdout: true, script: 'Git rev-parse HEAD').trim().\n\n\n\n\n\n DevOps Insights steps \n\nThe Cloud DevOps plug-in adds four steps to Jenkins pipelines for you to use. Use these steps in your pipelines to interact with DevOps Insights. Add these steps to your pipeline definition wherever you need them to run. For example, you might upload test results after you run a test, and then evaluate those results at a gate after they are uploaded.\n\n\n\nTable 3. DevOps Insights steps and uses\n\n Step Use \n\n publishBuildRecord Publishes build information \n publishTestResult Publishes test results \n publishDeployRecord Publishes deployment records \n evaluateGate Enforces policies \n\n\n\nBy default, the version number is set to be {pipeline name}:{build number}, you can also set the custom version number in each step\n\n\n\n\n\n Sample pipeline and code \n\nHere are two complete pipeline examples that are defined as [declarative Jenkins file](https:\/\/github.com\/jenkinsci\/ibm-cloud-devops-plugin\/blob\/master\/Declarative-Jenkinsfile) and a [scripted Jenkins file](https:\/\/github.com\/jenkinsci\/ibm-cloud-devops-plugin\/blob\/master\/Scripted-Jenkinsfile).\n\nThe [Git repo](https:\/\/github.com\/devops-insights\/DemoDRA) contains a sample nodejs application code, tests, and Jenkins file that you can experiment with. Fork the repo and modify the Jenkins file with your actual information.\n\nIf you didn't install NodeJS in your Jenkins environment, you might have to install the node.js Jenkins plug-in. If you installed NodeJS, you can comment out the \"tools\" section in the Jenkins file.\n\n\n\n\n\n Viewing Build Frequency \n\nWhen this build job completes, the pipeline publishes a message to DevOps Insights that a build is complete. You can view the build record on the Build Frequency page. To view the Build Frequency page, use the following steps.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-publish-build-jenkins"},{"document_id":"ibmcld_06792-7207-8785","score":24.6974425726,"text":"\n* one-pipeline-status Set to 1 if there is a stage failure in the pipeline run.\n\n\n\nCheck these variables before calling cocoa inventory add in this stage.\n\n\n\n Example \n\n Check the status of pipeline and then release the artifacts to inventory\n\nONE_PIPELINE_STATUS=$(get_env one-pipeline-status 0)\nif [ -n \"$(get_env skip-inventory-update-on-failure \"\")\" ]; then\nif [ $ONE_PIPELINE_STATUS -eq 1 ]; then\necho \"Skipping release stage as some of the pipeline stages are not successful.\"\nexit 1\nfi\nfi\n\n\n list_artifacts returns the list of the reference names of saved artifacts\n\nlist_artifacts | while IFS= read -r artifact ; do\n\n Add a new value to the inventory repository. cocoa inventory add creates a new file with the name option,\n if does not exist otherwise overwrites it.\n\ncocoa inventory add --name=\"${artifact}\" --artifact=\"$(load_artifact $artifact name)\" --repository-url=\"$(load_repo app-repo url)\" --commit-sha=\"$(load_repo app-repo commit)\" --build-number=\"${BUILD_NUMBER}\" --pipeline-run-id=\"${PIPELINE_RUN_ID}\" --version=\"$(get_env version)\" --app-artifacts=\"{ \"signature\": \"$(load_artifact $artifact signature)\", \"provenance\": \"$(load_artifact $artifact name)\" }\"\ndone\nShow more\n\nTo use the CLI, you must install it in your scripts, or use a base image that has the CLI pre-installed.\n\n\n\n\n\n\n\n Related information \n\n\n\n* Documentation on stages for user-defined scripts\n* API documentation for pipelinectl\n* Example test script\n* Example build scripts\n* Example release script\n* The default built-in image signing script\n* The default built-in VA scan checker script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-add-pipeline-steps"},{"document_id":"ibmcld_00708-78066-79614","score":24.6377808232,"text":"\nIf your Dockerfile requires ARGS, you can use the cra-custom-script-path parameter to set an individual ARG as an environment variable before you run the command. The custom script path is the path to a script that resides in the user's project. For example, if the Dockerfile uses IAM_USER ARG, export an environment variable inside the script that is named IAM_USER: export IAM_USER='value'. If the ARG that is required by your Dockerfile is set as an environment property within toolchains, you can use get_env to get the value. In this instance, you can export an environment variable within the IAM_USER: export IAM_USER=$(get_env iam_user_environment_property_name) script. The run-cra task automatically picks up these environment variables and passes them to the Docker build commands.\n\nThe following example shows how to use the cra-custom-script to export the ENV variable:\n\n!\/usr\/bin\/env bash\n\nif [ \"${PIPELINE_DEBUG:-0}\" == 1 ]]; then\ntrap env EXIT\nenv | sort\nset -x\nfi\n\nexport IAM_USER=$(get_env iam_user_environment_property_name)\n\nYou can also use the cra-custom-script-path parameter for scenarios in which the DevSecOps base image tool versions might be outdated, based on your project. For example, you can update commands such as pip\/pip3 for discovering Python packages that require a later pip version.\n\nThe following example shows how to use the cra-custom-script to update the pip version:\n\n!\/usr\/bin\/env bash\n\nif [ \"${PIPELINE_DEBUG:-0}\" == 1 ]]; then\ntrap env EXIT\nenv | sort\nset -x\nfi\n\npython3 -m pip install --upgrade pip","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-78074-79622","score":24.6377808232,"text":"\nIf your Dockerfile requires ARGS, you can use the cra-custom-script-path parameter to set an individual ARG as an environment variable before you run the command. The custom script path is the path to a script that resides in the user's project. For example, if the Dockerfile uses IAM_USER ARG, export an environment variable inside the script that is named IAM_USER: export IAM_USER='value'. If the ARG that is required by your Dockerfile is set as an environment property within toolchains, you can use get_env to get the value. In this instance, you can export an environment variable within the IAM_USER: export IAM_USER=$(get_env iam_user_environment_property_name) script. The run-cra task automatically picks up these environment variables and passes them to the Docker build commands.\n\nThe following example shows how to use the cra-custom-script to export the ENV variable:\n\n!\/usr\/bin\/env bash\n\nif [ \"${PIPELINE_DEBUG:-0}\" == 1 ]]; then\ntrap env EXIT\nenv | sort\nset -x\nfi\n\nexport IAM_USER=$(get_env iam_user_environment_property_name)\n\nYou can also use the cra-custom-script-path parameter for scenarios in which the DevSecOps base image tool versions might be outdated, based on your project. For example, you can update commands such as pip\/pip3 for discovering Python packages that require a later pip version.\n\nThe following example shows how to use the cra-custom-script to update the pip version:\n\n!\/usr\/bin\/env bash\n\nif [ \"${PIPELINE_DEBUG:-0}\" == 1 ]]; then\ntrap env EXIT\nenv | sort\nset -x\nfi\n\npython3 -m pip install --upgrade pip","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-78017-79565","score":24.6377808232,"text":"\nIf your Dockerfile requires ARGS, you can use the cra-custom-script-path parameter to set an individual ARG as an environment variable before you run the command. The custom script path is the path to a script that resides in the user's project. For example, if the Dockerfile uses IAM_USER ARG, export an environment variable inside the script that is named IAM_USER: export IAM_USER='value'. If the ARG that is required by your Dockerfile is set as an environment property within toolchains, you can use get_env to get the value. In this instance, you can export an environment variable within the IAM_USER: export IAM_USER=$(get_env iam_user_environment_property_name) script. The run-cra task automatically picks up these environment variables and passes them to the Docker build commands.\n\nThe following example shows how to use the cra-custom-script to export the ENV variable:\n\n!\/usr\/bin\/env bash\n\nif [ \"${PIPELINE_DEBUG:-0}\" == 1 ]]; then\ntrap env EXIT\nenv | sort\nset -x\nfi\n\nexport IAM_USER=$(get_env iam_user_environment_property_name)\n\nYou can also use the cra-custom-script-path parameter for scenarios in which the DevSecOps base image tool versions might be outdated, based on your project. For example, you can update commands such as pip\/pip3 for discovering Python packages that require a later pip version.\n\nThe following example shows how to use the cra-custom-script to update the pip version:\n\n!\/usr\/bin\/env bash\n\nif [ \"${PIPELINE_DEBUG:-0}\" == 1 ]]; then\ntrap env EXIT\nenv | sort\nset -x\nfi\n\npython3 -m pip install --upgrade pip","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15130-13654-15087","score":11.4308364735,"text":"\nmessage the provided token is not authorized\n\n\n\n\n\n 403 unauthorized error when using the API \n\n\"code\":\"not_authorized\",\n\"message\":\"the provided token is not authorized to list floating-ips in this account\"\n\"trace\":\"b266a31c-b359-4ecb-8b81-a27c1b2cdb7b\"\n\n\n\n\n\n\n\n Locating context-based restriction events in Activity Tracker \n\nYou can use the value of of Trace ID or Reference ID to search in your Activity Tracker instance for the events that are generated by the context-based restrictions service. The requestData.environment section shows the source IP address of the call and other information that you can use to verify why the authorization was denied. The requestData.action and requestData.resource fields can be used determine which underlying resource was denied access.\n\nThe following is an example context-based restriction event. Some fields have been removed to improve readability.\n\n{\n\"level\": \"critical\",\n\"action\": \"context-based-restrictions.policy.eval\",\n\"message\": \"Context based restriction rendered a deny\",\n\"severity\": \"critical\",\n\"correlationId\": \"TXID-b266a31c-b359-4ecb-8b81-a27c1b2cdb7b-df2f912c-80a1-422c-8b17-6092651fea00\",\n\"requestData\": {\n\"action\": \"is.vpc.vpc.create\",\n\"reqOrder\": 0,\n\"environment\": {\n\"attributes\": {\n\"ipAddress\": \"192.168.0.1\",\n\"networkType\": \"public\"\n}\n},\n\"resource\": {\n\"attributes\": {\n\"accountId\": \"67db3d7ff3f34220b40e2d81480754c9\",\n\"resource\": \"NEWRESOURCE\",\n\"vpcId\": \"NEWRESOURCE\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=cli"},{"document_id":"ibmcld_15129-13626-15059","score":11.4308364735,"text":"\nmessage the provided token is not authorized\n\n\n\n\n\n 403 unauthorized error when using the API \n\n\"code\":\"not_authorized\",\n\"message\":\"the provided token is not authorized to list floating-ips in this account\"\n\"trace\":\"b266a31c-b359-4ecb-8b81-a27c1b2cdb7b\"\n\n\n\n\n\n\n\n Locating context-based restriction events in Activity Tracker \n\nYou can use the value of of Trace ID or Reference ID to search in your Activity Tracker instance for the events that are generated by the context-based restrictions service. The requestData.environment section shows the source IP address of the call and other information that you can use to verify why the authorization was denied. The requestData.action and requestData.resource fields can be used determine which underlying resource was denied access.\n\nThe following is an example context-based restriction event. Some fields have been removed to improve readability.\n\n{\n\"level\": \"critical\",\n\"action\": \"context-based-restrictions.policy.eval\",\n\"message\": \"Context based restriction rendered a deny\",\n\"severity\": \"critical\",\n\"correlationId\": \"TXID-b266a31c-b359-4ecb-8b81-a27c1b2cdb7b-df2f912c-80a1-422c-8b17-6092651fea00\",\n\"requestData\": {\n\"action\": \"is.vpc.vpc.create\",\n\"reqOrder\": 0,\n\"environment\": {\n\"attributes\": {\n\"ipAddress\": \"192.168.0.1\",\n\"networkType\": \"public\"\n}\n},\n\"resource\": {\n\"attributes\": {\n\"accountId\": \"67db3d7ff3f34220b40e2d81480754c9\",\n\"resource\": \"NEWRESOURCE\",\n\"vpcId\": \"NEWRESOURCE\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr"},{"document_id":"ibmcld_07390-5266-6916","score":10.6690826625,"text":"\n-i, --instance INSTANCE\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output FORMAT\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n\n\n\n\n Permitted networks \n\nManage permitted networks by using the following permitted-network commands.\n\n\n\n ibmcloud dns permitted-network-add \n\nAdd a permitted network for a DNS zone.\n\nibmcloud dns permitted-network-add ZONE_ID --vpc-crn VPC_CRN [--type TYPE] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nZONE_ID\n: The ID of the DNS zone.\n\n--type\n: The permitted network type. Valid values: vpc.\n\n--vpc-crn\n: The CRN of VPC instance\n\n-i, --instance INSTANCE\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output FORMAT\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n\n\n ibmcloud dns permitted-network \n\nGet the permitted network details.\n\nibmcloud dns permitted-network ZONE_ID PERMITTED_NETWORK_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nZONE_ID\n: The ID of the DNS zone.\n\nPERMITTED_NETWORK_ID\n: The ID of the permitted network.\n\n-i, --instance INSTANCE\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output FORMAT\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n\n\n ibmcloud dns permitted-network-remove \n\nRemove a permitted network.\n\nibmcloud dns permitted-network-remove ZONE_ID PERMITTED_NETWORK_ID [-i, --instance INSTANCE] [-f,--force]\n\n\n\n Command options \n\nZONE_ID\n: The ID of the DNS zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"},{"document_id":"ibmcld_04345-5266-6916","score":10.6690826625,"text":"\n-i, --instance INSTANCE\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output FORMAT\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n\n\n\n\n Permitted networks \n\nManage permitted networks by using the following permitted-network commands.\n\n\n\n ibmcloud dns permitted-network-add \n\nAdd a permitted network for a DNS zone.\n\nibmcloud dns permitted-network-add ZONE_ID --vpc-crn VPC_CRN [--type TYPE] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nZONE_ID\n: The ID of the DNS zone.\n\n--type\n: The permitted network type. Valid values: vpc.\n\n--vpc-crn\n: The CRN of VPC instance\n\n-i, --instance INSTANCE\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output FORMAT\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n\n\n ibmcloud dns permitted-network \n\nGet the permitted network details.\n\nibmcloud dns permitted-network ZONE_ID PERMITTED_NETWORK_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nZONE_ID\n: The ID of the DNS zone.\n\nPERMITTED_NETWORK_ID\n: The ID of the permitted network.\n\n-i, --instance INSTANCE\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output FORMAT\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n\n\n ibmcloud dns permitted-network-remove \n\nRemove a permitted network.\n\nibmcloud dns permitted-network-remove ZONE_ID PERMITTED_NETWORK_ID [-i, --instance INSTANCE] [-f,--force]\n\n\n\n Command options \n\nZONE_ID\n: The ID of the DNS zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"},{"document_id":"ibmcld_01892-78436-80608","score":10.3670278142,"text":"\nTable 83. Platform roles - Regional Backup as a Service for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can create, manage, retrieve and delete backup polices and plans, including assigning access policies to other users. \n Editor As an editor, you can create, manage, retrieve and delete backup polices and plans except for managing the account and assigning access policies. \n Operator As an operator, you can manage and operate backup polices and plans. \n Viewer As a viewer, you can retrieve backup polices and plans but you can't modify them. \n\n\n\n\n\n\n\n Bare Metal Server for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.bare-metal-server for the service name.\n\nPlatform roles\n\nService roles\n\nActions\n\n\n\nTable 84. Platform roles - Bare Metal Server for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all functions of an editor and can also assign access policies to other users. \n Editor As an editor, you can view, create, edit, delete, update, and perform operator actions on a bare metal server. \n Operator As an operator, you can view and perform actions (such as restart) on a bare metal server. \n Viewer As a viewer, you can view bare metal servers, but not modify them. \n\n\n\n\n\n\n\n Dedicated Host for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.dedicated-host for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 85. Platform roles - Dedicated Host for VPC\nUse the tab buttons to change the context of the table.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions"},{"document_id":"ibmcld_07390-69188-70579","score":10.335779069,"text":"\nibmcloud dns cross-account linked-zone-permitted-network-add LINKED_ZONE_ID --vpc-crn VPC_CRN [--type TYPE] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\n--type value\n: The permitted network type. Valid values: vpc.\n\n--vpc-crn value\n: The CRN of VPC instance.\n\n-i, --instance value\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output value\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nibmcloud dns cross-account linked-zone-permitted-network-add 5365b73c-ce6f-4d6f-ad9f-d9c131b26370 --vpc-crn \"crn:v1:bluemix:public:is:eu-de:a\/bcf1865e99742d38d2d5fc3fb80a5496::vpc:6e6cc326-04d1-4c99-a289-efb3ae4193d6\" --i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns cross-account linked-zone-permitted-network \n\nGet a permitted network for a linked zone\n\nibmcloud dns cross-account linked-zone-permitted-network LINKED_ZONE_ID PERMITTED_NETWORK_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\nPERMITTED_NETWORK_ID\n: The ID of the permitted network.\n\n-i, --instance value\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output value\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"},{"document_id":"ibmcld_04345-69168-70559","score":10.335779069,"text":"\nibmcloud dns cross-account linked-zone-permitted-network-add LINKED_ZONE_ID --vpc-crn VPC_CRN [--type TYPE] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\n--type value\n: The permitted network type. Valid values: vpc.\n\n--vpc-crn value\n: The CRN of VPC instance.\n\n-i, --instance value\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output value\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nibmcloud dns cross-account linked-zone-permitted-network-add 5365b73c-ce6f-4d6f-ad9f-d9c131b26370 --vpc-crn \"crn:v1:bluemix:public:is:eu-de:a\/bcf1865e99742d38d2d5fc3fb80a5496::vpc:6e6cc326-04d1-4c99-a289-efb3ae4193d6\" --i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns cross-account linked-zone-permitted-network \n\nGet a permitted network for a linked zone\n\nibmcloud dns cross-account linked-zone-permitted-network LINKED_ZONE_ID PERMITTED_NETWORK_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\nPERMITTED_NETWORK_ID\n: The ID of the permitted network.\n\n-i, --instance value\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target is used.\n\n--output value\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"},{"document_id":"ibmcld_07368-2864-3679","score":9.7772078696,"text":"\n\"type\": \"vpc\",\n\"value\": \"crn:v1:bluemix:public:is:us-south:a\/12ab34cd56ef78ab90cd12ef34ab56cd::vpc:r134-d98a1702-b39a-449a-86d4-ef8dbacf281e\"\n}\n]\n}\n\n{\n\"id\": \"65810ac762004f22ac19f8f8edf70a34\",\n\"crn\": \"crn:v1:bluemix:public:context-based-restrictions:global:a\/12ab34cd56ef78ab90cd12ef34ab56cd::zone:65810ac762004f22ac19f8f8edf70a34\",\n\"name\": \"example-zone\",\n\"description\": \"this is an example of zone\",\n\"account_id\": \"12ab34cd56ef78ab90cd12ef34ab56cd\",\n\"addresses\": [\n{\n\"type\": \"ipAddress\",\n\"value\": \"169.23.56.234\"\n},\n{\n\"type\": \"ipRange\",\n\"value\": \"169.23.22.0-169.23.22.255\"\n},\n{\n\"type\": \"subnet\",\n\"value\": \"192.0.2.0\/24\"\n},\n{\n\"type\": \"vpc\",\n\"value\": \"crn:v1:bluemix:public:is:us-south:a\/12ab34cd56ef78ab90cd12ef34ab56cd::vpc:r134-d98a1702-b39a-449a-86d4-ef8dbacf281e\"\n}\n],\n\"address_count\": 4,\n\"excluded_count\": 0,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-cbr"},{"document_id":"ibmcld_01892-87304-89550","score":9.4278437971,"text":"\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Load Balancer for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.load-balancer for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 93. Platform roles - Load Balancer for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Network ACL \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.network-acl for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 94. Platform roles - Network ACL\nUse the tab buttons to change the context of the table. This table has row and column headers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions"},{"document_id":"ibmcld_07390-67986-69468","score":9.4090066573,"text":"\nibmcloud dns cross-account linked-zone LINKED_ZONE_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\n-i, --instance value\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target INSTANCE is used.\n\n--output value\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nibmcloud dns cross-account linked-zone 5365b73c-ce6f-4d6f-ad9f-d9c131b26370 -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns cross-account linked-zone-delete \n\nDelete a linked zone.\n\nibmcloud dns cross-account linked-zone-delete LINKED_ZONE_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\n-i, --instance value\n: Instance name or ID. If not set, the context instance specified by ibmcloud dns instance-target INSTANCE is used.\n\n--output value\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nibmcloud dns cross-account linked-zone-delete 5365b73c-ce6f-4d6f-ad9f-d9c131b26370 -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns cross-account linked-zone-permitted-network-add \n\nCreate a permitted network for a linked zone\n\nibmcloud dns cross-account linked-zone-permitted-network-add LINKED_ZONE_ID --vpc-crn VPC_CRN [--type TYPE] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nLINKED_ZONE_ID\n: The ID of the linked zone.\n\n--type value\n: The permitted network type. Valid values: vpc.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-1541-3629","score":47.1758947947,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":47.1758947947,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04831-50613-52356","score":46.321508866,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_04991-50585-52328","score":46.321508866,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_05032-6428-8442","score":45.0559509835,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-6428-8391","score":44.0452565073,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05088-34237-35994","score":43.6863232525,"text":"\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nlog_error(\"Unable to update metadata: {0}\".format(e))\nShow more\n\n\n\n\n\n Using COPY to update metadata \n\ndef update_metadata_copy(bucket_name, item_name, key, value):\ntry:\n set the new metadata\nnew_metadata = {\nkey: value\n}\n\n set the copy source to itself\ncopy_source = {\n\"Bucket\": bucket_name,\n\"Key\": item_name\n}\n\ncos_cli.copy_object(Bucket=bucket_name, Key=item_name, CopySource=copy_source, Metadata=new_metadata, MetadataDirective=\"REPLACE\")\n\nprint(\"Metadata update (COPY) for {0} Complete!n\".format(item_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nlog_error(\"Unable to update metadata: {0}\".format(e))\nShow more\n\n\n\n\n\n\n\n Using Immutable Object Storage \n\n\n\n Add a protection configuration to an existing bucket \n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\ndef add_protection_configuration_to_bucket(bucket_name):\ntry:\nnew_protection_config = {\n\"Status\": \"Retention\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_05168-15740-17188","score":43.2706449669,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04866-3142-5463","score":43.268477661,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-3142-5463","score":43.268477661,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16233-3661-5046","score":27.6178439754,"text":"\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Building your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview)\n* [Publishing and deploying your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see IBM Cloud [Prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-browsers).\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in [Supported languages](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_16270-0-505","score":26.9990320713,"text":"\n\n\n\n\n\n\n  Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see [IBM Cloud prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overviewweb-chat-architecture-browsers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-browser-support"},{"document_id":"ibmcld_16364-48497-50555","score":25.410008749,"text":"\nFor more information, see [Migrating to the new experience](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-overview).\n\n\n\n\n\n 28 March 2022 \n\nNew service desk support reference implementation\n: You can use the reference implementation details to integrate the web chat with the Kustomer service desk. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chatdeploy-web-chat-haa).\n\n\n\n\n\n 18 March 2022 \n\nCustom extensions\n: If you need to integrate your assistant with an external service that has a REST API, you can now build a custom extension by importing an OpenAPI document. Your assistant can then send requests to the external service and receive response data it can use in the conversation. For example, you might use an extension to interact with a ticketing or customer relationship management (CRM) system, or to retrieve real-time data such as mortgage rates or weather conditions.\n\nFor more information about custom extensions, see [Building a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-custom-extension) and [Calling a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extension).\n\nConfirmation customer response type\n: The confirmation customer response type is now available. Use this response type when a customer's response must be either Yes or No. For more information, see [Confirmation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infocustomer-response-type-confirmation).\n\nSearch integration highlights text in browser\n: Search results in Watson Assistant include a link. Now, when a customer clicks the link, search results are highlighted in their browser so it\u2019s easier for them to see the relevant content. This feature is supported on Chromium browsers, including Google Chrome and Microsoft Edge.\n\n\n\n\n\n 24 February 2022 \n\nRegex customer response type\n: The regex customer response type is now available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-49884-51881","score":25.1673821832,"text":"\nUse this response type when a customer's response must be either Yes or No. For more information, see [Confirmation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infocustomer-response-type-confirmation).\n\nSearch integration highlights text in browser\n: Search results in Watson Assistant include a link. Now, when a customer clicks the link, search results are highlighted in their browser so it\u2019s easier for them to see the relevant content. This feature is supported on Chromium browsers, including Google Chrome and Microsoft Edge.\n\n\n\n\n\n 24 February 2022 \n\nRegex customer response type\n: The regex customer response type is now available. Use this response type to capture a value that must conform to a particular pattern or format, such as an email address or telephone number. For more information, see [Regex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infocustomer-response-type-regex).\n\n\n\n\n\n 17 February 2022 \n\nAdding users from the Manage menu\n: If you want to collaborate with others on your assistants, you can now quickly add users with Administrator and Manager access from the Manage menu in your assistant. For more information, see [Adding users from the Manage menu](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-controlaccess-control-add-users).\n\nPreview page share link\n: When you use the Copy link to share button to share your assistant, the shared assistant now mirrors the Preview page. If you share the assistant with a colleague, they are able to see the assistant with any customizations that you made on the Preview page.\n\n\n\n\n\n 10 February 2022 \n\nLinks in assistant responses can be configured to open in a new tab\n: When you build an action, your assistant responses can include links. If you're using web chat, you can now control whether the link opens in a new tab. To enable a link to open in a new tab, select Open link in new tab from the Insert link configuration window.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16727-72473-74518","score":25.1292664612,"text":"\n[Integrations](https:\/\/cloud.ibm.com\/images\/integrations-icon.png). On the Integrations page, you can add search, channel, and extension integrations to your assistant. For more information, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n* Where is the Assistant ID found in the new product experience?\n\n Where is the Assistant ID found in the new product experience? \n\nThe assistant ID can be found in Assistant settings.\n\nIn Assistant settings, the assistant ID is in the Assistant IDs and API details section.\n* What do the draft and live tags mean?\n\nA Draft tag indicates that the information is linked to your draft environment, which means that you can preview these updates but they are not visible to your users. A Live tag indicates that the information is linked to your live environment, which means that the content is available to your users to interact with.\n\nFor more information, see [Environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments).\n* Why can't I log in?\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-72493-74543","score":25.1089649825,"text":"\n[Integrations](https:\/\/cloud.ibm.com\/docs\/images\/integrations-icon.png). On the Integrations page, you can add search, channel, and extension integrations to your assistant. For more information, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n* Where is the Assistant ID found in the new product experience?\n\n Where is the Assistant ID found in the new product experience? \n\nThe assistant ID can be found in Assistant settings.\n\nIn Assistant settings, the assistant ID is in the Assistant IDs and API details section.\n* What do the draft and live tags mean?\n\nA Draft tag indicates that the information is linked to your draft environment, which means that you can preview these updates but they are not visible to your users. A Live tag indicates that the information is linked to your live environment, which means that the content is available to your users to interact with.\n\nFor more information, see [Environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments).\n* Why can't I log in?\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16358-5986-7953","score":24.6526437061,"text":"\nFor this tutorial, you will create an assistant with a single action. First, you must create a Watson Assistant service instance.\n\nBoth Lite and Trial plan Watson Assistant service instances are available at no cost. You will create a Trial plan.\n\n\n\n1. From a new web browser tab, return to the IBM Cloud catalog.\n\nKeep the Discovery page open in a separate tab so you can switch easiily between the two applications.\n2. From the [Watson Assistant](https:\/\/cloud.ibm.com\/catalog\/services\/watson-assistant) resource page in the IBM Cloud catalog, create a Trial plan Watson Assistant service instance in the Dallas location.\n3. From the Watson Assistant plan service page in IBM Cloud, click Launch Watson Assistant.\n\nThe Watson Assistant product user interface is displayed where you can create your first assistant.\n4. Add Discovery expert as the assistant name, and then click Next.\n5. If you are asked to share information about you and your assistant, complete the required fields, and then click Next.\n\nWhen you create an assistant, a web chat application is created for you automatically.\n6. Click Create to create the assistant and the corresponding web chat app.\n\n\n\nAfter a congratulatory message, the home page for your new assistant is displayed.\n\nZoom\n\n![Shows the assistant page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-assistant.png)\n\nFigure 4. Assistant home page\n\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_03418-4-2127","score":24.4854537423,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Web chat overview \n\nLearn more about the web chat that you can add to your company website.\n\nWeb chat is a code snippet that you can immediately embed in your website.\n\nWhen you build a custom user interface for your assistant, you spend a lot of time and effort writing code to solve typical UI problems. For example, you must keep up with browser support changes, manage scrolling behavior, validate input, and design the layout and styling. The time you spend designing and maintaing a UI can be better spent building a quality assistant instead. When you use the web chat integration, you can rely on us to manage the user interface, so you can focus on designing conversational exchanges that address the unique business needs of your customers. Cutting-edge functionality from IBM Design and Research is incorporated into the web chat to deliver an exceptional user experience.\n\nFor more information about how to deploy the web chat, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_03330-4814-6444","score":24.453706247,"text":"\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud. For more information, see IBM Cloud [Prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser Support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-browsers).\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic.\n\n\n\n\n\n Terms and notices \n\nSee [IBM Cloud Terms and Notices](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-terms) for information about the terms of service.\n\nUS Health Insurance Portability and Accountability Act (HIPAA) support is available with Enterprise with Data Isolation plans that are hosted in the Washington, DC location created on or after 1 April 2019. For more information, see [Enabling HIPAA support for your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-enabling-hipaa).\n\nTo learn more about service terms and data security, read the following information:\n\n\n\n* [Service terms](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/saas?OpenDocument) (Search for the Watson Assistant offering)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_03330-3253-5192","score":24.3555467286,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16444-7-2064","score":25.5122106455,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-1455-3632","score":23.8025075454,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16563-1598-3452","score":23.5260986004,"text":"\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor more information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16507-7-2044","score":23.312678825,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16563-3072-4738","score":22.9985759467,"text":"\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows you how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n4. Select Dictionary, then click Next.\n5. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-3021-4769","score":22.8606319357,"text":"\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16464-1626-3475","score":22.5494560552,"text":"\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n What to do next \n\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16463-4148-5042","score":21.6483255732,"text":"\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16464-4463-6317","score":21.6004195227,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16507-10816-12778","score":21.5372642265,"text":"\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.\n\nThis task shows you how to create a dictionary that is editable. If you want to upload and pre-annotate your documents with a read-only dictionary, click the Menu icon next to the Create Dictionary button, and then select Upload Dictionary.\n\n\n\n\n\n Procedure \n\nTo create an editable dictionary and pre-annotate documents, follow these steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select the Assets > Dictionaries page.\n3. Click Create Dictionary, enter a name, and then click Save.\n4. From the Entity type list, select an entity type to associate with the dictionary.\n\nYou can also associate an entity type with the dictionary from the Machine Learning Model > Pre-annotation page. Click the overflow menu button in the Dictionaries row in the page, then click Map entity types.\n5. Add entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.8529278651,"ndcg_cut_10":0.8529278651}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09120-24412-25391","score":18.1850140597,"text":"\n$ ibmcloud kp instance policy-update dual-auth-delete --enable\n\nUpdating instance policy...\nOK\n\n create a new key\n$ ibmcloud kp key create my-protected-key\n\nCreating key: 'my-protected-key', in instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nOK\nKey ID Key Name\n6a8a129b-0cd4-4667-ba57-b355a125a7ca my-protected-key\n\n list the policies for the key - dual-auth-delete is\n enabled because the key inherits the instance policy\n$ ibmcloud kp key policies 6a8a129b-0cd4-4667-ba57-b355a125a7ca --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T19:13:00Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": { \"enabled\": true\n}\n}\n]\n\n attempt to delete the key - this fails\n$ ibmcloud kp key delete 6a8a129b-0cd4-4667-ba57-b355a125a7ca","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08987-23191-24170","score":18.1850140597,"text":"\n$ ibmcloud kp instance policy-update dual-auth-delete --enable\n\nUpdating instance policy...\nOK\n\n create a new key\n$ ibmcloud kp key create my-protected-key\n\nCreating key: 'my-protected-key', in instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nOK\nKey ID Key Name\n6a8a129b-0cd4-4667-ba57-b355a125a7ca my-protected-key\n\n list the policies for the key - dual-auth-delete is\n enabled because the key inherits the instance policy\n$ ibmcloud kp key policies 6a8a129b-0cd4-4667-ba57-b355a125a7ca --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T19:13:00Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": { \"enabled\": true\n}\n}\n]\n\n attempt to delete the key - this fails\n$ ibmcloud kp key delete 6a8a129b-0cd4-4667-ba57-b355a125a7ca","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_04488-23833-24812","score":18.1850140597,"text":"\n$ ibmcloud kp instance policy-update dual-auth-delete --enable\n\nUpdating instance policy...\nOK\n\n create a new key\n$ ibmcloud kp key create my-protected-key\n\nCreating key: 'my-protected-key', in instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nOK\nKey ID Key Name\n6a8a129b-0cd4-4667-ba57-b355a125a7ca my-protected-key\n\n list the policies for the key - dual-auth-delete is\n enabled because the key inherits the instance policy\n$ ibmcloud kp key policies 6a8a129b-0cd4-4667-ba57-b355a125a7ca --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T19:13:00Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": { \"enabled\": true\n}\n}\n]\n\n attempt to delete the key - this fails\n$ ibmcloud kp key delete 6a8a129b-0cd4-4667-ba57-b355a125a7ca","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-55132-56861","score":17.9766696513,"text":"\n\"updatedBy\": \"user id ...<redacted>...\",\n\"rotation\": {\n\"interval_month\": 2\n}\n}\n]\n\n\n\n\n\n Required parameters \n\nKEY_ID\n: The ID of the key that you want to query. To retrieve a list of your available keys, run the [kp keys](#kp-keys) command.\n\n\n\n\n\n Optional parameters \n\n-m, --monthly-interval\n: Set the key rotation interval in months. The deault is 1 (one) month. The rotation interval must be 1 to 12 months.\n\n\n\n\n\n\n\n kp key restore \n\nKey Protect can restore a previously deleted root key, which restores access to its associated data in the cloud.\n\nAs an admin, you might need to restore a root key that was imported into Key Protect to access data the key previously protected.\n\nWhen you restore a key, you move the key from the Destroyed (value is 5) to the Active (value is 1) key state, and you restore access to any data that was previously encrypted with the key.\n\nYou can restore a deleted key within 30 days of its deletion. This capability is available only for root keys that were created with a key material.\n\nYou can only restore root keys that were created with a key material, using kp key create with the -k, --key-material option. You cannot restore a root key if the --key-material option was not specified.\n\nIf you want to restore a deleted root key then you must save the key material that was used to create the root key. You cannot restore a deleted key without provided the original key material.\n\nibmcloud kp key restore KEY_ID\n-i, --instance-id INSTANCE_ID\n-k, --key-material KEY_MATERIAL\n[-n, --encrypted-nonce ENCRYPTED_NONCE]\n[-v, --iv IV]\n\n\n\n Examples \n\nThese are examples of kp key restore.\n\n\n\n Example 1 \n\nThis example creates a root key using a key material, deletes the key, then restores the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09562-7597-9856","score":17.7966941057,"text":"\nOne is the entry for the deployment that lists its status as delegator. It is \"User Created\".\n\n\n\nTable 1. Example delegator Key Protect Authorization\n\n Role Source Target Type \n\n AuthorizationDelegator, Reader <cloud-databases> Service Key Protect Service User defined \n\n\n\nAnd one for the Cloud Object Storage bucket for its backups, where the deployment is the initiator.\n\n\n\nTable 2. Example Key Protect Authorization for Cloud Object Storage from Cloud Databases\n\n Role Source Target Type \n\n Reader Cloud Object Storage service Key Protect Service Created by <cloud-databases-crn> \n\n\n\n\n\n\n\n Removing Keys \n\nIAM\/Key Protect does not stop you from removing the policy between the key and Cloud Object Storage (the second example), but doing so can make your backups unrestorable. To prevent this, if you delete the Cloud Object Storage policy that governs the ability of Cloud Databases to use the key for Cloud Object Storage, the policy is re-created to continue backing up your deployment.\n\nBe careful when removing keys and authorizations. If you have multiple deployments that use the same keys, it is possible to inadvertently destroy backups to all of those deployments by revoking the delegation authorization. If possible, do not use the same key for multiple deployment's backups.\n\nIf you want to shred the backups, you can delete the key. Cloud Object Storage ensures that the storage is unreadable and unwriteable. However, any other deployments that use that same key for backups encounter subsequent backup failures.\n\nIf you do require that the same key to be used for multiple deployment's backups, removing keys and authorizations can have the following side effects.\n\n\n\n* If you delete just the Cloud Object Storage authorization (as seen in Table 2), then not only is the deployment that is shown as the creator affected, but any deployments that also use the same key are also affected. Those deployments can encounter temporary backup failures until the policy is automatically re-created. There should be no lasting effects, except for missing backups.\n* If you delete just Cloud Databases delegator authorization, which is created by you (as seen in Table 1), nothing immediately breaks because the second authorization is still in place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"},{"document_id":"ibmcld_06638-7607-9866","score":17.7966941057,"text":"\nOne is the entry for the deployment that lists its status as delegator. It is \"User Created\".\n\n\n\nTable 1. Example delegator Key Protect Authorization\n\n Role Source Target Type \n\n AuthorizationDelegator, Reader <cloud-databases> Service Key Protect Service User defined \n\n\n\nAnd one for the Cloud Object Storage bucket for its backups, where the deployment is the initiator.\n\n\n\nTable 2. Example Key Protect Authorization for Cloud Object Storage from Cloud Databases\n\n Role Source Target Type \n\n Reader Cloud Object Storage service Key Protect Service Created by <cloud-databases-crn> \n\n\n\n\n\n\n\n Removing Keys \n\nIAM\/Key Protect does not stop you from removing the policy between the key and Cloud Object Storage (the second example), but doing so can make your backups unrestorable. To prevent this, if you delete the Cloud Object Storage policy that governs the ability of Cloud Databases to use the key for Cloud Object Storage, the policy is re-created to continue backing up your deployment.\n\nBe careful when removing keys and authorizations. If you have multiple deployments that use the same keys, it is possible to inadvertently destroy backups to all of those deployments by revoking the delegation authorization. If possible, do not use the same key for multiple deployment's backups.\n\nIf you want to shred the backups, you can delete the key. Cloud Object Storage ensures that the storage is unreadable and unwriteable. However, any other deployments that use that same key for backups encounter subsequent backup failures.\n\nIf you do require that the same key to be used for multiple deployment's backups, removing keys and authorizations can have the following side effects.\n\n\n\n* If you delete just the Cloud Object Storage authorization (as seen in Table 2), then not only is the deployment that is shown as the creator affected, but any deployments that also use the same key are also affected. Those deployments can encounter temporary backup failures until the policy is automatically re-created. There should be no lasting effects, except for missing backups.\n* If you delete just Cloud Databases delegator authorization, which is created by you (as seen in Table 1), nothing immediately breaks because the second authorization is still in place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-key-protect"},{"document_id":"ibmcld_09055-95678-96988","score":17.770554624,"text":"\n] ! ! ! !\n<-- <\/section \"id=\"section-kp-registrations-example-1\" \"> --><-- <section \"id=\"section-kp-registrations-example-2\" \"> --> Example 2 This example shows the full lifecycle of two cloud resources (Cloud Object Storage and Key Protect - from creating Key Protect instances and creating a policy between them to deleting the instances.A summary of the steps is:<-- <table> -->| Step | Where | Description || ---- | ---------- | -------------------------------------------------------------------------------------------------------------------------------------------------- || 1 | CLI | Create cloud object storage (COS) and Key Protect (KP) instances || 2 | CLI | Create a policy for COS to access KP encryption keys || 3 | CLI | Create a KP root key that COS uses to encrypt data || 4 | Console UI | Create a COS bucket and specify KP encryption; this is done in the console user interface (UI) because there is no API or CLI support at this time || 5 | CLI | View the KP registration || 6 | CLI | Upload and download an object to verify COS and KP works together || 7 | CLI | Delete the COS bucket and the KP root key || 8 | CLI | Delete the authorization policy between COS and KP || 9 | CLI | Delete the COS and KP instances |<-- <\/table \"\"> -->These commands show COS and Key Protect service plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_16059-9270-11112","score":17.6422393211,"text":"\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"},{"document_id":"ibmcld_02363-4044-6106","score":17.6314562767,"text":"\nSample queries to notify on account configuration changes \n\n\n\n Notify when services are created, modified, and deleted \n\nThe following table outlines queries that you can use to alert on configuraton changes that report when services are created, modified, and deleted:\n\n\n\nTable 1. Query samples when services are created, modified, and deleted\n\n Notify on Query UI Source API hosts \n\n Create a service instance instance.create N\/A N\/A \n Create a service instance for service type instance.create You can choose a specific service in the source filter section of the UI.<br><br>For example, to notify when a Key Protect service instance is created, choose kms as the source. You can specify the service in the hosts patameter.<br><br>For example, to notify when a Key Protect service instance is created, add \"hosts\": \"kms\" \n Delete a service instance instance.delete N\/A N\/A \n Delete a service instance for service type instance.delete You can choose a specific service in the source filter section of the UI.<br><br>For example, to notify when a Key Protect service instance is deleted, choose kms as the source. You can specify the service in the hosts patameter.<br><br>For example, to notify when a Key Protect service instance is deleted, add \"hosts\": \"kms\" \n Modify a service instance instance.update N\/A N\/A \n Modify a service instance for service type instance.update You can choose a specific service in the source filter section of the UI.<br><br>For example, to notify when a Key Protect service instance is changed, choose kms as the source. You can specify the service in the hosts patameter.<br><br>For example, to notify when a Key Protect service instance is changed, add \"hosts\": \"kms\" \n Create, delete or modify any service instance instance.create OR instance.delete OR instance.update N\/A N\/A \n\n\n\n\n\n\n\n Notify when account settings are modified \n\nThe following table outlines queries that you can use to alert on configuraton changes that report when account settings are modified:\n\n\n\nTable 2. Query samples when account settings are modified","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-alerts_configuration"},{"document_id":"ibmcld_16045-9337-11274","score":17.5249787685,"text":"\nVolume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":45.2855652701,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04195-6086-8151","score":39.3993060091,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04334-33215-34565","score":37.3872118483,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04110-7-2007","score":34.9325893831,"text":"\nAuditing events for CIS \n\nAs a security officer, auditor, or manager, you can use the Activity Tracker service to track how users and applications interact with the CIS service in IBM Cloud\u00ae.\n\nIBM Cloud Activity Tracker records user-initiated activities that change the state of a service in IBM Cloud. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. For more information, see the [getting started tutorial for IBM Cloud Activity Tracker](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-getting-started).\n\nNames for auditing events changed on 1 July 2020. The change replaced all underscore (_) characters in the names with dash (-) characters.\n\n\n\n List of events: DNS domains \n\nThe following table lists the actions that are related to DNS domains and generate an event:\n\n\n\nTable 1. Actions that generate DNS domain events\n\n Action Description \n\n internet-svcs.zones.create Create a DNS domain. \n internet-svcs.zones.update Update a DNS domain. \n internet-svcs.zones.delete Delete a DNS domain. \n internet-svcs.zones-activation-check.update Perform activation check for a DNS domain. \n internet-svcs.dnssec.update Enable or disable DNSSEC for a DNS domain. \n\n\n\n\n\n\n\n List of events: DNS records \n\nThe following table lists the actions that are related to DNS records and generate an event:\n\n\n\nTable 2. Actions that generate DNS record events\n\n Action Description \n\n internet-svcs.dns-records.create Create a DNS record. \n internet-svcs.dns-records.update Update a DNS record. \n internet-svcs.dns-records.delete Delete a DNS record. \n internet-svcs.dns-records-bulk.create Import DNS records from zone file. \n\n\n\n\n\n\n\n List of events: Load balancers \n\nThe following table lists the actions that are related to load balancers and generate an event:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events"},{"document_id":"ibmcld_04195-7739-8817","score":34.1759936721,"text":"\nTo select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).\n\nDNSSec adds a layer of authentication to the internet's DNS infrastructure, which otherwise is not secure. Secure DNS guarantees that visitors are directed to your web server when they type your domain name into a web browser. All you need to do is enable DNSSec in your DNS page from your IBM CIS account and add the DS record to your registrar.\n\nYou can select View DS records to display the information needed to add the DS record to your registrar. You must copy parts of the DS record and paste them into your registrar\u2019s dashboard. Every registrar is different, and your registrar might only require you to enter information for some of the available fields.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04111-1094-2517","score":34.1543257439,"text":"\nEnable \/ Disable DNSSEC PATCH \/v1\/{crn}\/zones\/{domain_id}\/dnssec internet-svcs.reliability.update internet-svcs.dnssec.update \n\n\n\n\n\n\n\n DNS Records \n\n\n\nTable 3. DNS Records\n\n Action Method IAM ACTION AT ACTION \n\n Get DNS records GET \/v1\/{crn}\/zones\/{domain_id}\/dns_records internet-svcs.reliability.read internet-svcs.dns-records.read \n Create a DNS record POST \/v1\/{crn}\/zones\/{domain_id}\/dns_records internet-svcs.reliability.manage internet-svcs.dns-records.create \n Update a DNS record PUT \/v1\/{crn}\/zones\/{domain_id}\/dns_records\/{record_id} internet-svcs.reliability.update internet-svcs.dns-records.update \n Delete a DNS record DELETE \/v1\/{crn}\/zones\/{domain_id}\/dns_records\/{record_id} internet-svcs.reliability.manage internet-svcs.dns-records.delete \n Import DNS records from zone file GET \/v1\/{crn}\/zones\/{domain_id}\/dns_records_bulk internet-svcs.reliability.read internet-svcs.dns-records-bulk.read \n Export DNS records to a zone file POST \/v1\/{crn}\/zones\/{domain_id}\/dns_records_bulk internet-svcs.reliability.manage internet-svcs.dns-records-bulk.create \n\n\n\n\n\n\n\n GLB \n\n\n\nTable 4. GLB\n\n Action Method IAM ACTION AT ACTION \n\n Get global load balancers GET \/v1\/{crn}\/zones\/{domain_id}\/load_balancers internet-svcs.reliability.read internet-svcs.load-balancers.read \n Create a global load balancer POST \/v1\/{crn}\/zones\/{domain_id}\/load_balancers internet-svcs.reliability.manage internet-svcs.load-balancers.create","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04149-4598-6150","score":32.8668533583,"text":"\nIf you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS. See [Managing DNS records in Cloudflare](https:\/\/developers.cloudflare.com\/dns\/manage-dns-records\/how-to\/create-dns-records\/) for detailed instructions by provider.\n\nAfter you configure your registrar or DNS provider, it can take up to 24 hours for the changes to take effect. When we verify that the specified name servers were configured correctly for your domain or subdomain, the domain's status changes from Pending to Active.\n\nYour domain must move to Active state within 60 days or your domain and any configuration data is removed.\n\n\n\n\n\n Step 5. Ensure that CIS is resolving the domain information for your application, hostname, or website \n\nTo proceed, select Reliability > DNS. Be sure to add the appropriate DNS records. Add the A Record and any AAAA or MX entries that are populated. If you forget to add these records before the registrar's delegation is complete, IBM Cloud Internet Services cannot resolve the domain information for your internet-facing applications.\n\n\n\n\n\n\n\n Next steps \n\nTo begin managing CIS functions and features, see [Managing your IBM Cloud Internet Services deployment](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04148-0-1895","score":32.2962732034,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_04160-1745-2938","score":32.1857063287,"text":"\nIf a global load balancer is created with the name glbcust.ibmmo.com using the origin pool, then a client on the internet can execute the command:\n\n$ ping glbcust.ibmmo.com\nPING glbcust.ibmmo.com (169.61.244.18): 56 data bytes\n\nIn this example, CIS:\n\n\n\n* Created a DNS record named glbcust.ibmmo.com.\n* Used the global load balancer to resolve the DNS name to one of the IP addresses identified in the origin pool.\n\n\n\nNotice that the global load balancer does not terminate the TCP connection.\n\nSetting a DNS element or global load balancer to proxy changes the behavior. If, for example, you turn on proxy and Security > TLS > Mode to something besides Off, the CIS now terminates the TCP connection and establishes a second connection between CIS and the originator.\n\nIn this example, CIS:\n\n\n\n* Created a DNS record named: glbcust.ibmmo.com.\n* Used the global load balancer to resolve the DNS name to a CIS provided IP address.\n\n\n\nNow, connections to glbcust.ibmmo.com are terminated by CIS, and HTTPS certificates are hosted by CIS (which is required for TCP termination).\n\nAfter the client connects to the application the picture looks like this:\n\n[client]<--tls-->[cis]<-->[origin server]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-global-load-balancer-glb-concepts"},{"document_id":"ibmcld_07578-978380-979969","score":32.0363433959,"text":"\nYou must re-import the certificate with a different CRN, and then update the VPN server with the new certificate CRN.\n* Can I use a customized hostname for the VPN server?\n\nYes, you can. You must create a CNAME DNS record and point it to the VPN server hostname in your DNS provider. After that, edit the client profile by replacing direct remote 445df6c234345.us-south.vpn-server.appdomain.cloud with remote your-customized-hostname.com.\n\n445df6c234345.us-south.vpn-server.appdomain.cloud is an example VPN server hostname.\n\nIf you are using [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started) as your DNS provider, refer to [CNAME Type record](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-ciscname-type-record) for information about how to add a CNAME DNS record.\n* What information should I provide in an IBM Support case if I need help?\n\nSupply the following content in your [IBM Support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case):\n\n\n\n1. Your VPN server ID.\n2. Your VPN client and operating system version.\n3. The logs from your VPN client.\n4. The time range when you encountered the problem.\n5. If user-ID-based authentication is used, supply the username.\n6. If certificate-based authentication is used, supply the common name of your client certificate.\n\nTo view the common name of your client certificate, use the OpenSSL command openssl x509 -noout -text -in your_client_certificate_file in the subject section.\n\n\n\n* How do I assign the VPN client role using IAM access management tags in the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05838-12220-14151","score":15.5924373187,"text":"\nYou can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_10189-3187-5240","score":15.5179648837,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-3185-5238","score":15.5179648837,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10290-70537-72315","score":15.4186019775,"text":"\nibmcloud oc cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud oc cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud oc cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud oc cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10642-1365-3347","score":15.4141501946,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10189-1607-3670","score":15.3496743317,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-1605-3668","score":15.3496743317,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_05891-71325-73333","score":15.3175603449,"text":"\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-72055-74063","score":15.3175603449,"text":"\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10246-14143-16190","score":15.3166190995,"text":"\nCheck the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06926-3212-5298","score":18.0568112854,"text":"\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.\n* IBM Cloud customers can extend or migrate the reach of their network significantly, due to addition of new sites or applications throughout the IBM network.\n* Tenant-specific routing tables narrow the aperture for IP address overlap, without the risk of overlap with other tenants' subnets or other parts of the network that are not applicable.\n\n\n\nCompared to the older ACL model, there are a few minor tradeoffs to take into account:\n\n\n\n* Converting to a customer VRF requires a maintenance window, which causes a brief disruption of backbone traffic flows.\n* Remote access by using the managed VPN services (SSL, IPsec) is limited to just SSL VPN into a data center; however, the shared ACL over the backbone allows global access from any entry point from either service.\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_03180-11118-12801","score":17.4999578193,"text":"\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_03162-10976-13038","score":17.4502232021,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_16258-7-1952","score":17.0126293102,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":17.0033383372,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_02844-1555-3643","score":16.938558628,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_16338-2788-4628","score":16.7478386901,"text":"\n* [Confidence scores](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-confidence)\n* [Step locator](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-step-locator)\n* [Follow along](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-follow-along)\n\n\n\n\n\n Start and end of an action \n\nThe assistant marks the spots in the conversation when a customer enters an input that fits within an action. The assistant also marks when an action completes, and how it completes.\n\nCompletion options include ending:\n\n\n\n* With an end step\n* Without an end step\n* With a human agent escalation\n* With a search to a knowledge base\n\n\n\n\n\n\n\n Action confidence score \n\nEvery input that you enter that can start a new topic shows a confidence score icon. Hover over this icon to see a list of actions with different confidence scores.\n\nThese scores represent the assistant\u2019s confidence that the sentence or phrase that you entered can be solved by the steps that are built into a specific action.\n\nZoom\n\n![Debug mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/rn-debug-confidence.png)\n\nDebug mode\n\nThe top score in green represents the action with the highest confidence and the one the assistant used.\n\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_16338-4145-6019","score":15.8256384716,"text":"\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.\n\nClick the icon, and the editor shows the corresponding step in the background.\n\nZoom\n\n![Step locator](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/review-step-locator.png)\n\nStep locator\n\n\n\n\n\n Follow along \n\nFollow along connects what you are seeing in Preview with what you built in the action. As you interact with your assistant, the debug mode automatically opens each step in the background. That means you can fix an error as soon as you see it, because the editor is already open to the corresponding step.\n\n\n\n\n\n\n\n Variable values in Preview \n\nAs you test your conversation in Preview, you can check that each variable is set correctly. Click Variable values to see the values stored in each variable during the conversation. The Variable values pane has two tabs, one for action variables and one for session variables. If you are using dialog, you can see session variables for both actions and dialog on the Session variables tab.\n\nZoom\n\n![Variable values](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/variable-values-preview.png)\n\nVariable values\n\nTo learn more about variables, see [Managing information during the conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-info).\n\n\n\n\n\n Extension inspector in Preview","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_06926-4859-5591","score":15.8076728202,"text":"\nDuring conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)\n* [VPC conversion instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure&interface=uihow-you-can-initiate-the-conversion)\n* [IBM Cloud service endpoints conversion instructions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpoint)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_10143-7-2020","score":15.7491766621,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cluster_access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00510-5537-7566","score":27.1413799344,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00558-23465-25360","score":26.3292425126,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":26.3292425126,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":25.6420776074,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00510-7123-9213","score":22.5515213855,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00556-7-1696","score":22.4364003598,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00564-1452-3164","score":21.5607342352,"text":"\ncouchbackup --url \"$SERVICE_URL\" --db animaldb > backup.txt\n\nThe [NPM readme file](https:\/\/github.com\/cloudant\/couchbackup\/blob\/master\/README.md) details other options, including the ones in this list:\n\n\n\n* Environment variables to set the names of the database and URL.\n* Using a log file to record the progress of a backup.\n* The ability to resume an interrupted backup.\n\nThis option is only available with the log file for the interrupted backup.\n* Sending the backup text file to a named output file, rather than redirecting the stdout output.\n\nThe CouchBackup tools have [limitations](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoverylimitations).\n\n\n\n\n\n\n\n Restoring your IBM Cloudant data \n\nTo restore your data, use the couchrestore tool. Use couchrestore to import the backup file into a new IBM Cloudant database. Then, ensure that you build all indexes before any application tries to use the restored data.\n\nFor example, to restore the data that was backed up in the earlier example:\n\ncouchrestore --url \"https:\/\/myaccount.cloudant.com\" --db newanimaldb < backup.txt\n\nThe [NPM readme file](https:\/\/github.com\/cloudant\/couchbackup\/blob\/master\/README.md) provides details of other restore options.\n\n\n\n\n\n Limitations \n\nThe CouchBackup tools have the following limitations:\n\n\n\n* _security settings aren't backed up by the tools.\n* Attachments aren't backed up by the tools.\n* Backups aren't precise \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, data in the database can change between the times when the first and last batches are read.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"},{"document_id":"ibmcld_00629-29811-31959","score":21.4175431141,"text":"\ncurl \"$SERVICE_URL\/$DATABASE\/_changes?feed=continuous&include_docs=true&since=now&filter=mydesigndoc\/myfilter\"\n\nThe ordering of documents within the _changes feed is not always the same. In other words, changes might not appear in strict time order. The reason is that data is returned from multiple IBM Cloudant nodes, and eventual consistency rules apply.\n\n\n\n\n\n Replication pitfalls \n\nTo replicate successfully, the sum of the document size and all attachment sizes must be less than the maximum request size of the target cluster. For example, if the maximum HTTP request size is 11 MB, then the following scenarios apply:\n\n\n\nTable 1. Various scenarios based on maximum HTTP request size 11 MB\n\n Document size Attachment size Total size Replicates? \n\n 1 MB Five 2-MB attachments 11 MB Yes \n 1 MB One 10-MB attachment 11 MB Yes \n 1 MB One hundred 1-MB attachments 101 MB No \n\n\n\nSeveral considerations apply when you use replication.\n\n\n\n Incorrect user permissions \n\nFor replication to proceed optimally when you replicate from database \"a\" to database \"b\", the credentials that are supplied must have:\n\n\n\n* _reader and _replicator permissions on database \"a\".\n* _writer permissions on database \"b\".\n\n\n\nAPI keys are generated in the IBM Cloudant Dashboard or through the [API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Each key can be given individual permissions that relate to a specific IBM Cloudant database. IBM Cloudant must be able to write its checkpoint documents at the \"read\" end of replication, otherwise no state is saved and replication cannot resume from where it stopped. If the state is not saved, it can lead to performance problems when replication of large data sets resumes. The reason is that without checkpoints, the replication process restarts from the beginning each time that it is resumed.\n\n\n\n\n\n Replication document is conflicted \n\nAnother consequence of setting user permissions incorrectly is that the _replicator document becomes conflicted. The _replicator document records the current state of the replication process. In an extreme case, the document can become huge because it contains many unresolved conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_00620-9537-11012","score":21.0330019323,"text":"\nHowever, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users. The _id of the sixth document becomes the startkey of your request for the next page of results.See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=6\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\nint pageSize = 5;\nPostAllDocsOptions.Builder docsOptionsBuilder =\nnew PostAllDocsOptions.Builder()\n.db(\"orders\")\n.limit(pageSize + 1); \/\/ Fetch pageSize + 1 documents\n\nAllDocsResult response =\nservice.postAllDocs(docsOptionsBuilder.build())\n.execute()\n.getResult();\n\nwhile (response.getRows().size() > 1) {\nList<DocsResultRow> responseDocuments = response.getRows();\n\/\/ on the last page, show all documents:\nif (responseDocuments.size() <= pageSize) {\nSystem.out.println(responseDocuments);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00485-1687-3253","score":20.199919051,"text":"\nFull-text search No No Yes, requires separate installer or container. Yes \n Partition queries No No Yes Yes \n Shard splitting No No Yes Available as tool for IBM Ops. \n Selector on changes feed No Yes Yes Yes \n Rate limits No No No User-defined [provisioned throughput capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioned-throughput-capacity) settings \n Request size 4 GB (default) 4 GB (default) 4 GB (default) 11 MB \n Attachment size 4 GB (default) 4 GB (default) 4 GB (default) 10 MB \n Security auth [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [IBM Cloudant legacy auth with API Keys](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization), [IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant), or [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) \n LDAP No No No No \n\n\n\nThe CouchDB _show, _list, _update, and _rewrite functions were deprecated in Apache CouchDB 3.0. For more information, see [deprecated feature warnings](https:\/\/docs.couchdb.org\/en\/stable\/whatsnew\/3.0.htmldeprecated-feature-warnings).\n\nAs a result, these functions are no longer supported for IBM Cloudant. They do not appear in IBM Cloudant documentation, and while the APIs currently remain in service, their use is not recommended. The IBM Cloudant Support team no longer supports them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-couchdb-and-cloudant"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03353-6854-8737","score":45.086561764,"text":"\nSave the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right) or RTL (right-to-left), or select Auto which will automatically choose the text direction based on your system settings. The None option will display left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the \"Try it out\" panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03120-3469-5331","score":43.3772088835,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-3583-5403","score":43.347889527,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_02839-1790-3940","score":41.5289740112,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_09218-1677-3252","score":41.0213655839,"text":"\n* The source and target languages must be among the [List of supported languages](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslist-languages-supported).\n* The service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).\n\n\n\nThis tutorial walks you through translating documents from the command line with curl. You can also use the Watson SDKs to translate documents with a number of programming languages. For more information, see the methods in the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/language-translator).\n\n\n\n\n\n Step 1: Submit a document to translate \n\nThe following example request submits the file curriculum.html to the service and translates it from English to French. Replace {apikey} and {url} with your service credentials, and replace curriculum.html with a relative path to your file. The source and target parameters specify the languages for the translation.\n\ncurl -X POST --user \"apikey:{apikey}\" --form \"file=@curriculum.html\" --form \"source=en\" --form \"target=fr\" \"{url}\/v3\/documents?version=2018-05-01\"\n\nTo translate a document with a [custom model](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-customizing), use the model_id parameter. The following request translates the document with the custom model identified by the model ID 96221b69-8e46-42e4-a3c1-808e17c787ca. The custom model is defined for en-fr translation, so the source and target parameters are not needed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial"},{"document_id":"ibmcld_03027-6555-8367","score":40.274541537,"text":"\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right), RTL (right-to-left), or Auto (which automatically chooses the text direction based on your system settings). The None option displays left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/bidi-options.png)\n3. Click the X to close the page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_09218-7-2223","score":40.1694833554,"text":"\nTranslating documents \n\nIBM is announcing the deprecation of the IBM Watson\u00ae Language Translator service for IBM Cloud\u00ae in all regions. As of 10 June 2023, the Language Translator tile will be removed from the IBM Cloud Platform for new customers; only existing customers will be able to access the product. As of 10 June 2024, the service will reach its End of Support date. As of 10 December 2024, the service will be withdrawn entirely and will no longer be available to any customers.\n\nYou can use the IBM Watson\u00ae Language Translator service to translate files from one language to another while preserving the original document format. The service supports translation of many file formats, including Microsoft\u00ae Office\u00ae, Open Office, subtitles, and many other common formats such as HTML, JSON, XML, and Adobe\u00ae PDF.\n\n\n\n Before you begin \n\nMake sure that you have the following information and meet the following requirements:\n\n\n\n* You need your Language Translator service credentials (apikey and url).\n* The document that you want to translate must not exceed the following size limits:\n\n\n\n* 2 MB for service instances on the Lite plan\n* 20 MB for service instances on the Standard plan\n* 50 MB for service instances on the Advanced plan\n* 150 MB for service instances on the Premium plan\n\n\n\n* The document must be in one of the supported file formats. Use the correct file extension for the format of the document or specify the content type (MIME type) of the format with the request. For more information, see [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats).\n* The source and target languages must be among the [List of supported languages](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslist-languages-supported).\n* The service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).\n\n\n\nThis tutorial walks you through translating documents from the command line with curl. You can also use the Watson SDKs to translate documents with a number of programming languages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial"},{"document_id":"ibmcld_09226-3194-5240","score":39.066714771,"text":"\nFor more information, see [Before you begin](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialtranslate-prerequisites) in the topic Translating documents.\n\nNew support for additional subtitle file formats\n: The service now supports additional subtitle formats:\n\n\n\n* Apple\u00ae iTunes\u00ae Timed Text (.itt files)\n* Distribution Format Exchange Profile (.dxfp and .xml files)\n* Source Code Control (.scc files)\n* Synchronized Accessible Media Interchange (.sami and .smi files)\n* SubStation Alpha (.ssa files)\n* Time Text Markup Language (.ttml files)\n\n\n\nFor more information about all supported file formats, see [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats).\n\nIdentifying file formats for translation\n: The service accepts two forms of identification for most file formats. You can identify the format of a file that you send for translation in one of two ways:\n\n\n\n* By specifying the appropriate file extension for the format.\n* By specifying the content type (MIME type) of the format as the type of the file parameter.\n\n\n\nThe documentation lists the valid file extensions and content types for each supported format. In most cases, specifying the correct file extension is preferred because it can eliminate ambiguity and is simpler. For subtitles, the documentation makes clear where either the file extension or the content type is needed. For more information about all file formats, their file extensions and content types, and how and when to specify the file extension or content type, see [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats).\n\nDocumentation updates for bidirectional translation\n: The documentation now states that the service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_09229-1545-3258","score":38.9344218159,"text":"\n\"supported_as_target\": false,\n\"identifiable\": true\n},\n{\n\"language\": \"ar\",\n\"language_name\": \"Arabic\",\n\"native_language_name\": \"\u0627\u0644\u0639\u0631\u0628\u064a\u0629\",\n\"country_code\": \"AR\",\n\"words_separated\": true,\n\"direction\": \"right_to_left\",\n\"supported_as_source\": true,\n\"supported_as_target\": true,\n\"identifiable\": true\n},\n. . .\n]\nShow more\n\nThe list of support languages is long, reporting more than 75 languages.\n\n\n\n\n\n List of supported languages \n\nThe following table list the translatable languages. The service can translate from the following languages to any other language in the list (with the exception of Basque and Catalan). The service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).\n\nThe service use ISO two-character codes for most languages. It uses an ISO three-character code (cnr) for Montenegrin. In some cases, it uses a two-character language code and a two-character country code separated by a hyphen, such as fr-CA for French Canadian, pa-PK for Punjabi spoken in Pakistan, and zh-TW for traditional (Mandarin) Chinese spoken in Taiwan.\n\nNot all language combinations that are supported for translation are also customizable. Usually, only the combinations with English as source or target language are customizable. Click the name of a language to see the customizable translation models for that language.\n\n\n\nTable 1. Translatable languages\n\n Language Language code Language Language code \n\n [Arabic](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelsarabic) ar [Latvian](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslatvian) lv","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_16334-40704-42594","score":38.2624521356,"text":"\n* Service desk agent initials are displayed: When the web chat transfers a user to a service desk agent, the agent's avatar is displayed in the chat window to identify messages sent from the service desk agent. If the agent does not have an avatar, the first initial of the agent's given name is displayed instead.\n\n\n\n\n\n\n\n 2.0 \n\nRelease date: 16 June 2020\n\n\n\n* Versioning was added to web chat: For more information, see [Versioning](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=key-conceptsversioning).\n* Added bidirectional support: You can now use the direction parameter to choose whether to show text and elements in the web chat in right-to-left or left-to-right order. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration).\n* Introduced the instance.destroySession() method: The instance.destroySession() method removes all cookie and browser storage that is related to the current web chat session. You can use this method as part of your website logout sequence. For more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsdestroySession).\n\n\n\n\n\n\n\n 1.5.3 \n\nRelease date: 14 April 2020\n\n\n\n* The Font family field was removed from the configuration page: The text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different set of fonts, you can customize the CSS for your web chat implementation. For more information, see [Theming](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodstheming).\n* When your implementation does not specify a unique user ID, the web chat adds a first party cookie with a generated anonymous ID to use to identify the unique user. The generated cookie now expires after 45 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.6719882468}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10510-72440-73853","score":32.5663896849,"text":"\nFor proper protection and encryption, store registry credentials in [Kubernetes imagePullSecrets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryother) and other personal information in [secrets](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) instead. Remember that if personal information is stored in a previous layer of an image, deleting an image might not be sufficient to delete this personal information.\n\n\n\n\n\n Kubernetes security bulletins \n\nIf vulnerabilities are found in Kubernetes, Kubernetes releases CVEs in security bulletins to inform users and to describe the actions that users must take to remediate the vulnerability. Kubernetes security bulletins that affect Red Hat OpenShift on IBM Cloud users or the IBM Cloud platform are published in the [IBM Cloud security bulletin](https:\/\/cloud.ibm.com\/status?component=containers-kubernetes&selected=security).\n\nSome CVEs require the latest patch update for a Red Hat OpenShift version that you can install as part of the regular [cluster update process](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) in Red Hat OpenShift on IBM Cloud. Make sure to apply security patches in time to protect your cluster from malicious attacks. For more information about what is included in a security patch, refer to the [version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10400-28590-29746","score":32.3317467518,"text":"\nFor more information, see the [Security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6997115). \n Red Hat OpenShift (worker node) 4.11.26 4.12.2 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.html). \n Red Hat OpenShift Control Plane Operator v4.11.0-20230123 v4.12.0-20230124 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.12.0+20230124). \n OpenVPN Operator image v1.4.13 v1.4.20 Updated ansible-operator base image to version v1.26.1 to resolve CVEs. \n Pause container image 3.8 3.9 See the [pause container image release notes](https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/build\/pause\/CHANGELOG.md). \n Portieris admission controller v0.12.6 v0.13.3 See the [Portieris admission controller release notes](https:\/\/github.com\/IBM\/portieris\/releases\/tag\/v0.13.3). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.11.0-20230123 v4.12.0-20230124 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.12.0+20230124).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_412"},{"document_id":"ibmcld_10068-2825-4119","score":32.1454652242,"text":"\nKubernetes API server auditing configuration N\/A N\/A Updated to support verbose[Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-auditaudit-api-server). \n OpenShift Container PlatformControl Plane Operator v4.5.0-20210816 v4.5.0-20210830 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.5.0+20210830). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.5.0-20210816 v4.5.0-20210830 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.5.0+20210830). \n Red Hat OpenShift on IBM Cloud toolkit 4.5.0+20210816 4.5.0+20210830 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.5.0+20210830). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.5.41_1551_openshift, released 13 September 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 4.5.41_1551_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.5.41_1549_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10068-128438-129745","score":31.9093589531,"text":"\nIBM Cloud File Storage for Classic plug-in and monitor 375 377 Fixed a bug that prevents persistent volume claim (PVC) creation failures from being retried. Updated to use Go version 1.13.8. \n IBM Cloud RBAC Operator 8882606 d80b738 Updated image for [CVE-2020-12049](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-12049) and to use Go version 1.13.14. \n Key Management Service provider v1.0.0 v2.0.2 Updated image for [CVE-2020-15586](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-15586). \n Kubernetes configuration N\/A N\/A The Kubernetes API server audit policy configuration is updated to include auditing of all API groups except apiregistration.k8s.io and coordination.k8s.io. \n Red Hat OpenShift Control Plane Operator v4.4.0-20200615 v4.4.0-20200805 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.4.0+20200805). \n Red Hat OpenShift 4.4.11 4.4.16 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.4\/release_notes\/ocp-4-4-release-notes.htmlocp-4-4-16). \n Red Hat OpenShift on IBM Cloud toolkit v4.4.0+20200615 v4.4.0+20200805 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.4.0+20200805).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10403-99780-101211","score":31.7611952317,"text":"\nUnsupported: Although the Kubernetes [SCTP protocol](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/sctp) and [application protocol](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/application-protocol) features are generally available in the community release, creating load balancers that use these protocols is not supported in Red Hat OpenShift on IBM Cloud clusters. \n IBM Cloud File Storage for Classic plug-in and monitor 392 393 Updated universal base image (UBI) to version 8.4 to resolve CVEs. \n IBM Cloud RBAC Operator 63cd064 cfd8ae9 Update to use Go version 1.16.4. Updated universal base image (UBI) to version 8.4 to resolve CVEs. \n Red Hat OpenShift 4.6.28 (master) 4.7.12 (master) See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.7\/release_notes\/ocp-4-7-release-notes.htmlocp-4-7-12). \n Red Hat OpenShift configuration N\/A N\/A Updated the [feature gate configuration](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-settingsfeature-gates). \n Red Hat OpenShift Control Plane Operator v4.6.0-20210512 v4.7.0-20210512 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.7.0+20210512). \n OpenVPN Operator image v1.3.1 v1.3.2 Updated ansible operator base image to version 1.7.2 to resolve CVEs and updated image to implement additional IBM security controls.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_47"},{"document_id":"ibmcld_16729-139037-140928","score":31.6596017684,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Part 4: Set up a Continuous Compliance (CC) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain)Part 4: Set up a Continuous Compliance (CC) toolchain\n\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10398-54946-56132","score":31.5082579285,"text":"\nIBM Cloud Controller Manager v1.23.9-3 v1.23.11-1 Updated Go dependencies and to use Go version 1.17.13. Updated to support the Kubernetes 1.23.11 release. \n IBM Cloud File Storage for Classic plug-in and monitor 414 416 Updated to Go version 1.18.6. Updated universal base image (UBI) to version 8.6-941 to resolve CVEs. \n Key Management Service Provider v2.5.8 v2.5.9 Updated Go dependencies and to Go version 1.18.6. \n Red Hat OpenShift on IBM Cloud 4.10.26 4.10.32 See the [Red Hat OpenShift on IBM Cloud Release Notes](https:\/\/docs.openshift.com\/container-platform\/4.10\/release_notes\/ocp-4-10-release-notes.htmlocp-4-10-32). \n OpenVPN Operator image v1.4.8 v1.4.9 Updated ansible operator base image to v1.23.0 to resolve CVEs. \n Red Hat OpenShift on IBM Cloud Control Plane Operator v4.10.0-20220822 v4.10.0-20220920 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.10.0+20220920). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.10.0-20220822 v4.10.0-20220920 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.10.0+20220920).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_410"},{"document_id":"ibmcld_10405-91538-92242","score":31.4761331334,"text":"\nAdded new ibm-admin flow schema to default [Kubernetes API priority and fairness configuration](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubeapi-priority). \n Pause container image 3.5 3.6 See the [pause container image release notes](https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/build\/pause\/CHANGELOG.md). \n Red Hat OpenShift Metrics Server v4.8.0-20220107 v4.9.0-20220201 See the [Red Hat OpenShift toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.9.0+20220201). \n Red Hat OpenShift toolkit 4.8.0+20220107 4.9.0+20220201 See the [Red Hat OpenShift toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.9.0+20220201).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_49"},{"document_id":"ibmcld_10405-71914-73172","score":31.1945755699,"text":"\nIBM Cloud Controller Manager v1.22.8-7 v1.22.10-1 Updated to support the Kubernetes 1.22.10 release. \n IBM Cloud File Storage for Classic plug-in and monitor 408 410 Updated universal base image (UBI) to version 8.6-751 to resolve CVEs. \n IBM Cloud RBAC Operator 8c8c82b 8c96932 Updated Go to version 1.18.1 \n Key Management Service provider v2.5.4 v2.5.5 Updated Go to version 1.17.10 and updated the golang dependencies. \n Load balancer and load balancer monitor for IBM Cloud Provider 1916 1998 Updated Go to version 1.17.10 and updated dependencies. \n OpenVPN Operator image v1.4.3 v1.4.5 Updated base image to v1.21.0 for CVE remediation. \n Red Hat OpenShift on IBM Cloud. 4.9.28 4.9.33 See the [Red Hat OpenShift on IBM Cloud release notes](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.htmlocp-4-9-33). \n Red Hat OpenShift on IBM Cloud Control Plane Operator v4.9.0-20220412 v4.9.0-20220509 See the [Red Hat OpenShift toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.9.0+20220509). \n Red Hat OpenShift Metrics Server v4.9.0-20220412 v4.9.0-20220509 See the [Red Hat OpenShift toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.9.0+20220509).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_49"},{"document_id":"ibmcld_10070-7-1616","score":31.1084486559,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":25.6767846313,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16377-7-1723","score":24.9178931725,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_16365-7-1700","score":24.9108838372,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16366-2985-3766","score":24.8002979423,"text":"\nFor more information, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity\n: You can protect your users' private information and prevent unauthorized messages to your assistant by enabling security on the Security tab. For more information about web chat security and how it works, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16384-7-2422","score":24.6801180152,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16334-23017-24816","score":24.499820339,"text":"\n* Support for Carbon components: As part of the new styling support, you can now use [Carbon components](https:\/\/www.carbondesignsystem.com\/components\/overview\/) in user-defined responses and web chat writeable elements. These components will inherit any theming customizations you have made to the web chat.\n* New embedded script: The embedded script you use to add the web chat to your website has been updated to avoid unexpected code changes when you lock on to a web chat version. (For more information about web chat versioning, see [Versioning](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-versions).) The previous version of the script will continue to work but is now deprecated. If you want to upgrade your existing web chat deployments to use the new script, copy the updated code snippet from the Embed tab of the web chat integration settings. (Remember to reapply any customizations you have made.)\n* Removal of deprecated methods and events:\n\n\n\n* The error event has been replaced by the onError method in the [configuration object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/testfest.html?to=api-configurationconfigurationobject).\n* The getID method has been removed.\n\n\n\n* Microsoft Internet Explorer 11 is no longer a supported browser.\n\n\n\n\n\n\n\n 4.5.1 \n\nRelease date: 30 August 2021\n\n\n\n* Bug fixes for the interactive launcher beta feature. (For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16380-7-2028","score":24.4217773363,"text":"\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16368-6482-8187","score":23.8123314083,"text":"\n[development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Example: For a working example that shows how to add custom elements to the home screen, see [Home screen custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/home-screen-custom-element).\n* To change the home screen style, use [CSS helper classes](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhelper_classes).\n\n\n\nCustomizing strings\n: You can customize the strings that define the various labels and hardcoded phrases displayed by the web chat. To customize strings, use the [updateLanguagePack()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace strings in the current language pack. For more information, see [Languages](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n\nSupporting global audiences\n: By default, the strings displayed by the web chat are in English. To change to a different language, use the [updateLanguagePack()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace the current language pack with one of the available translated language packs. For more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Opening, closing, and rendering the web chat window \n\nReplacing the default launcher","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16381-0-734","score":23.7616411723,"text":"\n\n\n\n\n\n\n  Web chat development tutorials \n\nThe tutorials in this section provide detailed examples, including code snippets, showing customizations that you can implement using the web chat API.\n\nEach tutorial includes links to a [GitHub repository](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/) where you can download complete working code for the example. You can run this code to see the customization in action, adapt it for your own web chat implementation, or use it as a guide for similar customizations of your own.\n\nThe GitHub repository also includes additional tutorials and examples that have not yet been added to this documentation, so feel free to browse.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials"},{"document_id":"ibmcld_16365-10062-12114","score":23.5172583485,"text":"\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03405-1639-3425","score":26.6859420647,"text":"\nA number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?\ni'd like to come in for brunch tomorrow\ncan i reserve a table?\n5. Click the Close![Close arrow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close_arrow.png) icon to finish adding the reservation intent and its example utterances.\n\n\n\n\n\n\n\n Step 2: Add entities \n\nAn entity definition includes a set of entity values that represent vocabulary that is often used in the context of a given intent. By defining entities, you can help your assistant identify references in the user input that are related to intents of interest. In this step, you will enable system entities that can recognize references to time, date, and numbers.\n\n\n\n1. Click Entities to open the Entities page.\n2. Enable system entities that can recognize date, time, and number references in user input. Click the System entities tab, and then turn on these entities:\n\n\n\n* @sys-time\n* @sys-date\n* @sys-number\n\n\n\n\n\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots"},{"document_id":"ibmcld_03406-15133-16658","score":26.6512886316,"text":"\n`@sys-number == 0` Please specify a number that is larger than 0. Clear slot and prompt again \n `(event.previous_value != null) && (event.previous_value != event.current_value)` Ok, updating the number of guests from ` ` to ` `. Move on \n `true` Ok. The reservation is for $guests guests. Move on \n\n\n\n\n\n\n\n\n\n Step 5: Add a confirmation slot \n\nYou might want to design your dialog to call an external reservation system and actually book a reservation for the user in the system. Before your application takes this action, you probably want to confirm with the user that the dialog has understood the details of the reservation correctly. You can do so by adding a confirmation slot to the node.\n\n\n\n1. The confirmation slot will expect a Yes or No answer from the user. You must teach the dialog to be able to recognize a Yes or No intent in the user input first.\n2. Click the Intents tab to return to the Intents page. Add the following intents and example utterances.\n\n\n\n\n\n* yes\n\nYes\nSure\nI'd like that\nPlease do\nYes please.\nOk\nThat sounds good.\n\n![Shows the yes intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/slots-yes-intent.png)\n* no\n\nNo\nNo thanks.\nPlease don't.\nPlease do not!\nThat's not what I want at all\nAbsolutely not.\nNo way\n\n![Shows the no intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/slots-no-intent.png)\n\n\n\n\n\n1. Return to the Dialog tab, and then click to edit the node with slots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots-complex"},{"document_id":"ibmcld_03072-15101-16661","score":26.6260337596,"text":"\nStep 5: Add a confirmation slot \n\nYou might want to design your dialog to call an external reservation system and actually book a reservation for the user in the system. Before your application takes this action, you probably want to confirm with the user that the dialog has understood the details of the reservation correctly. You can do so by adding a confirmation slot to the node.\n\n\n\n1. The confirmation slot will expect a Yes or No answer from the user. You must teach the dialog to be able to recognize a Yes or No intent in the user input first.\n2. Click the Intents tab to return to the Intents page. Add the following intents and example utterances.\n\n\n\n\n\n* yes\n\nYes\nSure\nI'd like that\nPlease do\nYes please.\nOk\nThat sounds good.\n\n![Shows the yes intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/slots-yes-intent.png)\n* no\n\nNo\nNo thanks.\nPlease don't.\nPlease do not!\nThat's not what I want at all\nAbsolutely not.\nNo way\n\n![Shows the no intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/slots-no-intent.png)\n\n\n\n\n\n1. Return to the Dialog tab, and then click to edit the node with slots. Click Add slot to add a fourth slot, and then specify the following values for it:\n\n\n\nConfirmation slot details\n\n Check for Save it as If not present, ask \n\n `(#yes || #no) && slot_in_focus` $confirmation I'm going to reserve you a table for $guests on $date at $time. Should I go ahead? \n\n\n\nThis condition checks for either answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots-complex"},{"document_id":"ibmcld_16364-210685-212822","score":26.0299086312,"text":"\nYou cannot rename or delete an intent with this name; to change the name, export your intents to a file, rename the intent in the file, and import the updated file into your workspace. Paying customers can contact support for a database change.\n\n\n\n\n\n 1 March 2017 \n\nSystem entities are now enabled in German\n: System entities are now enabled in German.\n\n\n\n\n\n 22 February 2017 \n\nMessages are now limited to 2,048 characters\n: Messages are now limited to 2,048 characters.\n\n\n\n\n\n 3 February 2017 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* We changed how intents are scored and added the ability to mark input as irrelevant to your application. For details, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents) and search for Mark as irrelevant.\n* This release introduced a major change to the workspace. To benefit from the changes, you must manually upgrade your workspace.\n* The processing of Jump to actions changed to prevent loops that can occur under certain conditions. Previously, if you jumped to the condition of a node and neither that node nor any of its peer nodes had a condition that was evaluated as true, the system would jump to the root-level node and look for a node whose condition matched the input. In some situations this processing created a loop, which prevented the dialog from progressing.\n\n\n\nUnder the new process, if neither the target node nor its peers is evaluated as true, the dialog turn is ended. To reimplement the old model, add a final peer node with a condition of true. In the response, use a Jump to action that targets the condition of the first node at the root level of your dialog tree.\n\n\n\n\n\n 11 January 2017 \n\nCustomize node titles\n: In this release, you can customize node titles in dialog.\n\n\n\n\n\n 22 December 2016 \n\nNode title section\n: In this release, dialog nodes display a new section for node title. The ability to customize the node title is not available. When collapsed, the node title displays the node condition of the dialog node. If there is not a node condition, \"Untitled Node\" is displayed as the title.\n\n\n\n\n\n 19 December 2016","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02953-7-1500","score":25.9567799217,"text":"\nImproving your conversation \n\nTest your dialog, and organize your dialog nodes.\n\n\n\n Testing your dialog \n\nAs you make changes to your dialog, you can test it at any time to see how the dialog responds to input.\n\nQueries you submit through the Try it out pane generate \/message API calls, but they are not logged and do not incur charges.\n\n\n\n1. From the Dialog tab, click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/ask_watson.png) icon.\n2. In the chat pane, type some text and then press Enter.\n\nMake sure the system has finished training on your most recent changes before you start to test the dialog. If the system is still training, a message is displayed in the Try it out pane:\n\n![Screen capture of training message](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/training.png)\n3. Check the response to see if the dialog correctly interpreted your input and chose the appropriate response.\n\nThe chat window indicates what intents and entities were recognized in the input:\n\n![Screen capture of test dialog output](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/test_dialog_output.png)\n4. To see the top intents that were recognized in the test input along with their confidence scores, hover over the eye icon that is displayed next to the intent with the highest confidence score.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03334-11146-13005","score":25.4218620064,"text":"\n[Screen capture of correcting a recognized intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/correct_intent.png)\n4. If the input is unrelated to any of the intents in your application, you can teach your assistant that by selecting the displayed intent, and then clicking Mark as irrelevant.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/irrelevant.png)\n\nFor more information about this action, see [Teaching your assistant about topics to ignore](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-mark-irrelevant).\n\n\n\nIf your intents are not being correctly recognized, consider making the following kinds of changes:\n\n\n\n* Add the unrecognized text as an example to the correct intent.\n* Move existing examples from one intent to another.\n* Consider whether your intents are too similar, and redefine them as appropriate.\n\n\n\n\n\n\n\n Absolute scoring \n\nThe Watson Assistant service scores each intent\u2019s confidence independently, not in relation to other intents. This approach adds flexibility; multiple intents can be detected in a single user input. It also means that the system might not return an intent at all. If the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03071-1627-3396","score":25.2060833994,"text":"\nIt has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?\ni'd like to come in for brunch tomorrow\ncan i reserve a table?\n5. Click the Close![Close arrow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/close_arrow.png) icon to finish adding the reservation intent and its example utterances.\n\n\n\n\n\n\n\n Step 2: Add entities \n\nAn entity definition includes a set of entity values that represent vocabulary that is often used in the context of a given intent. By defining entities, you can help your assistant identify references in the user input that are related to intents of interest. In this step, you will enable system entities that can recognize references to time, date, and numbers.\n\n\n\n1. Click Entities to open the Entities page.\n2. Enable system entities that can recognize date, time, and number references in user input. Click the System entities tab, and then turn on these entities:\n\n\n\n* @sys-time\n* @sys-date\n* @sys-number\n\n\n\n\n\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_03006-3162-5290","score":25.1961160689,"text":"\nThe dialog gathers any information it needs to respond or perform a transaction on the user's behalf.\n\nThe dialog can interact with the following resources:\n\n\n\n* Other IBM services: Connect with additional Watson services to analyze user input, such as Speech to Text.\n* Back-end systems: Based on the user's intent and additional information, extract information or perform transactions by interacting with your back-end systems. For example, answer question, open tickets, update account information, or place orders.\n\n\n\n* Any questions that cannot be answered by the dialog skill are sent to the search skill, which finds relevant answers by searching the company knowledge bases that you configure for the purpose. The search skill routes complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from the configured data sources and returns it so the assistant can share the information with the user as its response.\n\n\n\n\n\n\n\n Implementation \n\nThis diagram shows the implementation in more detail:\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/cp4d-diagram.png)\n\nHere's how you implement your assistant:\n\n\n\n1. Create an assistant.\n2. Create a dialog skill. Use the intuitive graphical tool to define the training data and dialog for the conversation between your assistant and your customers.\n\nThe training data consists of the following artifacts:\n\n\n\n* Intents: Goals that you anticipate your users have when they interact with your assistant. Define one intent for each goal that can be identified in a user's input. For example, you might define an intent that is named store_hours that answers questions about store hours. For each intent, you add sample utterances that reflect the input customers might use to ask for the information they need, such as, What time do you open?\n\nOr use prebuilt content catalogs that are provided by IBM to get started with data that addresses common customer goals.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index"},{"document_id":"ibmcld_03381-2858-4802","score":24.6171384498,"text":"\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues \n\nHere are some solutions to typical upload issues:\n\n\n\n* If you get the message, Error. Should NOT be shorter than 1 character, then check whether your skill has a name. If not, add one.\n* The @sys-person and @sys-location system entities are no longer supported. If the skill you are uploading references them in its dialog, an error is displayed. Remove these system entities from your dialog.\n* If you receive a message that says the skill contains artifacts that exceed the limits imposed by your service plan, complete the following steps to upload the skill successfully:\n\n\n\n1. Purchase a plan with higher artifact limits.\n2. Create a service instance in the new plan.\n3. Upload the skill to the new service instance.\n4. If you don't want to keep the higher-level plan, make edits to the skill such that it meets the artifact limit requirements for the plan you want to use going forward.\n\n\n\nFor information about how to decrease the number of dialog nodes, see [How many nodes are in my dialog?](\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-count-nodes).\n\n\n\n1. Download the edited skill to export it.\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_16364-101992-104197","score":24.4295038787,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07502-3631-6171","score":32.4386705805,"text":"\nIn all cases, after the infrastructure is available, data is then restored from backup before activating the passive deployment.\n\n\n\n\n\n Activating the alternative region \n\nShould a regional outage occur, an alternative region can be activated following pre-established and tested procedures. These procedures can include deploying infrastructure in the region by using project configurations that were created and tested in advance so that error free deployments can readily be accomplished. If pre-existing projects are not maintained, project configurations can be restored from backup and modified to target the alternative region.\n\nPlatform services such as enterprise accounts, accounts, IAM, and catalog are global and thus are not affected by regional outages. The enterprise account hierarchy, private catalogs, and all IAM configuration can continue to be used unchanged during a disaster recovery process. Regional service instances that include networking, VPC, various compute, storage, and databases must be recovered in the new region.\n\n\n\n\n\n\n\n\n\n Backups \n\nBackups must be stored in a different region from the workload, and ideally in a separate backup account. This separation in location and management domain (account) minimizes the chances that an outage, operational error, or security breach that affect the workload will also affect the backup. Backup regions should be multi-zone IBM Cloud regions or highly available Satellite regions. However, each family of services on IBM Cloud has its own backup mechanism that introduces some limitations that impact this overall strategy. For more information, see [service considerations](https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdrservice-considerations).\n\nIn addition, a \"disaster recovery kit\" should be developed and stored outside of IBM Cloud. The disaster recovery kit is an off-site and protected repository that includes hardware, software, and system secure configurations, one-time keys, and the disaster recovery plan. Use this disaster recovery kit during an incident response to restore services.\n\n\n\n Infrastructure as code \n\nInfrastructure as code ensures that good backup practices are implemented in a uniform way across the organization. Include implementation of backups as part of deployable architectures. Keep backup configuration close to provisioning code so that it is easier to ensure that backups are adjusted as information system changes occur. Create and configure backup accounts as code.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"},{"document_id":"ibmcld_15051-7-1984","score":31.6295762457,"text":"\nPlanning backups \n\nWhen you plan a strategy for backing up your Block Storage for VPC volumes, you might find this checklist helpful to configure and use the backup service.\n\n\n\n Planning backups \n\nConsider the following prerequisites before you set up the VPC Backup Service.\n\n\n\nTable 1. Checklist for planning backup policies\n\n Item Considerations \n\n Cloud Identity and Access Management (IAM) Evaluate your [IAM access permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-managebaas-vpc-iam) to create and manage backups. \n Volumes Evaluate which volumes are most important to back up. You can create backups of boot and data volumes. A volume with numerous changes and a lengthy retention period requires more attention than a volume with moderate changes. Also, the cumulative size of all backups for a volume can't exceed 10 TB. \n Backup schedule Determine a backup schedule based on the type of volumes that you're backing up. For example, you might want to back up critical data that changes frequently more often than static data. \n Retention Determine a retention policy for backups in the backup plan. As subsequent backups are created, keep in mind that you incur costs for each backup that you retain. Deleting older backups keeps costs down. \n Backup plans Decide on the number of backup plans that you need for a policy. For example, you can have separate plans for daily backups, weekly, and monthly. \n Interface Choose the UI, CLI, API, or Terraform for creating and managing your backups. \n Billing Think about the number of backup snapshots that you want to take and other [billing considerations](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=apisnapshots_vpc_considerations) as the number of backup snapshots grows. \n Volume restore Evaluate when you might want to restore a volume from a backup. Keep in mind that restoring from a backup is a manual operation and not immediate such as a disaster recovery solution.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-planning"},{"document_id":"ibmcld_07578-967938-969769","score":31.5590724143,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n\n\n\n* Can I add tags to a Block Storage for VPC snapshot?\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-967814-969645","score":31.5590724143,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n\n\n\n* Can I add tags to a Block Storage for VPC snapshot?\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10006-0-857","score":30.737133135,"text":"\n\n\n\n\n\n\n  Understanding business continuity and disaster recovery for Netezza Performance Server \n\nIBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service service gets deployed in a single zone. When a zone goes down, Netezza Performance Server service is brought online into another zone by a recovery strategy.\n\n\n\n  Disaster recovery strategy \n\nNetezza Performance Server uses the cloud storage snapshot technology to provide support for business continuity and disaster recovery. A snapshot is taken every day at 2 AM. Snapshots are available across three cloud zones within the same geographical region to ensure availability if a single zone fails.\n\nIf a zone failure occurs, the disaster recovery process is automatically triggered to quickly start the service in one of the remaining zones with the latest snapshot available.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-understanding-bc-dr"},{"document_id":"ibmcld_08117-7-2019","score":30.1128372599,"text":"\nIBM Cloud Disaster Recovery (DR) and Backup and Restore \n\nLocal service interruption can be caused by many things: hardware failures, bugs, power failures, planned and unplanned maintenance. To minimize a single point of failure, IBM Cloud\u00ae architects create resilient designs that have multiple virtual server instances to provide the highest availability.\n\nHowever, extreme failure events, such as data center wide failures due to network outages, natural disasters, or ransomware are harder to anticipate and plan for. Your Business Continuity and Disaster Recovery (BCDR) plan becomes a critical part of recovering from these types of events. Business continuity focuses on the processes and procedures that you implement to help your people minimize interruptions to business operations. Disaster recovery focuses on the IT components and restoring systems after a disaster.\n\n\n\n Disaster recovery components \n\nThe DR model has two main components that deal with what can be tolerated:\n\n\n\n* Recovery Time Objective (RTO) - the maximum time that the service can be down.\n* Recovery Point Objective (RPO) - the maximum amount of data loss.\n\n\n\nZoom\n\n![DR backup diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/df269b100c3499f1efcbb7d030dce8dec25c539b\/ha-infrastructure\/images\/ha-DR-backup-diagram.svg)\n\nFigure 1. DR backup diagram\n\nThese values are directly correlated to both cost and complexity. A lower amount of time and data loss equates to higher cost and complexity.\n\n\n\n\n\n DR Strategies \n\nYou can implement your DR strategy in one of two ways:\n\n\n\n Strategy Description Benefits \n\n Cold (Active\/Standby) With a Cold DR strategy, your solution is running in one environment and duplicate resources are available on standby. When an event occurs, you react and build up the standby site. A cold strategy is a reactive approach, where the upfront cost is minimal, other than storage costs for snapshots and backups. The cold approach typically entails higher RPO\/RTO times and is simple to implement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-ha-dr-backup-restore"},{"document_id":"ibmcld_11329-3230-4614","score":30.0137356826,"text":"\nYou can implement disaster recovery mechanisms between two IBM i virtual server instances by using PowerHA geographic mirroring. For a complete tutorial, see [IBM i Disaster Recovery with IBM Power Systems Virtual Servers](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/power-iaas-tutorials\/PowerVS_IBMi_DR_Tutorial_v1.pdf).\n\n\n\n\n\n Business Continuity through backup and restore \n\nYour Power Systems Virtual Server configuration and data are not backed up automatically. You can back up your virtual server to [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) as explained in [Backup strategies for Power Systems Virtual Server](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-backup-strategies). You can also restore your virtual server in case a critical failure occurs.\n\nImporting and exporting images requires a considerable amount of processing power and network bandwidth. As a result, you can submit only one import or export request before it is queued. Typically, users import or export system disks (AIX rootvg disks) that are smaller in size (less than 1 TB) to facilitate the transfer to and from Cloud Object Storage. If your image size is greater than 1 TB, your transfer might take a long time and is prone to failure. The maximum image size that you can import or export is 10 TB.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-ha-dr"},{"document_id":"ibmcld_16632-3717-4491","score":29.6153494766,"text":"\nOpen a support ticket with details if you have time periods longer than a minute with no connectivity so that the interruptions are investigated.\n\n\n\n\n\n Disaster Recovery Strategy \n\nIBM\u00ae watsonx.data provides mechanisms to protect your data and restore service functions. Business continuity plans are in place to achieve targeted recovery point objective (RPO) and recovery time objective (RTO) for the service. The following table outlines the targets for watsonx.data.\n\n\n\nTable 2. Disaster Recovery Strategy\n\n Disaster recovery objective Target Value \n\n RPO <= 24 hours \n RTO < 24 hours \n\n\n\n\n\n\n\n Locations \n\n\n\n AWS Regions \n\n\n\n1. Oregon (us-west-2)\n2. N. Virginia (us-east-1)\n3. Frankfurt (eu-central-1)\n\n\n\n\n\n\n\n IBM Regions \n\n\n\n1. Dallas (us-south)\n2. Washington (us-east)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hadr_wxd"},{"document_id":"ibmcld_07578-891912-893651","score":28.7665800726,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":28.7665800726,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-886144-887942","score":18.8510685899,"text":"\nYou can also use the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=cliexpand-existing-boot-vol-cli) or the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=apiexpand-existing-boot-vol-api).\n* How many volumes can I provision on my account?\n\n How many volumes can I provision on my account? \n\nYou can provision up to 300 Block Storage for VPC volumes per account in a region. You can request your quota to be increased by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and specifying the region where you need more volumes. For more information about preparing a support case when you're ordering Block Storage for VPC volumes or requesting an increase to your volume or capacity limits, see [Managing volume count and capacity limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit).\n* Can I set up shared storage in a multizone cluster?\n\n Can I set up shared storage in a multizone cluster? \n\nIn the IBM Cloud\u00ae, storage options are limited to an availability zone. Do not try to manage shared storage across multiple zones.\n\nInstead, use an IBM Cloud\u00ae classic service option outside a VPC such as IBM Cloud\u00ae Object Storage or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae if you must share your data across multiple zones and regions.\n* I have volumes on the Classic infrastructure. Can I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-886021-887819","score":18.8510685899,"text":"\nYou can also use the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=cliexpand-existing-boot-vol-cli) or the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=apiexpand-existing-boot-vol-api).\n* How many volumes can I provision on my account?\n\n How many volumes can I provision on my account? \n\nYou can provision up to 300 Block Storage for VPC volumes per account in a region. You can request your quota to be increased by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and specifying the region where you need more volumes. For more information about preparing a support case when you're ordering Block Storage for VPC volumes or requesting an increase to your volume or capacity limits, see [Managing volume count and capacity limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit).\n* Can I set up shared storage in a multizone cluster?\n\n Can I set up shared storage in a multizone cluster? \n\nIn the IBM Cloud\u00ae, storage options are limited to an availability zone. Do not try to manage shared storage across multiple zones.\n\nInstead, use an IBM Cloud\u00ae classic service option outside a VPC such as IBM Cloud\u00ae Object Storage or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae if you must share your data across multiple zones and regions.\n* I have volumes on the Classic infrastructure. Can I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08127-5015-6275","score":17.9542936253,"text":"\nThis storage is limited availability and is available only in certain regions. You can learn more about file storage [here](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about).\n* Object storage stores unstructured data as objects in a flat environment. Objects also include metadata (descriptive information) and a unique ID that better handles large amounts of data with limitless scalability. Data that is stored tends to be static. Typical use cases include backups, analytics, or streaming media. You can learn more about object storage [here](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage).\n\n\n\n\n\n\n\n Additional Resources \n\n\n\n* [Step by step guide for single-zone](https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-deploy-n-tier-app-saz)\n* [Regional snapshots in 3-tier architecture](https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-regional-snapshots-3-tier-arch)\n* [Building a highly available infrastructure for 3-tier web applications in VPC](https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-ha-3-tier)\n* [Cloud reliability and disaster recovery architecture](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/resilience\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-ref-arch-saz"},{"document_id":"ibmcld_15111-4420-6168","score":17.6935275452,"text":"\nYou can also use the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=cliexpand-existing-boot-vol-cli) or the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=apiexpand-existing-boot-vol-api).\n\n\n\n\n\n How many volumes can I provision on my account? \n\nYou can provision up to 300 Block Storage for VPC volumes per account in a region. You can request your quota to be increased by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and specifying the region where you need more volumes. For more information about preparing a support case when you're ordering Block Storage for VPC volumes or requesting an increase to your volume or capacity limits, see [Managing volume count and capacity limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit).\n\n\n\n\n\n Can I set up shared storage in a multizone cluster? \n\nIn the IBM Cloud\u00ae, storage options are limited to an availability zone. Do not try to manage shared storage across multiple zones.\n\nInstead, use an IBM Cloud\u00ae classic service option outside a VPC such as IBM Cloud\u00ae Object Storage or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae if you must share your data across multiple zones and regions.\n\n\n\n\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n\n\n\n\n\n What is image from volume and how does it relate to Block Storage for VPC volumes? \n\nWith the image from volume feature, you can create a custom image directly from a Block Storage for VPC boot volume. Then, you can use the custom image to provision other virtual server instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_16208-7528-9399","score":17.5419571129,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/b293a157aaf26e34a94525b64f55b4e73b099b09\/icons\/icon_hamburger.svg) > Classic Infrastructure > Devices > your virtual server instance. Select the Storage tab, and authorize your block and file storage if not listed there.\n\n\n\n\n\n\n\n Limitations \n\nReview the following storage migration limitations:\n\n\n\n* All migrations are limited to a volume size of 2 TB only.\n* You can choose only four volumes while provisioning a virtual server instance. Only four attached volumes, in addition to your boot volume, can be migrated. If you have more than four volumes in your classic instance, see [Volume attachment limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits) for details and use the Content Data Migrator in the VPC+ tool to migrate the additional volumes.\n* Up to four primary partitions or three primary with two logical on the fourth partition can be migrated.\n* Migration of block volumes and partitions without file systems is not yet supported.\n* A maximum of 10 IOPS\/Gb mapping will be done on virtual server instances for VPC.\n* Migration of storage attached to Windows is not yet supported.\n\n\n\nAll three storage types can be migrated if your use case satisfies these limitations.\n\n\n\n\n\n Storage migration use cases \n\nConsider the following uses cases for storage migration:\n\n\n\n1. Classic virtual server instance has portable storage that is attached with Linux file systems. This is migrated as-is to VPC.\n2. Classic virtual server instance has network file storage:\n\n\n\n* An equivalent Linux file system (ext4) is created in VPC and then the contents are copied over.\n* VPC does not yet support NAS storage. Your storage will be on the Linux file system on your VPC instance, and it cannot be shared.\n\n\n\n3. Classic virtual server has network block storage (iSCSI devices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/wanclouds-vpc-plus?topic=wanclouds-vpc-plus-migration-considerations"},{"document_id":"ibmcld_04731-1340-3170","score":17.5105564109,"text":"\nSo it is necessary to add RMM server\u2019s public key to the source and target server.\n\n\n\n\n\n Where can I find IBM Cloud documentation about VMware VM (on-premises or classic) to IBM Cloud VPC migration? \n\nFor On-premises VMware VM to IBM Cloud VPC migration with RMM documentation, click [here](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpc).\n\nFor Classic VMware VM to IBM Cloud VPC migration with RMM documentation, click [here](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpc-classic).\n\n\n\n\n\n Who do I contact for support? \n\nOpen any issue directly with the RackWare support team. The support team is available 365x24x7.\n\nOpen a case by using the following options:\n\n\n\n* Email: [support@rackwareinc.com](mailto:support@rackwareinc.com)\n* Phone: +1 (844) 797-8776\n\n\n\nIn all cases, add \u2018RMM - IBM Cloud\u2019 in the subject line. The RackWare support is based in United States and India.\n\n\n\n\n\n Can I migrate on-premises VMware virtual machines to IBM Cloud VPC virtual server instances? \n\nYes, as long as connectivity is established from on-premises to the RMM server and IBM Cloud VPC.\n\n\n\n\n\n Is data migration supported for IBM File or Block performance endurance storage? \n\nOnly local storage and Block performance endurance storage is supported in IBM Cloud classic. File performance and endurance volume\u2019s data migration is not supported, for this, consider that uses a third-party tool such as rsync. A sample script that uses rsync can be found [here](https:\/\/github.com\/IBM-Cloud\/vpc-migration-tools).\n\n\n\n\n\n Is the migration intrusive? \n\nUsually the migration is nonintrusive. It can be done while the server is up and running. However, the source server does need some unused space to do the image capture of the server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-faqs-vmware"},{"document_id":"ibmcld_07578-1010354-1012159","score":17.5105564109,"text":"\nSo it is necessary to add RMM server\u2019s public key to the source and target server.\n* Where can I find IBM Cloud documentation about VMware VM (on-premises or classic) to IBM Cloud VPC migration?\n\nFor On-premises VMware VM to IBM Cloud VPC migration with RMM documentation, click [here](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpc).\n\nFor Classic VMware VM to IBM Cloud VPC migration with RMM documentation, click [here](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpc-classic).\n* Who do I contact for support?\n\nOpen any issue directly with the RackWare support team. The support team is available 365x24x7.\n\nOpen a case by using the following options:\n\n\n\n* Email: [support@rackwareinc.com](mailto:support@rackwareinc.com)\n* Phone: +1 (844) 797-8776\n\n\n\nIn all cases, add \u2018RMM - IBM Cloud\u2019 in the subject line. The RackWare support is based in United States and India.\n* Can I migrate on-premises VMware virtual machines to IBM Cloud VPC virtual server instances?\n\nYes, as long as connectivity is established from on-premises to the RMM server and IBM Cloud VPC.\n* Is data migration supported for IBM File or Block performance endurance storage?\n\nOnly local storage and Block performance endurance storage is supported in IBM Cloud classic. File performance and endurance volume\u2019s data migration is not supported, for this, consider that uses a third-party tool such as rsync. A sample script that uses rsync can be found [here](https:\/\/github.com\/IBM-Cloud\/vpc-migration-tools).\n* Is the migration intrusive?\n\nUsually the migration is nonintrusive. It can be done while the server is up and running. However, the source server does need some unused space to do the image capture of the server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1010225-1012030","score":17.5105564109,"text":"\nSo it is necessary to add RMM server\u2019s public key to the source and target server.\n* Where can I find IBM Cloud documentation about VMware VM (on-premises or classic) to IBM Cloud VPC migration?\n\nFor On-premises VMware VM to IBM Cloud VPC migration with RMM documentation, click [here](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpc).\n\nFor Classic VMware VM to IBM Cloud VPC migration with RMM documentation, click [here](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpc-classic).\n* Who do I contact for support?\n\nOpen any issue directly with the RackWare support team. The support team is available 365x24x7.\n\nOpen a case by using the following options:\n\n\n\n* Email: [support@rackwareinc.com](mailto:support@rackwareinc.com)\n* Phone: +1 (844) 797-8776\n\n\n\nIn all cases, add \u2018RMM - IBM Cloud\u2019 in the subject line. The RackWare support is based in United States and India.\n* Can I migrate on-premises VMware virtual machines to IBM Cloud VPC virtual server instances?\n\nYes, as long as connectivity is established from on-premises to the RMM server and IBM Cloud VPC.\n* Is data migration supported for IBM File or Block performance endurance storage?\n\nOnly local storage and Block performance endurance storage is supported in IBM Cloud classic. File performance and endurance volume\u2019s data migration is not supported, for this, consider that uses a third-party tool such as rsync. A sample script that uses rsync can be found [here](https:\/\/github.com\/IBM-Cloud\/vpc-migration-tools).\n* Is the migration intrusive?\n\nUsually the migration is nonintrusive. It can be done while the server is up and running. However, the source server does need some unused space to do the image capture of the server.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16209-2868-4796","score":17.4637685528,"text":"\nIBM Cloud Object Storage and resource instance ID (service credentials) Your Object Storage bucket is used to store your images and volumes during the migration process and its resource instance ID allows VPC+ Cloud Migration to access your IBM Cloud Object Storage and import the images that you want to migrate. For more information, see [IBM Cloud Object Storage getting started tutorial](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) and [Service credentials](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials). \n (Optional) VRA (Vyatta 5600) configuration file If you want to migrate your Access Control Lists, VPN gateways, and public gateways, you need a VRA set command configuration file in txt format. JSON format is not supported. \n\n\n\n\n\n\n\n Establishing connection between classic and VPC \n\nIn some cases, resources in VPC still might need to access resources back in classic, such as databases or interprocess communication. In these cases, creating a transit gateway provides a bridge between the two environments. The VPC+ tool can help create the transit gateway, or you can create it through the IBM Cloud. If you want to learn more, see [About IBM Cloud Transit Gateway](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-about).\n\nReview the [Planning for IBM Cloud Transit Gateway](https:\/\/cloud.ibm.com\/docs\/wanclouds-vpc-plus?topic=transit-gateway-helpful-tips) information if you want to establish a connection between your VPC and classic infrastructure.\n\nFor IBM Cloud Transit Gateway use cases, check out the following information:\n\n\n\n* [Interconnect one or more VPCs in the same MZR and an IBM classic network](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-aboutuse-case-3-interconnect-one-or-more-vpcs-in-the-same-mzr-and-an-ibm-classic-network)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/wanclouds-vpc-plus?topic=wanclouds-vpc-plus-planning-for-migration"},{"document_id":"ibmcld_10631-0-973","score":16.4225119125,"text":"\n\n\n\n\n\n\n  Why can't I create Block Storage for VPC snapshots? \n\nInfrastructure provider: VPC\n\n  What\u2019s happening \n\nYou are unable to create volumesnapshots.\n\n  Why it\u2019s happening \n\nThere are several reasons why you might not be able to create snapshots. To debug the issue, complete the following steps to gather the required log files before contacting support.\n\n\n\n1.  Describe your volumesnapshot and review the status.\n\nkubectl describe volumesnapshot VOLUMESNAPSHOT\n2.  Get the logs of the ibm-vpc-block-csi-controller-0 driver and sidecar.\n\nkubectl logs -n kube-system ibm-vpc-block-csi-controller-0 -c csi-snapshotter\n\nkubectl logs -n kube-system ibm-vpc-block-csi-controller-0 -c iks-vpc-block-driver\n\nkubectl logs -n kube-system ibm-vpc-block-csi-controller-0\n3.  Open a [support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-storage-snapshotfails"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14546-2844-4906","score":24.4478170665,"text":"\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.\n\n\n\n\n\n\n\n VMware Shared on-demand billing plan \n\nVMware Shared on-demand virtual data center resources are allocated as needed. Pricing is hourly based on the resource usage in the virtual data center. The following metrics are part of this plan.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 2. VMware Shared Solutions On-demand billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_BASE_COST Monthly Virtual data center price, which includes the edge gateway with five IP addresses. \n TOTAL_VCPU_HOURS Hourly The peak vCPU usage over the period of an hour. \n TOTAL_RAM_GB_HOURS Hourly The peak memory usage over the period of an hour. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of an hour. This value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_12815-5234-7392","score":24.0905339048,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_14546-4405-6573","score":23.211585118,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_02665-3418-5653","score":22.1720493443,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_03729-1672-3956","score":22.0380659315,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-5228-7163","score":21.8502697774,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-7965-9641","score":21.7807407088,"text":"\nTier 3: 2001 - 3000 $0.75 USD \n Tier 4: 3001 - 4000 $0.60 USD \n Tier 5: > 4000 $0.40 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a graduated tier pricing model:\n\n\n\nTable 5. Charge calculation by using the graduated tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 500 \u00d7 1 (unit price for Tier 1) = 500 $500 USD \n 1500 (1000 \u00d7 1 (unit price for Tier 1)) + (500 \u00d7 0.90 (unit price for Tier 2)) = 1450 $1450 USD \n 2500 (1000 \u00d7 1 (unit price for Tier 1)) + (1000 \u00d7 0.90 (unit price for Tier 2)) + (500 \u00d7 0.75 (unit price for Tier 3)) = 2275 $2275 USD \n ... ... ... \n 5200 (1000 \u00d7 1 (unit price for Tier 1)) + (1000 \u00d7 0.90 (unit price for Tier 2)) + (1000 \u00d7 0.75 (unit price for Tier 3)) + (1000 \u00d7 0.60 (unit price for Tier 4)) + (1200 \u00d7 0.40 (unit price for Tier 5)) = 3730 $3730 USD \n\n\n\n\n\n\n\n Block tier \n\nIn the block tier model, the price is a set charge for the quantity you use within a usage level. The total price is the charge for your level of usage regardless of your actual usage. Each successive tier provides a lower price to quantity ratio. For example:\n\n\n\nTable 6. Block tier pricing table\n\n Quantity of Items Total Price for All Items \n\n Tier 1: <= 1000 $1000 USD \n Tier 2: <= 2000 $1900 USD \n Tier 3: <= 3000 $2800 USD \n Tier 4: <= 4000 $3500 USD \n Tier 5: <= 10000 $5000 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a block tier pricing model:\n\n\n\nTable 7. Charge calculation by using the block tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 The number of items falls into Tier 1, so the total price is $1000 USD. $1000 USD","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03729-6519-8345","score":21.5295935784,"text":"\nHowever, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items \n\n Tier 1: 1 - 1000 $1 USD \n Tier 2: 1001 - 2000 $0.90 USD \n Tier 3: 2001 - 3000 $0.75 USD \n Tier 4: 3001 - 4000 $0.60 USD \n Tier 5: > 4000 $0.40 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a simple tier pricing model:\n\n\n\nTable 3. Charge calculation by using the simple tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 500 \u00d7 1 = 500 $500 USD \n 1500 1500 \u00d7 0.90 = 1350 $1350 USD \n 2500 2500 \u00d7 0.75 = 1875 $1875 USD \n ... ... ... \n 5200 5200 \u00d7 0.40 = 2080 $2080 USD \n\n\n\n\n\n\n\n Graduated tier \n\nIn the graduated tier model, the unit price per tier decreases as your level of usage increases. The total price is the cumulative charges for each level of usage, consisting of your quantity multiplied by the unit price at that tier, for example:\n\n\n\nTable 4. Graduated tier pricing table\n\n Quantity of Items Unit Price for Items in the Tier \n\n Tier 1: 1 - 1000 $1 USD \n Tier 2: 1001 - 2000 $0.90 USD \n Tier 3: 2001 - 3000 $0.75 USD \n Tier 4: 3001 - 4000 $0.60 USD \n Tier 5: > 4000 $0.40 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a graduated tier pricing model:\n\n\n\nTable 5. Charge calculation by using the graduated tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 500 \u00d7 1 (unit price for Tier 1) = 500 $500 USD","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_02665-5090-7240","score":21.2175111469,"text":"\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usagefaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usagefaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_08067-0-1736","score":20.9930871381,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00620-14227-15704","score":32.4417927072,"text":"\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- <\/section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00462-1307-2903","score":31.5425151883,"text":"\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https:\/\/pypi.org\/project\/ibmcloudant\/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https:\/\/www.python.org\/about\/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https:\/\/github.com\/IBM\/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https:\/\/pkg.go.dev\/mod\/github.com\/IBM\/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com\/IBM\/cloudant-go-sdk\/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https:\/\/github.com\/ibm\/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant\/couchbackup\n\nFor more information, see [couchbackup](https:\/\/github.com\/cloudant\/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https:\/\/curl.haxx.se\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-libraries"},{"document_id":"ibmcld_00589-18424-20018","score":29.6664322387,"text":"\n* [cloudant-java-sdk](https:\/\/github.com\/IBM\/cloudant-java-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Java, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javaauthentication).\n\n\n\n\n\n Node.js \n\nThe following link provides the latest supported version of the IBM Cloudant Node.js library:\n\n\n\n* [cloudant-node-sdk](https:\/\/github.com\/IBM\/cloudant-node-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Node, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=nodeauthentication).\n\n\n\n\n\n Python \n\nThe following link provides the latest supported version of the IBM Cloudant Python library:\n\n\n\n* [cloudant-python-sdk](https:\/\/github.com\/IBM\/cloudant-python-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Python, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=pythonauthentication).\n\n\n\n\n\n Go \n\nThe following link provides the latest supported version of the IBM Cloudant Go library:\n\n\n\n* [go-sdk](https:\/\/github.com\/IBM\/cloudant-go-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Go, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication).\n\n\n\n\n\n\n\n Access by using HTTP client \n\nIBM Cloud IAM requires that an IAM API key is exchanged for a time-limited access token before you make a request to a resource or service. The access token is then included in the Authorization HTTP header to the service. When the access token expires, the client must handle getting a new one from the IAM token service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_00462-7-1647","score":28.7810653658,"text":"\nClient libraries \n\nClient libraries are the tools that you use to develop your own applications to work with IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases.\n\nThe following client libraries are formally supported by IBM Cloudant: Java\u2122, Node.js, Python, and Go.\n\nA supported library is one where you can contact IBM Cloudant if you come across a specific, reproducible problem in the current version of the library.\n\n\n\n Java \n\nThe IBM Cloudant SDK for Java\u2122 is the official IBM Cloudant library for Java\u2122.\n\nTo install the IBM Cloudant SDK for the Java\u2122 library, see [Installation](https:\/\/github.com\/ibm\/cloudant-java-sdkinstallation) about installing the library by adding it as a dependency to your Maven or Gradle builds. You can also see details and examples of how to use the library in the guide.\n\n\n\n Library for Java \n\n\n\n* [IBM Cloudant SDK for Java\u2122](https:\/\/github.com\/ibm\/cloudant-java-sdk)\n\n\n\n\n\n\n\n\n\n Node.js \n\nThe IBM Cloudant SDK for the Node.js library is the official IBM Cloudant library for Node.js.\n\nInstall the [IBM Cloudant SDK for Node.js](https:\/\/www.npmjs.com\/package\/@ibm-cloud\/cloudant) library by running the following command:\n\nnpm install @ibm-cloud\/cloudant\n\n\n\n Library for Node.js \n\n\n\n* [IBM Cloudant SDK for Node.js](https:\/\/github.com\/ibm\/cloudant-node-sdk)\n\n\n\n\n\n\n\n\n\n Python \n\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https:\/\/pypi.org\/project\/ibmcloudant\/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-libraries"},{"document_id":"ibmcld_00510-7-1689","score":27.6454742303,"text":"\nData modeling \n\nThe Data modeling document is the first best practice document in the series. It shows you the following best practices:\n\n\n\n* What you need to know about your APIs.\n* How to model your data.\n* What size documents you must use.\n* What to avoid.\n* How to configure your databases.\n\n\n\nFor more information, see [Indexing and querying](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the API that you are targeting \n\nYou can use [Java\u2122](https:\/\/github.com\/IBM\/cloudant-java-sdk), [Python](https:\/\/github.com\/IBM\/cloudant-python-sdk), [Go](https:\/\/github.com\/IBM\/cloudant-go-sdk), or [Node.js](https:\/\/github.com\/IBM\/cloudant-node-sdk) or some other use-case-specific language or platform. One of these languages most likely comes with convenient client-side libraries that integrate IBM Cloudant access nicely, following the conventions that you expect for your tools. These languages are great for programmer efficiency, but they also hide the API from view.\n\nThis abstraction is what you want, the whole reason for using a client library is to save yourself repeated, tedious boiler-plating. However, you must understand the underlying API is vital when you troubleshoot and report problems. When you report a suspected problem to IBM Cloudant, it helps us help you if you can provide a way for us to reproduce the problem.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00620-8515-9974","score":27.4773483249,"text":"\npanic(err)\n}\nb, _ := json.MarshalIndent(allDocsResult3, \"\", \" \")\nfmt.Println(string(b))\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\n)\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! ! for examples.This practice means you define the size of the data set and the range of the _id field to return, but that isn't quite the same as pagination.The startkey\/endkey values are in double quotation marks because they're expected to be JSON-encoded and JSON.stringify('order00077') === \"order00077\".<-- <\/section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --><-- <section \"id=\"section-pagination-options\" \"> --> Pagination options For performance reasons, if you are displaying large amounts of data, you must consider using pagination. In these examples, documents are fetched in blocks of five. However, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00512-21543-22914","score":27.382625493,"text":"\npostPartitionAllDocsOptions := service.NewPostPartitionAllDocsOptions(\n\"readings\",\n\"bridge-9876\",\n)\npostPartitionAllDocsOptions.SetIncludeDocs(true)\n\nallDocsResult, response, err := service.PostPartitionAllDocs(postPartitionAllDocsOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(allDocsResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n Finding recent readings for a piece of infrastructure \n\nThis query needs to use [the partitioned timestamped-readings index](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioningcreating-a-paritioned-ibm-cloudant-query-index). You can issue a query to the partition to get the readings for today, assuming today is 13 December 2018.\n\nThe partition is embedded in the HTTP path when you issue the request to IBM Cloudant:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL\/readings\/_partition\/bridge-9876\/_find\" -H 'Content-Type:\napplication\/json' --data '{\n\"selector\": {\n\"ts\": { \"$gte\": \"20181213\"}\n}\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00512-19432-20915","score":27.1996373773,"text":"\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/v5\/core\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n\n\n\n\n Making queries \n\nOverall, you want to make four queries:\n\n\n\n1. Readings for all time for a piece of infrastructure.\n2. Readings for today for a piece of infrastructure.\n3. Readings for all time for a specific device.\n4. Readings for today for a specific device.\n\n\n\n\n\n Finding all readings for a piece of infrastructure \n\nThese partitions are infrastructure-based, so you can use _all_docs for a partition. For example, query all readings for the bridge-9876 infrastructure piece by using the following command.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL\/readings\/_partition\/bridge-9876\/_all_docs\" -H 'Content-Type:\napplication\/json' --data '{\"include_docs\": true}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionAllDocsOptions;\nCloudant service = Cloudant.newInstance();\n\nPostPartitionAllDocsOptions allDocsOptions =\nnew PostPartitionAllDocsOptions.Builder()\n.db(\"readings\")\n.partitionKey(\"bridge-9876\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00620-9537-11012","score":26.9546104149,"text":"\nHowever, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users. The _id of the sixth document becomes the startkey of your request for the next page of results.See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=6\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\nint pageSize = 5;\nPostAllDocsOptions.Builder docsOptionsBuilder =\nnew PostAllDocsOptions.Builder()\n.db(\"orders\")\n.limit(pageSize + 1); \/\/ Fetch pageSize + 1 documents\n\nAllDocsResult response =\nservice.postAllDocs(docsOptionsBuilder.build())\n.execute()\n.getResult();\n\nwhile (response.getRows().size() > 1) {\nList<DocsResultRow> responseDocuments = response.getRows();\n\/\/ on the last page, show all documents:\nif (responseDocuments.size() <= pageSize) {\nSystem.out.println(responseDocuments);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_10841-22000-23598","score":26.9235938536,"text":"\n[CHANGELOG.md](https:\/\/github.com\/ibm-functions\/runtime-python\/blob\/master\/python3.7\/CHANGELOG.md). \n 3.6 Python 3.6 reached end of support on 2021\/12\/23. <br>See [end of life Python Releases](https:\/\/endoflife.date\/python). \n 2.7 Python 2.7 reached end of support on 2020\/01\/01. <br>See [the Active Python Releases](https:\/\/www.python.org\/downloads\/). \n\n\n\n\n\n Migrating from Python 3.7 to Python 3.9, Python 3.11 \n\n\n\nTable 2. Migrating details from Python 3.7 to Python 3.9\n\n Package Details \n\n ibmcloudant The cloudant sdk has moved to the new ibmcloudant sdk. It includes a number of breaking changes. See [migration guide](https:\/\/github.com\/cloudant\/python-cloudant\/blob\/master\/MIGRATION.md) for more information. \n ibm-watson The watson-developer-cloud sdk has renamed to the new ibm-watson sdk and includes breaking changes. See [pypi ibm-watson](https:\/\/pypi.org\/project\/ibm-watson\/) and [github ibm-watson](https:\/\/github.com\/watson-developer-cloud\/python-sdk) for more information. \n\n\n\nFor more information about migrating to python:3.9, see [(Details on GitHub)](https:\/\/github.com\/ibm-functions\/runtime-python\/blob\/master\/python3.9\/CHANGELOG.md).\n\n\n\n\n\n Python packages \n\nEnsure that your action uses only the packages that are mentioned in the following table. \\n While other Python packages might be part of the runtime, they are included only as indirect dependencies of the other listed packages. These unlisted packages are candidates to be removed as soon as they are not required by the referring package.\n\nPython 3.11 packages\n\nPython 3.9 packages\n\nPython 3.7 packages\n\n\n\nTable 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.6509209298,"ndcg_cut_10":0.6509209298}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10203-2544-4340","score":32.9447267628,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_14497-2717-4672","score":32.4264152655,"text":"\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.\n* Bootstrap node - As each node in the cluster requires information about the cluster when it is provisioned, a temporary bootstrap node is used. The bootstrap node creates the control plane nodes that make up the control plane. The control plane nodes then create the worker nodes. After the cluster initializes, the bootstrap node can be destroyed.\n* Control-plane nodes - These nodes run services that are required to control the Kubernetes cluster. They contain more than just the Kubernetes services for managing the cluster. The terms \"primary\" and \"control-plane\" are used interchangeably.\n* Compute nodes - In a Kubernetes cluster, the compute nodes are where the workloads are run. The compute nodes advertise their capacity to the control-plane nodes.\n* DNS - A correct DNS setup is imperative for a functioning Red Hat OpenShift cluster. The vCenter Server instance AD DNS server to host the required DNS records.\n* Load-balancer - An NSX ESG load-balancer service is used to front end the Red Hat OpenShift APIs, both internal and external, and the Red Hat OpenShift router. The load balancer is configured so that Port 6443 and 22623 point to the bootstrap and control plane nodes, while ports 80 and 443 are configured to point to the worker nodes.\n* Webserver - A web server is needed to hold the ignition configurations and installation images for the installation of RHEL CoreOS. NGINX is installed on the bastion node to provide this function.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10417-2600-4554","score":31.8208007115,"text":"\n: No. [Kubernetes pod security policies](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-policy\/) (PSPs) are originally based on Red Hat OpenShift SCCs. However, Red Hat OpenShift supports only SCCs, not PSPs.\n\nThe default Red Hat OpenShift SCCs are stricter than the default PSPs in community Kubernetes clusters. As such, app deployments that run in community Kubernetes clusters might need to be modified to run in Red Hat OpenShift.\n\n\n\n Customizing security context constraints \n\nTo create, edit, list, delete, and otherwise manage security context constraints, see the [Red Hat OpenShift docs](https:\/\/docs.openshift.com\/container-platform\/4.11\/authentication\/managing-security-context-constraints.html). You can also authorize users or groups to the default security context constraints by using role-based access control such as clusterroles, clusterrolebindings, roles, and rolebindings. You can also use the oc adm policy subcommands, such as oc adm policy add-scc-to-user, to manage these settings. The oc version is the same as that of the cluster being managed.\n\nGuidelines for assigning access to SCCs:\n\n\n\n* Authorize specific service accounts to the SCC that is to be used by pods running under that service account.\n* If a service account needs access to multiple SCCs, consider creating additional service accounts so that all pods running under a service account are expected to use the same SCC.\n* Do not authorize all users or all service accounts to use any SCC other than the restricted (4.10 and earlier) or restricted-v2 (4.11 and later) SCCs.\n* Do not change SCC authorization for service accounts in the openshift- namespaces. Red Hat OpenShift components are designed to run under specific SCCs and might not operate properly under a different SCC.\n\n\n\n\n\n\n\n Default Red Hat OpenShift security context constraints \n\nRed Hat OpenShift on IBM Cloud clusters come with the following security context constraints by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc"},{"document_id":"ibmcld_14497-1215-3210","score":31.4437844487,"text":"\n[VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.\n\nThe operating system of the nodes is Red Hat\u00ae Enterprise Linux\u00ae CoreOS, which is the container host version of Red Hat Enterprise Linux (RHEL) and features an RHEL kernel with SELinux enabled by default. RHEL CoreOS includes kubelet, which is the Kubernetes node agent, and the CRI-O container runtime, which is optimized for Kubernetes. In Red Hat OpenShift 4.7, you must use RHEL CoreOS for all control plane machines, but you can use Red Hat Enterprise Linux (RHEL) as the operating system for compute, or worker machines. If you choose to use RHEL workers, you must perform more system maintenance than if you use RHEL CoreOS for all of the cluster machines.\n\nThe reference architecture and this build process use RHEL CoreOS. The nodes must have direct Internet access to complete the following tasks.\n\n\n\n* Access the Red Hat OpenShift Infrastructure Providers page to download the installation program.\n* Access quay.io to obtain the packages that are required to install the cluster.\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10064-1605-3511","score":30.9018140279,"text":"\nAttempts to access the cluster control plane, which can be restricted by using the Cluster API type, do not generate Activity Tracker or audit log events.\n\n\n\n How Red Hat OpenShift on IBM Cloud integrates with context-based restrictions \n\nYou can create context-based restrictions (CBR) for Red Hat OpenShift on IBM Cloud resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect Red Hat OpenShift on IBM Cloud resources\n: [Restrict access to clusters, resource groups, or regions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbrresources-types-cbr).\n\nProtect specific APIs\n: Restrict accessing to provisioning and managing clusters and workers. Or, restrict access to Kubernetes APIs such as viewing pods and nodes. For more information, see [Protecting specific APIs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbrprotect-api-types-cbr).\n\nApplications running on Red Hat OpenShift on IBM Cloud clusters, for example web servers exposed by a Kubernetes LoadBalancer are not restricted by CBR rules.\n\n\n\n Protecting Red Hat OpenShift on IBM Cloud resources \n\nYou can create CBR rules to protect specific regions, and clusters.\n\nCluster\n: Protects a specific Red Hat OpenShift on IBM Cloud cluster. If you select a cluster in your CBR rule, only traffic from resources in the network zones that you associate with the rule can interact with that cluster.\n: If you use the CLI, you can specify the --service-instance CLUSTER-ID option to protect a specific cluster.\n: If you use the API, you can specify \"name\": \"serviceInstance\",\"value\": \"CLUSTER-ID\" in the resource attributes.\n\nRegion\n: Protects Red Hat OpenShift on IBM Cloud resources in a specific region. If you select a region in your CBR rule, then only traffic from resources in the network zones that you associate with the rule can interact with resources in that region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr"},{"document_id":"ibmcld_10510-20784-22884","score":30.8313190356,"text":"\nWorker node setup in Red Hat OpenShift on IBM Cloud excluding network security\n\nCIS-compliant RHEL image\n: Every worker node is set up with a Red Hat Enterprise Linux operating system that implements the benchmarks that are published by the Center of Internet Security (CIS). The user or the owner of the machine can't change this operating system to another operating system. To review the current RHEL version, run oc get nodes -o wide. IBM works with internal and external security advisory teams to address potential security compliance vulnerabilities. Security updates and patches for the operating system are made available through Red Hat OpenShift on IBM Cloud and must be installed by the user to keep the worker node secure. Red Hat OpenShift on IBM Cloud uses a Red Hat Enterprise Linux kernel for worker nodes. You can run containers based on any Linux distribution in Red Hat OpenShift on IBM Cloud. Check with your container image vendor to verify that your container images can run on a Red Hat Enterprise kernel.\n\nContinuous monitoring by Site Reliability Engineers (SREs)\n: The image that is installed on your worker nodes is continuously monitored by IBM Site Reliability Engineers (SREs) to detect vulnerabilities and security compliance issues. To address vulnerabilities, SREs create security patches and fix packs for your worker nodes. Make sure to apply these patches when they are available to ensure a secure environment for your worker nodes and the apps that you run on them.\n\nCIS Kubernetes worker node benchmark\n: To configure Red Hat OpenShift on IBM Cloud, IBM engineers follow relevant cybersecurity practices from the Kubernetes worker node benchmark that is published by the [Center of Internet Security (CIS)](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). You can review the compliance of worker nodes against [CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-worker-test) and [Red Hat OpenShift benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparison) standards.\n\nCompute isolation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10284-5722-7544","score":30.8273213429,"text":"\nWorker nodes are automatically provisioned with optimized kernel performance, but you can change the default settings by applying a custom [Kubernetes DaemonSet](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/daemonset\/) with an [init Container](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/pods\/init-containers\/) to your cluster. The daemon set modifies the settings for all existing worker nodes and applies the settings to any new worker nodes that are provisioned in the cluster. The init container makes sure that these modifications occur before other pods are scheduled on the worker node. No pods are affected.\n\nYou must have the [Manager IBM Cloud IAM service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) for all namespaces to run the sample privileged initContainer. After the containers for the deployments are initialized, the privileges are dropped.\n\nBefore you begin: [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n\n\n\n1. Save the following daemon set in a file named worker-node-kernel-settings.yaml. In the spec.template.spec.initContainers section, add the fields and values for the sysctl parameters that you want to tune. This example daemon set changes the default maximum number of connections that are allowed in the environment via the net.core.somaxconn setting and the ephemeral port range via the net.ipv4.ip_local_port_range setting.\n\nDepending on the systctl settings that you try to change, you might want to configure the security context. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/nodes\/containers\/nodes-containers-sysctls.html).\n\napiVersion: apps\/v1\nkind: DaemonSet\nmetadata:\nname: kernel-optimization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernel"},{"document_id":"ibmcld_10065-1605-3539","score":30.759480405,"text":"\nAttempts to access the cluster control plane, which can be restricted by using the Cluster API type, do not generate Activity Tracker or audit log events.\n\n\n\n How Red Hat OpenShift on IBM Cloud integrates with context-based restrictions \n\nYou can create context-based restrictions (CBR) for Red Hat OpenShift on IBM Cloud resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect Red Hat OpenShift on IBM Cloud resources\n: [Restrict access to clusters, resource groups, or regions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=cliresources-types-cbr).\n\nProtect specific APIs\n: Restrict accessing to provisioning and managing clusters and workers. Or, restrict access to Kubernetes APIs such as viewing pods and nodes. For more information, see [Protecting specific APIs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=cliprotect-api-types-cbr).\n\nApplications running on Red Hat OpenShift on IBM Cloud clusters, for example web servers exposed by a Kubernetes LoadBalancer are not restricted by CBR rules.\n\n\n\n Protecting Red Hat OpenShift on IBM Cloud resources \n\nYou can create CBR rules to protect specific regions, and clusters.\n\nCluster\n: Protects a specific Red Hat OpenShift on IBM Cloud cluster. If you select a cluster in your CBR rule, only traffic from resources in the network zones that you associate with the rule can interact with that cluster.\n: If you use the CLI, you can specify the --service-instance CLUSTER-ID option to protect a specific cluster.\n: If you use the API, you can specify \"name\": \"serviceInstance\",\"value\": \"CLUSTER-ID\" in the resource attributes.\n\nRegion\n: Protects Red Hat OpenShift on IBM Cloud resources in a specific region. If you select a region in your CBR rule, then only traffic from resources in the network zones that you associate with the rule can interact with resources in that region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=cli"},{"document_id":"ibmcld_10066-1605-3537","score":30.759480405,"text":"\nAttempts to access the cluster control plane, which can be restricted by using the Cluster API type, do not generate Activity Tracker or audit log events.\n\n\n\n How Red Hat OpenShift on IBM Cloud integrates with context-based restrictions \n\nYou can create context-based restrictions (CBR) for Red Hat OpenShift on IBM Cloud resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect Red Hat OpenShift on IBM Cloud resources\n: [Restrict access to clusters, resource groups, or regions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=uiresources-types-cbr).\n\nProtect specific APIs\n: Restrict accessing to provisioning and managing clusters and workers. Or, restrict access to Kubernetes APIs such as viewing pods and nodes. For more information, see [Protecting specific APIs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=uiprotect-api-types-cbr).\n\nApplications running on Red Hat OpenShift on IBM Cloud clusters, for example web servers exposed by a Kubernetes LoadBalancer are not restricted by CBR rules.\n\n\n\n Protecting Red Hat OpenShift on IBM Cloud resources \n\nYou can create CBR rules to protect specific regions, and clusters.\n\nCluster\n: Protects a specific Red Hat OpenShift on IBM Cloud cluster. If you select a cluster in your CBR rule, only traffic from resources in the network zones that you associate with the rule can interact with that cluster.\n: If you use the CLI, you can specify the --service-instance CLUSTER-ID option to protect a specific cluster.\n: If you use the API, you can specify \"name\": \"serviceInstance\",\"value\": \"CLUSTER-ID\" in the resource attributes.\n\nRegion\n: Protects Red Hat OpenShift on IBM Cloud resources in a specific region. If you select a region in your CBR rule, then only traffic from resources in the network zones that you associate with the rule can interact with resources in that region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=ui"},{"document_id":"ibmcld_10397-59149-59956","score":30.386479529,"text":"\nRed Hat OpenShift 3.11.346 3.11.380 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/3.11\/release_notes\/ocp_3_11_release_notes.htmlocp-3-11-380). \n\n\n\n\n\n\n\n Change log for worker node fix pack 3.11.380_1580_openshift, released 15 February 2021 \n\nThe following table shows the changes that are in the worker node fix pack 3.11.380_1580_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 3.11.374_1579_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 3.11.374 3.11.380 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/3.11\/release_notes\/ocp_3_11_release_notes.htmlocp-3-11-380).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_311"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10203-2544-4340","score":14.4384841285,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_03184-3236-4998","score":14.4165649415,"text":"\nThe client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable. This node responds with text output that includes the weather forecast, which the client application displays to the user. (If the $weather_forecast variable is not set, another child node can handle this case and report an error.)\n\n\n\nIt is also possible to call an external Web service directly from a dialog node, without involving the client application, by defining a webhook. For more information about how to call an external service using a webhook, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\n\n\n Procedure \n\nTo request a client action from a dialog node, complete the following steps:\n\n\n\n1. In the dialog node from which you want to request the client action, open the JSON editor for the node response.\n\n![Shows how to access the JSON editor associated with a standard noderesponse.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/contextvar-json-response.png)\n2. Use the following syntax to define the client action you want to request.\n\n{\n\"context\": {\n\"variable_name\" : \"variable_value\"\n},\n\"actions\": [\n{\n\"name\":\"<actionName>\",\n\"type\":\"client\",\n\"parameters\": {\n\"<parameter_name>\":\"<parameter_value>\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_02872-10099-11736","score":14.3403863609,"text":"\n\"result_variable\": \"context.my_forecast\"\n}\n]\n}\n\nNormally, the service only returns to the client from a POST \/message request when new user input is required, such as after executing a parent and before executing one of its child nodes. However, if you add a client action to a node, then after evaluation, the service always returns to the client so that the result of the action call can be returned. To prevent waiting for user input when it should not, such as for a node that is configured to jump directly to a child node, the service adds the following value to the message context:\n\n{\n\"context\": {\n\"skip_user_input\": true\n}\n}\n\nIf you want the client to perform an action, but not get user input, then you can follow the same convention, and add the skip_user_input context variable to the parent node to communicate that to the client application.\n\nYour client application should always check for the skip_user_input variable on context. If present, then it knows not to request new input from the user, but instead execute the action, add its result into the message, and pass it back to the service. The new POST message request should include the message returned by the previous POST message response (namely, the context, input, intents, entities, and optionally the output section) and, instead of the JSON object that defines the programmatic call to make, it should include the result that was returned from the programmatic call.\n\nIn a child node that you jump to after this node, add the response to show the user:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"It will be $my_forecast $date.literal in $location.literal.\"\n]\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-actions-client"},{"document_id":"ibmcld_02953-3805-5544","score":14.019556213,"text":"\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03184-1586-3749","score":13.991534028,"text":"\nIt is the responsibility of the client application to carry out the requested action, store the result in the context, and send it back to the dialog with the next message.\n\nYou might call a client application to do the following types of things:\n\n\n\n* Validate information that you collected from the user.\n* Do calculations or string manipulations on user input that are too complex for supported SpEL expression methods to handle.\n* Get data from another application or service.\n\n\n\nThe following diagram illustrates how client actions work, using the example of an action to get a weather forecast.\n\n![Shows someone asking for a weather forecast and the dialog sending a request to a client app, which sends it to the external service and returns the result](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/forecast.png)\n\nThe flow of requests and responses follows this pattern:\n\n\n\n1. The client application sends a message containing user input that asks for a weather forecast (using the message or message_stateless method).\n2. The user input triggers a dialog node conditioned on a #weather intent. In its response to the client, this node specifies the get_weather client action, which is a name that the client application recognizes. (This is in addition to any text response, such as Checking the weather forecast....)\n3. When it receives this response, the client application recognizes that the get_weather action is being requested. It calls an external web service (\/weather) to get the actual forecast information, passing any specified parameters (such as the user's location). The client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_03184-7285-9367","score":13.5938463736,"text":"\nIf multiple actions in a single JSON action array add the result of their programmatic call to the same context variable, then the order in which the context is updated matters. Per action type, the order in which the actions are defined in the array determines the order in which the context variable's value is set. The context variable value returned by the last action in the array overwrites the values calculated by any other actions.\n\nThe result_variable property is required. If the client action does not return any result, specify null as the value.\n\n\n\n\n\n\n\n\n\n Client action example \n\nThe following example shows what a request for a call to an external weather service might look like. It is added to the JSON editor that is associated with the node response. By the time the node-level response is triggered, slots have collected and stored the date and location information from the user. This example assumes that the client action is named weather_forecast, that it takes a location parameter, and that the results are to be stored in the weather_forecast context variable.\n\n{\n\"actions\": [\n{\n\"name\": \"get_weather\",\n\"type\": \"client\",\n\"parameters\": {\n\"location\": \"$location\"\n},\n\"result_variable\": \"weather_forecast\"\n}\n]\n}\n\nThe client application must check for the presence of any client actions in the responses to messages it sends to the assistant. When it recognizes a request for the get_weather action, it executes the action (calling the external weather service), and it stores the result in the specified context variable (weather_forecast). It then sends a message to the service, including the updated context.\n\nTo handle this message in your dialog, create a child node following the node that requested the action. You can condition this child node on the special condition true to ensure that it is always triggered by the message that the client sends after completing the requested action. In this child node, add the response to show the user, reading the stored action result from the $my_forecast context variable:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_06209-36554-38368","score":13.4473414482,"text":"\nYou can use worker pools to spread worker nodes evenly across zones and build a balanced cluster. Balanced clusters are more available and resilient to failures. If a worker node is removed from a zone, you can rebalance the worker pool and automatically provision new worker nodes to that zone. Worker pools are also used to install Kubernetes version updates to all your worker nodes.\n\nIf you created clusters before multizone clusters became available, your worker nodes are still stand-alone and not automatically grouped into worker pools. You must update these clusters to use worker pools. If not updated, you can't change your single zone cluster to a multizone cluster.\n\nReview the following image to see how your cluster setup changes when you move from stand-alone worker nodes to worker pools.\n\nZoom\n\n![Update your cluster from stand-alone worker nodes to worker pools](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_cluster_migrate.png)\n\nFigure 1. Update your cluster from stand-alone worker nodes to worker pools\n\nBefore you begin:\n\n\n\n* Ensure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) for the cluster.\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo update stand-alone worker nodes to worker pools:\n\n\n\n1. List existing stand-alone worker nodes in your cluster and note the ID, the Machine Type, and Private IP.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n2. Create a worker pool and decide on the flavor and the number of worker nodes that you want to add to the pool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05838-25355-26994","score":13.287395425,"text":"\nThe Autorecovery system uses various checks to query worker node health status. If Autorecovery detects an unhealthy worker node based on the configured checks, Autorecovery triggers a corrective action like rebooting a VPC worker node or reloading the operating system in a classic worker node. Only one worker node undergoes a corrective action at a time. The worker node must complete the corrective action before any other worker node undergoes a corrective action. For more information, see this [Autorecovery blog post](https:\/\/www.ibm.com\/cloud\/blog\/autorecovery-utilizes-consistent-hashing-high-availability).\n\nAutorecovery requires at least one healthy worker node to function properly. Configure Autorecovery with active checks only in clusters with two or more worker nodes.\n\nBefore you begin:\n\n\n\n* Ensure that you have the following [IBM Cloud IAM roles](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms):\n\n\n\n* Administrator platform access role for the cluster\n* Writer or Manager service access role for the kube-system namespace\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo configure Autorecovery:\n\n\n\n1. [Follow the instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-helminstall_v3) to install the Helm version 3 client on your local machine.\n2. Create a configuration map file that defines your checks in JSON format. For example, the following YAML file defines three checks: an HTTP check and two Kubernetes API server checks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_16261-15807-17466","score":12.5348176244,"text":"\n\/\/ Prompt for the next round of input unless skip_user_input is true.\nlet newMessageFromUser = '';\nif (result.context.global.system.skip_user_input !== true) {\nnewMessageFromUser = prompt('>> ');\n}\n\nif (newMessageFromUser !== 'quit') {\nnewMessageInput = {\nmessageType: 'text',\ntext: newMessageFromUser,\n}\nsendMessage(newMessageInput, context);\n}\n}\n\nThe only change from the previous example is that we are now storing the context received from the assistant in a variable called context, and we're sending it back with the next round of user input:\n\nThe only change from the previous example is that we are now storing the context received from the assistant in a variable called context, and we're sending it back with the next round of user input:\n\n\n\n* Python\n* Node\n\n\n\nresponse = assistant.message_stateless(\nassistant_id,\ninput = message_input,\ncontext = context\n).get_result()\n\nassistant\n.messageStateless({\nassistantId,\ninput: messageInput,\ncontext: context,\n})\n\nThis ensures that the context is maintained from one turn to the next, so the Watson Assistant service no longer thinks every turn is the first:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nHi, Robert! How can I help you?\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Next Monday\nWhat time works for you?\n>> 10 AM\nOK, Robert. You have an appointment for 10:00 AM on Sep 12. See you then!\n\nSuccess! The application now uses the Watson Assistant service to understand natural-language input, and it displays the appropriate responses.\n\nThis simple example illustrates how you can build a custom client app to communicate with the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_09320-7445-9366","score":12.475547045,"text":"\nDallas (us-south) kubectl create -f https:\/\/assets.us-south.logging.cloud.ibm.com\/clients\/logdna-agent-ds-k8s-v1.8.yaml -n ibm-observe \n Washington (us-east) kubectl create -f https:\/\/assets.us-east.logging.cloud.ibm.com\/clients\/logdna-agent-ds-k8s-v1.8.yaml -n ibm-observe \n\n\n\n\n\n\n\n\n\n Step 6. Verify that the logging agent is deployed successfully \n\nTo verify that the logging agent is deployed successfully, run any of the following commands:\n\nkubectl get all -n ibm-observe\n\nkubectl get pods -n ibm-observe\n\nThe deployment is successful when you see one or more logging pods.\n\n\n\n* The number of logging pods equals the number of worker nodes in your cluster.\n* All pods must be in a Running state.\n* Stdout and stderr are automatically collected and forwarded from all containers. Log data includes application logs and worker logs.\n* By default, the logging agent pod that runs on a worker collects logs from all namespaces on that node, including kube-system logs.\n\n\n\nTo get a copy of the logging agent configuration that is deployed, you can run the following command:\n\nkubectl get daemonset logdna-agent -o=yaml > prod-logdna-agent-ds.yaml -n ibm-observe\n\n\n\n\n\n\n\n Deploy the logging agent within the context of the cluster \n\nWhen you deploy and connect a logging agent within the context of the cluster, consider the following information:\n\n\n\n* You can launch the logging UI from the Kubernetes cluster UI in IBM Cloud.\n* The view that opens displays logs for your cluster.\n* The agent is deployed in the ibm-observe namespace.\n* A tag that informs about the cluster name is associated to each log line as metadata.\n* A tag that informs about the version of the agent is associated to each log line as metadata.\n* The logging instance must be available in the same IBM Cloud account where the cluster is provisioned.\n* The logging instance can be in a different resource group and IBM Cloud region than your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-config_agent_kube_cluster"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04170-7-2189","score":30.8720364539,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":28.6839040351,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":28.0799525108,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04168-6066-7283","score":26.4398829927,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04334-39121-41053","score":23.6803827801,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04113-1734-4014","score":23.5727353369,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04172-7-2047","score":23.0388058767,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04334-43529-45385","score":22.8196123669,"text":"\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16286-2915-4657","score":22.3810598391,"text":"\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1. Go to the [Microsoft Teams Developer Portal](https:\/\/dev.teams.microsoft.com\/home), and log in with your admin credentials.\n2. On the Apps tab, click New App.\n3. Enter a name, and click Add.\n4. On the Basic information page, enter app names, app ID, descriptions, developer information, and app URLs, and then copy and paste your app ID into Application (client) ID. Click Save.\n5. In the Configure section, select App features, and then Bot.\n6. On the Identify your bot page, select your bot.\n7. In the Select the scope in which people can use this command section, select Personal, Team, and Group Chat.\n8. Click Save, but keep the window open.\n9. In your Watson Assistant Microsoft Teams integration, click Finish.\n10. Click Publish to publish your bot.\n\n\n\n\n\n\n\n\n\n Publishing your Teams app \n\n\n\n1. In the Microsoft Teams Developer Portal window where you created and saved your Teams app, click Publish to publish your bot.\n2. Click Download the app package.\n3. Go to [Microsoft Teams](https:\/\/teams.microsoft.com), and log in with your admin credentials.\n4. Click Apps in the sidebar menu, and then click Manage your apps and Upload an app.\n5. Select Upload a custom app and specify the app package .zip file you downloaded.\n6. Click Add to finish.\n7. Test your actions and responses in the Chat section of your Teams app.\n\n\n\n\n\n\n\n Response types","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_04175-0-1274","score":22.049681313,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16388-7-1918","score":61.5458005583,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_16365-12876-14604","score":59.4665084351,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03180-5630-7213","score":58.2732377624,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_16298-4831-6878","score":58.0975540645,"text":"\nAgent status is set to Invisible unless it is explicitly changed.\n\n\n\n\n\n Turn on Agent Workspace \n\nZendesk Agent Workspace brings Zendesk Chat and Zendesk Support together, so all your customer interactions are in one place, and communication is seamless, personal, and efficient. That means more productive agents and happy customers.\n\nIn Zendesk:\n\n\n\n1. Click the Products icon and go to the Admin Center.\n2. Click Workspaces.\n3. Click the Turn on Agent Workspace button. The green On box should display.\n\n\n\nAgent Workspace should now feature on several screens in Zendesk Support, including on the Dashboard with tickets, the Visitors page, and in the top menu as Conversations where agents can accept chats from customers waiting for assistance.\n\n\n\n\n\n\n\n Securing the transfer to Zendesk \n\nYou must collect the name and email address of each user, if enabling security in Zendesk. This information must be passed to the web chat so it can be provided to Zendesk when the conversation is transferred.\n\nWhen you add security to your Zendesk integration, you ensure that the visitors you are helping are legitimate customers. Enabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Enabling authenticated visitors in Zendesk](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_03080-1529-3357","score":58.0825577765,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16298-6367-7794","score":57.0364350237,"text":"\nFor more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n\/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, \/\/ Required\niss: 'www.ibm.com', \/\/ Required\nacr: 'loa1' \/\/ Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_16365-11574-13329","score":56.279940841,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16364-119531-121469","score":55.2336981818,"text":"\nYou can [search your dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-search) to find out where you are currently using the entity, and remove it. Consider using a contextual entity to identify references to locations and people instead. After removing the entity from your dialog, disable the entity from the System entities page.\n\n\n\n\n\n 13 May 2020 \n\nStateless v2 message API\n: The v2 runtime API now supports a new stateless message method. If you have a client application that manages its own state, you can use this new method to take advantage of [many of the benefits](https:\/\/medium.com\/ibm-watson\/the-new-watson-assistant-v2-stateless-api-unlock-enterprise-features-today-2c02a4bbdef5) of the v2 API without the overhead of creating sessions. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message-stateless).\n\n\n\n\n\n 30 April 2020 \n\nWeb chat is generally available!\n: Add your assistant to your company website as a web chat widget that can help your customers with common questions and tasks. Service desk transfer support continues to be a beta feature. For more information, see [Integrating with your own website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nSecure your web chat\n: Enable the beta security feature of web chat so that you can verify that messages sent to your assistant come from only your customers and can pass sensitive information to your assistant.\n\n\n\n\n\n 27 April 2020 \n\nAdd personality to your assistant in web chat\n: You can add an assistant image to the web chat header to brand the window. You can add an avatar image that represents your assistant or a brand logo, for example. For more information, see [Integrating with your own web site](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nKnow your plan\n: Now your service plan is displayed in the page header.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03421-1518-3290","score":54.7735387087,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03369-82053-83986","score":54.5308365434,"text":"\n: As stated in the [March deprecation notice](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notesMarch2020-deprecation), the @sys-location and @sys-person system entities that were available as a beta feature are deprecated. If you are using one of these system entities in your dialog, a toggle is displayed for the entity on the System entities page. You can [search your dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-search) to find out where you are currently using the entity, and remove it. Consider using a contextual entity to identify references to locations and people instead. After removing the entity from your dialog, disable the entity from the System entities page.\n\n\n\n\n\n 13 May 2020 \n\nStateless v2 message API\n: The v2 runtime API now supports a new stateless message method. If you have a client application that manages its own state, you can use this new method to take advantage of [many of the benefits](https:\/\/medium.com\/ibm-watson\/the-new-watson-assistant-v2-stateless-api-unlock-enterprise-features-today-2c02a4bbdef5) of the v2 API without the overhead of creating sessions. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message-stateless).\n\n\n\n\n\n 30 April 2020 \n\nWeb chat is generally available!\n: Add your assistant to your company website as a web chat widget that can help your customers with common questions and tasks. Service desk transfer support continues to be a beta feature. For more information, see [Integrating with your own website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nSecure your web chat\n: Enable the beta security feature of web chat so that you can verify that messages sent to your assistant come from only your customers and can pass sensitive information to your assistant.\n\n\n\n\n\n 27 April 2020 \n\nAdd personality to your assistant in web chat","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13455-7-1568","score":39.2228056414,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13790-7-1700","score":39.1953780066,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-1284-2889","score":38.8955551846,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_03285-5746-7932","score":36.744722022,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":36.744722022,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13455-1311-2796","score":36.7207026131,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13429-127288-129174","score":35.3499460873,"text":"\nIf your application uses the sessions interface, you must migrate to one of the following interfaces by September 7:\n\n\n\n* For stream-based speech recognition (including live-use cases), use the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), which provides access to interim results and the lowest latency.\n* For file-based speech recognition, use one of the following interfaces:\n\n\n\n* For shorter files of up to a few minutes of audio, use either the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http)(POST \/v1\/recognize) or the [asynchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-async) (POST \/v1\/recognitions).\n* For longer files of more than a few minutes of audio, use the asynchronous HTTP interface. The asynchronous HTTP interface accepts as much as 1 GB of audio data with a single request.\n\n\n\n\n\nThe WebSocket and HTTP interfaces provide the same results as the sessions interface (only the WebSocket interface provides interim results). You can also use one of the Watson SDKs, which simplify application development with any of the interfaces. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n\n\n 13 July 2018 \n\nUpdates to Spanish narrowband model for improved speech recognition\n: The Spanish narrowband model, es-ES_NarrowbandModel, was updated for improved speech recognition. By default, the service automatically uses the updated model for all recognition requests. If you have custom language or custom acoustic models that are based on this model, you must upgrade your custom models to take advantage of the updates by using the following methods:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/upgrade_model\n* POST \/v1\/acoustic_customizations\/{customization_id}\/upgrade_model","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13790-2496-4190","score":35.0387338623,"text":"\n{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service. You must use the access token before it expires.\n\n\n\nIBM Cloud\n\nPass an Identity and Access Management (IAM) access token to authenticate with the service. You pass an IAM access token instead of passing an API key with the call. For more information, see [Authenticating to IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cloud).\nIBM Cloud Pak for Data\n\nPass an access token as you would with the Authorization header of an HTTP request. For more information, see [Authenticating to IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cpd).\n\n\n\nvoice (optional string)\n: Specifies the voice in which the text is to be spoken in the audio. Use the \/v1\/voices method to get the current list of supported voices. Omit the parameter to use the default voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) and [Using the default voice](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices-usespecify-voice-default).\n\ncustomization_id (optional string)\n: Specifies the globally unique identifier (GUID) for a custom model that is to be used for the synthesis. A specified custom model must match the language of the voice that is used for the synthesis.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13724-47667-49354","score":35.0032825619,"text":"\n* The voices do support all other SSML elements. However, they support only the International Phonetic Alphabet (IPA), not IBM Symbolic Phonetic Representation (SPR), with the <phoneme> element.\n\n\n\nFor more information about these and all available voices, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 12 December 2019 \n\nFull support for IBM Cloud IAM\n: The Text to Speech service now supports the full implementation of IBM Cloud Identity and Access Management (IAM). API keys for Watson services are no longer limited to a single service instance. You can create access policies and API keys that apply to more than one service, and you can grant access between services. For more information about IAM, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\nTo support this change, the API service endpoints use a different domain and include the service instance ID. The pattern is api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}.\n\n\n\n* Example HTTP URL for an instance hosted in the Dallas location:\n\nhttps:\/\/api.us-south.text-to-speech.watson.cloud.ibm.com\/instances\/6bbda3b3-d572-45e1-8c54-22d6ed9e52c2\n* Example WebSocket URL for an instance hosted in the Dallas location:\n\nwss:\/\/api.us-south.text-to-speech.watson.cloud.ibm.com\/instances\/6bbda3b3-d572-45e1-8c54-22d6ed9e52c2\n\n\n\nFor more information about the URLs, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech\/text-to-speechservice-endpoint).\n\nThese URLs do not constitute a breaking change. The new URLs work for both your existing service instances and for new instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_13429-91727-93405","score":34.9331264568,"text":"\nCustom language models and grammars can also influence how and where the service splits a transcript.\n\nThe parameter causes the service to add an end_of_utterance field to each final result to indicate the motivation for the split: full_stop, silence, end_of_data, or reset.\n\nFor more information, see [Split transcript at phrase end](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsingsplit-transcript).\n\n\n\n\n\n 12 December 2019 \n\nFull support for IBM Cloud IAM\n: The Speech to Text service now supports the full implementation of IBM Cloud Identity and Access Management (IAM). API keys for IBM Watson\u00ae services are no longer limited to a single service instance. You can create access policies and API keys that apply to more than one service, and you can grant access between services. For more information about IAM, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\nTo support this change, the API service endpoints use a different domain and include the service instance ID. The pattern is api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}.\n\n\n\n* Example HTTP URL for an instance hosted in the Dallas location:\n\nhttps:\/\/api.us-south.speech-to-text.watson.cloud.ibm.com\/instances\/6bbda3b3-d572-45e1-8c54-22d6ed9e52c2\n* Example WebSocket URL for an instance hosted in the Dallas location:\n\nwss:\/\/api.us-south.speech-to-text.watson.cloud.ibm.com\/instances\/6bbda3b3-d572-45e1-8c54-22d6ed9e52c2\n\n\n\nFor more information about the URLs, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text\/speech-to-textservice-endpoint).\n\nThese URLs do not constitute a breaking change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.6366824387}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06061-7-2184","score":29.0747877079,"text":"\nSetting up Secrets Manager in your Kubernetes Service cluster \n\nWhen you integrate IBM Cloud Secrets Manager with your IBM Cloud Kubernetes Service cluster, you can centrally manage Ingress subdomain certificates and other secrets.\n\n\n\n About Secrets Manager \n\nWith Secrets Manager, you can use a single service to manage your secrets and control who has access to them. A Secrets Manager instance is not automatically provisioned in your cluster. However, you can use a single Secrets Manager instance across multiple clusters, and a single cluster can have more than one instance.\n\n\n\n What functionality can I gain with Secrets Manager? \n\nWith Secrets Manager, you can:\n\n\n\n* Create managed Kubernetes secrets with Ingress TLS certificates included.\n* Create Kubernetes secrets of any type by using the CRN of any Secrets Manager instance you own.\n* Automatically update your secrets in your cluster on a regular basis.\n* Track the expiration dates of your certificates from the IBM Cloud console.\n* Control who has access to your secrets by creating secret groups for approved users.\n\n\n\nNote that to have your secrets automatically updated, you must register at least one Secrets Manager instance to your cluster. For more information, see [Registering your Secrets Manager instance to your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgrsecrets-mgr_setup_register).\n\n\n\n\n\n\n\n Secrets Manager FAQ \n\nKeep the following points in mind when using Secrets Manager.\n\nWhat types of secrets are supported with Secrets Manager?\n: Secrets Manager supports IAM credentials, key-value secrets, user credentials, arbitrary secrets, and Kubernetes secrets. For Kubernetes secrets, Secrets Manager supports both TLS and non-TLS (Opaque) secret types. With TLS secrets, you can specify one certificate CRN. With non-TLS secrets, you can specify multiple fields to pull non-certificate secrets. If you do not specify a secret type when you create a secret, TLS is applied by default. For more information on supported secrets, see [Working with secrets of different types](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgr"},{"document_id":"ibmcld_10508-7-2183","score":28.9939185162,"text":"\nSetting up Secrets Manager in your Red Hat OpenShift cluster \n\nWhen you integrate IBM Cloud Secrets Manager with your Red Hat OpenShift on IBM Cloud cluster, you can centrally manage Ingress subdomain certificates and other secrets.\n\n\n\n About Secrets Manager \n\nWith Secrets Manager, you can use a single service to manage your secrets and control who has access to them. A Secrets Manager instance is not automatically provisioned in your cluster. However, you can use a single Secrets Manager instance across multiple clusters, and a single cluster can have more than one instance.\n\n\n\n What functionality can I gain with Secrets Manager? \n\nWith Secrets Manager, you can:\n\n\n\n* Create managed Kubernetes secrets with Ingress TLS certificates included.\n* Create Kubernetes secrets of any type by using the CRN of any Secrets Manager instance you own.\n* Automatically update your secrets in your cluster on a regular basis.\n* Track the expiration dates of your certificates from the IBM Cloud console.\n* Control who has access to your secrets by creating secret groups for approved users.\n\n\n\nNote that to have your secrets automatically updated, you must register at least one Secrets Manager instance to your cluster. For more information, see [Registering your Secrets Manager instance to your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-secrets-mgrsecrets-mgr_setup_register).\n\n\n\n\n\n\n\n Secrets Manager FAQ \n\nKeep the following points in mind when using Secrets Manager.\n\nWhat types of secrets are supported with Secrets Manager?\n: Secrets Manager supports IAM credentials, key-value secrets, user credentials, arbitrary secrets, and Kubernetes secrets. For Kubernetes secrets, Secrets Manager supports both TLS and non-TLS (Opaque) secret types. With TLS secrets, you can specify one certificate CRN. With non-TLS secrets, you can specify multiple fields to pull non-certificate secrets. If you do not specify a secret type when you create a secret, TLS is applied by default. For more information on supported secrets, see [Working with secrets of different types](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-secrets-mgr"},{"document_id":"ibmcld_12498-4487-6713","score":28.1394469644,"text":"\nA secrets manager service can securely store these credentials, along with other types of secrets, in a centralized way for her to be able to access or maybe other services to access, like we'll see in a second. But when it's done, it's given her the peace of mind that her user credentials are securely stored and now she can worry about authenticating with the service and getting her job done because secrets manager is going to take care of that for her.\n\nHowever, what's really important for secrets manager service to do is interact with the cloud service provider's IAM, or identity and access management service. IAM is going to be the source of truth allowing secrets manager to one, authenticate who she is so that it can pass it down to GitHub, and secondarily also allow for her to get the correct set of roles based on the paradigm that they have within their IAM service. With this, we now understand what it's like for a user to get the correct permission and be able to access the tool of their choice of their service, and be able to do this in the context of using a secrets manager service.\n\nBut now, let's look what it's like for a service to interact with another service and potentially where data breaches could be harmful.\n\nLet's look at our service to service example. What we have to start with is a lending application. This lending app is going to want to request permissions to be able to access \u2013 again, we were talking about a database earlier. Let's be a little bit more specific: this database that it needs to access is a given table within the database has necessary information to give to its model in order to be able to make a judgment on whether or not they want to provide a consumer alone. So we're going to call this a profile database. So within here, we have profile DB, and we know that the set of permissions that we want to grant are going to be read permissions for table A. So again, where are we going to store the secret that's ultimately going to give us access to give us access to authentication and ultimately to the set of permissions that we need here? So that's again going to be the secrets manager service provided, and that service needs to talk to Cloud IAM again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12385-3409-5426","score":27.5134897366,"text":"\nIf you accidentally assign a secret to the wrong secret group, or if you don't want a secret to belong to the default secret group, delete the secret and create a new one.\n2. Optionally, use secret groups to allow privileged access to specific resources in your account.\n\nSecret groups can be used to grant direct access to resources that otherwise wouldn't be possible through IAM. For example, assume that User A has no access to Service A in IAM. If you create an IAM access policy that assigns User A to Secret Group A, and Secret Group A contains an [IAM credential](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) with a service ID that gives access to Service A, then you grant User A access to Service A. In this scenario, Secret Group A becomes a gateway to Service A, even if a restriction exists in IAM. Keep in mind that with this scenario it is possible to grant access to a resource unintentionally. Review your configuration carefully to ensure that your secret group assignments do not override your IAM access policies accidentally.\n3. Audit your secret groups regularly and remove them when they're no longer needed.\n\nGrant only the minimum access that is required, and delete a secret group when it is no longer needed.\n\nTo delete a secret group, it must be empty. If you need to remove a secret group that contains secrets, you must first [delete the secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-delete-secrets) that are part of the group.\n\n\n\n\n\n\n\n Track your related secrets by adding labels \n\nAdd labels so that you can further search by and categorize the secrets in your instance. When you use a consistent labeling schema, you can easily group similar secrets together.\n\n\n\n1. Label your secrets by using a consistent schema, such as creating labels to differentiate which secrets are used for a specific purpose. To add labels by using the Secrets Manager UI, go to the Secrets page, and then select a secret to edits its details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets"},{"document_id":"ibmcld_12415-7-1973","score":25.3633178868,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12417-1438-3340","score":25.0017472555,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets table, click Add.\n4. Select the User credentials tile.\n\nYou're all set to enter the details of your new secret. To describe and store your secret, continue to the next step.\n\n\n\n\n\n\n\n Step 2: Store the secret securely \n\nWhen you're working with secrets, it's important to organize them in a single location so that you help to reduce the risk of compromised credentials. By storing a secret in Secrets Manager, you can manage a secret centrally, use\n\nsecret groupsto control access, and avoid coding it directly into your apps or version control systems.\n\nComplete the following steps to enter the details of a secret and store it securely in your instance.\n\n\n\n1. In the Add user credentials page, add a name and description to easily identify your secret.\n2. Add the secret to a group to control who on your team has access to it.\n\nYou can click Create to provide a name and a description for a new group. Later, you can assign an access policy to the group so that you control who on your team has access to its contained secret.\n3. Optional: Add labels to help you to search for similar secrets in your instance.\n4. Supply the username and password values that you want to associate with the secret.\n5. Optional: Set an expiration date for the secret.\n6. Click Add.\n\nYou did it! The username and password are now stored in your dedicated, single-tenant instance of Secrets Manager.\n\n\n\n\n\n\n\n Step 3: Manage its lifecycle \n\nAfter you add a secret to your instance, you can establish a regular cadence for managing its lifecycle. For example, you might need to adhere to an internal requirement or regulatory control in your business for rotating secrets every 30 days.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started"},{"document_id":"ibmcld_07578-1213887-1215935","score":24.8691746243,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":24.8691746243,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10906-35292-37042","score":24.8409723318,"text":"\n<br>If you have configured a Secrets Manager instance as described in [Encrypt and protect your data](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklistsecuring), you can use that instance to dynamically generate a service ID and an API key each time a protected resource is read or accessed. For more information, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui). \n <br><br> * Create API keys<br><br><br> An API key is a unique code passed into an API to identify the calling application or user. You can use platform IBM Cloud API keys that are associated with user identities, and you can create other API keys for service IDs. For more information, see [Understanding API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manapikey). <br>If you have configured a Secrets Manager instance as described in [Encrypt and protect your data](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklistsecuring), you can use that instance to dynamically generate a service ID and an API key each time a protected resource is read or accessed. For more information, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui). \n <br><br> * Learn about IAM policies<br><br><br> A policy consists of a subject, target, and a role. A policy grants a subject one or multiple roles to a set of resources so that specific actions can be taken. The role defines the level of access that is granted. For more information, see [What are IAM policies and who can assign them?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamusermanpol) \n\n\n\n\n\n\n\n Get support and other resources","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_12498-7-2091","score":24.4000906355,"text":"\nWhat is a secret? \n\nA secret is a piece of sensitive information. For example, an API key, password, or any type of credential that you might use to access a confidential system.\n\nBy using secrets, you're able to authenticate to protected resources as you build your applications. For example, when you try to access an external service API, you're asked to provide a unique credential. After you supply your credential, the external service can understand who you are and whether you're authorized to interact with it.\n\nTo learn more about the general characteristics of a secret, check out the following video.\n\n\n\n* Video transcript\n\nHow are you making sure that your secrets are securely stored so that you can avoid data breaches and chaos in your DevOps workflows?\n\nHi, I'm Alex Greer with the IBM Cloud team, and before I get started make sure to like and subscribe now.\n\nWhat is a secret?\n\nA secret is a digital credential that is going to allow entities to communicate and perform actions on a service. This discrete piece of information keeps that access point secure. So let's look at how this paradigm exists.\n\nLet's start with an entity here that needs to access some sort of service. We'll leave it little ambiguous for now, but some sort of service. To properly communicate with the service and be able to take the action that it needs to get its job done, this entity is going to need to communicate to the service two things: One, who it is, so that service can understand what or who is interacting with it. Two, it's going to have to know the set of permissions that it should grant in the context of its service. With these, the service can now properly allow that entity to interact with them. How we enable this interaction is with something we call a \"secret.\"\n\nNow, with this dynamic established, let's move into an example with users. For users, we'll say that this user here is our entity, and we'll say our service here \u2013 let's say that it's a developer, and they happen to need read or write access. They're interacting with the development repo to do that.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":41.8807114884,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":41.8292239906,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":37.4601829104,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":36.4129984314,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_07971-2155-4528","score":36.4077989446,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01533-4-2366","score":35.7414609712,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":28.5584693997,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":28.5584693997,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-7085-8964","score":28.3285534341,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":27.2707449145,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":27.2707449145,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04488-133306-134586","score":26.7602105165,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-96989-98298","score":25.8003317383,"text":"\nThe ibmcloud resource service-instance-create command requires a service plan name and a location, which is in the catalog. show the catalog offerings for cloud object storage (COS) and Key Protect\n$ ibmcloud catalog service cloud-object-storage\n\n$ ibmcloud catalog service kms\n create a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_01660-8584-10307","score":25.3151124516,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_09055-104201-105670","score":25.1725854591,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- <\/section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS\/KP authorization policy<-- <\/ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_00558-2925-4840","score":25.1674844812,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.5802792109}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":61.4865002601,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":49.9753947359,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":48.0895419913,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":46.3113347148,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":45.1497942267,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":34.3022737434,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-44214-45420","score":32.4880461183,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":30.2093697884,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-2884-4620","score":29.0927655507,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-1628-3402","score":27.9322259936,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.9060254355,"ndcg_cut_10":0.9060254355}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12666-5872-8212","score":32.7386351631,"text":"\nTransfer the backups of the key management, Object Storage, and database services related to the Data Security Broker deployment, as well as the Data Security Broker Manager backup files, to a reliable backup storage location.\n\n\n\n\n\n\n\n Restore procedure \n\nThe Data Security Broker deployment can be recovered in a disaster recovery situation to a state that was previously backed up, provided that all the dependent services are also recovered in the same manner. This applies to any services that has suffered a irrecoverable failure. If the dependent services were not affected, all that is required is to ensure that the network connectivity between the Data Security Broker deployment and the dependent services is restored.\n\nSince Data Security Broker Manager contains all the configuration and metadata needed for a Data Security Broker deployment, the goal of the process is to restore Data Security Broker Manager to a previous state so that a new shield can be deployed to enforce the previously configured security policies.\n\n\n\n\n\n Restoring Data Security Broker Manager deployed on a Kubernetes or Red Hat OpenShift cluster to a previous state \n\nA new Data Security Broker Manager deployment needs to be set up in a Kubernetes or Red Hat OpenShift cluster, in order to return Data Security Broker Manager to its previous state. The administrator carrying out the restore operation requires network connectivity to the cluster as well as access to a workstation with permission to use the command-line tools for Kubernetes or Red Hat OpenShift cluster.\n\nTo restore a Data Security Broker deployment, follow the steps:\n\n\n\n1. Log in to the workstation using command-line tools, and use the recently installed Data Security Broker Manager to access the Kubernetes or Red Hat OpenShift cluster.\n2. To create a temporary storage area on the workstation, copy the Data Security Broker Manager backup files there. The names of the backup files includes the following:\n\n\n\nRelease-DSB.<release>MONGO.tar.gz\nRelease-DSB.<release>BM.tar.gz\n\n\n\n1. To restore the Data Security Broker Manager configuration files and MongoDB collections, create and execute the script provided below. As an input to the script, specify the location of the temporary storage location for backup files.\n\n\n\n!\/bin\/bash\nif [ $ -eq 0 ]\nthen\necho \"No arguments supplied\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_dr"},{"document_id":"ibmcld_06835-3900-5573","score":32.4560084111,"text":"\n* This toolchain uses [Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-cluster-config) to deploy an application to a group of clusters.\n* This toolchain assumes that you have a [Satellite cluster group](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig) with the required clusters.\n* This toolchain supports a Satellite cluster group that contains only one type of cluster (Red Hat\u00ae OpenShift\u00ae).\n\n\n\n\n\n\n\n Deployment \n\nDevSecOps provides out of the box scripts to deploy your application on the group of clusters. You might need to customize these scripts according to your application and cluster group requirements.\n\nThese scripts are located in the deployment repository and are specified in the pipeline-config.yml file.\n\ndeploy:\nimage: icr.io\/continuous-delivery\/pipeline\/pipeline-base-image:2.12@sha256:ff4053b0bca784d6d105fee1d008cfb20db206011453071e86b69ca3fde706a4\nscript: \n!\/usr\/bin\/env bash\n\nif [ \"$PIPELINE_DEBUG\" == 1 ]]; then\ntrap env EXIT\nenv\nset -x\nfi\n\nsource scripts\/deploy_setup.sh\nsource scripts\/deploy.sh\nexport DEPLOY_EXIT=$?\nsource scripts\/doi-publish-deploy.sh\nShow more\n\n\n\n\n\n\n\n Deploying to a custom target \n\nDeploy to a custom target if you want to:\n\n\n\n* Deploy your application on your own choice of infrastructure, such as Virtual Server Instances (VSI).\n* Perform custom tasks, such as updating some configurations in a Red Hat\u00ae OpenShift\u00ae cluster.\n\n\n\nIn these cases, select \"custom\" as a deployment target.\n\n\n\n Performing a custom deployment \n\n\n\n* DevSecOps templates are fully customizable. You can provide your own stages and steps in the pipeline-config.yml file of the deployment repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-deployment-target"},{"document_id":"ibmcld_06835-5127-5769","score":31.7230994009,"text":"\n* Deploy your application on your own choice of infrastructure, such as Virtual Server Instances (VSI).\n* Perform custom tasks, such as updating some configurations in a Red Hat\u00ae OpenShift\u00ae cluster.\n\n\n\nIn these cases, select \"custom\" as a deployment target.\n\n\n\n Performing a custom deployment \n\n\n\n* DevSecOps templates are fully customizable. You can provide your own stages and steps in the pipeline-config.yml file of the deployment repository.\n* You can provide your custom scripts in the setup, deploy, and acceptance-test stages in the pipeline-config.yml file.\n* These scripts are run during the continuous deployment (CD) pipeline run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-deployment-target"},{"document_id":"ibmcld_11640-2259-4018","score":30.6093784191,"text":"\nRed Hat's SAP Data Intelligence (SDI) Observer, SLC Bridge and SDI runtime components require separate projects\/namespaces for the related pods that will be deployed.\n\nIn the RHA, the sample project names (i.e. namespaces) are sdi, sdi-observer and sap-slcbridge. Following these naming conventions of the Red Hat article, create the related projects as follows.\n\n\n\n1. create the projects\n\n$ oc new-project sdi-observer\n$ oc new-project sap-slcbridge\n$ oc new-project sdi\n\n\n\n\n\n\n\n Deploying Red Hat's SAP Data Intelligence (SDI) Observer \n\nSAP Data Intelligence (SDI) Observer monitors SDI and SLC Bridge namespaces and applies changes to SDI deployments to allow SDI to run on OpenShift.\n\nThe projects' namespaces and Container Registry names used in the following steps are the same as those used in previous steps.\n\n\n\n1. SDI Observer needs a secret with credentials for registry.redhat.io\n\nFollow the section [4.2.1. Prerequisites for Connected OpenShift Cluster](https:\/\/access.redhat.com\/articles\/5100521sdi-observer-prereq-online) in the RHA and save your rht-registry-secret.yaml in the \/sap\/install directory. This yaml file will be required to automatically set the respective parameters below.\n2. Get information about Red Hat's SDI Observer installation script\n\nReview the section [4.2.3. Instantiation of Observer's Template](https:\/\/access.redhat.com\/articles\/5100521sdi-observer-instantiate) in the RHA to confirm the deployment instructions and the source URL are valid.\n3. Download the installation script\n\ncurl -O https:\/\/raw.githubusercontent.com\/redhat-sap\/sap-data-intelligence\/master\/observer\/run-observer-template.sh\n4. Edit the downloaded script file in your favorite editor; especially, mind the following parameters:\n\nFLAVOUR=ubi-build","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-rhos-di-dataintelligence"},{"document_id":"ibmcld_16729-86110-87974","score":30.1412367673,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Node.js Express application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Deploy a Java Spring app by using IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-spring-webapp)Deploy a Java Spring app by using IBM Cloud Schematics\n\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_12666-2025-3606","score":29.8284882908,"text":"\nAdditionally, the workstation must have a directory with write permissions and sufficient storage to store the backup. 125GB of storage space is sufficient for all deployments.\n\nTo take a backup, follow these steps:\n\n\n\n1. Access the cluster where Data Security Broker Manager is deployed by logging into a Kubernetes or Red Hat OpenShift workstation.\n2. To back up the MongoDB collections and Data Security Broker Manager configuration files, create the script provided below and execute it. The location that is specified after the -b option is where the backup file is kept by the script. Check whether the script is being used to back up a Data Security Broker Manager deployment on a Red Hat OpenShift cluster or a Kubernetes cluster, and uncomment the relevant command alias for the specified type of cluster where Data Security Broker Manager is installed.\n\n\n\n!\/bin\/bash\nif [ $ -eq 0 ]\nthen\necho \"No arguments supplied\"\necho \"Usage: $0 -b <backup location> -n <k8s namespace>\"\nfi\n\nwhile getopts b:n: flag\ndo\ncase \"${flag}\" in\nb) backup=${OPTARG};;\nn) namespace=${OPTARG};;\nesac\ndone\n\nif [ -z \"${backup}\" ];\nthen\necho \"Please provide backup location with -b option\"\nexit\nfi\n\nif [! -d \"$backup\" ];\nthen\necho \"Please provide a valid backup location with -b option\"\nexit\nfi\n\nif [ -z \"${namespace}\" ];\nthen\necho \"Please provide a valid namespace with -n option\"\nexit\nfi\n\n NOTE: SET THE kb ALIAS TO THE CORRECT ONE FOR THE CLUSTER TYPE\n\n For Kubernetes\nkb='kubectl --namespace $namespace'\n For OpenShift\nkb='kubectl --namespace '$namespace\n\n Retrieving container details\n\n\necho $kb","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_dr"},{"document_id":"ibmcld_11949-3497-5869","score":29.5313067838,"text":"\nThis use case is applicable to all industries.\n\n\n\n Deploying Red Hat OpenShift environment as a managed service wherever it is needed \n\nFrequent version upgrades and function modifications that require Kubernetes and Red Hat OpenShift skills are performed remotely through IBM Cloud managed services. The same services can be deployed wherever they are needed to process data close to its source to reduce latency.\n\nPain points:\n: It is hard to secure and maintain skills for running Red Hat OpenShift internally. There are limitations with where the services can be used as data must be loaded to cloud to use managed services.\n\nSatellite enables:\n: Using remotely delivered IBM\u2019s managed services eliminates the need to secure Red Hat OpenShift skills internally. You can deploy services wherever they are needed, on-premises or in remote locations.\n\n\n\n\n\n\n\n Finance use cases for Satellite \n\nThese use cases are applicable to the finance industry.\n\n\n\n Leveraging mainframe data for customers restricted from moving data to cloud \n\nThe on-premises platform is delivered remotely by IBM Cloud as a managed service. Cloud Pak for Data is run on this platform for analyzing and leveraging the mainframe data as is, on-premises.\n\nPain points:\n: Certain data cannot be placed on cloud for security reasons. Thus it is a challenge to maintain and manage data analytics systems.\n\nSatellite enables:\n: Analytics platform that was previously only available on cloud to be deployed on-premises at a customer site to bring mainframe data to life.\n\n\n\n\n\n Providing a unified environment for developing, verifying, and running containers for customer on third-party clouds \n\nIBM Cloud Managed Services that are required for developing, testing, and running containers are deployed on third-party clouds for a unified container platform. Red Hat OpenShift and container application versions can be managed from one single location.\n\nPain points:\n: It is hard to operate Red Hat OpenShift across locations and environments. Middleware and application versions and releases are inconsistent across environments.\n\nSatellite enables:\n: Central management of Red Hat OpenShift services that are deployed at various locations, ensuring that the services are run using consistent versions and releases.\n\n\n\n\n\n Extending IBM Cloud security and compliance for customers maintaining cloud security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-use-case"},{"document_id":"ibmcld_14490-7-2135","score":29.3646413213,"text":"\nManaging Red Hat OpenShift for VMware \n\nReview the following information to manage your Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service after deployment.\n\n\n\n Rotating the Red Hat OpenShift certificates (required) \n\nRed Hat OpenShift for VMware uses kubelet client certificates that must be rotated periodically for security purposes. Red Hat OpenShift mainly automates the rotation process, but requires manual approval of certificate signing requests (CSRs). Therefore, it is important that you understand the Red Hat OpenShift certificate rotation schedule to avoid expired certificates.\n\nThe initial certificates that are created during installation expire 24 hours after they are created. IBM's automation process, which installs Red Hat OpenShift, handles the approval of the CSRs for this initial rotation, which is done by running a script on the bastion for the first 30 hours. The script is named \/root\/approve-csr.sh and its log file is named \/root\/approve-csr.log.\n\nFor the script to run successfully, the initial kubeadmin credentials must be the same until the initial certificate rotation is complete. Do not change the kubeadmin credentials for the first 24 hours. If the credentials are changed, you must monitor and approve the CSRs for the initial certificate rotation. For more information, see [Approving the CSRs for your machines](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.htmlinstallation-approve-csrs_installing-vsphere).\n\nDo not restart any of the Red Hat OpenShift cluster virtual machines (VMs) or the bastion VM until the first certificate rotation is done.\n\nAfter the initial certificate rotation, certificates are renewed every 30 days. You must establish a process to approve the CSRs for every certificate rotation. According to Red Hat\u00ae, you can approve CSRs when they reach 80% of their expiration period, which is approximately 25 days into the lifespan of the CSRs.\n\nIf you do not approve CSRs in time and the certificates expire, you can recover from expired control plane certificates and get the Red Hat OpenShift cluster operational again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_managing"},{"document_id":"ibmcld_14492-8686-10586","score":29.2161964871,"text":"\n* Before the service is installed in your environment, a check is completed against the available capacity of the target cluster in the environment to ensure that the service components can fit. The storage capacity check applies only to vSAN storage. For NFS clusters, a new NFS datastore, dedicated to Red Hat OpenShift, is added.\n* The cluster is associated with the Red Hat account from the pull secret that is provided.\n* The Latency Sensitivity setting of the Red Hat OpenShift cluster VMs can affect Kubernetes scheduling performance. By default, the setting is set to Normal, but it can be set to High if you encounter Kubernetes performance issues.\n\n\n\n\n\n\n\n Considerations when you delete Red Hat OpenShift for VMware \n\n\n\n* Before you delete Red Hat OpenShift for VMware, you must remove any additional VMs that you created in the ocp directory on VMware. The VMware Solutions automation removes only the items that were deployed during the initial installation of Red Hat OpenShift (VMs, storage, and NSX). Any node that is deployed after the installation is not cleaned up.\n* The VXLAN, DLR, and the Edge Gateway that were created during the initial deployment of Red Hat OpenShift for VMware is deleted. The VMs that you deployed on VXLAN will lose connectivity after the removal of Red Hat OpenShift for VMware starts.\n* If your cluster uses NFS storage, deleting Red Hat OpenShift deletes the NFS datastore that was added during installation.\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_08259-0-511","score":29.1764127176,"text":"\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12791-3746-5818","score":24.2030886838,"text":"\nTable 2. Roles and example actions for a policy on all IAM account management services\n\n Roles Actions \n\n Viewer All viewer role actions for IAM services \n Operator All operator role actions for IAM services \n Editor All editor role actions for IAM services and the ability to create resource groups \n Administrator All administrator role actions for IAM services and the ability to create resource groups \n User API key creator Create API keys when the account setting to restrict API key creation is enabled \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 3. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_03710-0-838","score":23.255870589,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_12597-0-804","score":23.2217229442,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03786-7-2105","score":22.8326342589,"text":"\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https:\/\/cloud.ibm.com\/billing\/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https:\/\/www.ibm.com\/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03786-1684-3421","score":22.43745096,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03785-7-2010","score":22.2594981054,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_12791-59012-61053","score":21.8907537498,"text":"\nBilling \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 4. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise \n\n\n\nIt's possible to view subscription balances and usage from the Account settings page, but you can't view the Account settings page with the Viewer or Operator roles. To access the Account settings page and your subscription information from that page, you need the Editor role or higher.\n\n\n\n\n\n Catalog management \n\nYou can give users access to view private catalogs and catalog filters, create private catalogs, add software to private catalogs, and set catalog filters.\n\n\n\nTable 5. Roles and example actions for the catalog management service\n\n Roles Actions \n\n Viewer View account-level filters set for the IBM Cloud catalog<br><br>View private catalogs \n Operator Create private catalogs<br><br>Set filters for private catalogs<br><br>Add and update software<br><br>View account-level filters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_12791-80048-82089","score":21.8907537498,"text":"\nBilling \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 3. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise \n\n\n\nIt's possible to view subscription balances and usage from the Account settings page, but you can't view the Account settings page with the Viewer or Operator roles. To access the Account settings page and your subscription information from that page, you need the Editor role or higher.\n\n\n\n\n\n Catalog management \n\nYou can give users access to view private catalogs and catalog filters, create private catalogs, add software to private catalogs, and set catalog filters.\n\n\n\nTable 4. Roles and example actions for the catalog management service\n\n Roles Actions \n\n Viewer View account-level filters set for the IBM Cloud catalog<br><br>View private catalogs \n Operator Create private catalogs<br><br>Set filters for private catalogs<br><br>Add and update software<br><br>View account-level filters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_07578-1065299-1067188","score":21.6992452725,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1068047-1069909","score":21.6029666205,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11192-0-1195","score":22.4649058385,"text":"\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/planning-analytics?topic=planning-analytics-exploring-scorecards"},{"document_id":"ibmcld_09615-10623-12269","score":20.2249512157,"text":"\n\"containers-kubernetes\"\n]\n},\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-4729-6393","score":20.174480511,"text":"\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-2350-4116","score":20.0861290048,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-8271-10037","score":20.0861290048,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09628-1427-3147","score":20.0461002297,"text":"\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:\n\noperand\n: Operand is the name of the property in the target that is used to filter data. The following operands are supported: location, service_name, service_instance, resource_type, and resource. The value is extracted from the target CRN.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route_rules_definitions"},{"document_id":"ibmcld_09623-1182-2897","score":20.0014824749,"text":"\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Configure the route \n\nRun the following command to exclude all metrics received by IBM Cloud Metrics Routing from the us-south region.\n\nibmcloud metrics-router route create --name drop-route --rules '[{\"action\": \"drop\", \"inclusion_filters\":{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}]}]'\n\nWhere inclusion_filters specifies the filters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09623-4-1600","score":19.8793537823,"text":"\n* CLI\n\n\n\n\n\n\n\n Excluding metrics by using the drop action \n\nYou can configure IBM Cloud\u00ae Metrics Routing to exclude (drop) metrics based on a configured rule. Dropped metrics are not sent on to a target.\n\n\n\n Prereqs \n\n\n\n1. [Install the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli).\n2. [Install the IBM Cloud Metrics Routing CLI](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli-config).\n3. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing routes.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-iam)\n4. Log in to IBM Cloud. Run the following command: [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_login).\n\n\n\n\n\n\n\n Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location, service_name, service_instance, resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09625-1179-2989","score":19.7983372537,"text":"\nStep 2: Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Step 3: Configure the route","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-from-1-location"},{"document_id":"ibmcld_04612-2600-4714","score":19.2255028338,"text":"\nThe CPU utilization can be affected by the total workload of the hosting hardware and other factors.\n* Responsetime is the average amount of time that the app takes to respond to a request. Responsetime is specified in ms (milliseconds).\n* Throughput is the total number of the requests that are processed in a time period. Throughput is specified in rps (requests per second).\n* Custom_metric is your own custom metric. The Custom_metric name can be any alphanumeric value. Autoscaling is triggered when the corresponding metric is emitted to the App Autoscaler. For more information, see the [custom metric usage guide](https:\/\/github.com\/cloudfoundry\/app-autoscaler\/tree\/develop\/docsauto-scale-your-application-with-custom-metrics).\n\n\n\nIn addition to specifying the metric type, specify an operator, threshold, breach duration, adjustment, and cooldown period values.\n\nWhen the threshold is continuously breached during the breach duration period, and beyond the cooldown period, the App AutoScaler triggers the defined autoscaling action. The number or percentage of app instances is adjusted.\n\n\n\n* The operator can be >=, >, <=, or <.\n* The threshold must be a numeric value.\n* The breach duration is defined in seconds. The default value is 120 seconds.\n* The adjustment value specifies how the number of app instances change in each scaling action. You can specify an absolute number or a percentage of instances to add or remove.\n* The cooldown period specifies the time to wait before the taking the next autoscaling action. A cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13499-36436-37794","score":28.5819482829,"text":"\nmap(key0, value0, key1, value1, ...)\n: Creates a map with the indicated key\/value pairs.\n: Example of an SQL function usage fragment\n\n> SELECT map(1.0, '2', 3.0, '4')\n: Result value\n\n{1.0:\"2\",3.0:\"4\"}\n\n\n\n\n\n map_keys \n\nmap_keys(map)\n: Returns an unordered array that contains the keys of the map.\n: Example of an SQL function usage fragment\n\n> SELECT map_keys(map(1, 'a', 2, 'b'))\n: Result value\n\n[1,2]\n\n\n\n\n\n map_values \n\nmap_values(map)\n: Returns an unordered array that contains the values of the map.\n: Example of an SQL function usage fragment\n\n> SELECT map_values(map(1, 'a', 2, 'b'))\n: Result value\n\n[\"a\",\"b\"]\n\n\n\n\n\n max \n\nmax(expr)\n: Returns the maximum value of expr.\n\n\n\n\n\n md5 \n\nmd5(expr)\n: Returns an MD5 128-bit checksum as a hex string of expr.\n: Example of an SQL function usage fragment\n\n> SELECT md5('Spark')\n: Result value\n\n8cde774d6f7333752ed72cacddb05126\n\n\n\n\n\n mean \n\nmean(expr)\n: Returns the mean that is calculated from values of a group.\n\n\n\n\n\n min \n\nmin(expr)\n: Returns the minimum value of expr.\n\n\n\n\n\n minute \n\nminute(timestamp)\n: Returns the minute component of the string\/timestamp.\n: Example of an SQL function usage fragment\n\n> SELECT minute('2009-07-30 12:58:59')\n: Result value\n\n58\n\n\n\n\n\n mod \n\nexpr1 mod expr2\n: Returns the remainder after expr1\/expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 mod 1.8;\n: Result value","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_13499-10963-12511","score":25.2584476914,"text":"\n: Returns the inverse tangent (also known as arctangent).\n: Example of an SQL function usage fragment\n\n> SELECT atan(0)\n: Result value\n\n0.0\n\n\n\n\n\n atan2 \n\natan2(expr1, expr2)\n: Returns the angle in radians between the positive x-axis of a plane and the point that is indicated by the coordinates (expr1, expr2).\n: Example of an SQL function usage fragment\n\n> SELECT atan2(0, 0)\n: Result value\n\n0.0\n\n\n\n\n\n avg \n\navg(expr)\n: Returns the mean that is calculated from values of a group.\n\n\n\n\n\n base64 \n\nbase64(bin)\n: Converts the argument from a binary bin to a base 64 string.\n: Example of an SQL function usage fragment\n\n> SELECT base64('Spark SQL')\n: Result value\n\nU3BhcmsgU1FM\n\n\n\n\n\n bigint \n\nbigint(expr)\n: Casts the value expr to the target data type bigint.\n\n\n\n\n\n bin \n\nbin(expr)\n: Returns the string representation of the long value expr represented in binary.\n: Example of an SQL function usage fragment\n\n> SELECT bin(13)\n: Result value\n\n1101\n: Example of an SQL function usage fragment\n\n> SELECT bin(-13)\n: Result value\n\n1111111111111111111111111111111111111111111111111111111111110011\n: Example of an SQL function usage fragment\n\n> SELECT bin(13.3)\n: Result value\n\n1101\n\n\n\n\n\n binary \n\nbinary(expr)\n: Casts the value expr to the target data type binary.\n\n\n\n\n\n bit_length \n\nbit_length(expr)\n: Returns the bit length of string data or number of bits of binary data.\n: Example of an SQL function usage fragment\n\n> SELECT bit_length('Spark SQL')\n: Result value\n\n72\n\n\n\n\n\n boolean \n\nboolean(expr)\n: Casts the value expr to the target data type boolean.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_00644-12745-14507","score":22.8430063806,"text":"\nOr you can stop views from auto-updating by adding one of the following options to a design document. You can stop all index types from indexing if you set \"autoupdate\": false.\n\nSee the following examples:\n\n{\n\"_id\": \"_design\/lookup\",\n\"autoupdate\": false,\n\"views\": {\n\"view\": {\n\"map\": \"function(doc)...\"\n}\n}\n}\n\n{\n\"_id\": \"_design\/lookup\",\n\"autoupdate\": {\"views\": false},\n\"views\": {\n\"view\": {\n\"map\": \"function(doc)...\"\n}\n}\n}\n\n\n\n\n\n View freshness \n\nBy default, all index results reflect the current state of the database. IBM Cloudant builds its indexes automatically and asynchronously in the background. This practice usually means that the index is fully up to date when you query it. If not, by default, IBM Cloudant applies the remaining updates at query time.\n\nIBM Cloudant provides a few parameters, described next to alter this behavior. We recommend against using them as the side-effects typically outweigh their benefit.\n\n\n\n Parameters \n\nThe update option indicates whether you're prepared to accept view results without waiting for the view to be updated. The default value is true, meaning that the view is updated before results are returned. The lazy value means that the results are returned before the view is updated, but that the view must then be updated anyway.\n\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_13499-7-1400","score":21.300985229,"text":"\nSQL functions \n\nYou can use any of the following functions in your query.\n\n\n\n ! \n\nexpr\n: Logical not.\n\n\n\n\n\n % \n\nexpr1 % expr2\n: Returns the remainder after expr1\/expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 % 1.8\n: Result value\n\n0.2\n: Example of an SQL function usage fragment\n\n> SELECT MOD(2, 1.8)\n: Result value\n\n0.2\n\n\n\n\n\n & \n\nexpr1 & expr2\n: Returns the result of bitwise AND of expr1 and expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 3 & 5\n: Result value\n\n1\n\n\n\n\n\n * \n\nexpr1 * expr2\n: Returns expr1*expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 * 3\n: Result value\n\n6\n\n\n\n\n\n + \n\nexpr1 + expr2\n: Returns expr1+expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 1 + 2\n: Result value\n\n3\n\n\n\n\n\n - \n\nexpr1 - expr2\n: Returns expr1-expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 - 1\n: Result value\n\n1\n\n\n\n\n\n \/ \n\nexpr1 \/ expr2\n: Returns expr1\/expr2. It always performs floating point division.\n: Example of an SQL function usage fragment\n\n> SELECT 3 \/ 2\n: Result value\n\n1.5\n: Example of an SQL function usage fragment\n\n> SELECT 2L \/ 2L\n: Result value\n\n1.0\n\n\n\n\n\n < \n\nexpr1 < expr2\n: Returns true if expr1 is less than expr2.\n: Arguments\n\nexpr1, expr2 - The two expressions must be same type or can be cast to a common type, and must be a type that can be ordered. For example, map type is not orderable, so it is not supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_13499-34156-35576","score":21.190782373,"text":"\nln \n\nln(expr)\n: Returns the natural logarithm (base e) of expr.\n: Example of an SQL function usage fragment\n\n> SELECT ln(1)\n: Result value\n\n0.0\n\n\n\n\n\n locate \n\nlocate(substr, str[, pos])\n: Returns the position of the first occurrence of substr in str after position pos. The indicated pos and return value are 1-based.\n: Example of an SQL function usage fragment\n\n> SELECT locate('bar', 'foobarbar')\n: Result value\n\n4\n: Example of an SQL function usage fragment\n\n> SELECT locate('bar', 'foobarbar', 5)\n: Result value\n\n7\n: Example of an SQL function usage fragment\n\n> SELECT POSITION('bar' IN 'foobarbar')\n: Result value\n\n4\n\n\n\n\n\n log \n\nlog(base, expr)\n: Returns the logarithm of expr with base.\n: Example of an SQL function usage fragment\n\n> SELECT log(10, 100)\n: Result value\n\n2.0\n\n\n\n\n\n log10 \n\nlog10(expr)\n: Returns the logarithm of expr with base 10.\n: Example of an SQL function usage fragment\n\n> SELECT log10(10)\n: Result value\n\n1.0\n\n\n\n\n\n log1p \n\nlog1p(expr)\n: Returns log(1 + expr).\n: Example of an SQL function usage fragment u\n\n> SELECT log1p(0)\n: Result value\n\n0.0\n\n\n\n\n\n log2 \n\nlog2(expr)\n: Returns the logarithm of expr with base 2.\n: Example of an SQL function usage fragment\n\n> SELECT log2(2)\n: Result value\n\n1.0\n\n\n\n\n\n lower \n\nlower(str)\n: Returns str with all characters that are changed to lowercase.\n: Example of an SQL function usage fragment\n\n> SELECT lower('SparkSql')\n: Result value\n\nsparksql\n\n\n\n\n\n lpad","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_13464-1580-3453","score":21.1826255588,"text":"\nEach of these functions retrieves information about a time series.\n\nTS_DESCRIBE(DoubleTimeSeries)\n: Output: Statistics for time series\n: Returns a set of columns with timing statistics, value statistics, and numeric statistics.\n\nTS_COUNT(TimeSeries)\n: Output: Integer\n: Returns the number of observations in a time series.\n\nTS_COUNT_ANCHOR(TimeSeries, AnchorType)\n: Output: Integer\n: Returns the number of times that the specified anchor would be set in the input time series.\n\nTS_SEG_COUNT(SegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the number of observations in each segment of a time series. In the output, each timetick is the timetick of the first observation in the corresponding segment.\n\n\n\n\n\n Statistical functions \n\nEach of these functions derives statistical insight from time series data. Each statistical function is of one of the following types:\n\n\n\n* A transform produces, as output, a new time series.\n* A reducer produces, as output, a single value, such as a distance or average.\n\n\n\nTS_AWGN(DoubleTimeSeries, Double, Double)\n: Output: DoubleTimeSeries\n: Add, to a time series, white Gaussian noise with the specified mean (second parameter) and standard deviation (third parameter).\n\nTS_MWGN(DoubleTimeSeries, Double)\n: Output: DoubleTimeSeries\n: Add, to a time series, mean white Gaussian noise with the specified standard deviation (second parameter).\n\nTS_ZSCORE(DoubleTimeSeries, Double, Double)\n: Output: DoubleTimeSeries\n: Calculates the Z-score of a time series with the specified mean (second parameter) and standard deviation (third parameter).\n\nTS_PEAK(DoubleTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the peaks of the time series.\n\nTS_TROUGH(DoubleTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the troughs of the time series.\n\nTS_DIFF(DoubleTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the difference of the time series.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-data_processing_functions"},{"document_id":"ibmcld_13462-25116-27203","score":21.09081493,"text":"\nThe threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of pattern size to sublist. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the time series values, in sequence and contiguously. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSEQ_PS(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a subsequence of a string time series, to within the specified coverage threshold. The threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of pattern size to sequence size. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the sequence of time series values, in sequence but not necessarily contiguously. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSEQ_PM(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a subsequence of a string time series, to within the specified coverage threshold. The threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of pattern size to match string size. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the match string, in sequence but not necessarily contiguously. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSEQ_MS(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a subsequence of a string time series, to within the specified coverage threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-artifact"},{"document_id":"ibmcld_13499-66303-67259","score":20.9184154465,"text":"\n: Returns a short integer value, or the value zero if no match is found, or a match is found but the value is nonnumeric.\n: Example of an SQL function usage fragment\n\n> SELECT xpath_short('<a><b>1<\/b><b>2<\/b><\/a>', 'sum(a\/b)')\n: Result value\n\n3\n\n\n\n\n\n xpath_string \n\nxpath_string(xml, xpath)\n: Returns the text contents of the first xml node that matches the XPath expression.\n: Example of an SQL function usage fragment\n\n> SELECT xpath_string('<a><b>b<\/b><c>cc<\/c><\/a>','a\/c')\n: Result value\n\ncc\n\n\n\n\n\n year \n\nyear(date)\n: Returns the year component of the date\/timestamp.\n: Example of an SQL function usage fragment\n\n> SELECT year('2016-07-30')\n: Result value\n\n2016\n\n\n\n\n\n | \n\nexpr1 | expr2\n: Returns the result of bitwise OR of expr1 and expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 3 | 5;\n: Result value\n\n7\n\n## \n: expr\n: Returns the result of bitwise NOT of expr.\n: Example of an SQL function usage fragment\n\n> SELECT 0;\n: Result value\n\n-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_13462-26643-28783","score":20.8967868851,"text":"\nFor example, a threshold of 0.75 means that the specified pattern must match at least 75% of the match string, in sequence but not necessarily contiguously. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSEQ_MS(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a subsequence of a string time series, to within the specified coverage threshold. The threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of match string size to sequence size. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the sequence of time series values. If the threshold is met, the pattern is considered to match the subsequence and the function that uses the matcher returns the observations that correspond to the match string; otherwise, the function returns null.\n\nTS_MATCHER_SUBSET_PS(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a string time series, regardless of the order in the items in the pattern and the order in the time series. The specified coverage threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of pattern size to sequence size. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the sequence of time series values. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSET_PM(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a string time series, regardless of the order in which the items in the pattern occur in the time series. The specified coverage threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of pattern size to match string size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-artifact"},{"document_id":"ibmcld_13462-28201-29881","score":20.8918903005,"text":"\nIf the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSET_PM(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a string time series, regardless of the order in which the items in the pattern occur in the time series. The specified coverage threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of pattern size to match string size. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the match string, in sequence but not necessarily contiguously. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the pattern; otherwise, the function returns null.\n\nTS_MATCHER_SUBSET_MS(Double) Output: MatcherType\nCreates a matcher that matches an array of string values (the pattern) with a string time series, regardless of the order in which the items in the pattern occur in the time series. The specified coverage threshold is a double-precision number in the range 0.0 - 1.0 that indicates the minimum ratio of match string size to sequence size. For example, a threshold of 0.75 means that the specified pattern must match at least 75% of the match string, in sequence but not necessarily contiguously. If the threshold is met, the pattern is considered to match, and the function that uses the matcher returns the observations that correspond to the match string; otherwise, the function returns null.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-artifact"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":60.6551278358,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":60.460525294,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":57.8332924364,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":42.4022224127,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":39.8911059739,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":39.870443096,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03713-7896-8949","score":37.5954584042,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03794-0-812","score":34.0214812123,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_03793-7-1857","score":30.3218684637,"text":"\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https:\/\/cloud.ibm.com\/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm"},{"document_id":"ibmcld_07578-1068305-1070191","score":29.1691422287,"text":"\nYou can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqscancelaccount).\n\n\n\nManaging your account, resources, and access\n\n\n\n* How do I create an IBM Cloud account?\n\nYou can create an account by [registering](https:\/\/cloud.ibm.com\/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n* How is my credit card authorized?\n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09994-7-1823","score":29.3717712989,"text":"\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_00522-2652-4218","score":28.0884091488,"text":"\nOpen the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard1.png)\n\nFigure 1. Window for running queries\n\n\n\nIBM Cloudant matches the documents that meet your criteria and it seems to do it quickly, but there's a catch. IBM Cloudant isn't using an index to service this query, meaning that the database has to scan every document in the database to get your answer. This scan is fine for small data sets. But if you're running a production application where the data set is expanding all the time, you definitely don't want to rely on unindexed queries.\n\n\n\n\n\n Creating an index \n\nTo create an index, we can tell IBM Cloudant to create an index on the publisher and year fields that we are using in our query.\n\n\n\n1. From the IBM Cloudant Dashboard, select the books database.\n2. Select the Design Documents tab.\n3. Select New Indexes from the Design Documents menu.\n4. Copy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_02563-5820-8096","score":26.4211534478,"text":"\n* Expanding the types of resources that could be referenced by an href or embedded reference schema within the context of another resource.\n\n\n\n\n\n\n\n Changing default values \n\nAdditionally, a default value for a property in a request MAY be changed if the new default has no increase in price or regressions in performance or supported features at the time of the change.\n\nFor example, the default pricing profile for a new resource may be changed if the new default is considered better in all respects and is an equal or lower price at the time of the change. (The profile that was previously default may be made less expensive at the same time, or after, but not before the change.)\n\n\n\n\n\n Resolving API definition errata \n\nIf the implementation for an API is well-designed and functional, but the API definition differs from the implementation in an incompatible way, the definition SHOULD be updated to match the implementation, despite the resultant appearance of an incompatible change.\n\n\n\n\n\n\n\n Backward-incompatible changes \n\nA change that meaningfully alters the outcome or response format of any currently valid request MUST be considered backward-incompatible. Backward-incompatible changes SHOULD be supported in versioned updates.\n\nThe following kinds of changes SHOULD be considered backward-incompatible unless [a special case](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-change-compatibilityspecial-cases-for-backward-compatibility) applies:\n\n\n\n* Removing or renaming an existing path\n* Removing support for an existing method on an existing path\n* Removing or renaming an existing query parameter\n* Removing or renaming an existing property in a request or response schema\n* Adding a new required query parameter, header, or property in a request schema\n* Changing the status code for a particular scenario (except when the existing status code is 404)\n* Reducing acceptable values for an existing query parameter, header, or property in a request schema\n* Changing the semantics of a value for an existing query parameter, header, or property in a response schema\n* Changing a default value or behavior for an already-valid request\n* Redefining the nature of any relationship between resources\n\n\n\n\n\n Migrating to updated robustness best practices","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-change-compatibility"},{"document_id":"ibmcld_13480-7832-9910","score":25.9945840499,"text":"\nSELECT * FROM cos:\/\/us-geo\/sql\/customers.csv\nINTO cos:\/\/us-geo\/mybucket\/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS\n\nThis clause overwrites the current partition definitions for the table with the structure that is detected from Object Storage data by using the location prefix that is specified for the table. You can also update partition definitions selectively with the ADD PARTITION and DROP PARTITION clauses of the ALTER TABLE statement, for example, to attach more data to a table that was uploaded recently.\n\nWhen you added all partitions, the partitioned table is set up to be queried. You get all the German customers, if you submit the following query:\n\nSELECT customerID FROM customers WHERE country = 'Germany'\n\nThe query execution reads the objects only under the cos:\/\/us-geo\/sql\/customers_partitioned.csv\/country=Germany\/ prefix because the partition definitions are used by the query optimizer to minimize the necessary data transfer.\n\n\n\n\n\n\n\n Limitations \n\n\n\n* With the Standard plan, you can create up to 100 tables with up to 20,000 partitions per table.\n* If you use the Lite plan, the catalog management features, such as CREATE TABLE, are not allowed.\n* The ADD PARTITION option of the ALTER TABLE statement may not correctly locate partitions if the value for a partition column contains special characters, such as the colon : that can appear as a timestamp separator.\n\nWhen the location is inferred from one or more partition values, some special characters in the values are URL escaped when you construct the Object Storage location. For example, the statement ALTER TABLE mytable ADD PARTITION ( startTime = '2020-01-01 12:00:00' ) constructs a partition with an Object Storage location ...\/startTime=2020-01-01 12%3A00%3A00\/.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_09991-7-1416","score":25.3327798593,"text":"\nQuerying historical data \n\nYou can run the queries by using the command-line or the [query editor inside the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-query-editor).\n\nThe following table definition is used for the example queries.\n\nCREATE TABLE PRODUCT (PRODUCTID INTEGER, DESC VARCHAR (100), PRICE DECIMAL) DATA_VERSION_RETENTION_TIME 30;\n\nThe following rows are inserted at different times. The commit times of the inserts (the insert timestamps or _SYS_START values) are indicated in SQL comments.\n\nINSERT INTO PRODUCT VALUES(1001, 'Jacket', 102.00); -- 2020-10-23 16:00:00\nINSERT INTO PRODUCT VALUES(1002, 'Gloves', 20.50); -- 2020-10-23 16:05:00\nINSERT INTO PRODUCT VALUES(1003, 'Hat', 18.99); -- 2020-10-23 16:10:00\nINSERT INTO PRODUCT VALUES(1004, 'Shoes', 125.25); -- 2020-10-23 16:15:00\n\n\n\n Showing data with the insert and delete timestamps \n\nThis SELECT command shows the table data with the associated insert and delete timestamp values at that instant when the query was issued. The _SYS_START and _SYS_END timestamps are available only in time travel queries, hence the use of AS OF NOW().\n\nSELECT , _SYS_START, _SYS_END FROM <table_name> FOR SYSTEM_TIME AS OF NOW();\n\nExample:\n\nSELECT , _SYS_START, _SYS_END FROM PRODUCT FOR SYSTEM_TIME AS OF NOW();\nPRODUCTID | DESCRIPTION | PRICE | _SYS_START | _SYS_END\n----------+-------------+---------+---------------------+-----------","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-queryingdata_tt"},{"document_id":"ibmcld_00580-42802-44973","score":25.2225570287,"text":"\nThis practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.\n\nComplete the index definition with the JSON:\n\nClick Create Index when you're done.\n\nClicking the button sends a POST request to the _index endpoint (other API calls are available to update and delete existing indexes).\n\nIndexes are built asynchronously by IBM Cloudant in the background. For large databases, it can take IBM Cloudant some time to construct the index for the first time. The index cannot use the database until that initial build is ready.\n\nWe can repeat our query for books in the 20th century. This time we specify the index name with the use_index field. The answer returns - this time powered by our index. You might not notice a speed improvement for a small database, but the benefit is definitely felt as your data size and query volume grows. Indexing helps your queries remain performant as your application scales.\n\nWhen you tell IBM Cloudant to create a secondary index, it starts a background task that looks at all the documents in turn and creates a new data structure on disk: the index. The index is a balanced tree which pairs the keys (the attribute or attributes that you need indexed) with the document _id they came from.\n\nThe index can be used to efficiently lookup known keys and ranges of keys without having to rescan the entire database.\n\nAnother trick that you can employ at index time is the partial filter. You can optionally supply a partial filter in your index definition. This IBM Cloudant Query selector is executed at index time to decide which documents' data makes it to the index and which are ignored.\n\nIn this example, a selector is employed that allows only dates that fall on a weekend to make it to the index. Smaller indexes are faster and more efficient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_02628-2920-4398","score":24.8508074292,"text":"\n![toolkit-add-new-api.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/toolkit-add-new-api.png)\n6. Click Create API to complete the wizard.\n7. After your API is created, the Design tab is selected.\n8. Scroll to the Host panel. Enter $(catalog.host) as the value if the field is not automatically completed.\n9. Scroll to the Security tab and delete the \"clientIDHeader (API Key)\" that was auto-generated.\n(We'll visit security with API Keys in the next tutorial.)\n10. In the Paths panel, create a path by clicking +. a. Name the new path \"\/current\".\nb. In the same Paths panel, select the GET \/current section.\nc. In the GET \/current section, add a Parameter. As you noticed while exploring the sample app, the weather service requires zipcode as a parameter.\n\n\n\n* Name: zipcode\n* Located in: Query\n* Required: Yes\n* Type: string\n![path-current-1.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/path-current-1.png) d. Save your API.\n\n\n\n11. With your query parameters defined in the previous step, you are ready to define the response object, which is returned when you invoke the weather API. Scroll to the Definitions panel.\n\n\n\n1. Add a new definition.\n2. Name the new definition Current.\n3. Set the Type of Object.\n4. Add new properties for the Current definition as shown in Table 1.\n\n\n\nTable 1. Properties for the Current definition","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-tut_add_openapi_rest_tk"},{"document_id":"ibmcld_13498-100465-102250","score":24.5773852403,"text":"\nCAST(2018-10-31 23:55:00 AS TIMESTAMP) CAST(2018-2-28 23:55:00 AS DATE) CAST(HELLO AS TIMESTAMP) \n\n 2018-10-31 23:55:00.0 2018-02-28 null \n\n\n\n\n\n\n\n Boolean type \n\nThe BOOLEAN type represents a domain with two values, true or false. Any numeric value that represents zero, for example, 0, 0.0, or 0.0E10, can be cast to false. Numeric values that represent a nonzero value, for example, 1, 1.0, 1.0E10, or 21474.83648 can be cast to true. The string value '0' can be cast to false and '1' can be cast to true. Any other string value is cast to false.\n\n\n\n\n\n Binary type \n\nA BINARY type represents an array of byte values. Thus, string values can be cast to type BINARY.\n\n\n\n\n\n Related references - dataType \n\nA dataType is referenced by the following clauses:\n\n\n\n* [castExpression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecastExpression)\n* [createTable](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecreateTable)\n\n\n\n\n\n\n\n\n\n Catalog management \n\nThe following commands allow users to store table metadata catalog in the Data Engine catalog. By defining the tables, columns, and partitions in the catalog, you can use short table names in the SQL SELECT statements. Each instance of Data Engine has its own catalog, and table definitions are not visible from other instances. For more information, see [catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-101780-103603","score":24.5770566554,"text":"\nFor more information, see [catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.\n\nThe column and partition definitions are optional. If they are not provided, the table schema and partitioning is detected from the structure of the data at the indicated location. If you explicitly provide these definitions, ensure that they match the objects that are stored in Object Storage. See [data types](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencedataType) for details on the supported column types.\n\n-- create a definition for the table customer\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nlocation cos:\/\/us-geo\/sql\/customers.csv\nShow more\n\nBefore you can use a newly created partitioned table, you must call ALTER TABLE tablename RECOVER PARTITIONS. Otherwise, querying the table returns an empty result.\n\n-- create a definition for the table customers_partitioned\nCREATE TABLE customers_partitioned (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (COUNTRY)\nlocation cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\n-- attach table partitions by scanning the location of the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-39344-41146","score":24.297636243,"text":"\nWith this function, you can write results, for example, into Parquet, without the need to provide column by column alias names in your SQL when your input data has columns with these characters. A typical situation is the existence of space () in input columns.\n\nFor example, you can use SELECT * FROM CLEANCOLS(cos:\/\/us-geo\/sql\/iotmessages STORED AS JSON) INTO cos:\/\/us-geo\/mybucket\/myprefix STORED AS PARQUET to produce a result set that can be stored as is into Parquet target format.\n\nIf you wrap your external table definition with the DESCRIBE table transformer, the table does not show its actual content but the schema that is inferred from the objects in IBM Cloud\u00ae Object Storage instead. With this function, you can explore the schema before you author your actual SQL statements against it.\n\nWhen you use the DESCRIBE table transformer in your SQL statement, the default output format is JSON instead of CSV.\n\nYou can also wrap DESCRIBE around the other table transformers to explore the transformed table schema. However, you cannot wrap other table transformers around the DESCRIBE transformer.\n\n\n\n\n\n tableValuedFunction \n\nA table-valued function returns a relation, which is a set of rows. An example of a table-valued function is range(). For more information, see [SQL functions](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctionssqlfunctions).\n\n\n\n\n\n More topics - relation clause \n\nFor more information about the clauses that are used in relation clauses, see the following topics:\n\n\n\n* [booleanExpression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencebooleanExpression)\n* [COSURI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceCOSURI)\n* [expression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexpression)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15545-195860-197138","score":22.9573143126,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":22.9573143126,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-195756-197034","score":22.9573143126,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-195812-197090","score":22.9573143126,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_15507-5434-7003","score":21.3842138719,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15507-6657-8493","score":20.8312143002,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-26617-28366","score":20.6610062373,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":20.6610062373,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-30301-32015","score":20.6420028471,"text":"\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Remove previously scheduled custom image lifecycle status by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \"deprecation_at\": null }'\n* To change an image from obsolete to its previous state, change obsolescence_at to null. If the image previously contained a value other than null for deprecation_at, then this property change removes the obsolete state and changes it back to deprecated. If the previous state was available, meaning the image was moved from available directly to obsolete, then this property change moves from obsolete back to available.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \u201cobsolescence_at\": null }'\n* To change an image that has both the deprecation_at or obsolescence_at properties set back to available, you must update both the deprecation_at or obsolescence_at properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-30340-32054","score":20.6420028471,"text":"\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Remove previously scheduled custom image lifecycle status by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \"deprecation_at\": null }'\n* To change an image from obsolete to its previous state, change obsolescence_at to null. If the image previously contained a value other than null for deprecation_at, then this property change removes the obsolete state and changes it back to deprecated. If the previous state was available, meaning the image was moved from available directly to obsolete, then this property change moves from obsolete back to available.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \u201cobsolescence_at\": null }'\n* To change an image that has both the deprecation_at or obsolescence_at properties set back to available, you must update both the deprecation_at or obsolescence_at properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15545-195860-197138","score":24.4481042533,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":24.4481042533,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-195756-197034","score":24.4481042533,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-195812-197090","score":24.4481042533,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_15646-30301-32015","score":23.3612964265,"text":"\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Remove previously scheduled custom image lifecycle status by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \"deprecation_at\": null }'\n* To change an image from obsolete to its previous state, change obsolescence_at to null. If the image previously contained a value other than null for deprecation_at, then this property change removes the obsolete state and changes it back to deprecated. If the previous state was available, meaning the image was moved from available directly to obsolete, then this property change moves from obsolete back to available.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \u201cobsolescence_at\": null }'\n* To change an image that has both the deprecation_at or obsolescence_at properties set back to available, you must update both the deprecation_at or obsolescence_at properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-30340-32054","score":23.3612964265,"text":"\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Remove previously scheduled custom image lifecycle status by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \"deprecation_at\": null }'\n* To change an image from obsolete to its previous state, change obsolescence_at to null. If the image previously contained a value other than null for deprecation_at, then this property change removes the obsolete state and changes it back to deprecated. If the previous state was available, meaning the image was moved from available directly to obsolete, then this property change moves from obsolete back to available.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \u201cobsolescence_at\": null }'\n* To change an image that has both the deprecation_at or obsolescence_at properties set back to available, you must update both the deprecation_at or obsolescence_at properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-10332-12119","score":22.4778290545,"text":"\nThe previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \"deprecation_at\": null }'\n* To change an image from obsolete to its previous state, change obsolescence_at to null. If the image previously contained a value other than null for deprecation_at, then this property change removes the obsolete state and changes it back to deprecated. If the previous state was available, meaning the image was moved from available directly to obsolete, then this property change moves from obsolete back to available.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \u201cobsolescence_at\": null }'\n* To change an image that has both the deprecation_at or obsolescence_at properties set back to available, you must update both the deprecation_at or obsolescence_at properties.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{ \"deprecation_at\": null, \u201cobsolescence_at\": null }'\n\n\n\n\n\n\n\n Performance considerations \n\nSeveral factors can impact how quickly your image from volume is queued and created, such as size of the image and number of jobs in the queue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15507-6657-8493","score":21.824960046,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-26617-28366","score":21.6741463105,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":21.6741463105,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-9468-11364","score":26.1926402619,"text":"\nIn this sense, the installation is similar to IPI for you because you don't have to manage all the infrastructure and network settings. IBM also provides patch updates that you can choose to apply to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). SSH is disabled for added security. \n OCP versions and patch updates You are responsible for updating the underlying infrastructure for the master and worker nodes. You can use the Red Hat OpenShift web console to update OCP versions. IBM automatically applies updates to the master, and provides version updates and security patch updates for the worker nodes. You choose when to apply these updates to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). Supported versions might vary from standard OpenShift Container Platform. \n Autoscaling compute machines You can set up a ClusterAutoscaler resource. You can set up the [cluster autoscaler plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc). \n Worker node operating system CoreOS or RHEL For a list of supported operating systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). \n Support Provided per the terms of your Red Hat subscription or cloud provider. You can use the oc adm must-gather tool to help gather information. Provided by [IBM Cloud Support](https:\/\/www.ibm.com\/cloud\/support). You can use the oc adm must-gather tool, or the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to help gather information. \n Red Hat OpenShift web console You set up and can configure or disable the Red Hat OpenShift web console. The Red Hat OpenShift web console is set up for you. You can't configure or disable the web console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10462-7-2030","score":25.9435362754,"text":"\nSetting pod priority \n\nWith pod priority and preemption, you can configure priority classes to indicate the relative priority of the pods that make up your Red Hat OpenShift cluster's workload. The Red Hat OpenShift controller takes into consideration the priority of a pod and can even preempt (remove) pods with lower priority to make room on a worker node for higher priority pods. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/nodes\/pods\/nodes-pods-priority.html).\n\nWhy do I set pod priority?\n: As a cluster administrator, you want to control which pods are more critical to your cluster workload. Priority classes can help you control the Red Hat OpenShift controller decisions to favor higher priority pods over lower priority pods. The Red Hat OpenShift controller can even preempt (remove) lower priority pods that are running so that pending higher priority pods can be scheduled.\n\nBy setting pod priority, you can help prevent lower priority workloads from impacting critical workloads in your cluster, especially in cases where the cluster starts to reach its resource capacity.\n\nMake sure that you have [set up proper user access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersusers) to your cluster, and if applicable, [security context constraints (SCCs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_sccoc_sccs). Access policies and SCCs can help prevent untrusted users from deploying high priority pods that prevent other pods from scheduling.\n\nHow does priority scheduling and preemption work?\n\nIn general, pending pods that have a higher priority are scheduled before lower prioritized pods. If you don't have enough resources remaining in your worker nodes, the Red Hat OpenShift controller can preempt (remove) pods to free up enough resources for the higher prioritized pods to be scheduled. Preemption is also affected by graceful termination periods, pod disruption budgets, and worker node affinity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_priority"},{"document_id":"ibmcld_10203-7-1859","score":25.6592808373,"text":"\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10154-7-1896","score":25.3042749707,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10248-1412-3302","score":25.1815330454,"text":"\n* ibm-charts: Helm charts that are approved for Red Hat OpenShift on IBM Cloud and IBM Cloud Private clusters.\n* ibm-community: Helm charts that originated outside IBM, such as from [Red Hat OpenShift on IBM Cloud partners](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners). These charts are supported and maintained by the community partners.\n* kubernetes: Helm charts that are provided by the Kubernetes community and considered stable by the community governance. These charts are not verified to work in Red Hat OpenShift on IBM Cloud or IBM Cloud Private clusters.\n* kubernetes-incubator: Helm charts that are provided by the Kubernetes community and considered incubator by the community governance. These charts are not verified to work in Red Hat OpenShift on IBM Cloud or IBM Cloud Private clusters.\n* entitled: Helm charts of licensed software that you must purchase and for which you must set up cluster access with an entitlement key. For more information, see [Setting up a cluster to pull entitled software](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registrysecret_entitled_software).\n\n\n\nHelm charts from the iks-charts, ibm-charts, and, if licensed, entitled repositories are fully integrated into the IBM Cloud support organization. If you have a question or an issue with using these Helm charts, you can use one of the Red Hat OpenShift on IBM Cloud support channels. For more information, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help). [Install the latest release of Helm v3](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helminstall_v3).\n\n\n\n\n\n\n\n Installing Helm v3 in your cluster \n\nSet up Helm v3 and the IBM Cloud Helm repositories in your cluster.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helm"},{"document_id":"ibmcld_10203-16051-18088","score":25.1642869712,"text":"\nDeploying Cloud Paks, licensed software, and other integrations \n\nYou can deploy IBM Cloud Paks\u2122, licensed software, and other 3rd party integrations to Red Hat OpenShift on IBM Cloud clusters. You have various tools to deploy integrations, such as IBM Cloud service binding, managed add-ons, Helm charts, and more. After you install an integration, follow that product's documentation for configuration settings and other instructions to integrate with your apps. For more information, see [Enhancing cluster capabilities with integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-supported_integrations).\n\n\n\n\n\n Accessing the Red Hat OpenShift web console \n\nYou can use the Red Hat OpenShift console to manage your apps, deploy apps from the catalog, and access built-in functionality to help you operate your cluster. The Red Hat OpenShift console is deployed to your cluster by default, instead of the Kubernetes dashboard as in community Kubernetes clusters.\n\nFor more information about the console, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/web_console\/web-console.html).\n\n\n\n Red Hat OpenShift console overview \n\n\n\n1. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), select your Red Hat OpenShift cluster, then click OpenShift web console.\n2. To work with your cluster in the CLI, click your profile IAMuser.name@email.com > Copy Login Command. Display and copy the oc login token command into your command line to authenticate by using the CLI.\n\n\n\nYou can explore the following areas of the Red Hat OpenShift web console.\n\nAdministrator perspective\n: The Administrator perspective is available from the side navigation menu perspective switcher. From the Administrator perspective, you can manage and set up the components that your team needs to run your apps, such as projects for your workloads, networking, and operators for integrating IBM, Red Hat, 3rd party, and custom services into the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10367-7-1905","score":25.0472556218,"text":"\nAdding services by using managed add-ons \n\nManaged Red Hat OpenShift on IBM Cloud add-ons are an easy way to enhance your cluster with extra capabilities and open-source capabilities, such as the Diagnostics and Debug Tool, Block Storage for VPC, or the Cluster Autoscaler. The version of the driver, plug-in, or open-source tool that you add to your cluster is tested by IBM and approved to be used in Red Hat OpenShift on IBM Cloud.\n\nThe managed add-ons that you can install in your cluster depend on the type of cluster, the container platform, and the infrastructure provider that you choose.\n\nSupport\n: Managed add-ons are fully integrated into the IBM Cloud support organization. If you have a question or an issue with using the managed add-ons, you can use one of the Red Hat OpenShift on IBM Cloud support channels. For more information, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\nBilling\n: If the tool that you add to your cluster incurs costs, these costs are automatically integrated and listed as part of your Red Hat OpenShift on IBM Cloud billing. The billing cycle is determined by IBM Cloud depending on when you enabled the add-on in your cluster.\n: In general, no additional setup, such as opening ports or IP addresses is required. However, refer to the documentation of each managed add-on to find the prerequisites that your cluster must meet before you install the managed add-on.\n\n\n\n Adding managed add-ons \n\nTo enable a managed add-on in your cluster from the CLI, use the [ibmcloud oc cluster addon enable command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_addon_enable). To enable a managed add-on in your cluster in the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), use the Add-ons pane of the cluster details page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-managed-addons"},{"document_id":"ibmcld_10258-5539-7556","score":24.6421007333,"text":"\nRed Hat OpenShift on IBM Cloud integrates popular open source integrations by using [managed add-ons](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-managed-addons). Managed add-ons are an easy way to install an open source tool in your cluster that is tested by IBM and approved to be used in Red Hat OpenShift on IBM Cloud.\n\nManaged add-ons are fully integrated into the IBM Cloud support organization. If you have a question or an issue with using the managed add-ons, you can use one of the Red Hat OpenShift on IBM Cloud support channels. For more information, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\nIf the tool that you add to your cluster incurs costs, these costs are automatically integrated and listed as part of your monthly IBM Cloud billing. The billing cycle is determined by IBM Cloud depending on when you enabled the add-on in your cluster.\n\n\n\n\n\n Other third-party integrations \n\nYou can install any third-party open source tool that integrates with Kubernetes. For example, the Kubernetes community designates certain Helm charts stable or incubator. Note that these charts or tools are not verified to work in Red Hat OpenShift on IBM Cloud. If the tool requires a license, you must purchase a license before you use the tool. For an overview of available Helm charts from the Kubernetes community, see the kubernetes and kubernetes-incubator repositories in the [Helm charts](https:\/\/cloud.ibm.com\/kubernetes\/helm) catalog.\n\nAny costs that incur by using a third-party open source integration are not included in your monthly IBM Cloud bill.\n\nInstalling third-party open source integrations or Helm charts from the Kubernetes community might change the default cluster configuration and can bring your cluster into an unsupported state. If you run into an issue with using any of these tools, consult the Kubernetes community or the service provider directly.\n\n\n\n\n\n Extending Red Hat OpenShift API and software with CRDs and Operators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations"},{"document_id":"ibmcld_14497-1215-3210","score":24.616191554,"text":"\n[VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.\n\nThe operating system of the nodes is Red Hat\u00ae Enterprise Linux\u00ae CoreOS, which is the container host version of Red Hat Enterprise Linux (RHEL) and features an RHEL kernel with SELinux enabled by default. RHEL CoreOS includes kubelet, which is the Kubernetes node agent, and the CRI-O container runtime, which is optimized for Kubernetes. In Red Hat OpenShift 4.7, you must use RHEL CoreOS for all control plane machines, but you can use Red Hat Enterprise Linux (RHEL) as the operating system for compute, or worker machines. If you choose to use RHEL workers, you must perform more system maintenance than if you use RHEL CoreOS for all of the cluster machines.\n\nThe reference architecture and this build process use RHEL CoreOS. The nodes must have direct Internet access to complete the following tasks.\n\n\n\n* Access the Red Hat OpenShift Infrastructure Providers page to download the installation program.\n* Access quay.io to obtain the packages that are required to install the cluster.\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10392-218624-220182","score":24.557339847,"text":"\n4 December 2019 \n\nExposing apps with load balancers or Ingress ALBs\n: Added quick start pages to help you get up and running with [load balancers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer-qs) and [Ingress ALBs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-managed-ingress-about).\n\nRed Hat OpenShift charges\n: Now when you create Red Hat OpenShift clusters, you are not charged for the Red Hat Enterprise Linux operating system that is installed on the worker nodes. For more information, see [What am I charged for when I use Red Hat OpenShift clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges).\n\nRed Hat OpenShift routes\n: Added steps for [bringing your own hostname](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesroutes-setup) for public routes and steps for [setting up private routes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesprivate-routes-setup-43).\n\nUse the internal KVDB in Portworx\n: Automatically set up a key-value database (KVDB) during the Portworx installation to store your Portworx metadata. For more information, see [Using the Portworx KVDB](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_kv_store).\n\n\n\n\n\n\n\n November 2019 \n\n\n\n 26 November 2019 \n\nCLI change log\n: Updated the IBM Cloud Kubernetes Service CLI plug-in change log page for the [release of version 0.4.61](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog).\n\nDiagnostics and Debug Tool add-on for Red Hat OpenShift clusters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.2021073465}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07100-3950-4787","score":42.678424346,"text":"\nFor more information about the elements, see [Understanding contracts](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-contracts-schema).\n\n\n\n\n\n Content Mining \n\nFacets based on the Part of Speech enrichment are shown.\n\n\n\n1. To analyze your data, open the Content Mining application. Click Launch application.\n\n\n\nFor more information, see [Analyzing your data](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-contentminerapp).\n\n\n\n\n\n What to do next \n\n\n\n* For more information about how to enrich your documents so that you can find key information, see [Choosing enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain).\n* To explore ways to improve the query results, see [Improving your query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-results"},{"document_id":"ibmcld_07080-2080-3463","score":39.8354117146,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Run test queries to assess the quality of the initial results. [Previewing the default query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-results) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Take actions to improve your results. For example, you can customize the search bar to enable autocompletion. [Improving your query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your search solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Extract meaning \n\nUse award-winning natural language processing technology to enrich your data and ensure that the right information is found when someone searches for answers.\n\nZoom\n\n![Shows a custom machine learning facet.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/nlu-search.png)\n\nFigure 2. Machine learning facet for filtering search results with custom enrichment values","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"},{"document_id":"ibmcld_07176-3482-5433","score":39.2753757383,"text":"\nIf there are many top level fields, this can cause a performance impact for a natural_language_query when using training. Reducing the number of top level fields can improve performance. This can be done via normalization or by manually editing the JSON to put fields that are not helpful to finding relevant content in a nested structure. Changing the fields used for training also has an impact on the model so you\u2019ll need to consider both the impact to performance and accuracy of results if making this change. For more information about relevancy training, see [Improving result relevance](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n3. Continuous Relevancy Training - Continuous relevancy training searches across all collections in an environment. The more collections in an environment, the larger the impact on performance. See [Continuous Relevancy Training](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-crt) for more information.\n\n\n\n\n\n\n\n Collection size and complexity \n\nThe makeup of the documents in a private collection can also impact query performance:\n\n\n\n1. Total number of documents - Performance might be affected when approaching the upper limits of Number of Documents for Advanced plan sizes.\n2. Size of documents - Very large documents (those several MB in size) require movement of a large amount of data per request, which can negatively impact performance especially when using passage retrieval and relevancy training.\n3. Number of enrichments - Enrichments add complexity to documents by adding a significant number of nested fields. If an enrichment is not necessary for your use case, consider disabling it at ingestion time. Enrichments are not directly used for natural_language_query search relevance. See [Adding enrichments](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceadding-enrichments) for more about information on enrichments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-qp"},{"document_id":"ibmcld_07214-65893-68177","score":38.1232332275,"text":"\n: The new version string enables enrichments in German (de) or Spanish (es) if the language of a collection is set to one of those languages. Previously, all enrichments were performed in English regardless of a collection's language setting. : If you do not use enrichments in non-English languages, you can continue to use the 2016-12-01 version string. However, to avoid potential future conflicts, it is recommended that you update the version string as soon as possible.\n\nNew anomaly detection availability : Anomaly detection is now available as part of timeslice aggregations as a GA capability.\n\nNew beta improvement to relevancy tooling : Added the beta ability to improve the relevancy of query results using the Discovery tooling (relevancy tooling). See [Improving the relevance of your query results with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n 19 June 2017 \n\nNew select language of documents : Added option to specify the language of the documents in a new collection as English, Spanish, or German. To use it, choose Select the language of your documents on the Name your new collection dialog.\n\nAdded a Summary tab to the Build queries screen : The Summary tab displays an overview of the full query results provided in the existing JSON tab. The Summary display varies, based on your query and enrichments. Information that might be displayed includes: document name or ID, aggregation statistics, document passages in order of relevance, and results by enrichment.\n\nAdded a Natural Language Query option to the Build queries screen : To use it, click Ask a question in plain language in the Search for documents section, and a field displays where you can enter your question. You can now access the original query field, formerly titled Enter a query or keyword, by clicking the Use the Discovery Query Language button.\n\nThe Build queries screen was redesigned, but all fields and options remain. : Following are the old and new names for the fields.\n\n Old field name New field or section name \n\n Write and run a query Search for documents \n Narrow your query results (Filter) Limit which documents you query \n Group query results (Aggregation) Include analysis of your results","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07214-50985-53201","score":37.6212960112,"text":"\nFields that include whitespaces (for example: body.additional reading) are filtered out during ingestion. The notices description reads The field 'additional reading' is invalid: whitespace, '.', '' and ',' are invalid in a field name. The field result_metadata is filtered out during ingestion.\n\n\n\n\n\n 16 October 2017 \n\nUpdate to version string : The version string for all API calls changed to 2017-10-16 from 2017-09-01. : This version deprecates support for uploading new documents into existing collections enriched with AlchemyLanguage enrichments, and for creating new collections and enriching them with AlchemyLanguage enrichments. It is recommended that existing collections enriched with AlchemyLanguage be migrated to Natural Language Understanding enrichments as soon as possible. The Discovery tooling also uses the 2017-10-16 version, see below for more information. : The Discovery tooling uses the 2017-10-16 API version string, so if you are using the tooling, you can no longer upload documents into existing AlchemyLanguage collections or create new collections enriched with AlchemyLanguage enrichments after 2017-10-16. If you want to continue using the Discovery tooling for enriching collections, migrate your collections to Natural Language Understanding first.\n\nNew sample queries and link in Data schema explorer : The Data schema explorer displays sample queries for several enrichments in the IBM Watson\u2122 Discovery News collection. It also now has a Show more values link that displays additional example values for that enrichment in IBM Watson\u2122 Discovery News.\n\nImproved Manage data screen : Multiple productivity enhancements, including combining the collection statistics, errors and warnings, and data insights on the Manage data screen.\n\nNew completion notification : A message was added that displays an alert when documents are finished processing.\n\n\n\n\n\n 9 October 2017 \n\nNew unique count metric in the API : A new aggregation metric unique_count is available in the API. It returns a count of the unique instances of the specified field in a collection. See [unique_count](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregationsunique_count) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07113-7-2234","score":36.885761534,"text":"\nTesting and sharing your project \n\nAs you improve your project, periodically test how enrichments and search setting changes impact the query results.\n\nFor all project types except Conversational Search, you can see the fields that are associated with an indexed document by looking at the JSON view of a document that is returned by a query. Checking the JSON structure of a document can be useful if you want to check whether certain types of information are being captured.\n\nAfter you enrich your collection, you can use the JSON view of a query result to check whether your enrichments are being applied and retrieved properly. For example, you can check the JSON to confirm that a synonym that you defined in a dictionary is being tagged as an occurrence of the corresponding dictionary term.\n\nTo test your project, complete the following steps:\n\n\n\n1. From the navigation panel, open the Improve and customize page.\n2. Retrieve query results by doing one of the following things:\n\n\n\n* Content Mining project: Choose or add a facet to apply to the documents, and then click View filtered documents. To analyze your data in more depth, open the Content Mining application in a new window or tab by clicking Launch application.\n* Other project types: Enter a test query to submit or leave the field empty and press Enter to submit an empty query.\n\n\n\n3. From the query result list, click the link to view the document.\n\nA representation of the original document is displayed.\n4.\nIBM Cloud\n\nClick Open advanced view to see useful summary information, such as the number of occurrences of any enrichments that are detected in the document.\n\nOptional: Select an enrichment to highlight every occurrence of the element within the document text.\n\nFor a Document Retrieval for Contracts project, the Contract Data page is displayed. For more information about Contract filter options, see [Understanding contracts](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-contracts-schemacontracts-elements).\n5. You can learn more about information that is identified by the enrichments that are applied to your documents by reviewing the JSON representation of a document that is returned in a search result.\n\nIBM Cloud\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-test"},{"document_id":"ibmcld_07214-10855-12945","score":36.7956383631,"text":"\nSee [Query expansion](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion) for more information.\n\n\n\n\n\n 17 April 2019 \n\nDeprecated Data Crawler : The Data Crawler is no longer available for download and is no longer supported. See [Connecting to Data Sources](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources) for other connectivity options.\n\n\n\n\n\n 2 April 2019 \n\nUpdate to scoring algorithms : Beginning April 9, 2019, there is an upgrade to IBM Watson\u2122 Discovery. This upgrade includes changes to the scoring algorithms used in Discovery for ranking documents and passages. This means score and confidence results might change, following the upgrade. If your applications make use of the score or confidence fields directly, be prepared to update the application as necessary. See [Upgrading the infrastructure of the IBM Watson\u2122 Discovery](https:\/\/www.ibm.com\/blogs\/cloud-archive\/2019\/03\/announcement-for-the-ibm-watson-discovery-community\/) for details.\n\n\n\n\n\n 25 March 2019 \n\nUpdate to version string : The version string for all API calls changed to 2019-03-25 from 2019-01-01\n\nImproved extraction of title field from HTML documents : The title field is now extracted from HTML documents as a top-level field during conversion. This title field is included in each segment of any documents split, using document segmentation. For an example, see [Splitting documents with document segmentation](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicedoc-segmentation). This might improve the confidence score for query results, and might change the passages returned because the title might be returned, as part of a passage. Existing collections must be reindexed to extract the title field. : The Discovery tooling does not yet use the current API version: 2019-03-25 (it currently uses 2018-12-03), so the title is not extracted when ingesting HTML documents by uploading or using the Web Crawl connector in the Discovery tooling.\n\nNew enrichment for arrays : Arrays can now be enriched (previously, arrays could not be enriched).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07080-5205-6551","score":36.6725752201,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Submit test queries to assess the results. [Testing your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-test) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a facet that surfaces the enriched data from your documents. [Facets](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-facets) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Take actions to improve your results. [Improving your query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"},{"document_id":"ibmcld_07104-32103-34057","score":36.4492281991,"text":"\nFor more information, see [Monitoring usage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapiapi-usage).\n\n\n\n\n\n 30 August 2020 \n\nUpdate to API version\n: The current API version (v2) is now 2020-08-30. The following change was made with this version:\n\nChange to 'options' object\n: The List enrichments method no longer returns the options object per enrichment. Use the Get enrichment method to return the options object for a single enrichment.\n\n\n\n\n\n 2.1.3 release, 19 June 2020 \n\nNew release now available\n: IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data version 2.1.3 is available.\n: Discovery for Cloud Pak for Data now works with IBM Cloud Pak\u00ae for Data 3.0.1.\n\nNew Finnish and Hebrew language support\n: Added basic support for Finnish and Hebrew. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nChange to Analyze endpoint\n: The Analyze endpoint, which supports stateless document ingestion workflows. For details, see the [Analyze API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapi). The Analyze API supports JSON documents only. Use of the Analyze API affects license usage.\n\nNew options for Content Miner\n: The content mining application includes two new options: Cyclic time scale on the Time series dashboard, and the Contextual view tab.\n\nNew shortcut for Content Mining projects\n: For Content Mining projects only, the Improve and customize page includes a shortcut: the Launch application button. Previously, you were required to open the Integrate and deploy page, select the Launch application tab, and click the Launch button.\n\nImproved segment limit\n: The segment limit when splitting documents has been increased to 1,000. For details, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\nImproved Filenet connector","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes-data"},{"document_id":"ibmcld_07099-3978-5480","score":36.4000381338,"text":"\n[\"\"](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsphrase) Phrase query enriched_text.concepts.text:\"IBM Watson\" \n [(), ]](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsnestedquery) Nested groups filter-entities:(text:Turkey,type:Location) \n [|](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsor) or query-enriched.entities.text:Google IBM \n [,](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsand) and query-enriched.entities.text:Google,IBM \n [<=, >=, >, <](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorscomparisons) Numerical comparisons enriched_text.sentiment.document.score>0.679 \n [^x](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsmultiplier) Score multiplier text:IBM^3 \n [](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorswildcard) Wildcard query-enriched_text.concepts.text:pre* \n [n](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsvariation) String variation query-enriched_text.entities.text:cat1 \n [:](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsexists) Exists title:* \n [!](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsdnexist) Does not exist title!* \n\n\n\n\n\n\n\n Aggregations \n\nAggregations return a set of data values. The following table lists the available aggregations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03771-1594-3365","score":33.9750473324,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_07094-4220-5423","score":29.655456157,"text":"\n\"name\": \"categories\" \"label\": \"Category\" \"multiple_selections_allowed\": true \n \"name\": \"natures\" \"label\": \"Nature\" \"multiple_selections_allowed\": false \n \"name\": \"contract_terms\" \"label\": \"Contract Term\" \"multiple_selections_allowed\": false \n \"name\": \"contract_payment_terms\" \"label\": \"Contract Payment Term\" \"multiple_selections_allowed\": false \n \"name\": \"contract_types\" \"label\": \"Contract Type\" \"multiple_selections_allowed\": false \n \"name\": \"contract_currencies\" \"label\": \"Contract Currency\" \"multiple_selections_allowed\": false \n \"name\": \"invoice_buyers\" \"label\": \"Invoice Buyer\" \"multiple_selections_allowed\": false \n \"name\": \"invoice_suppliers\" \"label\": \"Invoice Supplier\" \"multiple_selections_allowed\": false \n \"name\": \"invoice_currencies\" \"label\": \"Invoice Currency\" \"multiple_selections_allowed\": false \n \"name\": \"po_payment_terms\" \"label\": \"Purchase Order Payment Term\" \"multiple_selections_allowed\": false \n \"name\": \"po_buyers\" \"label\": \"Purchase Order Buyer\" \"multiple_selections_allowed\": false \n \"name\": \"po_suppliers\" \"label\": \"Purchase Order Supplier\" \"multiple_selections_allowed\": false \n \"name\": \"po_currencies\" \"label\": \"Purchase Order Currency\" \"multiple_selections_allowed\": false","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults"},{"document_id":"ibmcld_03776-6753-8705","score":28.9310951396,"text":"\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_01623-6277-8255","score":28.5981560147,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_03704-4411-6289","score":27.5449375239,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1045891-1047755","score":27.5449375239,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1045762-1047626","score":27.5449375239,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03794-0-812","score":27.0549642447,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_12544-10042-12276","score":26.9005558957,"text":"\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice. If all of the credit in the credit pool is used, the invoice contains a line item for any overage charges.\n\nBecause all usage is invoiced through the enterprise account, child accounts within the enterprise don't receive separate invoices.\n\nYou can analyze usage costs for each account or account group on the Usage page in the enterprise account. For details, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Access management for enterprise billing and usage \n\nAs with other enterprise management roles, access to enterprise billing and usage is managed through the enterprise account. Users must be invited to the enterprise account and assigned an access policy with a role on the relevant service.\n\nIn an enterprise, billing access and usage access are assigned separately.\n\n\n\n* Billing access is provided by assigning enterprise users a role on the Billing account management service. For example, you can assign the Viewer role to an enterprise user so that they can view the amount of available subscription credit in the credit pool. If you would like an enterprise user to be able to add new subscriptions or manage payment methods, you can assign the Editor or Administrator role to them.\n* Usage access is provided by assigning enterprise users the Usage Reports Viewer, Editor, or Administrator role on the Enterprise account management service. You can assign this access for the entire enterprise or for specific account groups and accounts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_12544-4880-7097","score":25.9287612427,"text":"\nUsers in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit. When accounts in the enterprise create and use resources, the cost for this usage is deducted from the credit pool.\n\nWhen existing subscriptions are added to the enterprise, each individual subscription term is re-created within the credit pool, including characteristics such as the remaining credit balance, start dates, and end dates. As credit is used, the subscription terms burn down individually according to when they expire. For example, you imported two accounts with existing subscriptions in August 2019. One subscription, 32100456, is for $1,000 for 18 months that began in January 2019. Because it spans multiple years, the subscription is divided into terms of up to one year each. The other subscription, 55543210 is for $500 a month for two years that began in April 2019, which is also divided into multiple terms. Then, you purchased a new one-year subscription, 00012345, through your enterprise for $1,500 a month that starts in July 2020. As enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-6582-8092","score":20.2816869893,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":19.4568861718,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":19.4231542804,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12330-7-2140","score":16.5268135593,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_10852-45155-46272","score":15.8774179019,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":15.6504156947,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_00642-4873-6822","score":15.3826234301,"text":"\nfunction(newDoc, oldDoc, userCtx) {\n\/\/ any update to an existing doc is OK\nif(oldDoc) {\nreturn;\n}\n\n\/\/ reject tombstones for docs we don\u2019t know about\nif(newDoc[\"_deleted\"]) {\nthrow({forbidden : \"Deleted document rejected\"});\n}\n\nreturn; \/\/ Not strictly necessary, but clearer.\n}\n\nTo use a validate_doc_update function to remove tombstone documents:\n\n\n\n1. Stop replication from the source to the target database.\n2. If appropriate, delete the target database, then create a new target database.\n3. Add a suitable validate_doc_update function, similar to the example provided.\n4. Add it to a design document in the target database.\n5. Restart replication between the source and the (new) target database.\n6. When replication is complete, switch your application logic to use the new database.\n7. Verify that your applications work correctly with the new database.\n\n\n\nWhen you're satisfied that everything is working correctly, you might want to delete the old database.\n\nHere is another variation for using the validate_doc_update function to remove tombstone documents if possible.\n\n\n\n1. Add some metadata to the tombstone documents, for example, to record the deletion date.\n2. Use the function to inspect the metadata and allow deletion documents through if they must be applied to the target database.\n\n\n\nThis check helps ensure correct replication of the deletion.\n\n\n\n\n\n Performance implications of tombstone removal \n\nTombstones are used for more consistent deletion of documents from databases. This purpose is especially important for mobile devices: without tombstone documents, a deletion might not replicate correctly to a mobile device, with the result that documents might never be deleted from the device.\n\nIf you re-create a database, for example, a new target for a replication. Any clients that use the target database as a server must work through all the changes again because the database sequence numbers are likely to be different.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-tombstone-docs"},{"document_id":"ibmcld_07902-1732-3843","score":14.8126910115,"text":"\nInformation system entry and exit points include, for example, firewalls, electronic mail servers, web servers, proxy servers, remote-access servers, workstations, notebook computers, and mobile devices. Malicious code includes, for example, viruses, worms, Trojan horses, and spyware. Malicious code can also be encoded in various formats (e.g., UUENCODE, Unicode), contained within compressed or hidden files, or hidden in files using steganography. Malicious code can be transported by different means including, for example, web accesses, electronic mail, electronic mail attachments, and portable storage devices. Malicious code insertions occur through the exploitation of information system vulnerabilities. Malicious code protection mechanisms include, for example, anti-virus signature definitions and reputation-based technologies. A variety of technologies and methods exist to limit or eliminate the effects of malicious code. Pervasive configuration management and comprehensive software integrity controls may be effective in preventing execution of unauthorized code. In addition to commercial off-the-shelf software, malicious code may also be present in custom-built software. This could include, for example, logic bombs, back doors, and other types of cyber attacks that could affect organizational missions\/business functions. Traditional malicious code protection mechanisms cannot always detect such code. In these situations, organizations rely instead on other safeguards including, for example, secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to help ensure that software does not perform functions other than the functions intended. Organizations may determine that in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, actions in response to detection of malicious downloads, and\/or actions in response to detection of maliciousness when attempting to open or execute files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-3"},{"document_id":"ibmcld_10817-7707-9426","score":14.4276929494,"text":"\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate\nlet session = NSURLSession(configuration: NSURLSessionConfiguration.defaultSessionConfiguration(), delegate: NetworkUtilsDelegate(), delegateQueue:NSOperationQueue.mainQueue())\n\/\/ set the SDK to use this urlSession instead of the default shared one\nwhisk.urlSession = session\n\n\n\n Support for qualified names with mobile SDK \n\nAll actions and triggers have a fully qualified name that is made up of a namespace, a package, and an action or trigger name. The SDK can accept these elements as parameters when you are invoking an action or Firing a trigger. The SDK also provides a function that accepts a fully qualified name that looks like \/mynamespace\/mypackage\/nameOfActionOrTrigger. The qualified name string supports unnamed default values for namespaces and packages that all Cloud Functions users have, so the following parsing rules apply:\n\n\n\n* qName = \"foo\" results in namespace = default, package = default, action\/trrigger = \"foo\"\n* qName = \"mypackage\/foo\" results in namespace = default, package = mypackage, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/foo\" results in namespace = mynamespace, package = default, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/mypackage\/foo\" results in namespace = mynamespace, package = mypackage, action\/trigger = \"foo\"\n\n\n\nAll other combinations issue a WhiskError.QualifiedName error.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02674-7-1766","score":14.1124149111,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":54.6249339273,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":49.9753947359,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-7-1743","score":44.7533394666,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":44.2099850034,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-1342-3184","score":41.5288240284,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":32.6694530681,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-44214-45420","score":32.4880461183,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":28.7600266594,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-2884-4620","score":28.1600957109,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-1628-3402","score":26.5464990315,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.8854598816,"ndcg_cut_10":0.8854598816}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03285-5746-7932","score":33.4966722728,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":33.4966722728,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16321-14177-15957","score":27.6960064038,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-13886-15581","score":27.4403332546,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03285-12413-14528","score":26.8263397234,"text":"\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\nEach command type along with its related parameters are described in the following sections.\n\n\n\n command_info.type : configure \n\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the dialog or action flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-12507-14690","score":26.3389222641,"text":"\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the conversation flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03148-0-3315","score":26.306136573,"text":"\n\n\n\n\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n  SMS with Twilio integration reference \n\nAdd action commands to the message context object to manage the flow of conversations with customers who interact with your assistant by submitting SMS messages over the telephone.\n\nLearn about the supported commands and reserved context variables that are used by the SMS with Twilio integration.\n\n\n\n  Supported commands \n\nEach action consists of a command property, followed by an optional parameter property to define parameters for commands that require them. The commands that are described in the following table are supported by the SMS with Twilio integration.\n\n\n\nTable 1. Actions that you can initiate from the dialog\n\n Action command            Description                                                                                                                                                                                                                                       Parameters                                                                                       \n\n smsActForceNoInputTurn    Forces a new turn in the conversation without waiting for input from the user. The SMS with Twilio integration sends a message request with smsNoInputTurn in the text field so that you can map this request to an intent in your dialog.        None                                                                                             \n terminateSession          Ends the current SMS session. Use this command to ensure that the subsequent text message starts a new assistant-level session which does not retain any context values from the current session.                                                 None                                                                                             \n smsActSendMedia           Enables MMS messaging.                                                                                                                                                                                                                            mediaURL: Specifies a JSON array of publicly accessible media URLs that are sent to the user.    \n\n\n\n\n\n\n\n  Reserved context variables \n\nThe following table describes the context variables that have special meaning in the context of the SMS with Twilio integration. They should not be used for any purpose other than the documented use.\n\nTable 2 describes the context variables that you can set by the SMS with Twilio integration.\n\n\n\n  Context variables that are set by the integration \n\n\n\nSMS context variables set by the integration\n\n Context variable name        Description                                                                     \n\n assistant_phone_number       The phone number associated with the assistant that received the text message.  \n private.user_phone_number    The phone number that the text message was received from.                       \n\n\n\nExample:\n\n{\n\"context\" : {\n\"global\" : {...},\n\"skills\" : {...},\n\"integrations\" : {\n\"text_messaging\": {\n\"private\":{\n\"user_phone_number\":\"+12223456789\",\n}\n\"assistant_phone_number\":\"+18883456789\"\n}\n}\n}\n}\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-commands-sms"},{"document_id":"ibmcld_16294-8240-10414","score":23.3237564957,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_03285-31724-33317","score":22.3748821821,"text":"\n\"value\": \"XXXXXX\"\n}\n]\n}\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\n\n\n Sending a text message during a phone conversation \n\nThere are some situations when it is useful to be able to send a text message during an ongoing voice. For example, you might want the customer to specify a street address, which is easier to communicate accurately in writing than by transcribing voice input.\n\nBefore you can send SMS messages during a phone call, you must set up the SMS with Twilio integration. For more information, see [Integrating with SMS with Twilio](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms).\n\nWhen you exchange a text with a customer during a conversation, the dialog initiates the SMS message exchange. It sends a text message to the user and asks for the user to respond to it.\n\nTo send a specific message from a dialog node or action step, use the user_defined response type with the vgwActSendSMS command:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"values\":\n{\n\"text\": \"I will send you a text message now.\"\n}\n],\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"user_defined\",\n\"user_defined\": {\n\"vgwAction\": {\n\"command\": \"vgwActSendSMS\",\n\"parameters\": {\n\"message\": \"Hey, this is Watson Assistant. To send me your street address, respond to this text message with your address.\"\n}\n}\n}\n}\n]\n}\n}\nShow more\n\nYou can specify any of the following parameters in the parameters object:\n\n\n\n Parameter Type Description \n\n message string The text of the SMS message to send. Required. \n mediaURL list A list of URLs for media files to be sent with the message as MMS attachments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_10833-0-1231","score":22.1909978894,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":30.6219569676,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":30.5530285815,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":29.5442234838,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04168-6066-7283","score":28.4781502045,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04172-7-2047","score":24.2648701338,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04118-5438-6061","score":23.5479550216,"text":"\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_04175-0-1274","score":23.4999560679,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-7-2225","score":22.8991021285,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-1738-2974","score":22.866861271,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-35313-36062","score":22.7294465063,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03421-4-1877","score":94.6088125047,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-7-1901","score":92.7342238559,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16368-7-2072","score":89.6005910171,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16365-7-1700","score":80.7811634784,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16366-7-1826","score":77.5804468961,"text":"\nWeb chat setup overview \n\nYou can modify the web chat integration settings to configure the styling and appearance of the web chat.\n\nYou can quickly deploy and test the web chat integration using the default settings. However, before you go to production with your chatbot, you will need to configure the web chat to integrate with your website and better serve the needs of your customers.\n\nAt a minimum, you should update the following basic settings for your assistant:\n\n\n\n* The [assistant name](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style) that you want to show to your customers\n* The contents of the [home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen)\n* The [suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions) your assistant will offer if customers get stuck\n\n\n\nYou might also want to make additional configurations, such as changing the web chat colors to match your branding, changing the launcher greeting, or enabling encryption.\n\nIf you are a developer, you can customize the web chat by using the web chat API. With the API, you can customize the styling, change the behavior of the web chat widget and launcher, customize strings, modify message content, and more. For more information about using the web chat API, see [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop).\n\nTo change the web chat configuration, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16365-1312-3051","score":74.9273276063,"text":"\nFor more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03421-1518-3290","score":74.8225470879,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16366-1573-3444","score":73.3255621942,"text":"\nOn the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\n\n\n\n\n Setup tasks \n\nYou can configure the web chat in the following ways:\n\nStyle and appearance\n: You can configure the overall appearance of the web chat widget, including the assistant name, the colors of various elements, and the avatar image. For more information, see [Configuring style and appearance](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style).\n\nLauncher\n: You can change the greeting text that is shown by the launcher that invites users to open the web chat. On the Launcher tab, you can specify separate greeting messages for the desktop launcher and the mobile launcher.\n\nThe message you specify is immediately reflected by the launcher preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\nHome screen\n: You can configure the contents of the home screen that greets customers and helps them start the conversation. For more information, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_03080-1529-3357","score":73.2179309117,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03166-6034-7833","score":69.0958681106,"text":"\nYou add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n\n\n\n\n\n\n\n Deploy your assistant in production \n\n\n\n1. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n2. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.452508153}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10041-7462-8947","score":9.0024950192,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-7444-8929","score":9.0024950192,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_06282-4283-5732","score":8.97121861,"text":"\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-4309-5758","score":8.97121861,"text":"\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_06282-18946-20824","score":8.8949775977,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-19050-20928","score":8.8949775977,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_10689-19663-21541","score":8.8949775977,"text":"\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster\n\nThe cluster kube-<cluster-id> security group is applied.\n\n\n\n\n\n If you want the cluster security group and your own additional security groups \n\nCluster security group\n\nYour own security groups\n\nWhen you create the cluster, specify --cluster-security-group cluster and up to four additional security groups that you own. You must include a separate --cluster-security-group option for each individual security group you want to add. Note that at maximum of five security groups can be applied to workers, including the security groups that are applied by default.\n\nExample command to create a VPC cluster with the kube-<cluster-id> cluster security group and your own additional security groups:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id> --cluster-security-group cluster --cluster-security-group <group-id-1> --cluster-security-group <group-id-2> --cluster-security-group <group-id-3>\n\nThe following security groups are applied:\n\n\n\n* kube-<cluster-id>\n* Up to four of your own additional security groups, for a maximum of five total security groups.\n\n\n\n\n\n\n\n If you only want your own security groups \n\nYour own security groups\n\nWhen you create the cluster, specify up to five security groups that you own.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-group"},{"document_id":"ibmcld_10041-35993-37421","score":8.8824472126,"text":"\nGET\/v1\/clusters\/{idOrName}\/workers\/{workerId} View details of a worker node. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorker View details of a worker node for classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPool View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPools View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkers View all workers for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorker View details of a worker node for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPool View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPools View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkers View all workers for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorker View details of a worker node for VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-35959-37387","score":8.8824472126,"text":"\nGET\/v1\/clusters\/{idOrName}\/workers\/{workerId} View details of a worker node. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorker View details of a worker node for classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPool View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPools View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkers View all workers for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorker View details of a worker node for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPool View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPools View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkers View all workers for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorker View details of a worker node for VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05681-2673-4668","score":8.6713936492,"text":"\n* The vpc provider is designed to support multiple VPC subproviders. The supported VPC subprovider is vpc-gen2, which corresponds to a VPC cluster for Generation 2 compute resources.\n* Provider-specific requests have a path parameter in the URL, such as v2\/vpc\/createCluster. Some APIs are only available to a particular provider, such as GET vlan for classic or GET vpcs for VPC.\n* Provider-neutral requests can include a provider-specific body parameter that you specify, usually in JSON, such as {\"provider\": \"vpc\"}, if you want to return responses for only the specified provider.\n\n\n\nGET responses\n: v1 API: The GET method for a collection of resources (such as GET v1\/clusters) returns the same details for each resource in the list as a GET method for an individual resource (such as GET v1\/clusters\/{idOrName}).\n: v2 API: To return responses faster, the v2 GET method for a collection of resources (such as GET v2\/clusters) returns only a subset of information that is detailed in a GET method for an individual resource (such as GET v2\/clusters\/{idOrName}). Some list responses include a providers property to identify whether the returned item applies to classic or VPC infrastructure. For example, the GET zones list returns some results such as mon01 that are available only in the classic infrastructure provider, while other results such as us-south-01 are available only in the VPC infrastructure provider.\n\nCluster, worker node, and worker-pool responses\n: v1 API: Responses include only information that is specific to the classic infrastructure provider, such as the VLANs in GET cluster and worker responses.\n: v2 API: The information that is returned varies depending on the infrastructure provider. For such provider-specific responses, you can specify the provider in your request. For example, VPC clusters don't return VLAN information since they don't have VLANs. Instead, they return subnet and CIDR network information.\n\n\n\n\n\n Automating cluster deployments with the API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_api_install"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00589-8040-10059","score":29.2123299789,"text":"\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_07578-414710-416563","score":29.2121545202,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-414684-416537","score":29.2121545202,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-419683-421572","score":29.0614582929,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-419665-421554","score":29.0614582929,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00531-7-2145","score":27.9096424429,"text":"\nAuthenticating with IBM Cloudant FAQ \n\nIBM Cloud\u00ae Identity and Access Management (IAM) combines managing user identities, services, and access control into one approach. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae integrates with IBM Cloud Identity and Access Management.\n\n\n\n What is the difference between IBM Cloudant legacy and IAM access controls? \n\n\n\n IBM Cloud IAM \n\n\n\n* Centrally managed access management across IBM Cloud.\n* Allows a user or service to access many different resources by using the same set of credentials (for example, same username and password or IAM API key).\n* IAM API keys can be granted access to account management functions, like creating new databases.\n\n\n\n\n\n\n\n IBM Cloudant legacy \n\n\n\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\n Why is the Use only IAM mode preferred? \n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\n How can I create an instance by using the command line? \n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p '{\"legacyCredentials\": false}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-authenticating-cloudant"},{"document_id":"ibmcld_00579-7-1988","score":27.3852607573,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00589-9560-11733","score":26.7036261066,"text":"\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_03630-7-2200","score":21.8952601543,"text":"\nAbout RAID \n\nRAID (Redundant Array of Independent Disks) creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance. Following are the three key concepts in RAID:\n\n\n\n* Mirroring: copying data to more than one disk\n* Striping: splitting data across more than one disk\n* Error correction (fault tolerance): redundant data is stored to allow problems to be detected and possibly fixed.\n\n\n\nAlthough many different levels of RAID exist, IBM chooses to support the most common RAID types: 0, 1, 5, 6, and 10. The different RAID levels use one or more of the following techniques, depending on the system requirements. The main purpose of using RAID is to improve reliability by using either 3Ware 9550SX Raid SATA or an Adaptec SA-SCSI RAID controller for all RAID solutions deployed.\n\nRAID is not a backup solution. Rather, RAID creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance.\n\nRAID 0 (Striped set without parity \/ Non-Redundant Array) Implements data striping, where file blocks are written across multiple disks in fragments that require a minimum of two disks. The advantage of a RAID 0 is that the read\/write speed is dramatically increased. The more disks that are in the array, the greater the bandwidth. The disadvantage to a RAID 0 is that it has no fault tolerance. If a single drive fails, the array is broken. Also, RAID 0 does not implement error checking. So, any error is also unrecoverable. A common solution for fault tolerance is to have a drive outside of the array that is used as backup storage in a hardware failure.\n\nRAID 1 (Mirrored set without parity) Implements data mirroring. Data is duplicated on 2 or 4 disks through a hardware raid controller and provides some fault tolerance. The array is recoverable if at least one drive does not fail. It provides faster read performance than a single drive and provides drive redundancy if a drive failure occurs. Write speed is slightly reduced.\n\nRAID 5 (Striped set with dual distributed parity) Implements data striping at a block level and distributes parity among the disks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-raid-levels"},{"document_id":"ibmcld_05138-7979-9034","score":21.2538512409,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-417176-418645","score":14.2790300404,"text":"\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\nurl\n: IBM Cloudant service URL.\n\nusername\n: The internal IBM Cloudant account name.\n\nFor more information, see [IBM Cloud API keys and Use only IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantibm-cloudant-api-keys-and-use-only-iam_ai).\n\n\n\n\n\nIn most cases, rotating credentials is a straight-forward process:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs\/faqsfind-service-credentials-iam).\n2. Replace the current credential with the newly generated credential.\n3. Delete the no-longer-used service credential.\n\n\n\nHowever, when you rotate the credentials for a replication, if you are using legacy credentials in the replication document, the replication starts from the beginning. To ensure that changes arrive in a timely manner, we advise you to create a new replication once it catches up with deleting the previous replication and the associated service credential. The process is described in the following steps:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs\/faqsfind-service-credentials-iam).\n2. Create a replication with the same settings but new credentials.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00589-5073-6581","score":14.2716329207,"text":"\nTo provision an instance as Use both legacy credentials and IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p {\"legacyCredentials\": true}\n\n\n\n\n\n Service credential JSON examples for each option \n\nThe choice between Use only IAM and Use both legacy credentials and IAM access control affects how credentials are delivered to your application when you bind and generate service credentials. When you generate credentials within the primary IBM Cloud IAM interface, API keys are shown in that interface when generated.\n\nYou can also generate credentials from the Service Credentials section of a service instance. Generating service credentials this way creates a service credentials JSON blob that can be pasted into applications with all the details that are needed to access the service instance.\n\nNext, you can see what the service credential JSON looks like and what each value means.\n\nWhen you select Use only IAM, the service credentials that are generated contain only IAM values, and look like the following example.\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"iam_apikey_description\": \"Auto generated apikey during resource-key [...]\",\n\"iam_apikey_name\": \"auto-generated-apikey-050d21b5-5f[...]\",\n\"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Manager\",\n\"iam_serviceid_crn\": \"crn:v1:staging:public:iam-identity::[...]\",\n\"url\": \"https:\/\/76838001-b883-444d-90d0-46f89e942a15-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_16727-417150-418627","score":14.2676120114,"text":"\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\nurl\n: IBM Cloudant service URL.\n\nusername\n: The internal IBM Cloudant account name.\n\nFor more information, see [IBM Cloud API keys and Use only IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantibm-cloudant-api-keys-and-use-only-iam_ai).\n\n\n\n\n\nIn most cases, rotating credentials is a straight-forward process:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs?tab=faqsfind-service-credentials-iam).\n2. Replace the current credential with the newly generated credential.\n3. Delete the no-longer-used service credential.\n\n\n\nHowever, when you rotate the credentials for a replication, if you are using legacy credentials in the replication document, the replication starts from the beginning. To ensure that changes arrive in a timely manner, we advise you to create a new replication once it catches up with deleting the previous replication and the associated service credential. The process is described in the following steps:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https:\/\/cloud.ibm.com\/docs?tab=faqsfind-service-credentials-iam).\n2. Create a replication with the same settings but new credentials.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00483-3212-4996","score":14.2375797733,"text":"\n: The legacy credentials password that is required for applications to access the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nhost\n: The hostname that is used by applications to locate the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nport\n: The HTTPS port number for accessing the service instance on the host. It's 443 as only HTTPS access is allowed by IBM Cloudant. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nurl\n: The HTTPS URL to access the IBM Cloudant instance. If the Use both legacy credentials and IAM option is chosen, it also includes the embedded legacy username and password.\n\napikey\n: The IAM API key.\n\niam_apikey_description\n: Description of the IAM API key.\n\niam_apikey_name\n: ID of the IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of the service ID.\n\n\n\n\n\n Authentication \n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials in the service credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) and [legacy authentication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication) document for details about using either style of authentication.\n\nThe IBM Cloudant team recommends you use IAM access controls for authentication whenever possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-connecting"},{"document_id":"ibmcld_12422-16914-18005","score":14.202323766,"text":"\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region\nservice_id = \"ServiceId-f4b2deac-fbb5-4bf7-85de-88426701db97\"\nttl = \"1800\"\nname = \"test-iam-credentials-secret\"\nreuse_api_key = true\nsecret_group_id = ibm_sm_secret_group.sm_secret_group_test.secret_group_id\ndepends_on = [\nibm_sm_iam_credentials_configuration.iam_credentials_configuration\n]\n}\n\n\n\n\n\n Deleting IAM credentials \n\nIf you have a service ID or API key that was generated by the IAM credentials secret engine and delete your instance of Secrets Manager, you must also delete the secret from IAM. For more information, see [Managing user API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userapikey).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-16940-18031","score":14.202323766,"text":"\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region\nservice_id = \"ServiceId-f4b2deac-fbb5-4bf7-85de-88426701db97\"\nttl = \"1800\"\nname = \"test-iam-credentials-secret\"\nreuse_api_key = true\nsecret_group_id = ibm_sm_secret_group.sm_secret_group_test.secret_group_id\ndepends_on = [\nibm_sm_iam_credentials_configuration.iam_credentials_configuration\n]\n}\n\n\n\n\n\n Deleting IAM credentials \n\nIf you have a service ID or API key that was generated by the IAM credentials secret engine and delete your instance of Secrets Manager, you must also delete the secret from IAM. For more information, see [Managing user API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userapikey).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_00583-2378-4437","score":14.1722039039,"text":"\nIf anyone or any application has access to the credentials, they can effectively do whatever they want with the service instance. For example, they might create spurious data, or delete valuable information. Protect these credentials carefully.\n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) and [legacy authentication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) document for details about using either style of authentication.\n\nThe service credentials include the following fields, as well as designating the fields that are only shown if you select the Use both legacy credentials and IAM option:\n\n\n\nTable 1. Service credential fields\n\n Field Purpose Legacy-auth enabled \n\n username The username that is required for applications to access the service instance. \n password The legacy credentials password that is required for applications to access the service instance. X \n host The hostname that is used by applications to locate the service instance. X \n port The HTTPS port number for accessing the service instance on the host. It's 443 as only HTTPS access is allowed by IBM Cloudant. X \n url The HTTPS URL to access the IBM Cloudant instance. X (If the Use both legacy credentials and IAM option is chosen, it also includes the embedded legacy username and password.) \n apikey The IAM API key. \n iam_apikey_description Description of the IAM API key. \n iam_apikey_name ID of the IAM API key. \n iam_role_crn The IAM role that the IAM API key has. \n iam_serviceid_crn The CRN of the service ID. X \n\n\n\nTo create an application that can access your service instance, you need these credentials.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-your-service-credentials"},{"document_id":"ibmcld_00610-7-2079","score":14.1709918647,"text":"\nMigrating an instance with legacy credentials and IAM Authentication to IAM Only Authentication \n\nWhen you create a new service credential by using the IBM Cloud Dashboard or the IBM Cloud CLI, it always produces a new username and password combination. This method applies to legacy credentials as well as a new IAM API key. This tutorial guides you through migrating your instance from generating new legacy credentials and IAM API keys to generating new IAM API keys only.\n\nThis tutorial is only applicable to IBM Cloudant instances within resource groups with legacy credentials that are enabled.\n\nSee the effects of this tutorial on existing legacy credentials:\n\n\n\n* New format legacy credentials (usernames that start with apikey-v2-) continue to function until the service credential is deleted.\n* URL style legacy credentials if still active are revoked. If you would like to revoke them separately, follow the [Revoking credential that is tied to your instance URL](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-revoke-instance-url-style-credential) steps before you complete this tutorial.\n\n\n\n\n\n Objectives \n\n\n\n1. Update your applications to use IAM credentials instead of legacy credentials.\n2. Disable creation of new legacy credentials.\n\n\n\n\n\n\n\n Step 1: Generating new IBM Cloudant IAM Credentials \n\n\n\n1. Use the IBM Cloud Dashboard or the IBM Cloud CLI to [generate new service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials) for your IBM Cloudant instance. For more information, see [Creating service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-onlycreating-service-credentials) for further instructions.\n\n\n\n\n\n\n\n Step 2: Updating applications \n\n\n\n1. Update all applications to use IAM access tokens when you authenticate with the IBM Cloudant instance.\n\n\n\n\n\n\n\n Step 3: Migrating to IAM only \n\nThis operation cannot be undone. Make sure all applications that access the instance are using IAM to authenticate before you start this step.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-only"},{"document_id":"ibmcld_12404-7597-8376","score":14.1687109149,"text":"\nYou can configure a secrets engine programmatically by using Terraform for Secrets Manager.\n\nThe following example shows a configuration that you can use to configure the IAM credentials engine.\n\nresource \"ibm_sm_iam_credentials_configuration\" \"iam_credentials_configuration\" {\ninstance_id = local.instance_id\nregion = local.region\nname = \"iam_credentials_config\"\napi_key = var.ibmcloud_api_key\n}\n\n\n\n\n\n Next steps \n\nNow you can use Secrets Manager to dynamically generate IAM credentials for your apps. In the Secrets Manager UI, click Secrets > Add > IAM credentials to start creating secrets.\n\n\n\n* [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials)\n\n\n\nThe metadata update operation uses a secret ID as part of the path.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine"},{"document_id":"ibmcld_00583-1311-2968","score":14.1388469465,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/tutorials\/images\/img0052.png)\n\nFigure 2. Viewing the IBM Cloudant service credentials\n\nNow, you can see the service credentials:\n\nZoom\n\n![The service credentials in this image are surrounded by a red box. The credentials include apikey, host, iam_apikey_description, iam_apikey_name, iam_role_crn, iam_serviceid_crn, url, and username.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/tutorials\/images\/img0009.png)\n\nFigure 3. The IBM Cloudant service credentials\n\nThe service credentials in these examples were defined when a demonstration IBM Cloudant service was created on IBM Cloudant. The credentials are reproduced here to show how they would appear in the dashboard. However, the demonstration IBM Cloudant service was removed, so these credentials are no longer valid. You must supply and use your own service credentials.\n\n\n\n\n\n\n\n Step 2: Understanding your service credentials \n\nService credentials are valuable. If anyone or any application has access to the credentials, they can effectively do whatever they want with the service instance. For example, they might create spurious data, or delete valuable information. Protect these credentials carefully.\n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-your-service-credentials"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06341-2428-3641","score":21.3077738323,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":21.3077738323,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":21.3077738323,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":21.3077738323,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":21.3077738323,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_06381-1376-2975","score":20.613543789,"text":"\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_09551-1435-3087","score":20.5038718452,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06564-1431-3083","score":20.5038718452,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":19.7321623274,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":19.7321623274,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14913-0-1238","score":17.7170164686,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_16030-7-2126","score":17.354973426,"text":"\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"},{"document_id":"ibmcld_16026-0-358","score":16.4790527265,"text":"\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vnf-limitations"},{"document_id":"ibmcld_07953-7-2429","score":15.7069120467,"text":"\nEnsuring isolation between Satellite management functions and workload functions \n\nA key aspect of the IBM Cloud Framework for Financial Services is to separate user workloads from system management functions and isolate security functions from nonsecurity functions. The network infrastructure of the Satellite location can be used to provide physical and logical separation between the Satellite management control plane and your workloads.\n\nNetwork flow rule design should follow the IBM Cloud Framework for Financial Services's [information flow guidelines](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection) by using a \"deny by default\" approach.\n\n\n\n Before you begin \n\n\n\n1. Complete the work for [account setup and management](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-account-setup).\n2. Complete [Satellite location setup](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n\n\n\n\n\n\n\n Identify network areas for control plane hosts and workload hosts \n\n\n\n1. Place control plane hosts into a separate network segment. Control plane hosts support various management and security-related components of the Satellite location. To facilitate effective network flow restrictions within the Satellite location, it is recommended to place control plane hosts into a separate network segment (whether physical or virtual) that can enable clear identification of source or destination of the network flows related to control plane functionality. The control plane hosts can be deployed to different physical locations, but the address space they are assigned to should provide an easy way to identify this group of hosts (for example, CIDR blocks).\n2. Designate a separate network segment for each group of Satellite hosts assigned to Red Hat OpenShift on IBM Cloud workload clusters. Satellite hosts that are assigned to Red Hat OpenShift on IBM Cloud workload clusters (workload hosts) should use their own network segments that would enable network flow control and monitoring between workload hosts, control plane, and other components outside of the Satellite location. It is recommended to designate a separate network segment (virtual subnet, VLAN, or a similar entity) for each group of Satellite hosts assigned to the same workload cluster.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"},{"document_id":"ibmcld_16030-4758-6868","score":15.6838749739,"text":"\nInter-subnet, inter-zone data flows - For these flows, the implicit router function removes the VNI and forwards the packet in the VPC's MPLS VPN for transit across the cloud backbone. At the destination zone, the implicit router function tags the data packet with the appropriate VNI. Then, the packet is forwarded to the destination hypervisor, where the VNI is stripped off again so that the data packet can be forwarded to the destination virtual server instance.\n\nExtra-vpc service data flows - Packets that are destined for IaaS or IBM Cloud Service Endpoint (CSE) services use the VPC's implicit router function. They also use a network address translation (NAT) function. The translation function replaces the virtual server instance address with an IPv4 address that identifies the VPC to the IaaS or CSE service that is requested.\n\nExtra-vpc internet data flows - Packets that are destined for the internet are the most complex. In addition to using the VPC's implicit router function, each of these flows also rely on one of the implicit router's two network address translation (NAT) functions.\n\n\n\n* An explicit one-to-many NAT through a public gateway function that serves all subnets that are connected to it.\n* One-to-one NAT assigned to individual virtual server instances.\n\n\n\nAfter NAT translation, the implicit router forwards these internet-destined packets to the internet, by using the cloud backbone.\n\n\n\n\n\n Life cycle of external IP addresses that are associated with public gateway functions \n\nAs both external IP addresses and PGWs are bound to an availability zone. A public gateway function can have only a single external IP. This external IP has the following lifecycle:\n\n\n\n* The external IP is allocated when the public gateway is created.\n* The external IP is released when the public gateway is deleted.\n\n\n\n\n\n\n\n Classic access \n\nThe [classic access](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) feature for VPC is accomplished by reusing the VRF identifier from the IBM Cloud\u00ae classic infrastructure account as the VRF identifier for VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"},{"document_id":"ibmcld_04709-1717-3966","score":15.5688987807,"text":"\nPricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience \n\n\n\nSuspend billing supports only hourly, SAN instances that are provisioned with a public profile from one of the Balanced, Compute, Memory, or Variable compute families.\n\n\n\n\n\n Network differentiators \n\nSee the following table for the networking differences between classic and VPC.\n\n\n\nTable 2. Network comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, navigate to the row and find the details for the feature that you're interested in.\n\n Category Classic infrastructure VPC infrastructure \n\n Location construct Data centers and PODs <br>(Might require VLAN spanning to connect two different pods or data centers, and purchasing gateways to control and route traffic) Regional model that abstracts infrastructure so you don't need to worry about pod locations. \n Network functions and services Physical and virtual appliances from multiple vendors Cloud-native network functions (VPNs, LBaaS) <br>(VPC isolation, dedicated resources carved out of public cloud, with more options for VPNs, LBaaS, multiple vNIC instances, and larger subnet sizes) \n IP addresses IPv6 addresses supported IPv4 addresses only \n Gateway routing Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Traffic routing is handled by public gateway and floating IP services \n Network address translation (NAT) Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Supported by the Bring-your-own-IP (BYOIP) functionality","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"},{"document_id":"ibmcld_07877-0-2001","score":15.5290713543,"text":"\n\n\n\n\n\n\n  SC-2 - Application Partitioning \n\n\n\n  Control requirements \n\nSC-2 - 0\n:   The information system separates user functionality (including user interface services) from information system management functionality.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Creating and connecting the management and workload VPCs](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-create-vpcs)\n\n\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether at least # Virtual Private Cloud (VPC)s have been created\n*  Check whether at least # instances of Transit Gateway have been created\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nInformation system management functionality includes, for example, functions necessary to administer databases, network components, workstations, or servers, and typically requires privileged user access. The separation of user functionality from information system management functionality is either physical or logical. Organizations implement separation of system management-related functionality from user functionality by using different computers, different central processing units, different instances of operating systems, different network addresses, virtualization techniques, or combinations of these or other methods, as appropriate. This type of separation includes, for example, web administrative interfaces that use separate authentication methods for users of any other information system resources. Separation of system and user functionality may include isolating administrative interfaces on different domains and with additional access controls.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sc-2"},{"document_id":"ibmcld_15810-70646-72492","score":15.3417701595,"text":"\nApplication Load Balancer (ALB) for VPC\n: Application load balancers now support HTTP\/HTTPS compression, which you use to compress data that is transmitted to your users. For more information, see [Compression (HTTP\/HTTPS only)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-advanced-traffic-managementcompression).\n\nHigh Availability (HA) Virtual Network Function (VNF) support\n: Support for a highly available, highly resilient virtual network functions can be achieved by using the \"routing mode\" feature of the IBM Cloud Network Load Balancer (NLB) for VPC. For more information, see [About virtual network functions over VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf) and [About HA VNF deployments](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf-ha).\n\nUpdates to Getting started with IBM Cloud VPC button\n: The \"Getting started with IBM Cloud VPC\" button now includes access to tours that are specific to what you are doing on the IBM console. If a tour is not available, the button takes you to the VPC List view.\n\n\n\n\n\n 06 January 2022 \n\nUI update when you create a virtual server\n: When you create a virtual server, the UI is updated to include a link in the Operating system section that opens a panel that contains information about the image lifecycle.\n\n\n\n\n\n\n\n December 2021 \n\n\n\n 16 December 2021 \n\nFile Storage for VPC (LA)\n: IBM Cloud\u00ae File Storage for VPC is now available for customers with special approval to preview this service in the Washington, Dallas, Frankfurt, London, Sydney, and Tokyo regions.\n: For more information about this service, see [About File Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about).\n\n\n\n\n\n 09 December 2021 \n\nSecurity updates\n: The following stock images were refreshed with the most recent fixes and security updates.\n\n\n\n* Debian version 10\n* CentOS version 7","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-release-notes"},{"document_id":"ibmcld_07717-6101-8054","score":15.09628392,"text":"\nin deployed artifacts<br> * Check whether Virtual Private Cloud (VPC) has no rules in the default security group<br> * Check whether App ID Cloud Directory users aren't able to self-sign up to applications<br> * Check whether all network interfaces of a virtual server instance have at least one Virtual Private Cloud (VPC) security group attached<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether Virtual Servers for VPC instance has the minimum # interfaces<br> * Check whether App ID redirect URIs are using HTTPS only<br> * Check whether Cloud Internet Services (CIS) has TLS mode set to End-to-End CA signed<br> * Check whether Application Load Balancer for VPC pool uses the HTTPS protocol for HTTPS listeners<br> * Check whether Application Load Balancer for VPC uses HTTPS (SSL & TLS) instead of HTTP<br> * Check whether Cloud Object Storage public access is disabled in IAM settings (not applicable to ACLs managed using S3 APIs)<br> * Check whether App ID anonymous authentication is disabled<br> * Check whether App ID avoid password reuse policy is enabled<br> * Check whether App ID user profile updates from client apps is disabled<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow ingress from 0.0.0.0\/0 to RDP port<br> * Check whether App ID redirect URIs are not using localhost or 127.0.0.1<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow ingress from 0.0.0.0\/0 to SSH port<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow egress from 0.0.0.0\/0 to any port<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nInformation systems can provide a wide variety of functions and services. Some of the functions and services, provided by default, may not be necessary to support essential organizational operations (e.g., key missions, functions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-cm-7"},{"document_id":"ibmcld_14128-0-2207","score":14.6399923059,"text":"\n\n\n\n\n\n\n  Overview of Parallels Server 4 bare metal server \n\nParallels Server Bare Metal is a virtualization solution that provides hardware virtualization along side the software virtualization of Virtuozzo, providing technology for both virtual machines and containers*.\n\nCommand line interface\n\nAlong with the usual Virtuozzo commands, other commands are available: pctl, pmigrate, pstat, and prl_disk_tool.\n\nMigration\n\nYou can now migrate Virtuozzo Containers to virtual machines, physical servers to Virtuozzo Containers, and physical servers to virtual machines to allow for consolidation of services. This functionality also allows for one to migrate containers or VMs between bare metal servers, convert VMs that were created on different virtualized environments (V2V), and change Windows SIDs when you clone or deploy a Windows VM from a template.\n\nIP address usage and VLANs\n\nYou can assign VMs to an IP from the physical server by using Parallels Tools that are in the VM. Additionally, PSBM allows for virtual switches and VLANs to be created within the VMs to better secure intra-VM network traffic.\n\nExecuting commands\n\nYou can run raw commands from the physical server directly within the Virtuozzo Containers and now within VMs (when parallels tools are installed within the VM), including user password resets.\n\nProcess accounting\n\nYou use Parallels Server Bare Metal to increase and reduce the priority of resources that are allocated (CPU, Disk I\/O Priority) to a VM quickly.\n\nBackup\n\nParallels Server Bare Metal provides the functionality to back up and restore VMs and containers on either the local bare metal server or a remote bare metal server to include full, and incremental backups.\n\nNetwork accounting\n\nYou use Parallels Server Bare Metal to easily view and locate VMs or Containers based on current and historical network throughput.\n\nNetwork\n\nParallels Server Bare Metal uses Portable IP addresses, while Virtuozzo uses either Portable or Static IP addresses (depending on the configuration).\n\n* IBM Cloud\u00ae licenses only hardware virtual machines on Parallels Server 4 Bare Metal, unless otherwise indicated on the order form. VM = virtual machine. V = VPS or Container.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-overview-of-parallels-server-4-bare-metal"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11503-1647-2794","score":22.3360131761,"text":"\n* Simulated Qubits: 63\n\n\n\n\n\n\n\n\n\n Standard plan \n\nA pay-as-you-go plan for accessing IBM Quantum systems and simulators. Build your own programs and access all the benefits of Qiskit Runtime by running on real quantum hardware.\n\n\n\n\n\n Pricing overview \n\nThe Lite plan is free. The Standard plan charges you per Qiskit Runtime second when running on physical systems. The following diagram illustrates what is included in a QR second. Any time spent waiting for results or in the queue for the quantum computer are excluded.\n\nZoom\n\n![This diagram shows that everything before the program starts (such as queuing) is free. After the job starts, it costs $1.60 per second.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5f399fa794584e8a662591b494b9a99aa927c74c\/quantum-computing\/images\/Runtime_Accounting_Diagram.png)\n\nFigure 1. Runtime second accounting\n\nQiskit Runtime usage is the time counted by Qiskit Runtime to process a job, and is determined by the use of internal resources.\n\n\n\n\n\n Next steps \n\n\n\n* See [Manage costs](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) to learn how to determine and minimize your costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans"},{"document_id":"ibmcld_03729-3519-5413","score":21.8876966715,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_04031-1609-3779","score":21.4231567823,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-10880-12984","score":20.5793038009,"text":"\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions. The pricing examples above are based on an IBM Cloud Kubernetes single-zone cluster only. If you chose a multi-zone cluster, there are extra fees for the additional zones and the required multi-zone load balancer. IBM Cloud IP allocation charges are not included and considered negligible.\n\nThere is no limit to the number of service instances that you can provision and associate to a single Kubernetes cluster. But you need to ensure that adequate resources are available by monitoring the CPU, memory, and storage usage to avoid disruption of service. The IBM Blockchain Platform nodes do not have to be in their own cluster. You can have other IBM Cloud services running in the same cluster that your blockchain components are running in, but again you need to ensure that you have adequate compute and storage to address all the requirements of all service instances.\n\nInterested in more pricing examples? See the Reference topic on [Detailed pricing scenarios](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-detailed-pricing) for additional configurations and prices.\n\nReady to get started? Check out [Getting started with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-get-started-ibp) to see the options.\n\n\n\n\n\n Default resource allocations \n\nThe values in the following table are useful to estimate the hourly cost of your custom network based on CPU, compute, and storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_11491-1403-3320","score":20.0201482007,"text":"\nFor more information about these plans, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n\n\n\n* Lite: Free simulators-only plan to help you get started with Qiskit Runtime. Learn to use Qiskit Runtime by following our examples and tutorials for one of the pre-built programs available for running circuits efficiently.\n* Standard: A pay-as-you-go model for accessing IBM Quantum systems and simulators. Build your own programs and leverage all the benefits of Qiskit Runtime by running on real quantum hardware, while maintaining access to all of the systems available to the Lite plan.\n\n\n\nBecause this is not a free plan, it is important to understand how to best manage your costs. See [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) for tips to limit your cost, how to set up spending notifications, and more.\n2. Complete the required information, then click Create.\n\n\n\n\n\n\n\n Step 2: Install or update Qiskit packages \n\nInstall or update the following packages in your development environment. They let you create circuits and work with primitive programs with Qiskit Runtime. For detailed instructions, refer to the [Qiskit Getting started topic](https:\/\/qiskit.org\/documentation\/getting_started.html). Periodically check the [Qiskit release notes](https:\/\/qiskit.org\/documentation\/release_notes.html) (or rerun these commands) so that you always have the latest version.\n\nBe sure to run these commands even if you already installed the packages, to ensure that you have the latest versions.\n\n Installs the latest version of the Qiskit meta-package for circuit creation.\npip install qiskit -U\n\n Installs the latest version of the Qiskit Runtime package, which is needed to interact with the Qiskit Runtime primitives on IBM Cloud.\npip install qiskit-ibm-runtime -U\n\n\n\n\n\n Step 3: Authenticate to the service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-get-started"},{"document_id":"ibmcld_04031-10086-11557","score":19.1464248933,"text":"\nCPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr ) \n Hourly cost: IBM Cloud Kubernetes cluster $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) \n Hourly cost: Storage $0.06 USD <br>340GB <br>[Bronze](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>2 IOPS\/GB $0.09 USD <br>420GB <br>[Silver](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>4 IOPS\/GB \n Total hourly cost $0.71 USD $1.19 USD \n\n\n\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_09986-0-1400","score":19.0723303558,"text":"\n\n\n\n\n\n\n  Pausing and resuming instances \n\nWhen you pause IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service instances, you shut down and free up all of the compute resources that are associated with a specified Netezza Performance Server instance. Pausing instances helps to save on the service cost. You usually pause instances if no workload exists on them. After an instance is paused, your Netezza Performance Server service is not available for executing new workloads.\n\nResuming Netezza Performance Server instances is the reverse of the pausing operation. When you resume instances the necessary compute resources are reprovisioned, the Netezza Performance Server service is brought back online, and it is ready for executing new workloads.\n\nYou can launch pause\/resume by using the Netezza Performance Server web console. Pause\/resume can be performed by the platform owner, administrator and editor only. For more infomation, see [Managing IAM access for Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-iam-docs).\n\nDepending on your requirements, you can also choose a scheduled pause\/resume along with an on demand (ad hoc) pause\/resume.\n\n\n\n  Pasuing and resuming instances with the web console \n\nFor more information, see [Pausing and resuming](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-patterns&interface=uipnr-console).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-pauseresume"},{"document_id":"ibmcld_04649-12160-14248","score":18.798123218,"text":"\nOptional: Unbind or delete a service instance.\n\nYou might want to unbind or delete a service instance when it is no longer used or when you want to free up some spaces. To unbind a service instance from your app, use the ibmcloud cf unbind-service command. To delete a service instance, use the ibmcloud cf delete-service command.\n\nFor more information about services, see Services. For more information about the ibmcloud cf options that you can use to manage your apps in the IBM Cloud environment, run ibmcloud cf --help in the ibmcloud cf command line interface.\n\nMake sure you no longer require a service instance before you delete it. Deleting a service instance erases all data that is associated with that instance of the service. Any app that is bound to a deleted service cannot have its <VCAP_SERVICES> environment variable updated until the app is restarted.\n\n\n\n\n\n\n\n\n\n Calculating your app cost \n\nIf your 30-day free trial has expired, and you want to continue to use IBM Cloud, you must add your credit card information for a Pay As You Go account or a Subscription account. However, IBM Cloud still provides free allowances for the community runtime frameworks (Python, PHP, Go, Ruby, Tomcat) and services even after you convert to a pay account. You are not charged by IBM Cloud unless the usage is beyond the free allowances.\n\nIBM Cloud provides an estimator and calculator for you to see your app cost. You can see the cost of your app in the following ways:\n\nIn your console, click your app. Then, in the Overview page, click estimate the cost of this app to see the price of SDK for Node.js runtime and Support, and the total monthly price of your app.\n\nOr, in the Pricing Sheet page, type the monthly usage of the runtime and services of your app. For example, 3 instances of SDK for Node.js with 1 GB memory for each instance. The monthly price is calculated and displayed.\n\nYou can also calculate your app cost manually by adding up the prices of your runtimes and services and deducting the free allowance. For more information, see Calculating your costs manually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started"},{"document_id":"ibmcld_02597-4595-6892","score":18.6537081053,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_09647-7-2622","score":18.6511660755,"text":"\nLicensed Mobility through Microsoft Software Assurance Overview \n\n\n\n Overview \n\nOrganizations around the world are benefitting from the power, flexibility, and efficiency of cloud computing. Whether you want to deploy server applications in a traditional customer on- premises environment, through a partner or a Microsoft cloud-hosted model, or a combination of all three, Microsoft gives you the flexibility to choose what is right for you, on your terms and on your schedule.\n\n\n\n\n\n License mobility through Microsoft Software Assurance \n\nWith more businesses adopting Infrastructure as a Service (IaaS), customers moving server workloads and applications to the cloud want to take advantage of their existing licensing investments as part of their IT strategy.\n\nLicense Mobility through Microsoft Software Assurance gives Microsoft Volume Licensing customers the flexibility to deploy certain server applications with active Software Assurance on-premises or in the cloud, without having to buy additional licenses. As a result, customers can take advantage of the lowest and flexible cost infrastructure for changing business priorities. Because of this new Software Assurance benefit, customers do not need to purchase new Microsoft Client Access Licenses (CALs), and no associated mobility fees exist.\n\n\n\n\n\n Products eligible for License mobility through Software Assurance \n\nFor specific Microsoft server products, [License Mobility through Software Assurance](https:\/\/www.microsoft.com\/en-us\/licensing\/licensing-programs\/software-assurance-license-mobility?rtc=1tab=3) gives customers enhanced flexibility. A customer can assign their application server licenses with active Software Assurance to run server instances on shared hardware via Microsoft Azure or a License Mobility through Software Assurance Partner\u2019s data center. Although sharing hardware, such server instances (virtual machines) must be dedicated to a single customer and are not shared with other customers.\n\nThe list of eligible server applications includes Microsoft SQL Server database software, Microsoft Exchange Server, Microsoft SharePoint Server, Microsoft Skype for Business Server, Microsoft System Center servers, and Microsoft Dynamics 365 Server for Customer Service and Sales applications. (Note: For SQL Server customers with core-based licensing and Software Assurance coverage, broader benefits are available under [Azure Hybrid Benefit](https:\/\/azure.microsoft.com\/en-us\/pricing\/hybrid-benefit\/) rights. For more information, see Azure Hybrid Benefit. The steps described below do not apply to Azure Hybrid Benefit use.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-microsoft-license-mobility"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14546-4405-6573","score":19.5600351228,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_14546-1313-3289","score":17.6343818914,"text":"\nVMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.\n\nFor example, a single-zone on-demand virtual data center is created with a resource limit of 100 vCPU and 800 GB RAM. The data center has no VMs running on it, so you do not receive a charge for the vCPU and RAM. If an 8 vCPU with 8 GB virtual machine (VM) is started, metering is calculated for the size of that VM. If the VM uses fewer resources than the ones assigned to it, metering is applicable to the full size of the VM.\n\n\n\n\n\n Allocation \n\nMetering is applicable to the full potential size of the resource for the life of the resource.\n\nFor example, a single zone reserved virtual data center is created with a resource allocation of 100 vCPU and 800 GB RAM and no VMs are created or running on it. Metering is applicable to 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Monthly peak metric usage \n\nThe maximum value of the metric used over a full month.\n\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_03729-4932-7001","score":16.9030028929,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_14007-0-1917","score":16.1526426111,"text":"\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"},{"document_id":"ibmcld_03729-1672-3956","score":16.1246200315,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_05666-7-2151","score":15.1686697945,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-7-2157","score":15.1119444723,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_14537-7-2256","score":14.7664178077,"text":"\nOrdering virtual data centers \n\nIBM Cloud\u00ae for VMware Solutions Shared offers either a standardized or customizable deployment option of VMware\u00ae virtual data center environments. Choose the On-demand or Reserved option.\n\n\n\n Requirements for virtual data centers \n\nIf you are ordering a virtual data center for the first time, ensure that you completed the tasks in the Before you begin section on the ordering page. For more information, see [Setting up your environment for your first order](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-completing_checklist).\n\n\n\n\n\n System settings \n\nYou must specify the following system settings when you order a VMware Shared virtual data center.\n\n\n\n Pricing plans \n\nThe pricing plan is based on your selection of On-demand or Reserved.\n\n\n\n On-demand \n\nFor the On-demand offering, virtual data center virtual CPU (vCPU) and RAM are allocated as needed. The amount of time that the allocation takes depends on global usage of the virtual data center vCPU and RAM.\n\n\n\n* The limits that are established for the amount of vCPU and RAM are maximum values that can be used at any time.\n* You can increase and decrease the vCPU and RAM resources on a virtual data center later as required.\n* The price is calculated hourly and it is based on the resource usage in the virtual data center.\n* The amount of storage that can be allocated and used in the virtual data center is limited to 200 TB for each storage policy. Charges are calculated per hour and are based on GB of allocated storage.\n* The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.\n\n\n\n\n\n\n\n Reserved \n\nFor the Reserved offering, the vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.\n\n\n\n* The price is calculated monthly for the full reservation and it is based on the allocation size of the virtual data center.\n* vCPU and RAM resources can be increased and decreased later as required.\n* The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are calculated per hour and are based on GB of allocated storage.\n* The amount of inbound and outbound public networking is unlimited.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_ordering"},{"document_id":"ibmcld_07578-335595-337885","score":14.5397463382,"text":"\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-335569-337859","score":14.5397463382,"text":"\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.4161811555,"ndcg_cut_10":0.4161811555}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00558-2925-4840","score":32.7399578239,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-2979-4903","score":32.7006742532,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00612-7-2163","score":31.5197769334,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_00609-0-1350","score":31.2893906668,"text":"\n\n\n\n\n\n\n  Migrating from a Lite plan to a Standard plan \n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\n\n\n  Step 1: Authenticate with IBM Cloud Dashboard \n\n\n\n1.  Go to the [IBM Cloud\u00ae Dashboard](https:\/\/cloud.ibm.com\/).\n2.  Authenticate with your username and password. The IBM Cloud Dashboard opens to the Resource list.\n\n\n\n\n\n\n\n  Step 2: Select your IBM Cloudant instance \n\n\n\n1.  Under Services, open the IBM Cloudant instance that you want to migrate.\n2.  Select Plan.\n3.  From the list of pricing plans, select Standard.\n\nZoom\n\n![Standard plan is a serverless scaling of throughput and storage. Includes 20 GB of free data storage, more storage metered. Users can adjust provisioned throughput capacity in blocks of 100 reads\/sec, 50 writes\/sec, 5 global queries\/sec. Max JSON document size of 1 MB. $1.00 USD\/GB of data storage. $0.25 USD\/Read capacity. $0.50 USD\/Write capacity. $5.00 USD\/Global Query capacity.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/migrate3.png)\n\nFigure 1. Standard plan\n\n\n\n\n\n\n\n  Step 3: Upgrade to the Standard plan \n\n\n\n1.  Click Upgrade. All your existing data is kept.\n2.  Adjust your capacity by using the Throughput Capacity slider to increase or decrease capacity as needed.\n\n\n\nNow, you're ready to go.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan"},{"document_id":"ibmcld_00558-1499-3456","score":30.5001284744,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-1535-3460","score":30.4999922643,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00540-7-1622","score":29.4113372678,"text":"\nFinding your IBM Cloudant plan \n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\n\n\n Step 1: Finding your plan \n\nThe following steps show where you can see the type of plan that you selected.\n\n\n\n1. Go to the [IBM Cloud Dashboard](https:\/\/cloud.ibm.com\/).\n2. Authenticate with your username and password.\nThe IBM Cloud Dashboard opens to the Resource list.\n3. Click an instance to find more information.\n4. Click Plan. A checkmark indicates the plan that you use as shown in the following screen capture. For more information, see the [Migration FAQ](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration).\n\nZoom\n\n![Standard dashboard includes a serverless scaling of throughput and storage. Includes 20 GB of free data storage, extra storage metered. Users can adjust provisioned throughput capacity in blocks of 100 reads\/sec, 50 writes\/sec, 5 global queries\/sec. Max JSON document size of 1 MB. $1.00 USD\/GB of data storage. $0.25 USD\/Read capacity. $0.50 USD\/Write capacity. $5.00 USD\/Global Query capacity.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/ibmcloud_instance_standard_plan.png)\n\nFigure 1. Standard dashboard\n\nIf the Plan tab indicates that you're on the Standard plan, you don't need to read any further. You're already on a paid SLA-backed IBM Cloudant service. No further action is required.\n\n\n\n\n\n\n\n Step 2: Finding your legacy Enterprise plan \n\nYou can find your Enterprise plan in the IBM Cloudant Dashboard by following these steps.\n\n\n\n1. Open the IBM Cloudant Dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan"},{"document_id":"ibmcld_00612-1678-3526","score":28.3720530878,"text":"\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month. You can buy extra storage, which is charged by the GB.\n\nBy using the slider in the IBM Cloudant Dashboard, you can reserve a smaller or larger capacity for your IBM Cloudant service whenever you need it:\n\nZoom\n\n![You can increase or decrease your capacity for IBM Cloudant service by using the slider.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/slider.png)\n\nFigure 1. Slider\n\nThe amount that you can change the throughput capacity is limited to a maximum of 10 units per change with a maximum of one change per hour. Notice the \"change limit\" point on the slider. Changes downward are unlimited in size, but still subject to the time limit.\n\nYou're billed on the highest capacity that is selected in any given hourly window. Your database throughput can scale up to deal with seasonal demands and scale down again for the quiet times. Your monthly bill is always predictable; upgrades are automatic; and your SLA is [99.99%](https:\/\/www.ibm.com\/support\/customer\/csol\/terms?id=i126-6627&lc=endetail-document).\n\nIf you exceed your quota of reads, writes, and global queries in a given second, the IBM Cloudant API responds with a 429: too many requests HTTP response. Your application might retry the request later. You can use our official libraries to retry such requests with an exponential back off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_00558-19133-20902","score":25.7821473946,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/monitoring-current_operations.png)\n\nFigure 4. Monitoring - Current Operations\n\nDenied Requests tab\n\n\n\n* Shows the number of requests that were denied in a given second.\n* Shows the response, 429: too many requests.\n* Requests are denied because they exceed the provisioned throughput capacity that is allocated to the instance. The graphs are broken down by reads, writes, and global queries.\n\n\n\nZoom\n\n![Monitoring - Denied Requests shows the number of requests that were denied in a given second. Shows 429: too many requests. Requests are denied because they exceed the provisioned throughput capacity that is allocated to the instance.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/monitoring-denied_requests.png)\n\nFigure 5. Monitoring - Denied Requests\n\nMonitoring helps you recognize that a change to the provisioning in your plan might be advisable. For example, if you frequently approach the maximum number of database reads, then you can modify the capacity for the instance through the [Capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicviewing-and-changing-capacity) UI.\n\n\n\n\n\n\n\n Data usage \n\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-19214-20992","score":25.7381052973,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/monitoring-current_operations.png)\n\nFigure 4. Monitoring - Current Operations\n\nDenied Requests tab\n\n\n\n* Shows the number of requests that were denied in a given second.\n* Shows the response, 429: too many requests.\n* Requests are denied because they exceed the provisioned throughput capacity that is allocated to the instance. The graphs are broken down by reads, writes, and global queries.\n\n\n\nZoom\n\n![Monitoring - Denied Requests shows the number of requests that were denied in a given second. Shows 429: too many requests. Requests are denied because they exceed the provisioned throughput capacity that is allocated to the instance.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/monitoring-denied_requests.png)\n\nFigure 5. Monitoring - Denied Requests\n\nMonitoring helps you recognize that a change to the provisioning in your plan might be advisable. For example, if you frequently approach the maximum number of database reads, then you can modify the capacity for the instance through the [Capacity](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicviewing-and-changing-capacity) UI.\n\n\n\n\n\n\n\n Data usage \n\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4776237035,"ndcg_cut_10":0.4776237035}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16318-7-1772","score":30.8676393474,"text":"\nMigrating intents and entities \n\nYou can migrate your intents and entities from the classic Watson Assistant experience to the new Watson Assistant experience.\n\n\n\n Downloading intents \n\nYou can download intents to a CSV file, so you can then upload and reuse them as actions or example phrases in the new Watson Assistant experience.\n\n\n\n1. Go to the Intents page.\n2. Select the intents that you want to download, and then click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/download-icon.png).\n\nIf you plan to use a downloaded intent file to upload example phrases for a specific action, download only a single intent. In the new experience, only one intent can be uploaded per action.\n3. Specify the name and location in which to store the CSV file that is generated, and click Save.\n\n\n\nYou can now perform the following tasks to migrate information to the new Watson Assistant:\n\n\n\n* Upload intents as actions. For more information, see [Uploading intents as actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-upload-download-actionsupload-download-actions-upload-intents).\n* Upload the examples from a single intent as example phrases for a specific action. For more information, see [Uploading phrases](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-uploading-examples).\n\n\n\n\n\n\n\n Downloading entities \n\nYou can download a number of entities to a CSV file, so you can then upload and reuse them as saved customer responses in the new Watson Assistant experience.\n\n\n\n1. Go to the Entities page.\n2. Select the entities that you want to download, and then click the Download icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entities"},{"document_id":"ibmcld_16359-2807-4644","score":30.3764016464,"text":"\nEach phrase can be up to 1,024 characters in length.\n\nBy adding these phrases, your assistant learns what is the right action for what a customer wants. The additional examples build the training data that the machine learning engine of Watson Assistant uses to create a natural language processing model. The model is customized to understand your uniquely defined actions.\n\n\n\n Uploading phrases \n\nIf you have many example phrases, you can upload them from a comma-separated value (CSV) file than to define them one by one. If you are migrating intent information from the classic Watson Assistant experience to example phrases in the new Watson Assistant experience, see [Migrating intents and entities](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entities).\n\n\n\n1. Collect the phrases into a CSV file. Save the CSV file with UTF-8 encoding and no byte order mark (BOM).\n\n\n\n* If you are creating a new CSV file to upload phrases, the format for each line in the file is as follows:\n\n<phrase>\n\nWhere <phrase> is the text of a user example phrase. If you\u2019re using a spreadsheet to create a CSV file, put all your phrases into column 1, as shown in the following example:\n\nZoom\n\n![Example spreadsheet to upload phrases](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/uploading-phrases-spreadsheet.png)\n\nExample spreadsheet\n* If you [downloaded intents from the classic experience](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download), the format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nWhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_03334-4-1943","score":29.9553143582,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Creating intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\nTo learn more about creating intents, watch the following 2 1\/2-minute video.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03405-4-2057","score":29.8235033105,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots"},{"document_id":"ibmcld_16364-37713-39824","score":29.5508181035,"text":"\nThis allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.\n* Releases: Retrieve information about the releases (versions) that have been published for an assistant, and assign an available release to an environment.\n\n\n\nFor more information, see the v2 [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\n\n\n\n\n 5 August 2022 \n\nInitial value of session variables\n: You can now set the initial value of a session variable to an expression. For more information, see [Creating a session variable](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-infocreate-session-variable).\n\nUploading intents\n: If you created intents in the classic Watson Assistant experience, you can migrate your intents to actions in the new Watson Assistant experience. This can provide a helpful starting point when you are ready to start building actions in the new experience. For more information, see [Uploading intents as actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-upload-download-actionsupload-download-actions-upload-intents).\n\n\n\n\n\n 19 July 2022 \n\nChanges to publishing and environments\n: You can now publish versions of your content without assigning to the live environment, allowing you to make continuous updates before customers see it in production. Also, the formerly separate pages for your draft and live environments now appear as tabs on a single Environments page, from which you can set up unique configurations for building and testing in the draft environment, and for your customers in the live environment. For more information, see the [Publishing overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview).\n\nLogs reader role","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-4830-7108","score":29.4670714893,"text":"\nSince then, support for more languages has been added. This algorithm version was stabilized in December 2022 with minor enhancements since that time.\n\nWith this new release, the June 1, 2022 version is now labeled as Previous (01 Jun 2022). The oldest release labeled as 01 Jan 2022 is no longer available for training. As of now, the new Beta version has the same behavior as the Latest (20 Dec 2022) version. Updates to the Beta version will be released soon.\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 6 March 2023 \n\nImprovements to algorithm version beta\n: Improvements to the current Beta algorithm version include:\n\n\n\n* Relevant examples are expected to get higher confidence\n* For Spanish-language assistants, intent detection is improved in the presence of direct entity references\n* Intent detection is more stable regarding occurrence of numerics, such as postal codes\n* Intent detection now accounts for fuzzy closed entity mentions\n* For German-language assistants, intent detection is more robust in the presence of umlauts\n\n\n\nFor more information, see [Algorithm version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 26 January 2023 \n\nIntent recommendations and intent user example recommendations discontinued\n: As of this release, intent recommendations and intent user example recommendations are discontinued. Intent recommendations has been removed from the Intents page and Recommended examples has been removed from intents. In the new Watson Assistant experience, you can [use unrecognized requests to get action recommendations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-recognition).\n\n\n\n\n\n 18 January 2023 \n\nAlgorithm version stability improvement\n: As of this date, the Latest (01 Jun 2022) and Beta algorithm versions now have more stable behavior across retrained models, in the presence of overlapping entities (the same entity value belonging to more than one entity type). Previously, when there were overlapping entities definitions, confidences could differ across different retraining. With this improvement, you can expect to see similar confidences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-9254-11397","score":29.4409111069,"text":"\nIf a customer accidentally input Pflegegelb, the assistant would incorrectly match with Pflege rather than Pflegegeld.\n\nWith this fix, the Pflegegelb input value would correctly match Pflegegeld, not Pflege. For more information, see [How fuzzy matching works](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\nImproved enhanced intent detection available in more languages\n: Previously, the exact match in enhanced intent detection was improved to better handle small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence. For example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update now includes the following languages: Arabic, Czech, and Dutch. For more information, see [Accessing intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 24 June 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Chinese (Traditional), Japanese, and Korean. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\nImproved enhanced intent detection available in more languages","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03145-4-1748","score":29.4147101202,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Using built-in intents \n\nContent Catalogs provide an easy way to add common intents to your Watson Assistant dialog skill.\n\nIntents you add from the catalog are meant to provide a starting point. Add to or edit the catalog intents to tailor them for your use case.\n\nThe latest content catalog, named Covid-19, is available in Brazilian Portuguese, English, French, and Spanish only. For more information about language support for the catalogs, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n Adding a content catalog to your dialog skill \n\n\n\n1. Open your dialog skill, open the Content Catalog page.\n\n![Screen capture showing available catalogs](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/catalog-overview.png)\n2. Select a content catalog, such as Banking, to see the intents that are provided with it.\n\n![Screen capture showing Banking category intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/catalog-open.png)\n\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_16360-7-1967","score":29.2998134865,"text":"\nUploading or downloading all actions \n\nYou can upload or download all your actions as a JSON file.\n\n\n\n Downloading \n\nTo back up all your actions, download a JSON file and store it.\n\n\n\n1. On the Actions page, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Upload\/Download tab, click the Download button.\n\n\n\n\n\n\n\n Uploading \n\nTo reinstate a backup copy of actions that you exported from another service instance or environment, import the JSON file of the actions you exported.\n\nIf the Watson Assistant service changes between the time you export the actions and import it, due to functional updates that are regularly applied to instances in cloud-hosted continuous delivery environments, your imported actions might function differently than before.\n\n\n\n1. On the Actions page, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Upload\/Download tab, drag and drop a JSON file onto the tab or click to select a file from your local system, then click Upload.\n\n\n\nThe imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON file cannot contain tabs, newlines, or carriage returns.\n\n\n\n\n\n Uploading intents as actions \n\nIf you created intents in the classic Watson Assistant experience, you can migrate your intents to actions in the new Watson Assistant experience. When you upload intents, each intent is created as a new action. All phrases corresponding to an intent are created as example phrases for the new action. This can provide a helpful starting point when you are ready to start building actions in the new experience.\n\n\n\n1. Download the intents that you want to migrate to actions from the classic Watson Assistant experience. For more information, see [Downloading intents](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-upload-download-actions"},{"document_id":"ibmcld_16359-4231-5828","score":29.2263227158,"text":"\n* If you [downloaded intents from the classic experience](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download), the format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nWhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions\nIs it raining?,weather_conditions\nWhat's the temperature?,weather_conditions\n\nOnly one intent can be uploaded per action, so the <intent> information listed in the second column of the CSV file must be the same.\n\n\n\n2. Go to Customer starts with at the start of the action.\n3. Click the Upload icon ![Upload icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/upload-icon.png).\n4. Select a file from your computer.\n\nThe file is validated and uploaded, and the system trains itself on the new data.\n\n\n\n\n\n\n\n Downloading phrases \n\nYou can download your example phrases to a CSV file, so you can then upload and reuse them in another Watson Assistant application.\n\n\n\n1. Go to Customer starts with at the start of the action.\n2. Click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/download-icon.png).\n\nYour example phrases are downloaded to a CSV file.\n\n\n\n\n\n\n\n\n\n Asking clarifying questions \n\nWhen your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-7-1988","score":81.4835771485,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-1211-2688","score":76.2313017178,"text":"\nFor more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using IBM Cloud\u00ae console \n\nTo configure your Analytics Engine instance from the IBM Cloud\u00ae Resource list, complete the following steps:\n\n\n\n1. Log in to your IBM Cloud\u00ae account.\n2. Access the [IBM Cloud\u00ae Resource list](https:\/\/test.cloud.ibm.com\/resources).\n3. Search your Analytics Engine instance and click the instance to see the details.\n4. Click Manage > Configuration to view the configuration.\n5. In the Default Spark configuration section, click Edit.\n6. Add the following configuration to the Default Spark configuration section.\n\nspark.sql.catalogImplementation = hive\nspark.driver.extraClassPath = \/opt\/ibm\/connectors\/iceberg-lakehouse\/iceberg-3.3.2-1.2.1-hms-4.0.0-shaded.jar\nspark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\nspark.sql.iceberg.vectorization.enabled = false\nspark.sql.catalog.lakehouse = org.apache.iceberg.spark.SparkCatalog\nspark.sql.catalog.lakehouse.type = hive\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_16641-2355-3755","score":74.7510858926,"text":"\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_13481-5443-6857","score":73.5448346302,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-4554-5850","score":71.9155218172,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* BASE_URL: The Analytics Engine URL for the region where you provisioned the instance. For example, api.region.ae.ibmcloud.com.\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n* hms-thrift-endpoint-from-watsonx.data: Specify the credentials for watsonx.data.\n* hms-user-from-watsonx.data: The watsonx.data username.\n* hms-password-from-watsonx.data: The watsonx.data password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_13481-6212-7871","score":68.7650769562,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-3545-4909","score":68.6932299482,"text":"\ncurl -X POST https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<GUID of Analytic Engine>\/spark_applications --header \"Authorization: Bearer $TOKEN\" -H \"content-type: application\/json\" -d @listTablesExample.json\n\n\n\n\n\n Apache Spark Data Engine integration \n\nFor self-hosted Apache Spark installations use the following instructions.\n\n\n\n1. Ensure that [Stocator](https:\/\/github.com\/CODAIT\/stocator) is installed according to the instructions provided.\n2. Download the Hive-compatible client with the provided [instructions](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastorehive_compatible_client).\n3. Either download the [provided convenience libraries](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastoreconvenience_libraries) or, in case you don't want to use them, set the following settings in SparkContext yourself:\n\nspark = SparkSession.builder.appName('Python-App') \n.config(\"spark.sql.pyspark.jvmStacktrace.enabled\", True) \n.config(\"spark.hive.metastore.truststore.path\", \"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\") \n to access IBM Cloud Object Storage ensure that stocator is available\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-6629-7897","score":68.5371793443,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-7452-8829","score":66.0202061406,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00029-8568-9861","score":65.8327529617,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3692678015}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10203-2544-4340","score":28.668856412,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10576-7-1739","score":28.5473805698,"text":"\nClassic: Why can't I add worker nodes with an invalid VLAN ID? \n\nClassic infrastructure\n\n What\u2019s happening \n\nYour IBM Cloud account was suspended, or all worker nodes in your cluster were deleted. After the account is reactivated, you can't add worker nodes when you try to resize or rebalance your worker pool. You see an error message similar to the following:\n\nSoftLayerAPIError(SoftLayer_Exception_Public): Could not obtain network VLAN with id 123456.\n\n Why it\u2019s happening \n\nWhen an account is suspended, the worker nodes within the account are deleted. If a cluster has no worker nodes, IBM Cloud infrastructure reclaims the associated public and private VLANs. However, the cluster worker pool still has the previous VLAN IDs in its metadata and uses these unavailable IDs when you rebalance or resize the pool. The nodes fail to create because the VLANs are no longer associated with the cluster.\n\n How to fix it \n\nYou can [delete your existing worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_rm), then [create a new worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_create).\n\nAlternatively, you can keep your existing worker pool by ordering new VLANs and using these to create new worker nodes in the pool.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. To get the zones that you need new VLAN IDs for, note the Location in the following command output. Note: If your cluster is a multizone, you need VLAN IDs for each zone.\n\nibmcloud oc cluster ls\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-suspended"},{"document_id":"ibmcld_05634-7-1626","score":28.5452177281,"text":"\nDeploying apps to worker pools where autoscaling is enabled \n\nTo limit a pod deployment to a specific worker pool that is managed by the cluster autoscaler, use a combination of labels and nodeSelector or nodeAffinity to deploy apps only to the autoscaled worker pools. With nodeAffinity, you have more control over how the scheduling behavior works to match pods to worker nodes. Then, use taints and tolerations so that only these apps can run on your autoscaled worker pools.\n\nFor more information, see the following Kubernetes docs:\n\n\n\n* [Assigning pods to nodes](https:\/\/kubernetes.io\/docs\/concepts\/scheduling-eviction\/assign-pod-node\/)\n* [Taints and tolerations](https:\/\/kubernetes.io\/docs\/concepts\/scheduling-eviction\/taint-and-toleration\/)\n\n\n\nBefore you begin:\n\n\n\n* [Install the ibm-iks-cluster-autoscaler plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-install-addon).\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo limit pods to run on certain autoscaled worker pools:\n\n\n\n1. Make sure that you labeled and tainted your autoscaled worker pool as described in [Preparing your cluster for autoscaling](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc).\n2. In your pod spec template, match the nodeSelector or nodeAffinity to the label that you used in your worker pool.\n\nExample of nodeSelector:\n\n...\nspec:\ncontainers:\n- name: nginx\nimage: nginx\nimagePullPolicy: IfNotPresent\nnodeSelector:\napp: nginx\n...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-deploy-apps"},{"document_id":"ibmcld_10444-5383-7233","score":28.4244269263,"text":"\nFor more information, see [worker node resource reserves](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesresource_limit_node).\n\nWant to be sure that you always have enough worker nodes to cover your workload? Try out [the cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc).\n\n\n\n\n\n Why do my worker nodes have the master role? \n\nWhen you run oc get nodes or oc describe node <worker_node>, you might see that the worker nodes have master,worker roles. In OpenShift Container Platform clusters, operators use the master role as a nodeSelector so that OCP can deploy default components that are controlled by operators, such as the internal registry, in your cluster. No master node processes, such as the API server or Kubernetes scheduler, run on your worker nodes. For more information about master and worker node components, see [Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architectureservice-architecture-4).\n\n\n\n\n\n How can I check the operating system that my worker nodes run? \n\nWhen you create a worker pool, you choose the flavor, which describes the operating system along with the compute resources of the worker nodes. Supported operating systems are RHEL 7.\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\noc get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\noc describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"},{"document_id":"ibmcld_05707-8988-11065","score":28.360557226,"text":"\n[Portable public IP addresses](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-subnetsreview_ip) Yes \n [Logging and monitoring](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-healthlogging) Yes \n [Option to provision your worker nodes on physical (bare metal) servers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes) Yes \n\n\n\n\n\n\n\n Comparison between Red Hat OpenShift and community Kubernetes clusters \n\nBoth Red Hat OpenShift on IBM Cloud and IBM Cloud Kubernetes Service clusters are production-ready container platforms that are tailored for enterprise workloads. The following table compares and contrasts some common characteristics that can help you choose which container platform is best for your use case.\n\n\n\nCharacteristics of community Kubernetes and Red Hat OpenShift clusters\n\n Characteristics Community Kubernetes clusters Red Hat OpenShift clusters \n\n Complete cluster management experience through the IBM Cloud Kubernetes Service automation tools (API, CLI, console) Yes Yes \n Worldwide availability in single and multizones Yes Yes \n Consistent container orchestration across hybrid cloud providers Yes Yes \n Access to IBM Cloud services such as AI Yes Yes \n Software-defined storage Portworx solution available for multizone data use cases Yes Yes \n Create a cluster in an IBM Virtual Private Cloud (VPC) Yes Yes \n Latest community Kubernetes distribution Yes \n Scope IBM Cloud IAM access policies to access groups for service access roles that sync to cluster RBAC Yes \n Classic infrastructure cluster on only the private network Yes \n GPU bare metal worker nodes Yes Yes \n Integrated IBM Cloud Paks and middleware Yes \n Built-in container image streams, builds, and tooling ([read more](https:\/\/blog.cloudowski.com\/articles\/why-managing-container-images-on-openshift-is-better-than-on-kubernetes\/)) Yes \n Integrated CI\/CD with Jenkins Yes \n Stricter app security context set up by default Yes \n Simplified Kubernetes developer experience, with an app console that is suited for beginners Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_10565-3519-5200","score":28.2290591956,"text":"\nYou can exclude worker nodes from your Portworx cluster or remove the entire Portworx cluster if you don't want to use Portworx anymore.\n\nRemoving your Portworx cluster removes all the data from your Portworx cluster. Make sure to [create a snapshot for your data and save this snapshot to the cloud](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/storage-operations\/create-snapshots\/).\n\n\n\n* Remove a worker node from the Portworx cluster: If you want to remove a worker node that runs Portworx and stores data in your Portworx cluster, you must migrate existing pods to remaining worker nodes and then uninstall Portworx from the node. For more information, see [Decommission a Portworx node in Kubernetes](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/operate-and-maintain-on-kubernetes\/uninstall\/decommission-a-node\/).\n* Remove the Portworx DaemonSet: When you remove the Portworx DaemonSet, the Portworx containers are removed from your worker nodes. However, the Portworx configuration files remain on the worker nodes and the storage devices, and the data volumes are still intact. You can use the data volumes again if you restart the Portworx DaemonSet and containers by using the same configuration files. For more information, see [Removing the Portworx DaemonSet](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_removingremove_px_daemonset).\n* Remove Portworx from your cluster: If you want to remove Portworx and all your data from your cluster, follow the steps to [remove Portworx](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_removing) from your cluster.\n\n\n\n\n\n\n\n Removing the Portworx DaemonSet","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_removing"},{"document_id":"ibmcld_10284-5722-7544","score":28.1367361844,"text":"\nWorker nodes are automatically provisioned with optimized kernel performance, but you can change the default settings by applying a custom [Kubernetes DaemonSet](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/daemonset\/) with an [init Container](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/pods\/init-containers\/) to your cluster. The daemon set modifies the settings for all existing worker nodes and applies the settings to any new worker nodes that are provisioned in the cluster. The init container makes sure that these modifications occur before other pods are scheduled on the worker node. No pods are affected.\n\nYou must have the [Manager IBM Cloud IAM service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) for all namespaces to run the sample privileged initContainer. After the containers for the deployments are initialized, the privileges are dropped.\n\nBefore you begin: [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n\n\n\n1. Save the following daemon set in a file named worker-node-kernel-settings.yaml. In the spec.template.spec.initContainers section, add the fields and values for the sysctl parameters that you want to tune. This example daemon set changes the default maximum number of connections that are allowed in the environment via the net.core.somaxconn setting and the ephemeral port range via the net.ipv4.ip_local_port_range setting.\n\nDepending on the systctl settings that you try to change, you might want to configure the security context. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/nodes\/containers\/nodes-containers-sysctls.html).\n\napiVersion: apps\/v1\nkind: DaemonSet\nmetadata:\nname: kernel-optimization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernel"},{"document_id":"ibmcld_10394-7-1848","score":28.0974482224,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-7-1827","score":27.9985859502,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10042-20678-22724","score":27.9167066876,"text":"\ncontainers-kubernetes.cluster-worker-pool-zone.list The worker pools for a cluster in a particular zone are listed as part of cluster autoscaler operations. \n containers-kubernetes.cluster-worker-pool-zone.resize A worker node is added to or removed from a zone that the worker pool spans. \n containers-kubernetes.cluster-worker-pool-zone-network.add The networking data, such as public and private VLAN data, is added for a zone that the worker pool spans. \n containers-kubernetes.cluster-worker-pool-zone-worker.list The worker nodes within a zone that a the worker pool spans are listed as part of cluster autoscaler operations. \n containers-kubernetes.worker.delete A worker node is deleted from the cluster. \n containers-kubernetes.worker.get The details of a worker node in the cluster are returned. \n containers-kubernetes.worker.reboot A worker node is rebooted. \n containers-kubernetes.worker.reload A worker node is reloaded. \n containers-kubernetes.worker.replace A worker node is removed and another worker node of the same flavor is created in the cluster. \n containers-kubernetes.worker.update A worker node version is updated. \n\n\n\n\n\n\n\n Viewing your cluster events \n\nTo [view events](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-view_events) that are sent to IBM Cloud Activity Tracker, you select the Activity Tracker instance that matches with the location of your Red Hat OpenShift on IBM Cloud cluster.\n\nThe following table shows the Activity Tracker location where your events are sent to. To view your events, make sure that you have an Activity Tracker instance in the location that matches your cluster location. Note that clusters in the Montreal, Toronto, and Washington, D.C. locations forward all events to the Dallas Activity Tracker location.\n\n\n\nCorresponding Activity Tracker instance and Red Hat OpenShift on IBM Cloud cluster locations.\n\n Red Hat OpenShift on IBM Cloud classic location Activity Tracker event location \n\n Dallas (dal10, dal12, dal13) Dallas \n Montreal (mon01) Washington, D.C.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-at_events"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00510-5537-7566","score":27.1413799344,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00558-23465-25360","score":26.3292425126,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":26.3292425126,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":25.6420776074,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00510-7123-9213","score":22.5515213855,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00556-7-1696","score":22.4364003598,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00564-1452-3164","score":21.5607342352,"text":"\ncouchbackup --url \"$SERVICE_URL\" --db animaldb > backup.txt\n\nThe [NPM readme file](https:\/\/github.com\/cloudant\/couchbackup\/blob\/master\/README.md) details other options, including the ones in this list:\n\n\n\n* Environment variables to set the names of the database and URL.\n* Using a log file to record the progress of a backup.\n* The ability to resume an interrupted backup.\n\nThis option is only available with the log file for the interrupted backup.\n* Sending the backup text file to a named output file, rather than redirecting the stdout output.\n\nThe CouchBackup tools have [limitations](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoverylimitations).\n\n\n\n\n\n\n\n Restoring your IBM Cloudant data \n\nTo restore your data, use the couchrestore tool. Use couchrestore to import the backup file into a new IBM Cloudant database. Then, ensure that you build all indexes before any application tries to use the restored data.\n\nFor example, to restore the data that was backed up in the earlier example:\n\ncouchrestore --url \"https:\/\/myaccount.cloudant.com\" --db newanimaldb < backup.txt\n\nThe [NPM readme file](https:\/\/github.com\/cloudant\/couchbackup\/blob\/master\/README.md) provides details of other restore options.\n\n\n\n\n\n Limitations \n\nThe CouchBackup tools have the following limitations:\n\n\n\n* _security settings aren't backed up by the tools.\n* Attachments aren't backed up by the tools.\n* Backups aren't precise \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, data in the database can change between the times when the first and last batches are read.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"},{"document_id":"ibmcld_00629-29811-31959","score":21.4175431141,"text":"\ncurl \"$SERVICE_URL\/$DATABASE\/_changes?feed=continuous&include_docs=true&since=now&filter=mydesigndoc\/myfilter\"\n\nThe ordering of documents within the _changes feed is not always the same. In other words, changes might not appear in strict time order. The reason is that data is returned from multiple IBM Cloudant nodes, and eventual consistency rules apply.\n\n\n\n\n\n Replication pitfalls \n\nTo replicate successfully, the sum of the document size and all attachment sizes must be less than the maximum request size of the target cluster. For example, if the maximum HTTP request size is 11 MB, then the following scenarios apply:\n\n\n\nTable 1. Various scenarios based on maximum HTTP request size 11 MB\n\n Document size Attachment size Total size Replicates? \n\n 1 MB Five 2-MB attachments 11 MB Yes \n 1 MB One 10-MB attachment 11 MB Yes \n 1 MB One hundred 1-MB attachments 101 MB No \n\n\n\nSeveral considerations apply when you use replication.\n\n\n\n Incorrect user permissions \n\nFor replication to proceed optimally when you replicate from database \"a\" to database \"b\", the credentials that are supplied must have:\n\n\n\n* _reader and _replicator permissions on database \"a\".\n* _writer permissions on database \"b\".\n\n\n\nAPI keys are generated in the IBM Cloudant Dashboard or through the [API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Each key can be given individual permissions that relate to a specific IBM Cloudant database. IBM Cloudant must be able to write its checkpoint documents at the \"read\" end of replication, otherwise no state is saved and replication cannot resume from where it stopped. If the state is not saved, it can lead to performance problems when replication of large data sets resumes. The reason is that without checkpoints, the replication process restarts from the beginning each time that it is resumed.\n\n\n\n\n\n Replication document is conflicted \n\nAnother consequence of setting user permissions incorrectly is that the _replicator document becomes conflicted. The _replicator document records the current state of the replication process. In an extreme case, the document can become huge because it contains many unresolved conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_00620-9537-11012","score":21.0330019323,"text":"\nHowever, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users. The _id of the sixth document becomes the startkey of your request for the next page of results.See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=6\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\nint pageSize = 5;\nPostAllDocsOptions.Builder docsOptionsBuilder =\nnew PostAllDocsOptions.Builder()\n.db(\"orders\")\n.limit(pageSize + 1); \/\/ Fetch pageSize + 1 documents\n\nAllDocsResult response =\nservice.postAllDocs(docsOptionsBuilder.build())\n.execute()\n.getResult();\n\nwhile (response.getRows().size() > 1) {\nList<DocsResultRow> responseDocuments = response.getRows();\n\/\/ on the last page, show all documents:\nif (responseDocuments.size() <= pageSize) {\nSystem.out.println(responseDocuments);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00485-1687-3253","score":20.199919051,"text":"\nFull-text search No No Yes, requires separate installer or container. Yes \n Partition queries No No Yes Yes \n Shard splitting No No Yes Available as tool for IBM Ops. \n Selector on changes feed No Yes Yes Yes \n Rate limits No No No User-defined [provisioned throughput capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioned-throughput-capacity) settings \n Request size 4 GB (default) 4 GB (default) 4 GB (default) 11 MB \n Attachment size 4 GB (default) 4 GB (default) 4 GB (default) 10 MB \n Security auth [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [IBM Cloudant legacy auth with API Keys](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization), [IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant), or [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) \n LDAP No No No No \n\n\n\nThe CouchDB _show, _list, _update, and _rewrite functions were deprecated in Apache CouchDB 3.0. For more information, see [deprecated feature warnings](https:\/\/docs.couchdb.org\/en\/stable\/whatsnew\/3.0.htmldeprecated-feature-warnings).\n\nAs a result, these functions are no longer supported for IBM Cloudant. They do not appear in IBM Cloudant documentation, and while the APIs currently remain in service, their use is not recommended. The IBM Cloudant Support team no longer supports them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-couchdb-and-cloudant"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03120-3469-5331","score":44.1124119935,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-1790-3940","score":43.0888136304,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_02839-3583-5403","score":42.9645990469,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03353-4-2000","score":41.4066423177,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03120-4-2233","score":41.1371665034,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-7-2335","score":39.4053059932,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03027-7-1946","score":39.1363791802,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03120-1659-3917","score":37.7222256555,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_07578-18457-20516","score":37.5788391682,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-18457-20516","score":37.5788391682,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2,"recall_5":0.2,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2139862647,"ndcg_cut_10":0.3209793971}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04111-12664-14293","score":33.0036106636,"text":"\nUpdate universal SSL setting PATCH \/v1\/{crn}\/zones\/{domain_id}\/ssl\/universal\/settings internet-svcs.security.update internet-svcs.universal-ssl-setting.update \n Get edge certificates ordered from CIS GET \/v1\/{crn}\/zones\/{domain_id}\/ssl\/certificate_packs internet-svcs.security.read internet-svcs.certificate-packs.read \n Order an edge certificate POST \/v1\/{crn}\/zones\/{domain_id}\/ssl\/certificate_packs internet-svcs.security.manage internet-svcs.certificate-packs.create \n Delete an edge certificate DELETE \/v1\/{crn}\/zones\/{domain_id}\/ssl\/certificate_packs\/{cert_id} internet-svcs.security.manage internet-svcs.certificate-packs.delete \n Get uploaded certificates GET \/v1\/{crn}\/zones\/{domain_id}\/custom_certificates internet-svcs.security.read internet-svcs.custom-certificates.read \n Upload a certificate to CIS edge POST \/v1\/{crn}\/zones\/{domain_id}\/custom_certificates internet-svcs.security.manage internet-svcs.custom-certificates.create \n Update the certificate uploaded to CIS edge PATCH \/v1\/{crn}\/zones\/{domain_id}\/custom_certificates\/{cert_id} internet-svcs.security.update internet-svcs.custom-certificates.update \n Delete a certificate uploaded to CIS edge DELETE \/v1\/{crn}\/zones\/{domain_id}\/custom_certificates\/{cert_id} internet-svcs.security.manage internet-svcs.custom-certificates.delete \n Get origin certificate issued by CIS GET \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates internet-svcs.security.read internet-svcs.origin-certificates.read \n Create an origin certificate issued by CIS POST \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates internet-svcs.security.manage internet-svcs.origin-certificates.create","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_05440-4287-5611","score":31.5615254175,"text":"\nIn Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).\n5. [Configure a global load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configure-glb) in CIS.\n6. [Enable the HTTP proxy mode for the load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-proxy-modes) in CIS. This activates DDoS protection on Layer 7 and other CIS security features.\n7. In Code Engine, turn off the public system provided domain mappings of your application. Go to your application, from the Domain mapping tab for your app, select No external system domain mapping.\n8. Click Create to save the application revision.\n\n\n\nFor more information about DDoS in CIS, see [Dealing with Distributed Denial of Service attacks in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts). For more ways to address Layer 7 attacks, see [Mitigating Layer 7 attacks in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-ciscis-mitigate-layer7-attacks).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"},{"document_id":"ibmcld_05353-18865-20445","score":30.9364073431,"text":"\nTo obtain the CNAME record with the CLI, use the [ibmcloud ce domainmapping get](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-domainmapping-get) command. For example,\n\nibmcloud ce domainmapping get --domain-name www.example.com\n\nExample output\n\nGetting domain mapping 'www.example.com'...\nOK\n\nDomain Name: www.example.com\nCNAME: custom.abcdabcdabc.us-south.codeengine.appdomain.cloud\nTarget Name: myapp\nTarget Type: app\nTLS Secret: mytlssecret\nStatus: ready\n\nAfter you have the CNAME target, you are ready to add the CNAME record entry to the DNS settings of your custom domain. Note that publishing of the CNAME record with the domain registrar can take some time to populate the DNS changes in the internet.\n\n\n\n\n\n How can I use Cloud Internet Services (CIS) with custom domain mapping? \n\nYou cannot use the CIS TLS encryption mode of End-to-End flexible with Code Engine custom domain mappings because this mode uses self-signed certificates that are not allowed. Instead, you can use the default TLS encryption mode of [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed). If you use the CIS TLS mode of End-to-End-flexible, you can switch to use the CIS TLS End-to-End CA signed mode, and obtain a CA signed certificate that is created outside of Cloud Internet Services (CIS).\n\n\n\n1. Create the TLS\/SSL certificate outside of CIS. See [How can I obtain a certificate for my custom domain?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain-cert)\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings"},{"document_id":"ibmcld_05440-3062-4677","score":30.390997515,"text":"\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"},{"document_id":"ibmcld_04186-9163-11063","score":30.2462567875,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_04111-13789-15438","score":29.9135748064,"text":"\nDelete a certificate uploaded to CIS edge DELETE \/v1\/{crn}\/zones\/{domain_id}\/custom_certificates\/{cert_id} internet-svcs.security.manage internet-svcs.custom-certificates.delete \n Get origin certificate issued by CIS GET \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates internet-svcs.security.read internet-svcs.origin-certificates.read \n Create an origin certificate issued by CIS POST \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates internet-svcs.security.manage internet-svcs.origin-certificates.create \n Revoke an origin certificate issued by CIS DELETE \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates\/{cert_id} internet-svcs.security.manage internet-svcs.origin-certificates.delete \n\n\n\n\n\n\n\n Edge Functions \n\n\n\nTable 15. Edge Functions\n\n Action Method IAM ACTION AT ACTION \n\n Get edge function scripts GET \/v1\/{crn}\/workers\/scripts internet-svcs.performance.read internet-svcs.edge-functions-scripts.read \n Create edge function script POST \/v1\/{crn}\/workers\/scripts internet-svcs.performance.manage internet-svcs.edge-functions-scripts.create \n Update edge function script PUT \/v1\/{crn}\/workers\/scripts\/{script_name} internet-svcs.performance.update internet-svcs.edge-functions-scripts.update \n Delete edge function script DELETE \/v1\/{crn}\/workers\/scripts\/{script_name} internet-svcs.performance.manage internet-svcs.edge-functions-scripts.delete \n Get edge function routes GET \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes internet-svcs.performance.read internet-svcs.edge-functions-routes.read \n Create edge function route POST \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes internet-svcs.performance.manage internet-svcs.edge-functions-routes.create","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_05351-7-1916","score":29.8347069236,"text":"\nConfiguring a highly available application \n\nYou can deploy your IBM Cloud\u00ae Code Engine application across multiple regions to make it resilient to regional failures. Note that this example uses [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started), but you can use alternate providers. This example also uses a custom domain.\n\n\n\n Prerequisites \n\n\n\n* You must have a custom domain name for your application, such as example.com. This domain name is used by your Code Engine application.\n* Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services).\n* [Add your domain name to Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedadd-configure-your-domain). When you register your domain name with Cloud Internet Services (CIS), you are delegating control of your domain name to Cloud Internet Services (CIS). Note that this step can take a while to complete.\n\n\n\n\n\n\n\n Step 1: Create projects in different regions \n\nCreate a Code Engine project in three different regions. You can use a common naming pattern and a shared tag.\n\nFor example, create a project called global-app-project in the au-syd, eu-de, and br-sao regions with either the CLI or from the console.\n\n\n\nTable 1. Projects in multiple regions\n\n Name Status Tag Location Resource group Created \n\n global-app-project Ready global-app Sydney (au-syd) default \n global-app-project Ready global-app Frankfurt (eu-de) default 2 min \n global-app-project Ready global-app Sao Paulo (br-sao) default 3 min \n\n\n\nFor more information, see [Managing projects](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-project).\n\n\n\n\n\n Step 2: Deploy your apps in multiple regions \n\nNow that your projects are created in multiple regions, deploy your application in each project.\n\nFor example, deploy the codeengine\/helloworld app.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-multiple-regions"},{"document_id":"ibmcld_01391-9188-11098","score":29.7769976633,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_13139-9571-11542","score":29.6618918879,"text":"\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.\n\nWhen the domain's status on the Overview page changes from Pending to Active, you can use the dig <your_domain_name> ns command to verify that the new name servers have taken effect.\n\n\n\n\n\n\n\n Configure Health Check for the Global Load Balancer \n\nHealth Checks monitor responses to HTTP\/HTTPS requests from origin pools on a set interval. They are used with origin pools to determine if the pools are still running properly.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_13234-11167-13184","score":29.6448590081,"text":"\nCIS provides Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the IP addresses or hostnames of the VPC load balancers,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the VPC load balancers.\n\n\n\n\n\n Add a custom domain to IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next.\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. At this point you can click on Cancel to get back to the main page, after you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.\n\nWhen the domain's status on the Overview page changes from Pending to Active, you can use the dig <your_domain_name> ns command to verify that the new name servers have taken effect.\n\n\n\n\n\n\n\n Configure Health Check for the Global Load Balancer \n\nA health check helps gain insight into the availability of pools so that traffic can be routed to the healthy ones. These checks periodically send HTTP\/HTTPS requests and monitor the responses.\n\n\n\n1. In the IBM Cloud Internet Services dashboard, navigate to Reliability > Global Load Balancers.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09118-10321-12086","score":37.9393027876,"text":"\n[View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09118-9294-10691","score":31.359752233,"text":"\n[Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Tone Analyzer](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Watson OpenScale](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09906-1621-3194","score":30.6950828948,"text":"\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"url\": \"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"url\":\"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_13074-16820-18514","score":30.2696230099,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_09919-7713-9881","score":29.8545516469,"text":"\n: Version 2 entity type support is now available, for all public and premium service instances, for the following languages: Russian and Swedish. For details, see [Entity type systems](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems).\n\n\n\n\n\n 3 August 2022 \n\nSupport for Single Label Classifications\n: Classifications now allows users to pass in a model_type training parameter when creating or updating a model, in order to train a single label classifier. See [Classifications training parameters](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classificationsclassification-training-parameters) for more details.\n\n\n\n\n\n 11 July 2022 \n\nImproved [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) model - Japanese\n: Japanese custom classifications models now train and perform inference faster, with improved model results.\n\nImproved [custom categories](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories) model\n: Model contains improved word filtering, resulting in better category determination.\n\n\n\n\n\n 7 April 2022 \n\nCategories bug fix\n: Fixed a bug in the Version 2 Categories type system.\n\n\n\n\n\n 14 February 2022 \n\nEmotion support\n: Support for emotion is now available, for all public service instances, for French. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\nImproved error handling and validation for emotion\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_09892-7-1976","score":29.7383319762,"text":"\nAbout \n\nWith IBM Watson\u00ae Natural Language Understanding, developers can analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment.\n\n\n\n Features \n\nSend requests to the API with text, HTML, or a public URL, and specify one or more of the following features to analyze:\n\n\n\n Categories \n\nCategorize your content using a five-level classification hierarchy. View the complete list of categories [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy). For example:\n\nInput\n\n> url: \"www.cnn.com\"\n\nResponse\n\n> \/news\n> \/art and entertainment\n> \/movies and tv\/television\n> \/news\n> \/international news\n\n\n\n\n\n Concepts \n\nIdentify high-level concepts that aren't necessarily directly referenced in the text. For example:\n\nInput\n\n> text: \"Natural Language Understanding uses natural language processing to analyze text.\"\n\nResponse\n\n> Linguistics\n> Natural language processing\n> Natural language understanding\n\n\n\n\n\n Emotion \n\nAnalyze emotion conveyed by specific target phrases or by the document as a whole. You can also enable emotion analysis for entities and keywords that are automatically detected by the service. For example:\n\nInput\n\n> text: \"I love apples, but I hate oranges.\"\n> targets: \"apples\", and \"oranges\"\n\nResponse\n\n> \"apples\": joy\n> \"oranges\": anger\n\n\n\n\n\n Entities \n\nFind people, places, events, and other types of entities mentioned in your content. View the complete list of entity types and subtypes [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems). For example:\n\nInput\n\n> text: \"IBM is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries.\"\n\nResponse\n\n> IBM: Company\n> Armonk: Location\n> New York: Location\n> United States: Location\n\n\n\n\n\n Keywords","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about"},{"document_id":"ibmcld_07140-17709-19868","score":29.1388046143,"text":"\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations. Optionally, a Knowledge Studio custom model can be specified to extract custom entities.\n\n\n\n* \"sentiment\" : boolean - optional - When true, sentiment analysis is performed on the extracted entity in the context of the surrounding content.\n* \"emotion\" : boolean - optional - When true, emotional tone analysis is performed on the extracted entity in the context of the surrounding content.\n* \"limit\" : INT - optional - The maximum number of entities to extract from the ingested document. The default is 50.\n* \"mentions\": boolean - optional - When true, the number of times that this entity is mentioned is recorded. The default is false.\n* \"mention_types\": boolean - optional - When true, the mention type for each mention of this entity is stored. The default is false.\n* \"sentence_location\": boolean - optional - When true, the sentence location of each entity mention is stored. The default is false.\n* \"model\" : string - optional - When specified, the custom model is used to extract entities instead of the public model. This option requires a Knowledge Studio custom model to be associated with your instance of Discovery. See [Integrating with Watson Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks) for more information.\n\n\n\n\n\n\n\n keywords \n\nThe keywords enrichment extracts instances of significant words within the text. To understand the difference between keywords, concepts, and entities, see [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_07140-13434-14787","score":28.8238246146,"text":"\nIf the destination_field already exists a new instance of the destination_field is created.\n* merge - the contents of the source_field and the destination_field are merged into the destination_field.\n* remove_nulls - fields with null content are removed.\n\n\n\n* \"source_field\": string - optional - the field that the operation is performed on.\n* \"destination_field\": string - optional - the destination field the the operation is output to.\n\nField names defined in your configuration must meet the restrictions defined in [Field Name Requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configreffield_reqs).\n\n\n\n\n\n\n\n\n\n\n\n Enrichments \n\n\"enrichments\": [\n{\n\"enrichment\": \"elements\",\n\"source_field\": \"html\",\n\"destination_field\": \"enriched_html\",\n\"options\": {\n\"model\": \"contract\"\n}\n},\n{\n\"enrichment\": \"natural_language_understanding\",\n\"source_field\": \"title\",\n\"destination_field\": \"enriched_title\",\n\"options\": {\n\"features\": {\n\"keywords\": {\n\"sentiment\": true,\n\"emotion\": false,\n\"limit\": 50\n},\n\"entities\": {\n\"sentiment\": true,\n\"emotion\": false,\n\"limit\": 50,\n\"mentions\": true,\n\"mention_types\": true,\n\"sentence_locations\": true,\n\"model\": \"WKS-model-id\"\n},\n\"sentiment\": {\n\"document\": true,\n\"targets\":\n\"IBM\",\n\"Watson\"\n]\n\n},\n\"emotion\": {\n\"document\": true,\n\"targets\":\n\"IBM\",\n\"Watson\"\n]\n},\n\"categories\": {},\n\"concepts\": {\n\"limit\": 8\n},\n\"semantic_roles\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_09906-2727-4077","score":28.691050815,"text":"\nThe targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"text\": \"I love apples! I do not like oranges.\",\n\"features\": {\n\"sentiment\": {\n\"targets\": [\n\"apples\",\n\"oranges\",\n\"broccoli\"\n]\n},\n\"keywords\": {\n\"emotion\": true\n}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\nShow more\n\nRunnable command for Windows users:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"text\":\"I love apples! I do not like oranges.\",\"features\":{\"sentiment\":{\"targets\":[\"apples\",\"oranges\",\"broccoli\"]},\"keywords\":{\"emotion\":true}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\n\n\n\n\n Next steps \n\n\n\n* View the [API reference](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understanding).\n* Learn how to identify [custom entities and relations](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_09921-1508-2973","score":28.3781094175,"text":"\nsatisfied An affective response to perceived service quality \n sympathetic An affective mode of understanding that involves emotional resonance \n\n\n\n\n\n* Example response:\n\n{\n\"usage\": {\n\"text_units\": 1,\n\"text_characters\": 60,\n\"features\": 1\n},\n\"language\": \"en\",\n\"classifications\": [\n{\n\"confidence\": 0.564849,\n\"class_name\": \"excited\"\n},\n{\n\"confidence\": 0.355816,\n\"class_name\": \"satisfied\"\n},\n{\n\"confidence\": 0.126127,\n\"class_name\": \"polite\"\n},\n{\n\"confidence\": 0.026995,\n\"class_name\": \"sympathetic\"\n},\n{\n\"confidence\": 0.012211,\n\"class_name\": \"frustrated\"\n},\n{\n\"confidence\": 0.011065,\n\"class_name\": \"sad\"\n},\n{\n\"confidence\": 0.000872,\n\"class_name\": \"impolite\"\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n Migrating from Watson Tone Analyzer Customer Engagement endpoint to Natural Language Understanding \n\nYou can migrate your [Watson Tone Analyzer customer-engagement](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-utco) analysis requests to Natural Language Understanding. This can help you better understand your interactions with customers and improve your communications generally, or for specific customers.\n\n\n\n Reformatting your input data \n\nIn Watson Tone Analyzer, you pass the \/v3\/tone_chat method a JSON ToneChatInput object consisting of utterances, text, and an optional user string fields. For Natural Language Understanding, you pass a JSON object that contains text to be analyzed, and a language-specific model classification ID, to the \/v1\/analyze method.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3585335885}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-1255-3053","score":22.6321940133,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4-1684","score":20.4778019579,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":20.4613201496,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":20.0475644791,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-6973-8664","score":19.7494015513,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-4-1966","score":19.4706284247,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-1334-3188","score":19.3682151216,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":19.1550091528,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08988-22772-24349","score":19.0345900826,"text":"\nDeleting a key that has a dual authorization policy requires an authorization from two users.\n\nFor more information, see [deleting keys using dual authorization](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys) and [setting dual authorization policies for keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n Notes \n\nDual authorization delete for an instance is different than dual authorization delete for keys.\n\nOnce you enable dual-auth-delete for a key you cannot disable it or remove it. You must wait 7 days for the policy to expire.\n\nDual authorization delete for an instance can be enabled or disabled anytime.\n\nIf a key has a dual-auth-delete policy, changing the instance policy does not change any existing key policies.\n\nWhen you change the instance policy, new keys are enforced with the instance policy.\n\nibmcloud kp instance policy-update dual-auth-delete\n-i, --instance-id INSTANCE_ID\n-d, --disable OR\n-e, --enable\n\n\n\n\n\n Examples \n\nThese are examples of kp instance policy-update dual-auth-delete.\n\n\n\n Example 1 \n\nThis example enables the dual authorization delete policy.\n\n enable the instance dual authorization policy\n$ ibmcloud kp instance policy-update dual-auth-delete --enable\n\nUpdating instance policy...\nOK\n\n list the instance policies\n$ ibmcloud kp instance policies --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T18:45:14Z\",\n\"lastUpdated\": \"2020-06-22T18:45:14Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"policy_type\": \"dualAuthDelete\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09120-22053-23574","score":18.9515281307,"text":"\nFor more information, see [deleting keys using dual authorization](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys) and [setting dual authorization policies for keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n Notes \n\nDual authorization delete for an instance is different than dual authorization delete for keys.\n\nOnce you enable dual-auth-delete for a key you cannot disable it or remove it. You must wait 7 days for the policy to expire.\n\nDual authorization delete for an instance can be enabled or disabled anytime.\n\nIf a key has a dual-auth-delete policy, changing the instance policy does not change any existing key policies.\n\nWhen you change the instance policy, new keys are enforced with the instance policy.\n\nibmcloud kp instance policy-update dual-auth-delete\n-i, --instance-id INSTANCE_ID\n-d, --disable OR\n-e, --enable\n\n\n\n\n\n Examples \n\nThese are examples of kp instance policy-update dual-auth-delete.\n\n\n\n Example 1 \n\nThis example enables the dual authorization delete policy.\n\n enable the instance dual authorization policy\n$ ibmcloud kp instance policy-update dual-auth-delete --enable\n\nUpdating instance policy...\nOK\n\n list the instance policies\n$ ibmcloud kp instance policies --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T18:45:14Z\",\n\"lastUpdated\": \"2020-06-22T18:45:14Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"policy_type\": \"dualAuthDelete\",\n\"policy_data\": { \"enabled\": true\n}\n}\n]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10041-7462-8947","score":15.1780952423,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-7444-8929","score":15.1780952423,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-37096-38624","score":15.0021689599,"text":"\nGET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/workerpools\/{poolidOrName} Resize or rebalance a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.update \n PATCH\/v1\/clusters\/{idOrName}\/workerpools\/{poolidOrName}\/zones\/{zoneid} Updates network configuration for a worker pool for a given zone. containers-kubernetes.cluster.operate containers-kubernetes.zone.update \n POST\/v1\/clusters\/{idOrName}\/workerpools Create a worker pool for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.create \n POST\/v1\/clusters\/{idOrName}\/workerpools\/{poolidOrName}\/zones Add a zone to the specified worker pool for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.create \n POST\/v1\/clusters\/{idOrName}\/workers Add worker nodes to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.worker.create \n POST\/v2\/rebalanceWorkerPool Rebalance workers in a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/removeWorker Delete a worker node from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/removeWorkerPool Removes a worker pool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-37062-38590","score":15.0021689599,"text":"\nGET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/workerpools\/{poolidOrName} Resize or rebalance a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.update \n PATCH\/v1\/clusters\/{idOrName}\/workerpools\/{poolidOrName}\/zones\/{zoneid} Updates network configuration for a worker pool for a given zone. containers-kubernetes.cluster.operate containers-kubernetes.zone.update \n POST\/v1\/clusters\/{idOrName}\/workerpools Create a worker pool for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.create \n POST\/v1\/clusters\/{idOrName}\/workerpools\/{poolidOrName}\/zones Add a zone to the specified worker pool for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.create \n POST\/v1\/clusters\/{idOrName}\/workers Add worker nodes to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.worker.create \n POST\/v2\/rebalanceWorkerPool Rebalance workers in a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/removeWorker Delete a worker node from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/removeWorkerPool Removes a worker pool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-38301-39909","score":14.8079423329,"text":"\nPOST\/v2\/rebalanceWorkerPool Rebalance workers in a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/removeWorker Delete a worker node from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/removeWorkerPool Removes a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/resizeWorkerPool Resize an existing worker pool. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.update \n POST\/v2\/setWorkerPoolLabels Set custom labels for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/setWorkerPoolTaints Set custom taints for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/vpc\/createWorkerPool Create a worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/createWorkerPoolZone Create a zone in the specified worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n PUT\/v1\/clusters\/{idOrName}\/workers\/{workerId} Reboot, reload, or update a worker node for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.worker.update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-38267-39875","score":14.8079423329,"text":"\nPOST\/v2\/rebalanceWorkerPool Rebalance workers in a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/removeWorker Delete a worker node from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/removeWorkerPool Removes a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/resizeWorkerPool Resize an existing worker pool. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.update \n POST\/v2\/setWorkerPoolLabels Set custom labels for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/setWorkerPoolTaints Set custom taints for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/vpc\/createWorkerPool Create a worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/createWorkerPoolZone Create a zone in the specified worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n PUT\/v1\/clusters\/{idOrName}\/workers\/{workerId} Reboot, reload, or update a worker node for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.worker.update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-35993-37421","score":14.6779056516,"text":"\nGET\/v1\/clusters\/{idOrName}\/workers\/{workerId} View details of a worker node. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorker View details of a worker node for classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPool View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPools View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkers View all workers for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorker View details of a worker node for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPool View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPools View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkers View all workers for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorker View details of a worker node for VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-35959-37387","score":14.6779056516,"text":"\nGET\/v1\/clusters\/{idOrName}\/workers\/{workerId} View details of a worker node. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorker View details of a worker node for classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPool View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPools View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkers View all workers for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorker View details of a worker node for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPool View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPools View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkers View all workers for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorker View details of a worker node for VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-17616-19200","score":14.4820514387,"text":"\nPOST\/v2\/alb\/updateAlb Update ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb.update \n POST\/v2\/alb\/vpc\/createAlb Create a public or private ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/vpc\/disableAlb Disable an ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.delete \n POST\/v2\/alb\/vpc\/enableAlb Enable an existing ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.enable \n PUT\/v1\/alb\/albsecrets Update an ALB secret that you imported from Secrets Manager. containers-kubernetes.cluster.create cluster-ingress-secret.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/update Force a one-time update of all ALB pods to the latest build. containers-kubernetes.cluster.update cluster-alb.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Enable or disable automatic updates for the Ingress ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb-policy.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updaterollback Roll back all ALB pods in a cluster to their previously running build. containers-kubernetes.cluster.update cluster-alb-policy.update \n\n\n\n\n\n\n\n Ingress load balancer \n\n\n\nIngress load balancer API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n GET\/ingress\/v2\/load-balancer\/configuration Get the configuration of load balancers for Ingress ALBs. containers-kubernetes.cluster.read N\/A \n PATCH\/ingress\/v2\/load-balancer\/configuration Update the configuration of load balancers for Ingress ALBs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-17596-19180","score":14.4820514387,"text":"\nPOST\/v2\/alb\/updateAlb Update ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb.update \n POST\/v2\/alb\/vpc\/createAlb Create a public or private ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/vpc\/disableAlb Disable an ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.delete \n POST\/v2\/alb\/vpc\/enableAlb Enable an existing ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.enable \n PUT\/v1\/alb\/albsecrets Update an ALB secret that you imported from Secrets Manager. containers-kubernetes.cluster.create cluster-ingress-secret.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/update Force a one-time update of all ALB pods to the latest build. containers-kubernetes.cluster.update cluster-alb.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Enable or disable automatic updates for the Ingress ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb-policy.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updaterollback Roll back all ALB pods in a cluster to their previously running build. containers-kubernetes.cluster.update cluster-alb-policy.update \n\n\n\n\n\n\n\n Ingress load balancer \n\n\n\nIngress load balancer API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n GET\/ingress\/v2\/load-balancer\/configuration Get the configuration of load balancers for Ingress ALBs. containers-kubernetes.cluster.read N\/A \n PATCH\/ingress\/v2\/load-balancer\/configuration Update the configuration of load balancers for Ingress ALBs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":65.0093511856,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04175-0-1274","score":58.0362776763,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-3403-5572","score":49.6262538766,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04168-6066-7283","score":41.1672541646,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04127-7-2300","score":39.5862320674,"text":"\nLearning about CIS architecture and workload isolation \n\nReview the following sample architecture for IBM Cloud\u00ae Internet Services, and learn about different isolation levels so that you can choose the solution that best meets the requirements of the workloads that you want to run in the cloud.\n\n\n\n CIS architecture and workload isolation \n\nCloud Internet Services (CIS) is a public, global, multitenant service offered in partnership with Cloudflare. It offers DNS name resolution, global load balancing, and security and CDN services, for zones or domains delegated to this service.\n\nIn the control plane, you can configure your zone and the services that are applied to traffic to your site via UI, CLI, or API. All access authorization and authentication to your zone or domain is managed through Identity and Access Management (IAM) access policies.\n\nAll configuration requests eventually reach the multitenant Cloud Internet Services (CIS) control plane on IBM Cloud\u00ae as API calls to an SSL-secured API endpoint. The control plane interacts with the platform IAM service to authenticate the user and authorize the action. The original request targets the customer's Cloud Internet Services (CIS) instance. Each Cloud Internet Services (CIS) instance is uniquely mapped to an anonymized subaccount in Cloudflare's system. The request is converted to a Cloudflare API request that targets the subaccount and is delivered via HTTPS to the Cloudflare API endpoint. Zones and domains from different customers are isolated and maintained in separate subaccounts within the Cloud Internet Services (CIS) account at Cloudflare. Access to the account at Cloudflare is strictly controlled and limited. Access to the Cloud Internet Services (CIS) control plane infrastructure is also strictly controlled and limited to essential maintenance personnel only.\n\nData that is stored at Cloudflare is encrypted except when it is required to be publicly accessible, for example, in the case of DNS records, the control plane is separate from the data plane.\n\nThe data plane for your site is handled exclusively by Cloudflare. All proxied traffic is resolved to an IP address owned by Cloudflare and routed through Cloudflare's Anycast network to the nearest data center capable of processing the request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation"},{"document_id":"ibmcld_04136-7-2226","score":37.3297289455,"text":"\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_04111-35313-36062","score":35.9037971512,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04170-7-2189","score":35.6584801165,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-34153-35639","score":34.7480171118,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04146-2946-5057","score":34.6734298595,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":52.3799065091,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":50.1605284039,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-43319-44485","score":49.7496908545,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":45.0487977267,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":44.4349274483,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":42.6561565583,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-15747-17355","score":35.1394186795,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-14062-16080","score":34.7089090973,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_12332-1034-2510","score":32.5087718738,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-2884-4620","score":29.0927655507,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.8529278651,"ndcg_cut_10":0.8529278651}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":30.4308101173,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16291-1353-3298","score":28.3121793414,"text":"\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_03179-4-1759","score":27.8722760048,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16280-3111-5196","score":27.6756404123,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_03158-4-2042","score":27.3903033365,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nBy adding the phone integration to your assistant, you can make your assistant available to customers over the phone.\n\nWhen you add the phone integration to your assistant, you can automatically generate a working phone number that is automatically connected to your assistant. Or, if you prefer, you can connect the assistant to your existing infrastructure by configuring an existing Session Initiation Protocol (SIP) trunk.\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX). If you choose to generate a free phone number for your assistant, a SIP trunk is automatically provisioned from IntelePeer. You can also choose to use an existing SIP trunk from a provider such as IntelePeer, Genesys, or Twilio.\n\nGenerating a free phone number is available only with new phone integrations. If you have an existing phone integration and you want to switch to a free phone number, you must delete the existing integration and create a new one.\n\nWhen your customer makes a phone call using the telephone number connected to your assistant, the phone integration answers. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service. The audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-2940-4987","score":26.7944501007,"text":"\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03165-4477-6547","score":26.7920620586,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16297-7-1893","score":26.7394666448,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_16288-7-2218","score":26.677516266,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16291-7-1781","score":26.5034341117,"text":"\nIntegrating with phone and NICE CXone contact center ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nConnect your assistant to a NICE CXone contact center with live agents.\n\nTransfer customers from a chat with your assistant to live agents who can help them by phone. If customers ask to speak to someone, your assistant can forward them directly to customer support with the conversation history.\n\nThis integration creates a connection between your assistant and a contact center using NICE CXone.\n\nYou need a Plus or Enterprise Plan to use this feature.\n\n\n\n Before you begin \n\nYou must have a NICE CXone account and phone numbers allocated for this integration.\n\n\n\n1. Go to the [NICE website](https:\/\/www.nice.com\/).\n2. Create an account.\n3. Follow the instructions to get phone numbers or select existing phone numbers.\n\n\n\n\n\n\n\n Generate NICE CXone access keys \n\nAccess keys are used for authentication and consist of two parts: an access key ID and a secret access key.\n\nTo generate NICE CXone access keys to use with your assistant:\n\n\n\n1. Log in to the NICE CXone console.\n2. Click the app selector ![appselectoricon.png](https:\/\/help.nice-incontact.com\/content\/resources\/images\/icons\/appselectoricon.png) and select Admin.\n3. Click Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":46.1689654174,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-7-2072","score":45.4056359553,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03080-7-1901","score":44.8988579577,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16365-12876-14604","score":43.9727547268,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03166-4-2012","score":43.7781371452,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16326-1697-3495","score":43.6748837046,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_03421-4-1877","score":43.4948467456,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-1365-2938","score":42.7557975352,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-7-2041","score":42.6862120937,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16365-11574-13329","score":42.4617773317,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.7977228895}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":15.9736888673,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12498-9696-11699","score":14.7706064455,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":13.8283721669,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_00894-7096-9156","score":13.4389024572,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12960-7096-9156","score":13.4389024572,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12717-7818-8740","score":13.200128825,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_12467-1716-3849","score":12.7890163867,"text":"\n* When you try to modify or delete a secret while it is locked, Secrets Manager denies the request with an HTTP 412 Precondition Failed response. You see an error message similar to the following example:\n\nThe requested action can't be completed because the secret version is locked.\n\nIf you're working with\n\ndynamic secrets, such as IAM credentials, locking your secrets also means that by default, those secrets can't be read or accessed. For more information, see [Why can't I read a locked IAM credentials secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-iam-credentials)\n* If a locked secret reaches its expiration date, it stays in the Active state and its data remains accessible to your applications. Secrets Manager moves the secret to the Destroyed state and permanently deletes the expired secret data only after all locks on the secret are removed.\n\nSSL\/TLS certificates still reach their defined expiration dates and move into a Destroyed state even if they are locked. For more information, see [Why did my locked certificate move to the Destroyed state?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-certificates)\n* If you try to rotate a secret while its current version is locked and the previous version is unlocked (or if an automatic rotation is scheduled), the request to rotate the secret is allowed. The current secret version becomes the new previous version, retaining its existing locks. A new current version is created without any locks.\n* If you try to rotate a secret while its previous version is locked (or if an automatic rotation is scheduled), your request to rotate the secret is denied. Rotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_12447-1578-3681","score":12.355249558,"text":"\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12493-27359-28981","score":12.3490693607,"text":"\nPrerequisites \n\nYou need the [Writer service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to rotate secrets.\n\n\n\n\n\n Command options \n\npayload\n: The new data to store for an arbitrary secret. Only text-based payloads are supported. If you need to store a binary file, be sure to base64 encode it before you save it to Secrets Manager. For more information, see [Examples](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-static-secret-examples).\n\npassword\n: The new password to assign to a username_password secret.\n\ncertificate\n: The new certificate data to store for an imported_cert secret. Supported file type is .pem.\n\nprivate_key\n: The new private key data to store for an imported_cert secret. Supported file type is .pem.\n\nintermediate\n: The new intermediate certificate data to store for an imported_cert secret. Supported file type is .pem.\n\n-format\n: Prints the output in the format that you specify. Valid formats are table, json, and yaml. The default is table. You can also set the output format by using the VAULT_FORMAT environment variable.\n\n-force\n: Replaces the password that is stored for a username_password secret with a randomly generated, 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\n\n\n\n\n Examples \n\nManually rotate the secret data that is stored for an arbitrary secret.\n\nvault write -format=json ibmcloud\/arbitrary\/secrets\/fe874c2b-e8fd-bbb6-9f19-e91bbe744735\/rotate payload=\"Updated secret data.\"\n\nManually rotate the password that is stored for a username_password secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_07578-1215486-1217535","score":12.3399637704,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.5205067333}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03126-3707-6008","score":30.0830828379,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03118-1768-3298","score":28.2663369912,"text":"\n(Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes. If you use the v1 \/message method, you must implement your own state management, and you cannot take advantage of versioning or any of the other features of an assistant.\n\n\n\n\n\n Authoring applications \n\nThe v1 API provides methods that enable an application to create or modify dialog skills, as an alternative to building a skill graphically using the Watson Assistant user interface. An authoring application uses the API to create and modify skills, intents, entities, dialog nodes, and other artifacts that make up a dialog skill. For more information, see the [v1 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1).\n\nNote: The v1 authoring methods create and modify workspaces rather than skills. A workspace is a container for the dialog and training data (such as intents and entities) within a dialog skill. If you create a new workspace using the API, it will appear as a new dialog skill in the Watson Assistant user interface.\n\nFor a list of the available API methods, see [API methods summary](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-methods).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_03293-18722-20426","score":28.1098123533,"text":"\nAnnotation-based entites are those for which you annotate occurrences of the entity in sample sentences to teach your assistant about the context in which the entity is typically used.\n\nIn order to train a contextual entity model, you can take advantage of your intent examples, which provide readily-available sentences to annotate.\n\nThis feature is generally available in English-language dialog skills and is available as a beta feature in French-langage dialog skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1. From your dialog skill, click the Intents tab.\n2. Click an intent to open it.\n\nFor this example, the intent buy_supplies defines the order function for an online retailer.\n\n![Select the #buy_supplies intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oe-intent.png)\n3. Click Annotate entities, and then review the intent examples for potential entity mentions.\n\n![Shows the Annotate entities toggle](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oe-annotate.png)\n4. Click any word, words, or punctuation that is part of a single entity mention from the intent examples.\n\nIn this example, mobile phones is the entity mention.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities"},{"document_id":"ibmcld_16364-67629-69709","score":28.0248763277,"text":"\n: We have added step-by-step documentation for connecting to [Genesys](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled. (For more information about the enhanced intent recognition model, and how to determine whether it is enabled, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).)\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message. It shows you the confidence score of top three possible action when the input triggers an action. You can also follow the step in the action editor along with the conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-31953-34073","score":27.924899491,"text":"\nDeploy your assistant on the phone in minutes\n: We have partnered with [IntelePeer](https:\/\/intelepeer.com\/) to enable you to generate a phone number for free within the phone integration. Simply choose to generate a free number when following the prompts to create a phone integration, finish the setup, and a number is assigned to your assistant. These numbers are robust and ready for production.\n\nConnect to your existing service desks\n: We have added step-by-step documentation for connecting to [Genesys](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled.\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_02970-17020-19106","score":27.540307607,"text":"\nYou can also define an English entity value\/synonym, and fuzzy matching will match only your defined entity value\/synonym. For example, fuzzy matching may match the term unsure with insurance; but if you have unsure defined as a value\/synonym for an entity like @option, then unsure will always be matched to @option, and not to insurance.\n\nYour fuzzy matching setting has no impact on synonym recommendations. Even if fuzzy matching is enabled, synonyms are suggested for the exact value you specify only, not the value and slight variations of the value.\n\nTo understand how fuzzy matching and autocorrection are related to one another, see the [autocorrection documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-checkdialog-runtime-spell-check-vs-fuzzy-matching).\n\n\n\n\n\n\n\n Adding contextual entities \n\nIf you are using version 1.3 of the product, see [Adding contextual entities in v1.3](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based-v130) instead. The way you annotate entity mentions changed between releases.\n\nAnnotation-based entites are those for which you annotate occurrences of the entity in sample sentences to teach your assistant about the context in which the entity is typically used.\n\nIn order to train a contextual entity model, you can take advantage of your intent examples, which provide readily-available sentences to annotate.\n\nThis feature is generally available in English-language dialog skills and is available as a beta feature in French-langage dialog skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities"},{"document_id":"ibmcld_03054-18427-20301","score":27.2386522126,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03118-4-2208","score":26.9714758106,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_16364-82764-84754","score":26.9026443676,"text":"\n* For a Phone integration, if you connect to existing speech service instances, make sure those speech services use credentials that were generated with the latest endpoint syntax (a URL that starts with https:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/).\n* For a search skill, if you connect to an existing Discovery service instance, make sure the Discovery service uses credentials that were generated with the supported syntax (a URL that starts with https:\/\/api.{location}.discovery.watson.cloud.ibm.com\/).\n* If you are using [Jupyter notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs) to do advanced analytics, check your Jupyter notebook files to make sure they don't specify URLs with the old watsonplatform.net syntax. If so, update your files.\n* No action is required for the following integration types:\n\n\n\n* Intercom\n* SMS with Twilio\n* WhatsApp with Twilio\n* Zendesk service desk connection from web chat\n\n\n\n\n\n\n\n\n\n 23 March 2021 \n\nActions skill improvement\n: Actions have a new toolbar making it easier to send feedback, access settings, save, and close.\n\n\n\n\n\n 17 March 2021 \n\nChannel transfer response type\n: Dialog skills now include a channel transfer response type. If your assistant uses multiple integrations to support different channels for interaction with users, there might be some situations when a customer begins a conversation in one channel but then needs to transfer to a different channel. The most common such situation is transferring a conversation to the web chat integration, to take advantage of web chat features such as service desk integration. For more information, see [Adding a Channel transfer response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-channel-transfer).\n\nIntercom and WhatsApp integrations now available in Lite plan\n: The integrations for Intercom and WhatsApp are now available in the Lite plan for Watson Assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03383-17365-19519","score":26.8338713873,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10261-4065-5659","score":12.781256129,"text":"\nreplicas: <number_of_replicas>\nselector:\nmatchLabels:\napp: <app_name>\ntemplate:\nmetadata:\nlabels:\napp: <app_name>\nspec:\ncontainers:\n- name: <app_name>\nimage: <region>.icr.io\/<project>\/<image>:<tag>\nShow more\n\n<deployment>\n: Give your deployment a name.\n\n<number_of_replicas>\n: Enter the number of replica pods that the deployment creates.\n\napp: <app_name>\n: Use the name of your app as a label for the container.\n\nname: <app_name>\n: Give your container a name, such as the name of your app label.\n\nimage: <region>.icr.io\/project>\/image>:tag>\n: Replace the image URL variables with the information for your image:\n: region>: The regional IBM Cloud Container Registry API endpoint for the registry domain. To list the domain for the region that you are logged in to, run ibmcloud cr api.\n: namespace>: The registry namespace. To get your namespace information, run ibmcloud cr namespace-list.\n: image>:tag>: The image and tag that you want to use for your container. To list the images that are available in your registry namespace, run ibmcloud cr images.\n3. Create the deployment in your cluster.\n\noc apply -f <deployment>.yaml\n\n\n\n\n\n\n\n Deploying containers from an encrypted image \n\nDeploy containers from an encrypted image to your cluster by using the Image Key Synchronizer cluster add-on.\n\nIn clusters that run Red Hat OpenShift 4.5 or later, [the CRI-O container runtime supports using encrypted container images](https:\/\/github.com\/cri-o\/cri-o\/blob\/main\/tutorials\/decryption.md). Encrypted container images are Open Container Initiative (OCI) images that contain encrypted layer contents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-images"},{"document_id":"ibmcld_01412-7-1617","score":12.7626654004,"text":"\nEncrypting images for content confidentiality \n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nCreate an encrypted image so that people without the\n\nprivate keycan't access the content. Create the encrypted image by using an RSA public-private key pair to encrypt and decrypt the image. A public key is not a secret and anyone can use it to encrypt an image. A private key is a secret, and only users that have that private key can use it to decrypt the image.\n\nEncryption is supported in IBM Cloud Container Registry and complies with the following standards:\n\n\n\n* [opencontainers\/image-spec](https:\/\/github.com\/opencontainers\/image-spec)\n* [opencontainers\/artifacts](https:\/\/github.com\/opencontainers\/artifacts\/pull\/15)\n\n\n\nFor more information about encrypting images, see [Advancing container image security with encrypted container images](https:\/\/developer.ibm.com\/articles\/advancing-image-security-encrypted-container-images\/) and [Advancing image security and compliance through Container Image Encryption](https:\/\/www.youtube.com\/watch?v=dYXhAxxPkqA).\n\n\n\n Before you begin \n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt"},{"document_id":"ibmcld_10480-15354-16992","score":12.4694310294,"text":"\nCreate a secured route for the image-registry service that uses reencrypt TLS termination. With re-encryption, the router terminates the TLS connection with a certificate, and then re-encrypts the connection to the internal registry with a different certificate. With this approach, the full path of the connection between the user and the internal registry is encrypted. To provide your own custom domain name, include the --hostname option.\n\noc create route reencrypt --service=image-registry -n openshift-image-registry\n3. Retrieve the hostname (HOST\/PORT) and the PORT that were assigned to the image-registry route.\n\noc get route image-registry -n openshift-image-registry\n\nExample output\n\nNAME HOST\/PORT PATH SERVICES PORT TERMINATION WILDCARD\nimage-registry image-registry-openshift-image-registry.<cluster_name>-<ID_string>.<region>.containers.appdomain.cloud image-registry 5000-tcp reencrypt None\n4. Edit the route to set the [load balancing strategy](https:\/\/docs.openshift.com\/container-platform\/3.11\/architecture\/networking\/routes.htmlload-balancing) to source so that the same client IP address reaches the same server, as in a passthrough route setup. You can set the strategy by adding an annotation in the metadata.annotations section: haproxy.router.openshift.io\/balance: source. You can edit the configuration file from the Red Hat OpenShift Application Console or in your command line by running the following command.\n\noc edit route image-registry -n openshift-image-registry\n\nAdd the annotation.\n\napiVersion: route.openshift.io\/v1\nkind: Route\nmetadata:\nannotations:\nhaproxy.router.openshift.io\/balance: source\n...\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registry"},{"document_id":"ibmcld_10261-11047-12754","score":12.2042949351,"text":"\nThis command copies the OCI image that you previously pulled, uses your public key to encrypt the image, and saves the encrypted image to a different local file. Consider naming the encrypted image <source_image>_encrypted for easy identification.\n\nskopeo copy --encryption-key jwe:.\/mypubkey.pem <source_image>:<tag> <source_image>_encrypted:<tag>\n7. Optional: To locally verify that the image is encrypted, you can try to decrypt the image with an incorrect key.\n\n\n\n1. Generate a new private key.\n\nopenssl genrsa --out wrongkey.pem 1024\n2. Attempt to use this new key to decrypt the image. The decryption command fails because the incorrect private key was specified.\n\nskopeo copy --decryption-key .\/wrongkey.pem <source_image>_encrypted:<tag> <source_image>_decrypted:<tag>\n\n\n\n8. Optional: [Push the encrypted image to IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgs_registry_images_pushing), which supports encrypted OCI images.\n9. Specify the encrypted image in your app deployment. For example, if you pushed the encrypted image to IBM Cloud Container Registry, you can follow the example in [Deploying containers from an IBM Cloud Container Registry image to the default Red Hat OpenShift project](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesnamespace). When you create the deployment in your cluster, the container runtime uses the private decryption key in the \/etc\/crio\/keys\/synced directory to decrypt the image before running it.\n10. For any subsequent images that you want to encrypt, you can either use the same public key to encrypt the images with Skopeo, or repeat these steps to use a different public and private key pair.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-images"},{"document_id":"ibmcld_05278-81328-82897","score":12.1287557594,"text":"\nibmcloud ce buildrun submit (--build BUILD_NAME [--name NAME]) | (--name NAME [--commit COMMIT] [--context-dir CONTEXT_DIR] [--dockerfile DOCKERFILE] [--git-repo-secret GIT_REPO_SECRET] [--registry-secret REGISTRY_SECRET] [--size SIZE] [--strategy STRATEGY]) [--image IMAGE] [--no-wait] [--output OUTPUT] [--quiet] [--service-account SERVICE_ACCOUNT] [--source SOURCE] [--timeout TIMEOUT] [--wait] [--wait-timeout WAIT_TIMEOUT]\n\n\n\n Command Options \n\n--build, -b, --bd\n: The name of the build configuration to use. This value is optional.\n\n--commit, --cm, --revision\n: The commit, tag, or branch in the source repository to pull. The build commit option is allowed if the --source option is set to the URL of a Git repository and not allowed if the --source option is not set to the URL of a Git repository. This value is optional.\n\n--context-dir, --cdr\n: The directory in the repository that contains the buildpacks file or the Dockerfile. The build context directory option is allowed if the --build option is not set and not allowed if the --build option is set. This value is optional.\n\n--dockerfile, --df\n: The path to the Dockerfile. Specify this option only if the name is other than Dockerfile. The build dockerfile option is allowed if the --build option is not set and not allowed if the --build option is set. This value is optional. The default value is Dockerfile.\n\n--git-repo-secret, --grs, --repo, -r\n: The name of the SSH secret, which contains the credentials to access the private repository that contains the source code to build your container image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_04335-79876-81445","score":12.1287557594,"text":"\nibmcloud ce buildrun submit (--build BUILD_NAME [--name NAME]) | (--name NAME [--commit COMMIT] [--context-dir CONTEXT_DIR] [--dockerfile DOCKERFILE] [--git-repo-secret GIT_REPO_SECRET] [--registry-secret REGISTRY_SECRET] [--size SIZE] [--strategy STRATEGY]) [--image IMAGE] [--no-wait] [--output OUTPUT] [--quiet] [--service-account SERVICE_ACCOUNT] [--source SOURCE] [--timeout TIMEOUT] [--wait] [--wait-timeout WAIT_TIMEOUT]\n\n\n\n Command Options \n\n--build, -b, --bd\n: The name of the build configuration to use. This value is optional.\n\n--commit, --cm, --revision\n: The commit, tag, or branch in the source repository to pull. The build commit option is allowed if the --source option is set to the URL of a Git repository and not allowed if the --source option is not set to the URL of a Git repository. This value is optional.\n\n--context-dir, --cdr\n: The directory in the repository that contains the buildpacks file or the Dockerfile. The build context directory option is allowed if the --build option is not set and not allowed if the --build option is set. This value is optional.\n\n--dockerfile, --df\n: The path to the Dockerfile. Specify this option only if the name is other than Dockerfile. The build dockerfile option is allowed if the --build option is not set and not allowed if the --build option is set. This value is optional. The default value is Dockerfile.\n\n--git-repo-secret, --grs, --repo, -r\n: The name of the SSH secret, which contains the credentials to access the private repository that contains the source code to build your container image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_06004-36463-38401","score":12.1114748728,"text":"\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_01377-4232-6305","score":11.9595200042,"text":"\nFor more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nFor an example of how to set up context-based restrictions, see the context-based restrictions tutorial [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\nWhen you set up context-based restrictions, the restrictions apply to everything for the selected service in the account unless you select a subset of resources. To set up your own context-based restrictions for Container Registry, when you're creating a rule, in the Select your resources section, select Container Registry. Container Registry supports the following subset of resources: resource type = namespace and resource id = YOUR_IMAGE_NAMESPACE, where YOUR_IMAGE_NAMESPACE is the namespace of your image.\n\nFor example, if your image is in the format uk.icr.io\/<my_project>\/<my_image>:latest, where <my_project> is the name of your project and <my_image> is the name of the image, the attribute types are as shown in the following table.\n\n\n\nTable 1. Example attribute types\n\n Attribute type Operator Value \n\n Region string equals London \n Resource Type string equals namespace \n Resource Name string equals <my_project> \n\n\n\nThe Resource Name value is a namespace, as shown by the [ibmcloud cr namespace-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_namespace_list) command.\n\n\n\n\n\n Platform management roles \n\nThe following table details actions that are mapped to platform management roles. Platform management roles enable users to perform tasks on service resources at the platform level, for example assign user access for the service, and create or delete service IDs.\n\n\n\nTable 2. IAM user roles and actions\n\n Platform management roles Description of actions Example actions \n\n Viewer Not supported \n Editor Not supported \n Operator Not supported \n Administrator Configure access for other users.<br><br>Apply pull secrets to clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-4258-6331","score":11.9595200042,"text":"\nFor more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nFor an example of how to set up context-based restrictions, see the context-based restrictions tutorial [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\nWhen you set up context-based restrictions, the restrictions apply to everything for the selected service in the account unless you select a subset of resources. To set up your own context-based restrictions for Container Registry, when you're creating a rule, in the Select your resources section, select Container Registry. Container Registry supports the following subset of resources: resource type = namespace and resource id = YOUR_IMAGE_NAMESPACE, where YOUR_IMAGE_NAMESPACE is the namespace of your image.\n\nFor example, if your image is in the format uk.icr.io\/<my_project>\/<my_image>:latest, where <my_project> is the name of your project and <my_image> is the name of the image, the attribute types are as shown in the following table.\n\n\n\nTable 1. Example attribute types\n\n Attribute type Operator Value \n\n Region string equals London \n Resource Type string equals namespace \n Resource Name string equals <my_project> \n\n\n\nThe Resource Name value is a namespace, as shown by the [ibmcloud cr namespace-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_namespace_list) command.\n\n\n\n\n\n Platform management roles \n\nThe following table details actions that are mapped to platform management roles. Platform management roles enable users to perform tasks on service resources at the platform level, for example assign user access for the service, and create or delete service IDs.\n\n\n\nTable 2. IAM user roles and actions\n\n Platform management roles Description of actions Example actions \n\n Viewer Not supported \n Editor Not supported \n Operator Not supported \n Administrator Configure access for other users.<br><br>Apply pull secrets to clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_08231-3044-5238","score":11.7854378314,"text":"\nIt contains the source code from which the image was built as well as the build log. You can download the manifest file from the Secure Build Server, and, for example, use it for audit purposes or pass it to an auditor. The manifest file is signed by signing keys that are kept inside the secure enclave.\n* Secure Build Server creates an encrypted registration file, which can be used to provision an instance of the application on Hyper Protect Virtual Servers by using Bring Your Own Image (BYOI).\n\n\n\nZoom\n\n![The Secure Build Server](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/29e0ddc9fd7149f916889ba6a4d131cc3528c9bc\/hp-virtual-servers\/image\/secure-build.png)\n\nFigure 1. The Secure Build Server\n\nThe registration file specifies the container registry, the application image, and the credentials that are required to access the container registry. The registration file is encrypted and can be decrypted by Hyper Protect Virtual Servers only.\n\nYou can download and use the encrypted registration file yourself, or you can pass it to a cloud administrator who uses the registration file and the Hyper Protect Virtual Servers CLI to provision a Hyper Protect Virtual Servers server instance with your image. The cloud administrator cannot access the information that is included in the registration file, namely the container registry credentials because the registration file is encrypted. In consequence \u2013 given access control is correctly set up for the container registry and the credentials are not exposed, the cloud administration cannot download or access the application image and any secrets that are contained in the image.\n\n\n\n\n\n Digital wallets \n\nAs digital wallets are targeted by hackers, it is important that the digital assets be protected in an environment that is also easily accessible by the user (known as a \"hot wallet\"). A protected environment is an environment where both privileged admins and external threats cannot compromise the data, thru encryption and other mechanisms. In addition, the application must be built in a secure environment that uses a Secure Build process that prevents malicious actors from tampering the application code and application image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-tutorial_secure_build_server"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07115-5269-7471","score":45.4195113524,"text":"\nYour documents might not have a text field if you uploaded a CSV file that doesn't have a column named text, or uploaded a JSON file that doesn't have an object named text, or if you used the Smart Document Understanding tool to define fields with other names in which the bulk of the content of your documents now are stored.\n\nWhen you train a project from the API, results are taken from all of the root-level fields and they are all considered to have equal significance. Unlike Discovery Query Language queries, with natural language queries you cannot specify which fields from the document you care about or how much significance to give to each one. When you teach Discovery with examples, the service figures out for you how much weight to give to each field.\n\nDiscovery builds a model that assigns different weights to term, bigram, and skip-gram matches for each of the root-level fields and balances them against matches from all of the other document fields. With enough examples, Discovery can return better answers because it knows where the best answers are typically stored.\n\nRelevancy training cannot be used to give more weight to nested fields. Nested fields are grouped and assigned one overall score. No matter how much you train, Discovery never gives a nested field more weight than it gives to a root-level field. For more information about nested fields, see the [FAQ](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-faqsfaq-nested-fields).\n\n\n\n\n\n Training a project \n\nThe training data that is used to train the relevancy model includes these parts:\n\n\n\n* A natural language query that is representative of a query that your users might submit\n* Results of the query which are returned by the service\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"},{"document_id":"ibmcld_07163-7-1995","score":43.2081053765,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_13075-7-2200","score":41.5063536483,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07214-41790-43719","score":40.2093067139,"text":"\nImproved query limits for Advanced and Premium plans : [Query expansion](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion) limits are increased for Advanced and Premium plans to 5,000 query expansions and 25,000 total terms. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details.\n\n\n\n\n\n 28 February 2018 \n\nDeprecated AlchemyLanguage enrichments : AlchemyLanguage enrichments are deprecated, effective 1 March 2018.\n\n\n\n\n\n 23 February 2018 \n\nNew document similarity query feature : Added the ability to query by document similarity. You can query for similar documents by document ids, and optionally further refine the similarity by specifying fields. See [Document similarity](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsdoc-similarity) for more information.\n\nImproved highlight parameter : The [highlight parameter](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight) in query results is enhanced. Query results return complete sentences, ordered by their score.\n\n\n\n\n\n 21 February 2018 \n\nFixed PDF file type : Previously, when ingesting PDF documents, the file_type returned when ingestion notices were queried, in the extracted_metadata object, and from the document details API was html. This is no longer the case. The file_type returned is now pdf.\n\n\n\n\n\n 26 January 2018 \n\nNew Korean and Spanish accessibility in Discovery News : Added the ability to access Korean and Spanish collections to the [IBM Watson\u2122 Discovery News](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-watson-discovery-news) tile in the tooling. Previously, these collections could only be queried via the API.\n\n\n\n\n\n 23 January 2018 \n\nNew query expansion : Added the ability to expand the scope of a query - for example, you can expand a query for \"car\" to include \"automobile\" and \"motor vehicle\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07237-1522-3387","score":39.860762401,"text":"\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n\n\n\n\n\n Is there size limitation on the length of Natural Language Queries (NLQ)? \n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n\n\n\n\n\n How do you improve query results? \n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n How do you know that relevancy training is complete? \n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Where can I learn more about uploading documents to Watson Discovery? \n\nYou can upload documents using the API or the Discovery tooling. You can also connect to several different data sources (including Box, Salesforce, SharePoint Online, SharePoint 2016, and IBM Cloud Object Storage), or do a web crawl. For details, see [Adding content](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontent).\n\n\n\n\n\n What document types are supported for ingestion?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-troubleshoot"},{"document_id":"ibmcld_07214-23189-25155","score":39.8393753165,"text":"\nThese words are now extracted from the highlights, rather than simply displaying the first 50 words of the article. See [highlight](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight) for an explanation of highlights. Highlights do not need to be explicitly included in your query to enable this behavior.\n\n\n\n\n\n 25 September 2018 \n\nNew Continuous Relevancy Training feature : Released Continuous Relevancy Training, which uses interactions from users to learn how to surface the most relevant results. It can learn from user behavior automatically, significantly reducing the effort required to improve the relevancy ranking of results. See [Continuous Relevancy Training](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-crt) for details.\n\nNew API support for longer queries : Added API support for performing longer queries. This increases the character limit to 10,000 characters, and makes it possible to increase the number of filters in your queries and perform more complex aggregations. See the POST Query at [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylong-collection-queries) and [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylong-environment-queries) for details.\n\nImproved ability to upgrade to Advanced plan : You can now upgrade your Advanced plan using the API. See [Upgrading your plan](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-upgrading-your-planswitchadvanced) for details.\n\nNew Element Classification objects : The Element Classification enrichment now has updated classified elements, contract elements, and parties and tables identified. For the updates, see [Element Classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\nNew full support for Brazilian Portuguese : Added full support for the Brazilian Portuguese language. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-language-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_13075-1823-3835","score":39.7219978029,"text":"\nFor more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07214-71282-73334","score":39.706216131,"text":"\n: [Resolved](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notesdiscovery-30june2017)\n\nImproved tooling error log : The Tooling error log is no longer limited to a maximum of eight (8) pages of results. The error log still displays the document ID if the document name is not available.\n\nUpdate to configuration names : Configuration names are limited to 50 characters and must consist of the characters [a-zA-Z0-9-_].\n\nImproved availability of 'passages' parameter : The passages parameter previously available only through the API is now available through the Tooling as well as the API.\n\n\n\n\n\n 25 April 2017 \n\nNew training data functionality : Use training data to improve the accuracy of your query results. When you provide a Discovery instance with training data, the service uses advanced Watson algorithms to determine the most relevant results. As you add more training data, the service instance becomes more accurate and sophisticated in the results it returns. See [Improving the relevance of your query results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) and the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data) for information.\n\nNew beta support for 'natural_language_query' parameter : The API now supports the natural_language_query parameter as a beta release. This parameter enables you to specify a query in natural language instead of in the Discovery service's query language. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\n\n\n\n\n 14 April 2017 \n\nNew enhancements to query API : Enhancements are now available for the query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query). See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nNew support for 'passages' parameter in the query API : The query API now supports the passages parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07163-1627-3707","score":39.4401589723,"text":"\nSee [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\nThe components needed to train a Discovery instance include the following:\n\n\n\n* Training data. This is the set of queries and examples the service uses to refine query results.\n* Query. A natural-language query that applies to the training-data set. Each query has one or more associated examples, as described in the following bullet point. Each query must be unique within the training-data set.\n* Example. This is a document indexed in a Discovery collection that acts as an exemplar, good or bad, for the associated query. When you add an example to a training-data query, you include a relevance label that indicates the relevance (or \"goodness\" versus \"badness\") of the document as it applies to the specified query.\n\nExamples are identified by the indexed document ID. As noted, every example must include a label that indicates the \"goodness\" or \"badness\" of the document as it pertains to the query.\n\nExamples can optionally specify a cross-reference query. The cross-reference query needs to return only the example document and must be independent of the unique Watson Discovery document ID. Cross-reference queries are not currently used automatically but can be used to repair training data in the event that new IDs are assigned to documents during an ingestion event.\n\n\n\n\n\n Training data requirements","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_13075-5007-7084","score":39.4206761019,"text":"\nTo return to the main Build queries screen at any time, click Build queries on the upper left. To return to the Manage data screen, click the name of the collection on the upper right.\n\nIf you would like to delete all of the training data in your collection at one time, you must do so via the API. See [Delete all training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data) for more information. For more information about training via the API, see [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api).\n\n\n\n\n\n Testing and iterating on the relevancy of results \n\nAfter you complete rating results and Watson applies the training, test to see if your query results improved. To do so, run test queries that are related, but not identical to, your training queries. Check to see if the results of your test queries improved.\n\nIf you would like to further improve results after testing, you could:\n\n\n\n* Add more documents to your collection.\n* Add more training queries.\n* Rate more results, making sure to use both the Relevant and Not relevant ratings.\n\n\n\nFor additional training guidance, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Confidence scores \n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language.\n\nThe confidence score is returned for both trained and untrained private collections (with the exception of filter-only queries of untrained collections). In addition, Discovery returns a document_retrieval_strategy field that indicates the source of the confidence score:\n\n\n\n* untrained\n* relevancy_training, or\n* continuous_relevancy_training\n\n\n\nThe document_retrieval_strategy can be used along with the confidence score to determine how the results provided should be used. In cases where load is high, the document_retrieval_strategy returned might be untrained, even if the collection is trained.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02114-39348-41345","score":17.0522629515,"text":"\n: URL pointing to the .zip file of the product.\n\n--include-config (optional)\n: If provided, all configuration values are included and available when you add the product.\n\n\n\n\n\n\n\n ibmcloud catalog offering version merge-draft \n\nRun the following command to merge a draft version of a product.\n\nibmcloud catalog offering version merge-draft --version-locator VERSION_NUMBER\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering enable-sharing \n\nRun the following command to enable your product to be shared.\n\nibmcloud catalog offering enable-sharing --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering ready \n\nRun the following command to mark your product as ready to share or publish.\n\nibmcloud catalog offering ready --version-locator VERSION_NUMBER\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering delete \n\nRun the following command to delete a product from your private catalog. You cannot delete a product that is published in the IBM Cloud catalog. To deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-39324-41321","score":17.0522629515,"text":"\n: URL pointing to the .zip file of the product.\n\n--include-config (optional)\n: If provided, all configuration values are included and available when you add the product.\n\n\n\n\n\n\n\n ibmcloud catalog offering version merge-draft \n\nRun the following command to merge a draft version of a product.\n\nibmcloud catalog offering version merge-draft --version-locator VERSION_NUMBER\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering enable-sharing \n\nRun the following command to enable your product to be shared.\n\nibmcloud catalog offering enable-sharing --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering ready \n\nRun the following command to mark your product as ready to share or publish.\n\nibmcloud catalog offering ready --version-locator VERSION_NUMBER\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering delete \n\nRun the following command to delete a product from your private catalog. You cannot delete a product that is published in the IBM Cloud catalog. To deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-39408-41405","score":17.0522629515,"text":"\n: URL pointing to the .zip file of the product.\n\n--include-config (optional)\n: If provided, all configuration values are included and available when you add the product.\n\n\n\n\n\n\n\n ibmcloud catalog offering version merge-draft \n\nRun the following command to merge a draft version of a product.\n\nibmcloud catalog offering version merge-draft --version-locator VERSION_NUMBER\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering enable-sharing \n\nRun the following command to enable your product to be shared.\n\nibmcloud catalog offering enable-sharing --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering ready \n\nRun the following command to mark your product as ready to share or publish.\n\nibmcloud catalog offering ready --version-locator VERSION_NUMBER\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering delete \n\nRun the following command to delete a product from your private catalog. You cannot delete a product that is published in the IBM Cloud catalog. To deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_02114-9608-11655","score":17.0293316206,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-9608-11655","score":17.0293316206,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-9608-11655","score":17.0293316206,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_02114-40817-42812","score":16.9527006939,"text":"\nTo deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have access to the private catalog and its containing resource group can create an instance and start using it.\n\nibmcloud catalog offering publish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish allowlist \n\nRun the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the allowlisted accounts can create an instance and start using it.\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish enterprise \n\nRun the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the product.\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering suspend-offering \n\nRun the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-40793-42788","score":16.9527006939,"text":"\nTo deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have access to the private catalog and its containing resource group can create an instance and start using it.\n\nibmcloud catalog offering publish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish allowlist \n\nRun the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the allowlisted accounts can create an instance and start using it.\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish enterprise \n\nRun the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the product.\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering suspend-offering \n\nRun the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-40877-42872","score":16.9527006939,"text":"\nTo deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have access to the private catalog and its containing resource group can create an instance and start using it.\n\nibmcloud catalog offering publish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish allowlist \n\nRun the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the allowlisted accounts can create an instance and start using it.\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish enterprise \n\nRun the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the product.\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering suspend-offering \n\nRun the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_02114-46642-48711","score":16.6649536623,"text":"\nRun the following command to check your working directory's Terraform modules for updates from the catalog and update the source attribute to the latest version. The README.md is also updated.\n\nibmcloud catalog utility update-module-references\n\n\n\n\n\n ibmcloud catalog offering unpublish account \n\nRun the following command to unpublish a product from your account. After the product is unpublished, users in your account cannot create an instance of the product.\n\nibmcloud catalog offering unpublish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish allowlist \n\nRun the following command to remove account IDs from the product's allowlist. Accounts that are removed from the allowlist cannot create an instance of the product.\n\nibmcloud catalog offering unpublish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish enterprise \n\nRun the following command to unpublish a product from an enterprise. After the product is unpublished, the enterprise cannot create an instance of the product.\n\nibmcloud catalog offering unpublish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish public \n\nRun the following command to publish your private offering to the IBM Cloud catalog for all users to see and use. To get to this step in the publication process, you must first publish the offering to your account and to all IBMers to complete the testing process. After your testing is complete, you can run this command.\n\nThis option requires approval. As soon as your approval is complete, your tile is available for all IBM Cloud customers.\n\nibmcloud catalog offering publish public [--catalog CATALOG]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03037-7-1971","score":31.5863399649,"text":"\nAdvanced tasks \n\nLearn about APIs and other tools you can use to access and analyze log data.\n\n\n\n API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_16364-4643-6555","score":30.7955874907,"text":"\nFor more information, see [Building a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-custom-extension) and [Adding an extension to your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-add-custom-extension).\n\n\n\n\n\n 8 June 2023 \n\nEdit step titles\n: You can now add and edit titles for each step, which can help you more easily identify what a step does in an action. For more information, see [Editing actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview).\n\nNew message when deleting a subaction\n: If you delete an action that is a subaction, there is a new message that lists all the actions that call the subaction and asks you to confirm the deletion. The message helps you preserve dependencies between actions and subactions.\n\n\n\n\n\n 5 June 2023 \n\nFiltering the list of actions\n: You can locate specific actions by filtering the list by subactions, by custom extension, or by variable. For more information, see [Filtering actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-actions).\n\n\n\n\n\n 29 May 2023 \n\nNew expression choice for setting a session variable\n: Previously, to use an expression to set or modify a variable value, you needed to pick an existing variable or create a new one and select the expression option. Now you can use a new Expression choice to write an expression directly without first picking a variable. For more information, see [Storing a value in a session variable](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-infostore-session-variable).\n\nChanges to validation of OpenAPI specifications\n: When you build a custom extension, you work with OpenAPI specification files. This release includes changes to the validation of OpenAPI files, which might affect the connection between your actions and extensions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03364-5344-7201","score":30.3907834143,"text":"\n* [Dialog Skill Analysis for Watson Assistant](https:\/\/github.com\/watson-developer-cloud\/assistant-dialog-skill-analysis)\n* [Watson Assistant Recommendation notebooks (Measure and Analyze Effectiveness)](https:\/\/github.com\/watson-developer-cloud\/assistant-improve-recommendations-notebook)\n* [Watson Assistant Dialog Flow Analysis notebook](https:\/\/github.com\/watson-developer-cloud\/assistant-dialog-flow-analysis)\n\n\n\nAgain, the [Watson Assistant Continuous Improvement Best Practices Guide](https:\/\/github.com\/watson-developer-cloud\/assistant-improve-recommendations-notebook\/raw\/master\/notebook\/IBM%20Watson%20Assistant%20Continuous%20Improvement%20Best%20Practices.pdf) outlines which notebook to use at each stage of your improvement process.\n\n\n\n\n\n\n\n Using the logs API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-filter-reference).\n\nThe API logs messages that are exchanged in conversations that are defined by a dialog skill only.\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_16255-7734-9537","score":29.9490202023,"text":"\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nSee the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference) for additional details.\n\n\n\n\n\n Deleting data \n\nTo delete any message log data associated with a specific user that your assistant might have stored, use the DELETE \/user_data v1 API method. Specify the customer ID of the user by passing a customer_id parameter with the request.\n\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securing"},{"document_id":"ibmcld_03109-7703-9557","score":28.9665397474,"text":"\nTo delete any query data that is associated with a specific customer, you must send a separate delete request directly to the Discovery service instance that is linked your the assistant. See the Discovery [information security](https:\/\/cloud.ibm.com\/docs\/discovery\/information-security?topic=discovery-information-security) topic for details.\n\n\n\n\n\n Querying user data \n\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nSee the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference) for additional details.\n\n\n\n\n\n Deleting data \n\nTo delete any message log data associated with a specific user that your assistant might have stored, use the DELETE \/user_data v1 API method. Specify the customer ID of the user by passing a customer_id parameter with the request.\n\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_03007-4839-6655","score":28.3523288101,"text":"\n* v2: [Information security](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-information-security)\n\n\n\n\n\n\n\n Querying user data \n\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2service-endpoint).\n\nSee the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference) for additional details.\n\n\n\n\n\n Deleting data \n\nTo delete any message log data associated with a specific user that your assistant might have stored, use the DELETE \/user_data v1 API method. Specify the customer ID of the user by passing a customer_id parameter with the request.\n\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-information-security"},{"document_id":"ibmcld_16392-0-1833","score":28.3407049301,"text":"\n\n\n\n\n\n\n  Extending your assistant with webhooks \n\nA webhook is a mechanism that allows you to call out to an external program based on events in your program. You can use webhooks to make calls from your assistant to an external service or application during a conversation.\n\nWatson Assistant supports the following types of webhooks:\n\n\n\n*  [Premessage](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-pre)\n*  [Postmessage](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-post)\n*  [Logs](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-log)\n\n\n\nThese webhooks are called with every exchange in a conversation between the customer and the assistant.\n\nIf you want to limit webhook processing so it happens only in certain situations, any condition to check for before taking an action must be defined in the external application code. For example, if your webhook performs a simple language translation, you might want to use a condition to check the language of the incoming message before sending the text to the translation service.\n\nYou don't need to define a condition for the log webhook unless you want to filter the messages somehow. In most cases, the goal is to write out every message that is submitted, so the messages can be stored for as long as you want, and analyzed by an external application or service.\n\nWebhooks are configured separately for each environment:\n\n\n\n1.  Go to the Environments page and open the environment where you want to configure webhooks.\n2.  On the Environments page, click the ![Environment settings icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/gear-icon-black.png) icon beside the environment title to open the environment settings.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview"},{"document_id":"ibmcld_03028-7-1945","score":27.5674194599,"text":"\nImprove your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nThe Analytics page was introduced with version 1.5.0.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nMessage logs are retained for 90 days.\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_16255-6267-8075","score":27.4719146904,"text":"\n'Content-Type: application\/json'\n'X-Watson-Metadata: customer_id=abc'\n--data\n'{\"input\":{\"text\":\"hello\"}}'\n'{url}\/v2\/assistants\/{assistant_id}\/sessions\/{session_id}\/message?version=2019-02-28'\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nThe customer_id string cannot include the semicolon (;) or equal sign (=) characters. You are responsible for ensuring that each customer ID property is unique across your customers.\n\nOnly the first customer ID value that is passed in the X-Watson-Metadata header is used as the customer_id string for the message log. This customer ID value can be deleted with DELETE \/user_data v1 API calls.\n\nIf you add search to an assistant, user input that is submitted to the assistant is passed to the Discovery service as a search query. If the Watson Assistant integration provides a customer ID, then the resulting \/message API request includes the customer ID in the header, and the ID is passed through to the Discovery \/query API request. To delete any query data that is associated with a specific customer, you must send a separate delete request directly to the Discovery service instance that is linked your the assistant. See the Discovery [information security](https:\/\/cloud.ibm.com\/docs\/discovery\/information-security?topic=discovery-information-security) topic for details.\n\n\n\n\n\n Querying user data \n\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securing"},{"document_id":"ibmcld_16340-16148-18298","score":26.9963801019,"text":"\nFor more information about session variables, see [Defining session variables](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-addactions-variables-global).\n3. Set the value of the variable by using an expression that looks like this: <? input.text ?>.\n\n\n\nThis expression captures the complete message that was submitted by the customer. As a result, your variable captures the customer message that triggered this action.\n\n\n\n1. Add the session variable to the Custom query field (for example, ${original_message}).\n\n\n\n* Custom results filter: Add a text string that defines information that must be present in any of the search results that are returned.\n\nYou are effectively defining the value that is used by the Discovery API as the filter parameter. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfilter).\n\nThe syntax to use for the filter value is not intuitive. Here are a few examples of common use cases:\n\n\n\n* To indicate that you want to return only documents with positive sentiment, for example, specify enriched_text.sentiment.document.label:positive.\n* To filter results to include only documents that mention Boston, MA, specify enriched_text.entities.text:\"Boston, MA\".\n* To filter results to include only documents that mention a city name that you saved in a context variable named $destination, you can specify enriched_text.entities.text:$destination.\n\n\n\n\n\nIf you add both a query and a filter value, the filter parameter is applied first to filter the data collection documents and cache the results. The query parameter then ranks the cached results.\n3. If you want the search for an answer to be the last step in the action, select End the action after returning results.\n4. Click Apply.\n\n\n\n\n\n\n\n Test the search integration \n\nAfter you configure search, you can send test queries to see the search results that get returned from Discovery by using the Preview page.\n\nTo test the full experience that customers have when they ask questions that are either answered by the action or trigger a search, use the Preview for your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16447-7-2125","score":23.3218338324,"text":"\nUser roles in Knowledge Studio for IBM Cloud Pak for Data \n\nIBM Watson\u2122 Knowledge Studio roles are used to organize a team of people who create machine learning or rule-based models.\n\n\n\n Notes about roles in Knowledge Studio \n\n\n\n* Knowledge Studio roles control access to Knowledge Studio functionality and are managed in the Knowledge Studio application.\n* The first user to launch the Knowledge Studio application is assigned the Admin role.\n* Once assigned, user roles can't be downgraded from higher to lower levels of permissions. Admins can't be downgraded to project managers or human annotators, and project managers can't be downgraded to human annotators. For information about adding users, upgrading roles, and deactivating user accounts, see [Assembling a team](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-team).\n* To manage a workspace, project managers need to be assigned to the workspace by an admin.\n* Admins and project managers can perform the role of human annotators. They can also [directly annotate document sets](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotating-document-sets-directly) without creating annotation tasks.\n\n\n\n\n\n\n\n Knowledge Studio role descriptions \n\nKnowledge Studio roles are described in the following table. Roles are listed in order of highest to lowest level of permissions.\n\n\n\nTable 1. Role descriptions\n\n Role Description \n\n Admin Responsible for administrative tasks, which include managing users, resource consumption, and monthly charges. In large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"},{"document_id":"ibmcld_16442-1404-3155","score":22.3917684343,"text":"\nSee [Establishing a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem) <br> <br>- Source documents: Create a corpus by uploading sample documents that are representative of your domain content into the workspace. See [Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation). Partition the corpus into document sets, specify the percentage of documents that are shared among all document sets, and assign the document sets to human annotators. <br> <br>- Dictionaries: Upload or create dictionaries for annotating text. You can choose to manually add dictionary entries or upload entries from a file, and then edit the entries. See [Creating dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries). \n Optional: Pre-annotate documents Pre-annotate documents according to the terms in the workspace dictionaries or based on rules that you define. See [Bootstrapping annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation). \n Annotate documents <br><br>1. Admins and project managers can annotate documents directly, without needing to create annotation tasks or go through the adjudication process. See [Annotating document sets directly](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotating-document-sets-directly).<br>2. The project manager generally assigns annotation tasks to human annotators, configures the inter-annotator agreement threshold, and provides annotation guidelines for the human annotators to follow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator"},{"document_id":"ibmcld_06981-1673-3761","score":21.4746940306,"text":"\nLater, you can limit the search to return content from only the tips field.\n\nOr maybe you have extra large documents that contain subsections. You can teach the SDU model to recognize these subsections, and then split the large document into multiple, smaller, and easier-to-manage documents that begin with one of these subsections.\n* The best way to prepare a collection for use in Conversational Search projects is to identify discrete question-and-answer pairs. You can use the SDU tool to find and annotate them. If you configure the project to contain answers in an answer field, you must update the search configuration in Watson Assistant to get the body of the response from the custom answer field.\n* A pretrained SDU model is applied to Document Retrieval for Contracts projects automatically. The pretrained SDU model knows how to recognize terms and concepts that are significant to contracts. As a result, you cannot apply a user-trained SDU model to this project type, but you also don't need to.\n* The SDU tool is rarely used with Content Mining projects.\n\n\n\nYou can use the SDU tool to annotate the following file types only:\n\n\n\n* Image files (PNG, TIFF, JPG)\n* Microsoft PowerPoint\n* Microsoft Word\n* PDF\n\n\n\nFor a complete list of file types that Discovery supports, see [Supported file types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n\nThe Smart Document Understanding tool uses optical character recognition (OCR) to extract text from images in the files that it analyzes. Images must meet the minimum quality requirements that are supported by OCR. For more information, see [Optical character recognition](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionsocr).\n\nThe tool cannot read documents with the following characteristics; remove them from your collection before you begin:\n\n\n\n* Documents that appear to have text that overlays other text are considered double overlaid and cannot be annotated.\n* Documents that contain multiple columns of text on a single page cannot be annotated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_16417-7-2273","score":21.4012656051,"text":"\nBuilding the ground truth \n\nThe objective of the annotation project is to obtain ground truth, the collection of vetted data that is used to adapt Watson to a particular domain. In Knowledge Studio, human annotators, who are typically experts in the subject matter of the target domain, play a major role in determining ground truth.\n\nA typical workflow includes the following steps:\n\n\n\n1. Human annotators submit annotated documents for review.\n2. The project manager (who might be a senior domain expert) reviews the accuracy of their work and compares how consistently the human annotators annotated documents that overlap between the annotation sets.\n3. If the inter-annotator agreement score is too low, the project manager rejects the annotation set and returns it to the human annotator to be improved. When an annotation set is rejected, all documents in the set are placed back into editable mode.\n4. If the project manager approves an annotation set, documents that do not overlap across annotation sets are promoted to ground truth so that the annotations can be used to train the model.\n5. The project manager reviews the overlapping documents and resolves the annotation conflicts. At this stage, referred to as adjudication, the team might review and revise the annotation guidelines to help clarify misunderstandings that caused text to be incorrectly or inconsistently annotated by different human annotators.\n\nIn some cases, a project manager might want a higher percentage of overlap for evaluating inter-annotator agreement than the percentage of overlap for adjudicating differences. For example, if inter-annotator agreement looks OK, then the project manager might decide that it is OK to promote either annotation to ground truth.\n6. As the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-7-2273","score":21.4012656051,"text":"\nBuilding the ground truth \n\nThe objective of the annotation project is to obtain ground truth, the collection of vetted data that is used to adapt Watson to a particular domain. In Knowledge Studio, human annotators, who are typically experts in the subject matter of the target domain, play a major role in determining ground truth.\n\nA typical workflow includes the following steps:\n\n\n\n1. Human annotators submit annotated documents for review.\n2. The project manager (who might be a senior domain expert) reviews the accuracy of their work and compares how consistently the human annotators annotated documents that overlap between the annotation sets.\n3. If the inter-annotator agreement score is too low, the project manager rejects the annotation set and returns it to the human annotator to be improved. When an annotation set is rejected, all documents in the set are placed back into editable mode.\n4. If the project manager approves an annotation set, documents that do not overlap across annotation sets are promoted to ground truth so that the annotations can be used to train the model.\n5. The project manager reviews the overlapping documents and resolves the annotation conflicts. At this stage, referred to as adjudication, the team might review and revise the annotation guidelines to help clarify misunderstandings that caused text to be incorrectly or inconsistently annotated by different human annotators.\n\nIn some cases, a project manager might want a higher percentage of overlap for evaluating inter-annotator agreement than the percentage of overlap for adjudicating differences. For example, if inter-annotator agreement looks OK, then the project manager might decide that it is OK to promote either annotation to ground truth.\n6. As the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16447-1597-3270","score":21.1760298042,"text":"\nIn large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Export models \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"},{"document_id":"ibmcld_16423-18026-19831","score":21.0077389968,"text":"\nDave and Phil, the human annotators, annotate documents in the sets that are assigned to them.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_datatask.svg) Figure 2. This figures illustrates that the project manager creates annotation sets and assigns them to an annotation task. Dave and Phil, the human annotators, annotate documents in the sets that are assigned to them.\n\nAfter the project manager approves annotation sets in an annotation task, annotations in documents that do not overlap with other annotation sets become ground truth. For documents that overlap between annotation sets (represented by document 2 in this example), the project manager must adjudicate and resolve conflicts. The annotations in overlapping documents do not become ground truth until they are approved through adjudication.\n\nGround truth is then used for training and testing a machine learning model, or it can be used as the basis for the next iteration of model development. To use ground truth in a new iteration, you must create a new annotation task.\n\n![This figure illustrates how annotations added by two human annotators become ground truth. One document, labeled document 2, is annotated by both human annotators. The annotations in this overlapping document must be adjudicated before they become ground truth.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_datatruth.svg) Figure 3. This figure illustrates how annotations added by two human annotators become ground truth. One document, labeled document 2, is annotated by both human annotators. The annotations in this overlapping document must be adjudicated before they become ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_16518-1687-3559","score":20.8318939861,"text":"\nTable 1. Role descriptions\n\n Role Description \n\n Admin Responsible for administrative tasks, which include managing users, resource consumption, and monthly charges. In large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Deploy and undeploy models to runtime services \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-roles"},{"document_id":"ibmcld_07032-1096-2800","score":20.5563713192,"text":"\n* For more information about how to create a Content Mining project, see [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects).\n* For more information about how to apply enrichments to a collection in the Content Mining application, see [Applying the annotator](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-custom-annotatorcm-custom-annotator-deploy).\n\n\n\n\n\n\n\n Importing dictionaries from Watson Explorer Analytical Components \n\nYou can import [user dictionaries](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SS8NLW_12.0.0\/com.ibm.discovery.es.ad.doc\/iiysatauserdict.html) from IBM Watson Explorer Analytical Components.\n\nThe default file location and name for dictionaries that are saved in Watson Explorer Analytical Components is ${primary_server_node}\/{primary_configuration}\/{collection_ID}\/{dictionary_name}.fdic.xml.\n\n\n\n1. Download your user dictionaries from Watson Explorer Analytical Components.\n2. From your Discovery Content mining project, open the Content Mining application.\n3. From the analysis view of your collection, click the Collections link in the breadcrumb to open the Create a collection for your analytics solutions page of the Content Mining application.\n4. To create an annotator, click collection, and then select custom annotator from the list.\n\nZoom\n\n![Shows the collection menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/cm-collection-menu.png)\n\nFigure 1. Collection menu\n5. Click Create custom annotator.\n6. Name your annotator, and then optionally add a description.\n7. From the Annotator Type menu, select Dictionary, and then click Next.\n8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-enrichmig"},{"document_id":"ibmcld_06959-9352-11219","score":20.369071545,"text":"\n* The patterns must be defined in an array, even if you plan to define only one pattern.\n* Escape any backslash () characters with a backslash.\n* For more information about the facet value options, see the Regular expression facet value options table.\n\n\n\n2. Click Import, and then choose the JSON file where the patterns are defined.\n3. Click Save.\n\n\n\n\n\n Regular expression limits \n\n\n\nRegular expression plan limits\n\n Plan Regex enrichments per service instance Regex patterns per service instance \n\n Cloud Pak for Data Unlimited Unlimited \n Premium 100 50 \n Enterprise 100 50 \n\n\n\nTotals include enrichments that you create in this Content Mining project and in other projects in the same service instance.\n\n\n\n\n\n\n\n Applying the annotator \n\nAfter the annotator is created, you must apply it to your collection.\n\n\n\n1. From the Create a custom annotator for your analytics solutions page of the Content Mining application, click custom annotator, and then select collection from the list.\n2. In the tile for your collection, click the options icon, and choose Edit collection.\n\nZoom\n\n![Collection tile overflow menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/cm-edit-colxn-icon.png)\n\nFigure 1. Collection menu\n3. Click the Enrichment tab, and then select the annotator that you created.\n\nYou might need to scroll to find it.\n4. Click Save, and then confirm the action.\n\n\n\nGive the index time to rebuild.\n\n\n\n\n\n Filtering documents with your facet \n\n\n\n1. Click the collection tile to open your collection in the data analysis page.\n2. Do one of the following things:\n\n\n\n* Your custom facets are listed in the Facets view. Scroll and click Load more repeatedly until your facets are displayed.\n* Submit an empty search to return all documents. In the Facet analysis pane, select the facet that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-custom-annotator"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":78.7931723211,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":75.1506364345,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13761-7-2364","score":51.2583651209,"text":"\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_16313-10077-11045","score":50.4258859053,"text":"\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16356-7-2036","score":49.8603241936,"text":"\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16313-8575-10638","score":46.8978074356,"text":"\nFor more information on uploading or downloading example phrases, see [Adding more examples](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-adding-more-examples).\n\n\n\n\n\n\n\n Editing the fallback action \n\nThe built-in Fallback action is automatically provided with each assistant and cannot be deleted. However, you can edit the Fallback action to modify the conversation your users have with the assistant when errors occur. For example, you might want to add steps or modify step conditions to provide more control over how specific error conditions are handled.\n\nTo edit the Fallback action, click Set by assistant in the list of actions, and then click Fallback.\n\nZoom\n\n![Fallback built-in action](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/fallback-action.png)\n\nFallback built-in action\n\nWhenever the Fallback action is triggered, the assistant also sets a value for the Fallback reason session variable. This value indicates what kind of situation led to the Fallback action being triggered. By default, this variable can have one of five values:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a live agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_07214-75944-77800","score":46.2173542679,"text":"\nFor example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string. JSON fields and calculated fields, such as sentiment score, are typed as defined. [Update](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontentadding-content-with-the-api-or-tooling) : The preview operation does not currently check for nested JSON arrays within a submitted JSON document. The service does not currently support nested JSON arrays, so a document with nested arrays can successfully pass the preview operation but fail upon an ingestion attempt. See [Can I upload JSON arrays?](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-troubleshootfaq-array) : If you encounter ingestion errors with the message unsupported text language, update your configuration with the \"language\": \"english\" enrichment option to force all text to be interpreted as English, as shown in the following example.\n\n\n\"enrichments\": [\n{\n\"enrichment\": \"alchemy_language\",\n\"source_field\": \"author.label\",\n\"options\": {\n\"extract\": \"taxonomy,entity,relation,doc-emotion,doc-sentiment,concept,keyword\",\n\"sentiment\": true,\n\"quotations\": true,\n\"language\": \"english\"\n}\n}\n]\n\n\nFixed known issue : Improved performance and stability of the service.\n\n\n\n\n\n 8 March 2017 \n\nImproved back end performance : Optimized the back end, including the addition of new timeouts, to improve overall performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07140-15962-18273","score":46.1697304333,"text":"\n* \"destination_field\" : string - required - The name of the container object where enrichments are created.\n\nField names defined in your configuration must meet the restrictions defined in [Field Name Requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configreffield_reqs).\n\n\n\n\n\n Element Classification enrichments \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nWhen you use the Element Classification, each elements enrichment object must contain an \"options\": {} object with the following parameters specified:\n\n\n\n* \"model\" : string - required - The element extraction model to be used with on this document. Currently supported models are: contract\n\n\n\nWhen you use the elements enrichment, it is important to follow the guidelines specified in [Element Classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification). Specifically, only PDF files can be ingested when this enrichment is specified.\n\n\n\n\n\n Natural Language Understanding enrichments \n\nWhen you use the Natural Language Understanding, each object within the enrichments array must also contain an \"options\": { \"features\": { } } object that contains one or more of the following enrichments:\n\n\n\n\n\n categories \n\nThe categories enrichment identifies any general categories in the ingested document. This enrichment has no options and must be specified as an empty object \"categories\" : {}\n\n\n\n\n\n concepts \n\nThe concepts enrichment finds concepts with which the input text is associated, based on other concepts and entities that are present in that text.\n\n\n\n* \"limit\" : INT - required - The maximum number of concepts to extract from the ingested document.\n\n\n\n\n\n\n\n emotion \n\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_06964-7-2137","score":44.6647806683,"text":"\nDetecting phrases that express sentiment \n\nAnalyze a document to find phrases that express an opinion or reaction and assess whether the sentiment expressed is positive, neutral, or negative. For English and Japanese, you can also detect specific sentiment targets. The Content Mining application marks these extractions as annotations.\n\nFor example, if a product feedback form contains the following sentence, you want to find it and indicate that it is a positive statement.\n\nI love my XYZ blender...\n\nWhat's the difference between phrase and document sentiment?\n: Document sentiment is a built-in Natural Language Processing enrichment that is available for all project types. Document sentiment evaluates the overall sentiment that is expressed in a document to determine whether it is positive, neutral, or negative. Phrase sentiment does the same. However, phrase sentiment can detect and assess multiple opinions in a single document and, in English and Japanese documents, can find specific phrases. For more information about the document sentiment enrichment, see [Sentiment](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlunlu-sentiment).\n\nComplete the following steps to enable phrase sentiment analysis:\n\n\n\n1. From the analysis view of your collection, click the Collections breadcrumb link in the page header.\n2. In the tile for your collection, click the open and close list of options icon, and then choose Edit collection.\n3. Click the Enrichment tab, and then select the Sentiment of phrases annotator.\n4. Click Save, and then click OK to verify the change.\n\nThe collection is reindexed. Wait for processing to be completed.\n5. Click Close to return to the Collections page, and then click your collection tile.\n6. In the What do you want to analyze? field, enter a term to search for in your documents or select one or more facets, and then click Search to filter the documents.\n\nThe search results are displayed in the mining graph. The Facet analysis pane is displayed also. By default, Relevancy analysis is shown.\n7. In the drop-down menu from the Facet analysis pane, select Sentiment.\n8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-phrase-sentiment"},{"document_id":"ibmcld_07096-2877-4735","score":44.5615808663,"text":"\nBecause we are using the wildcard operator, we also changed the term to lowercase.\n\n{\n\"query\":\"test_results:p53\"\n}\n\nWith this syntax, occurrences of p53, tp53, P53, or TP53 are all returned.\n\n\n\n\n\n \"\" (Phrase query) \n\nPhrase queries only match occurrences of the whole phrase. The order of the words in the phrase must match.\n\nFor example, the following query returns only documents that contain a field named quotation with the text, There's no crying in baseball.\n\n{\n\"query\":\"quotation:There's no crying in baseball\"\n}\n\nA document with a quotation field that says Jimmy Dugan said there's no crying in baseball is also returned. However, documents that only mention baseball or crying without the entire phrase are not matched. Neither is a document with In baseball, there's no crying. Documents that contain the right text in the wrong field also are not matched. For example, a document with the text There's no crying in baseball in the text field is not returned.\n\nSingle quotation marks (') are not supported. You cannot use wildcards (*) in phrase queries.\n\n\n\n\n\n :: (Exact match) \n\nThis operator specifies an exact match for the query term. Exact matches are case-sensitive.\n\nFor example, the following query searches for documents that contain entities of type Organization:\n\n{\n\"query\":\"enriched_text.entities.type::Organization\"\n}\n\nThe entire content of the field that you specify must match the phrase you specify. For example, the following query finds documents in which only entity mentions of IBM Cloud are detected, not IBM Cloud Pak for Data or IBM cloud or Cloud.\n\n{\n\"query\":\"enriched_text.entities.text::\"IBM Cloud\"\"\n}\n\n\n\n\n\n :! (Does not include) \n\nThis operator specifies that the results do not contain a match for the query term.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:!\"cloud computing\"\"\n}\n\n\n\n\n\n ::! (Not an exact match)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-3634-5079","score":35.7653923799,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-6973-8664","score":33.4936083244,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":31.5336696203,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4-1684","score":31.1946489169,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":30.5293374031,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":29.9911498512,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":28.2350028142,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-4-1966","score":26.8738697885,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-22025-23534","score":25.0374502219,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-29325-30645","score":24.9758009236,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5413996682,"ndcg_cut_10":0.6715263516}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14311-3835-5367","score":24.4025889682,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-2669-4435","score":23.1209545321,"text":"\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-7-1811","score":21.3210136546,"text":"\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_15141-6204-8279","score":20.9311100219,"text":"\nThe VPN server receives the username and passcode from the VPN client and makes an IAM call to verify the passcode and permission with IAM policy.\n\n\n\n* The passcode is an one-time password. The user MUST re-generate the passcode for re-connection, even if the re-connection is initiated by the VPN server.\n* The SoftLayer MFA is not supported because SoftLayer MFA enforcement is not done via the browser.\n\n\n\nIf you use user ID\/passcode authentication, maintenance activities force users to re-authenticate by fetching and re-entering the code. The connection is restored only after the new code is entered. This is applicable using stand-alone or HA mode.\n\n\n\n\n\n Client certificate revocation lists \n\nOptionally, you can import a certificate revocation list (CRL), which is a time-stamped list of certificates that have been revoked by a certificate authority (CA). A certificate in a certificate revocation list (CRL) might not be expired, but is no longer trusted by the certificate authority that issued the certificate. The VPN client uses this list to validate digital certificates.\n\nAfter you import a CRL, the VPN client uses this list to validate digital certificates. The CRL is saved as a string (not a file) in the system. If you need to download the CRL in the future, it is renamed as <vpn_server_name>.pem.\n\nFor more information, see [Setting up client-to-server authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-authentication).\n\n\n\n\n\n Transport protocol \n\nThe transport layer oversees the delivery of data from a process on one device to a process on another device. Transport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_16000-0-2579","score":19.864701563,"text":"\n\n\n\n\n\n\n  Understanding Internet Communication Protocols \n\nGenerally speaking, a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information. The internet has a large suite of protocols to cover many situations. In creating web-based applications and programming interfaces, software developers commonly use three of these communication protocols to describe the state of the network and the ways that data packets are moved across the network:\n\n\n\n*  ICMP, Internet Control Message Protocol, part of the internet protocol suite defined in RFC 792.\n*  TCP, Transmission Control Protocol\n*  UDP, User Datagram Protocol\n\n\n\nThe protocols that are used for a particular implementation of, say, an API call, can influence the overall behavior of your network. So it is worthwhile to understand the basic differences between them. If you need more information, many good articles are available on the internet with detailed descriptions of the protocols.\n\n\n\n  ICMP \n\nICMP is a control protocol, meaning that it is designed to carry information about the status of the network itself. It is essentially a network layer (OSI layer 3) error-reporting and error-control protocol for the network. The best-known examples of ICMP in practice are the ping and traceroute utilities. The ping utility uses ICMP to probe remote hosts for responsiveness and overall round-trip time of the probe messages. The traceroute utility uses ICMP to discover and trace network routes that the ICMP packets take when they travel to their destination.\n\nWhat developers need to know is that ICMP packets have no TCP or UDP port numbers that are associated with them because port numbers are a layer 4 (transport layer) construct.\n\n\n\n\n\n  TCP and UDP \n\nBoth Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are OSI layer 4 transport protocols. These protocols are used to pass the actual data. The main difference between TCP and UDP, from a developer's perspective, is how they handle packet order.\n\nTCP is a connection-oriented protocol, it guarantees that all sent packets reach the destination in the correct order.\n\nAlternatively, UDP is a connection-less protocol. Communication is datagram-oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach a destination and can arrive out of order, or possibly they don't arrive at all.\n\nTypically, UDP is used for real-time communication, where a little percentage of the packet loss rate is preferable to the overhead of a TCP connection.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-understanding-icp"},{"document_id":"ibmcld_15141-7808-9997","score":19.2470747478,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_04107-6095-8145","score":18.6878537809,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04107-7548-9466","score":18.6229774461,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_11891-7-2391","score":18.5774034649,"text":"\nSetting up Satellite as a Secure Gateway for on-prem solutions \n\nDeploy IBM Cloud Satellite as a secure solution for connecting resources in a protected on-premises environment to cloud resources.\n\n\n\n Satellite as a Layer 4 connection solution \n\nWhile you can set up many possible solutions to enable secure connections between your on-premises network and IBM Cloud, you can use Satellite to control client communications among your hybrid cloud deployments.\n\nFor example, you might use a minimal Satellite location deployment as an alternative to the [Secure Gateway solution](https:\/\/cloud.ibm.com\/docs\/SecureGateway?topic=SecureGateway-getting-started-with-sg). Satellite provides the same application-level transport through common ports as Secure Gateway, with greater client visibility and audit control. The Satellite Link functionality improves upon the Secure Gateway client experience with a highly available and secure-by-default communication between the cloud and on-premises networks, third-party clouds, or network edge.\n\nOn-premises setup with a Satellite location\n: A minimum deployment of Satellite includes using three RHEL 7 or 8 hosts to set up a Satellite location control plane. These hosts might be in your on-premises network or in other clouds. Then, you can attach more hosts to your location and deploy IBM Cloud managed services to run on these hosts. For example, you can deploy a Red Hat OpenShift cluster to your on-premises hosts that are attached to your Satellite location. Then, you can deploy any apps that need secure access to IBM Cloud to your Red Hat OpenShift cluster.\n\nSecure transport to IBM Cloud\n: Next, your on-premises client that runs on the location hosts can use [Satellite Link](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-cloud-createlink-location) as Layer 4 application transport between the location and other services that run in IBM Cloud or your own applications that run within IBM Cloud. You can use Satellite Link to create location endpoints, which allow resources in IBM Cloud to securely access a resource in your on-premises Satellite location, and cloud endpoints, which allow resources in your on-premises Satellite location to access a resource that runs anywhere outside of the Satellite location. To allow access to a resource, authorization must granted in the Link endpoint's access control list.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sg-usecase"},{"document_id":"ibmcld_14311-5070-5527","score":18.4639758002,"text":"\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)\n* [Administering NSX-T Layer 2 bridging](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/administration\/GUID-B4ABDE64-52BC-40F0-A560-670D3B7EAF7A.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06968-15099-17180","score":25.5901453578,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_16423-3286-5408","score":25.3002376454,"text":"\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_07117-1664-3943","score":25.2409163031,"text":"\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot-ingestion"},{"document_id":"ibmcld_00556-7-1696","score":23.632678766,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00510-5537-7566","score":22.5655206225,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00542-1321-3172","score":22.5004827524,"text":"\n* Health data, extra conditions apply to be covered in the [IBM Cloudant Dedicated Cluster Service Description](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/pdf\/6756-04\/$file\/i126-6756-04_05-2018_en_US.pdf) and [IBM Cloud\u00ae Additional Service Description](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/saas?OpenDocument).\n\n\n\nIf you're storing healthcare data, you must complete the following tasks:\n\n\n\n* Notify IBM Cloudant before you write any data.\n* Request a HIPAA-compliant Dedicated Cluster.\n\n\n\nFor more information about supported classifications of Personal Data, see the [Data Sheet Addendum (DSA) under 2. Personal Data](https:\/\/www.ibm.com\/software\/reports\/compatibility\/clarity-reports\/report\/html\/softwareReqsForProduct?deliverableId=2EBB5860B34311E7A9EB066095601ABB).\n\n\n\n\n\n Data about me \n\nIBM Cloudant records some data about its users, and is a Data Controller for said Personal Information (PI) data. The data that IBM Cloudant records depends on the type of account you have.\n\nIf you have an IBM Cloudant Dedicated Cluster or IBM Cloudant Enterprise Cluster, IBM Cloudant records data about you and are considered a Data Controller for your data within the context of GDPR. If you have an IBM Cloudant Dedicated Cluster or IBM Cloudant Enterprise Cluster, IBM Cloudant stores the following information about you:\n\n\n\n* Name\n* Email\n\n\n\nThe data that IBM Cloudant holds can be viewed and updated through the IBM Cloudant Dashboard.\n\nIf you have an account that is provisioned by IBM Cloud (including a dedicated instance), IBM Cloudant does not collect the personal data that was discussed earlier. This data is held by IBM Cloud.\n\nDo not use sensitive data for IBM Cloudant instance names when you provision by using IBM Cloud, such as: Personal Information (PI), Personal Identifying Information (PII), and Customer-specific Data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-general-data-protection-regulation-gdpr-"},{"document_id":"ibmcld_00576-7385-9302","score":22.4852834891,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_07232-1707-3805","score":22.3616547563,"text":"\nIf you crawl Box or Salesforce, a list of available resources is presented when you configure a source, using the Discovery tooling.\n* If you are using the Discovery tooling, you can configure a collection with a single data source.\n* Crawling a data source uses resources, namely API calls, of the data source. The number of API calls depends on the number of documents that need to be crawled. You must obtain an appropriate level of service license, for example Enterprise, for the data source. For information about the appropriate service level license that you need, contact the source system administrator.\n* Discovery source crawls do not delete documents that are stored in a collection, but you can manually delete them using the API. When a source is re-crawled, new documents are added, updated documents are modified to the current version, and deleted documents remain as the version last stored.\n* Discovery can only ingest the following file types, and it ignores all other document types:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* IBM Watson\u2122 Discovery supports crawling JSON and HTML documents, but you cannot edit these documents using the SDU editor. To change the configuration of HTML and JSON documents, you must use the API. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).\n\n** Individual image files, such as PNG, TIFF, and JPG, are scanned, and any text is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned, and any text is extracted.\n\nView the following table to see the objects that a data source can crawl and which data sources support crawling new and modified documents during a refresh:\n\n\n\nTable 1. Data sources that support crawling new and modified documents during refresh and objects that can be crawled\n\n Data source Crawls new and modified documents during refresh? Compatible objects that can be crawled \n\n Box (Application level access) No Files, folders","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources"},{"document_id":"ibmcld_00554-7-1717","score":22.077836084,"text":"\nHow is data stored in IBM Cloudant? \n\nEvery database in IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae is formed of one or more distinct shards, where the number of shards is referred to as Q. A shard is a distinct subset of documents from the database.\n\n\n\n Concepts \n\nAll Q shards together contain the data within a database. Each shard is stored in three separate copies. Each shard copy is called a shard replica. Each shard replica is stored on a different server. The servers are available within a single Region. If the Region supports Availability Zones, the replicas are stored on servers in different Zones. The collection of servers in a Region is called a cluster.\n\nZoom\n\n![A single database is split into Q shards, which are each stored in triplicate on three separate servers.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/sharding_database.svg)\n\nFigure 1. Data storage\n\nA document is assigned to a particular shard by using consistent hashing of its ID. This assignment means that a document is always stored on a known shard and a known set of servers.\n\nZoom\n\n![A single document is assigned to a single shard so ends up on three replicas on three separate servers.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/sharding_document.svg)\n\nFigure 2. Document consistent hashing\n\nOccasionally, shards are rebalanced. Rebalancing involves moving replicas to different servers. Rebalancing occurs for several reasons, for example, when server monitoring suggests that a server is more heavily or lightly used than other servers, or when a server must be taken out of service temporarily for maintenance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-"},{"document_id":"ibmcld_00510-7123-9213","score":21.8638992018,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2890648263}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10642-10731-12253","score":29.3957129215,"text":"\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud oc worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\noc describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>\nLabels: arch=amd64\nbeta.kubernetes.io\/arch=amd64\nbeta.kubernetes.io\/os=linux\nfailure-domain.beta.kubernetes.io\/region=us-south\nfailure-domain.beta.kubernetes.io\/zone=dal12","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10642-5227-6888","score":29.377586614,"text":"\nUpdate your API server and associated master components by using the [IBM Cloud console](https:\/\/cloud.ibm.com\/login) or running the CLI ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_update).\n5. Wait a few minutes, then confirm that the update is complete. Review the API server version on the IBM Cloud clusters dashboard or run ibmcloud oc cluster ls.\n6. Install the version of the [oc cli](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cli-install) that matches the API server version that runs in the master. Kubernetes does not support oc client versions that are two or more versions apart from the server version (n +\/- 2).\n\n\n\nWhen the master update is complete, you can update your worker nodes, depending on the type of cluster infrastructure provider that you have.\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10642-6354-8294","score":29.0653261942,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10642-7855-9754","score":28.3297582652,"text":"\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10290-118955-120623","score":28.2976717309,"text":"\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker rm command \n\nibmcloud oc worker rm --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker update \n\nClassic infrastructure\n\nUpdate worker nodes to apply the latest security updates and patches to the operating system, and to update the Kubernetes version to match the version of the Kubernetes master. You can update the master Kubernetes version with the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_update). Remember that your worker nodes can be only up to two versions behind the master version (n-2). The worker node IP address remains the same after the update operation.\n\nTo update a worker node in a VPC cluster, use the [ibmcloud oc worker replace command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) instead.\n\nRunning ibmcloud oc worker update can cause downtime for your apps and services. During the update, all pods are rescheduled onto other worker nodes, the worker node is reimaged, and data is deleted if not stored outside the pod. To avoid downtime, [ensure that you have enough worker nodes to handle your workload while the selected worker nodes are updating](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10642-9304-11080","score":28.2948554748,"text":"\nYou can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only. These rules do not impact worker node reloads which means reloading happens immediately when requested.\n\nWhat if I choose not to define a config map?\n: When the config map is not defined, the default is used. By default, a maximum of 20% of all your worker nodes in each cluster can be unavailable during the update process.\n\n\n\n Prerequisites \n\nBefore you update your classic infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is reimaged, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10197-7-2062","score":28.1149347726,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For Red Hat Openshift clusters, check the Red Hat OpenShift on IBM Cloud component.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"},{"document_id":"ibmcld_10068-145546-146168","score":28.0023857015,"text":"\nThe following table shows the changes that are in the worker node fix pack update 4.3.40_1546_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.40_1545_openshift\n\n Component Previous Current Description \n\n Ephemeral storage reservations N\/A N\/A Local ephemeral storage is reserved on the Kubernetes data disk for system components. For more information, see [Worker node resource reserves](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesresource_limit_node).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10510-17837-19983","score":27.9202670891,"text":"\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10290-110067-111621","score":27.8262917439,"text":"\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud oc worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud oc worker replace command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12439-7-1984","score":26.8817004447,"text":"\nComparison between Secrets Manager and related IBM Cloud services \n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you to protect your sensitive data and centralize your secrets. If you need to integrate general-purpose secrets to authenticate your apps, you can use Secrets Manager to create\n\ndynamic secretsand manage their lifecycle. But for other application secrets, such as encryption keys, your business might require a higher level of control that relies on highly secure, customer-controlled cryptographic hardware.\n\nFor example, consider the following scenarios and how they map to secrets management offerings and data protection offerings in IBM Cloud.\n\nZoom\n\n![The image describes three use cases for secrets management and how they map to available services in IBM Cloud. The content is explained fully in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/secrets-mgmt-options.svg)\n\nFigure 1. Secrets management use cases\n\n\n\n Which data protection service is best for me? \n\nThe following table lists the different offerings that you can use with IBM Cloud to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n As a DevOps team contributor, you need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. With [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager), you can manage secrets of various types in a dedicated instance. \n You need to generate, renew, and manage SSL\/TLS certificates for your deployments. You can also manage your SSL\/TLS certificates and private keys in dedicated instance of [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager). \n You need to create and manage encryption keys that are backed by FIPS 140-2 Level 3 validated hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud"},{"document_id":"ibmcld_12435-5067-6856","score":25.633196956,"text":"\n\"key1\": \"val1\",\n\"key2\": \"val2\"\n},\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\"\n\nA successful response returns the ID value of the secret, along with other metadata. For more information about the required and optional request parameters, see [Create a secret](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2create-secret).\n\n\n\n\n\n Creating key-value secrets with Terraform \n\nYou can create key-value secrets programmatically by using Terraform for Secrets Manager.\n\nFollow Terraform best practices for protecting sensitive input variables such as secret credentials. For more information, see [Protect sensitive input variables](https:\/\/developer.hashicorp.com\/terraform\/tutorials\/configuration-language\/sensitive-variables).\n\nThe following example shows a configuration that you can use to create a key-value secret by setting sensitive values in a terraform.tfvars file.\n\n\n\n1. Define an input variable for the key-value secret data in a variables.tf file.\n\n\n\nvariable \"kv_secret_data\" {\ndescription = \"KV secret data\"\ntype = map(any)\nsensitive = true\n}\n\n\n\n2. Assign a value to the kv_secret_data variable in a terraform.tfvars file.\n\nBy setting values with a .tfvars file, you can separate sensitive values from the rest of your variable values, and ensure that your users who work with your configuration know which values are sensitive. For security purposes, you must maintain and share the .tfvars file only with your users who have the appropriate access. You must also be careful not to store .tfvars files with sensitive values into version control such as Github, in clear text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value"},{"document_id":"ibmcld_07982-7-2122","score":25.4138458054,"text":"\nHandling and securing secrets \n\nA secret is any piece of data that is sensitive within the context of an application or service. Secrets must be securely protected through their entire lifecycle.\n\nSecrets include all of the following but are not limited to:\n\n\n\n* Passwords of any type (database logins, OS accounts, functional IDs, and so on)\n* API keys\n* Long-lived authentication tokens (OAuth2, GitHub, IAM, and so on)\n* SSH keys\n* Encryption keys\n* Other private keys (PKI\/TLS certificates, HMAC keys, signing keys, and so on)\n\n\n\nApplication providers should ensure:\n\n\n\n* Secrets are generated and stored in the environment (for example, dev, test, and production) where your service is deployed.\n* Secrets never leave their environments (for example, dev, test, and production) and should be secured by using access control measures. Service design should minimize the number of machines and people with access to secrets by using both authorization and network restrictions based on the principle of least privilege.\n* Secrets are rotated in according with the requirements of the IBM Cloud Framework for Financial Services with minimal or no downtime.\n* Secrets are never stored in source code, configuration files, or documentation.\n\n\n\nThe following table lists the different solutions that you can use to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n You need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. Use [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started). \n You need to generate, renew, and manage TLS\/SSL certificates for your deployments. Use [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started). \n You need to create and manage encryption keys. Use [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overview) to manage encryption keys in a single-tenant service with dedicated hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-secrets"},{"document_id":"ibmcld_12371-4-1766","score":24.5539905393,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Storing arbitrary secrets \n\nYou can use IBM Cloud\u00ae Secrets Manager to store arbitrary secrets that are used to access protected systems that are inside or outside of IBM Cloud.\n\nAn arbitrary secret is a type of application secret that can be used to hold structured or unstructured data, such as a key, configuration file, or any other piece of sensitive information. After you create the secret, you can use it to connect your application to a protected resource, such as a third-party app or database. Your secret is stored securely in your dedicated Secrets Manager service instance, where you can centrally manage its lifecycle.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n\n\n Creating arbitrary secrets in the UI \n\nTo add an arbitrary secret by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets table, click Add.\n4. From the list of secret types, click the Other secret type tile.\n5. Click Next.\n6. Add a name and description to easily identify your secret.\n7. Select the\n\nsecret groupthat you want to assign to the secret.\n\nDon't have a secret group?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets"},{"document_id":"ibmcld_12942-5996-7891","score":24.4974145712,"text":"\nYou can use a toolchain secret reference for this parameter. For more information about secret references, see [Protecting your sensitive data in Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_securitycd_secure_credentials). \n secret_filter optional, updatable String secret_filter A regular expression to filter the list of secret names that are returned from your HashiCorp Vault instance. \n secret_id optional, updatable Password secret_id The authentication secret ID for your HashiCorp Vault instance when you use the approle authentication method. This parameter is ignored for other authentication methods. You can use a toolchain secret reference for this parameter. For more information about secret references, see [Protecting your sensitive data in Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_securitycd_secure_credentials). \n server_url required, updatable String server_url The server URL for your HashiCorp Vault instance. \n token optional, updatable Password token The authentication token for your HashiCorp Vault instance when you use the github and token authentication methods. This parameter is ignored for other authentication methods. You can use a toolchain secret reference for this parameter. For more information about secret references, see [Protecting your sensitive data in Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_securitycd_secure_credentials). \n username optional, updatable String username The authentication username for your HashiCorp Vault instance when you use the userpass authentication method. This parameter is ignored for other authentication methods. \n\n\n\n\n\n\n\n Learn more about HashiCorp Vault \n\nTo learn more about HashiCorp Vault, see [HashiCorp Vault](https:\/\/www.vaultproject.io\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-hashicorpvault"},{"document_id":"ibmcld_12435-4-1798","score":23.9912827012,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Storing key-value secrets \n\nYou can use IBM Cloud\u00ae Secrets Manager to store and manage key-value secrets, including complex JSON documents, that are used to access protected systems that are inside or outside of IBM Cloud.\n\nA key-value secret is a type of application secret that can be used to hold sensitive data that is structured as a JSON object. After you create the secret, you can use it to connect your application to a protected resource, such as a database or a third-party app. Your secret is stored securely in your dedicated Secrets Manager service instance, where you can centrally manage its lifecycle.\n\nYou can store multiple versions per key and access the history and metadata of your key-value secret with Secrets Manager. For more information, see [Managing key-value secrets with Vault](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-manage-kv).\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n\n\n Creating key-value secrets in the UI \n\nTo add a key-value secret by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the IBM Cloud console, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets table, click Add.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value"},{"document_id":"ibmcld_09081-7-2309","score":23.604455934,"text":"\nProtecting data with envelope encryption \n\nKey Protect uses envelope encryption to assist in protecting your Key Protect data. Envelope encryption involves encrypting your data with a Data Encryption Key, then encrypting the Data Encryption Key with a root key. This topic describes the process of envelope encryption and how to use Key Protect to encrypt and decrypt your data.\n\nWhen working with sensitive data, it is important to use advanced encryption techniques to prevent a data breach. If you have large amounts of confidential data, it is often helpful to use a Key Management System to assist in keeping your data secure. Key Protect uses the envelope encryption technique to keep your data resilient. Envelope encryption is the process of using encrypted keys, Data Encryption Keys and Root Keys, to protect your sensitive data.\n\nImagine that you plan to send a letter to a colleague. You want to discuss information that is highly sensitive, so you generate a secret code (Data Encryption Key) that is used to write (encrypt) the message in the letter. The letter is delivered to a mailbox (wrapped Data Encryption Key) that can only be opened by those with a copy of the mailbox key (Root key), including the colleague. Anyone who does not have an exact copy of the key will be unable to open the mailbox and see it's contents. When your colleague uses the key to unlock (unencrypt) the mailbox, they will need to know the secret code that the letter is written in to be able to understand the message. Everyone who is not aware of the secret code will conclude that the letter is a random mix of characters and will not be able to understand the letter's contents.\n\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_10916-69092-70947","score":23.5626892221,"text":"\nA catalog in which approvals for publishing and lifecycle actions are bypassed so that it can be used for testing APIs under development.\n\n\n\n\n\n scale \n\nTo increase platform (or system) capacity by adding more application or service instances\n\n\n\n\n\n SCM \n\nSee [source control management](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx3579285).\n\n\n\n\n\n scope \n\nA grouping of resources that can be validated or evaluated for security and compliance. See also [rule](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2037526), [profile](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2034950).\n\n\n\n\n\n secret \n\nA type of sensitive information, such as a password or an API key, that is used by an application to access a protected resource. See also [dynamic secret](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx9968958).\n\n\n\n\n\n secret group \n\nThe environment and constraints that contained secrets in an instance must adhere to. A user can be associated with a secret group to enable access and collaboration.\n\n\n\n\n\n secrets engine \n\nA component that serves as a back end for a specific type of secret, such as a password or an API key, within a secrets management service. Depending on its type, a secrets engine can store data, generate secrets on demand, and more. See also [dynamic secret](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx9968958).\n\n\n\n\n\n Secure Shell (SSH) \n\nA network protocol for secure data exchange between two networked devices. The client can use public-key and private-key authentication, or password authentication, to access the remote server.\n\n\n\n\n\n Secure Sockets Layer (SSL) \n\nA security protocol that provides communication privacy. With SSL, client\/server applications can communicate in a way that is designed to prevent eavesdropping, tampering, and message forgery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_11720-1745-3784","score":23.4829605006,"text":"\n* Satellite resources, such as the names of locations, hosts, Satellite Link endpoints, Satellite configurations, versions, subscriptions, cluster group names, or storage configurations.\n* [Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services) resources, such as the names of service instances or clusters.\n* Managed Kubernetes resources that run in clusters in your Satellite location, such as the names and resource definitions of deployments, pods, services, secrets, or config maps.\n* The definitions of resources managed by Satellite config, including their data. Sensitive keys or personally identifiable information should be managed with Secrets Manager, or encrypted with Key Protect.\n* Any other resources that run in your Satellite location.\n\n\n\n\n\n\n\n\n\n How is my information stored, backed up, and encrypted when using Satellite? \n\nReview the following image to see how your personal and sensitive information is stored, backed up, and encrypted.\n\nZoom\n\n![Satellite data security](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c8335d66af691d19e837116fd633481c477061eb\/satellite\/images\/satellite_data_security.svg)\n\nFigure 1. Satellite data security\n\n(1) All personal and sensitive information\n: Review the location, access, backup and encryption details for personal and sensitive information.\n\n\n\n* Location: All data is stored in a Satellite persistent storage instance in the location's Satellite control plane master.\n* Access and data management: The persistent storage instance is owned and managed by the Satellite control plane service team. You cannot access the data in the persistent storage instance.\n* Backup: See 2 and 3 to see how data is backed up.\n* Encryption: Data is encrypted at rest with a customer root key from an IBM-owned IBM Key Protect service instance.\n\n\n\n(2) TLS certificate, TLS secret, and Certificate Authority to encrypt the Satellite control plane domain\n: Review the location, access, backup and encryption details for TLS secret and CA information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-data-security"},{"document_id":"ibmcld_12371-6291-8165","score":23.1858159046,"text":"\n\"secret_group_id\": \"67d025e1-0248-418f-83ba-deb0ebfb9b4a\",\n\"secret_type\": \"arbitrary\",\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"} }' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\"\n\nA successful response returns the ID value of the secret, along with other metadata. For more information about the required and optional request parameters, check out the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2create-secret).\n\n\n\n\n\n Creating arbitrary secrets with Terraform \n\nYou can create arbitrary secrets programmatically by using Terraform for Secrets Manager.\n\nFollow Terraform best practices for protecting sensitive input variables such as secret credentials. For more information, see [Protect sensitive input variables](https:\/\/developer.hashicorp.com\/terraform\/tutorials\/configuration-language\/sensitive-variables).\n\nThe following example shows a configuration that you can use to create an arbitrary secret by setting sensitive values in a terraform.tfvars file.\n\n\n\n1. Define an input variable for the arbitrary secret payload in a variables.tf file.\n\n\n\nvariable \"arbitrary_secret_payload\" {\ndescription = \"Arbitrary secret payload\"\ntype = string\nsensitive = true\n}\n\n\n\n2. Assign a value to the arbitrary_secret_payload variable in a terraform.tfvars file.\n\nBy setting values with a .tfvars file, you can separate sensitive values from the rest of your variable values, and ensure that your users who work with your configuration know which values are sensitive. For security purposes, you must maintain and share the .tfvars file only with your users who have the appropriate access. You must also be careful not to store .tfvars files with sensitive values into version control such as Github, in clear text.\n\narbitrary_secret_payload = \"my sensitive arbitrary payload\"\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-891912-893651","score":18.5640732839,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":18.5640732839,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14984-13428-15314","score":18.5244623362,"text":"\nThe instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6. Optionally, increase the size of the volume within the specified range.\n7. Click Save. The side panel closes and messages indicate that the restored volume is being attached to the instance.\n\n\n\nThe new volume appears in the list of Storage volumes. Hover over the camera icon to see the name of the backup snapshot from which it was created.\n\n\n\n\n\n\n\n Restoring a volume from a snapshot from the CLI \n\nUse the CLI to create a boot or data volume from a backup snapshot. The commands are the same as the ones that are used to restore a volume from a manually created snapshot. For more information, see [Restore a volume from a snapshot with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=clisnapshots-vpc-restore-CLI).\n\nFor more information about all backup service commands, see the [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n Restoring a volume from a backup snapshot with the API \n\nYou can restore boot and data volumes from a backup snapshot with the VPC API. To begin, make a GET \/snapshots request to see a list of snapshots. You can filter by resource group and source volume ID in the request.\n\n\n\n* To restore a boot volume from a bootable backup snapshot, specify the boot volume attachment and snapshot ID in the POST \/instances request.\n* To restore a data volume from a backup snapshot and attach it, specify the data volume attachment and snapshot ID in the POST \/instances request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_14996-13519-15405","score":18.5244623362,"text":"\nThe instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6. Optionally, increase the size of the volume within the specified range.\n7. Click Save. The side panel closes and messages indicate that the restored volume is being attached to the instance.\n\n\n\nThe new volume appears in the list of Storage volumes. Hover over the camera icon to see the name of the backup snapshot from which it was created.\n\n\n\n\n\n\n\n Restoring a volume from a snapshot from the CLI \n\nUse the CLI to create a boot or data volume from a backup snapshot. The commands are the same as the ones that are used to restore a volume from a manually created snapshot. For more information, see [Restore a volume from a snapshot with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=clisnapshots-vpc-restore-CLI).\n\nFor more information about all backup service commands, see the [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n Restoring a volume from a backup snapshot with the API \n\nYou can restore boot and data volumes from a backup snapshot with the VPC API. To begin, make a GET \/snapshots request to see a list of snapshots. You can filter by resource group and source volume ID in the request.\n\n\n\n* To restore a boot volume from a bootable backup snapshot, specify the boot volume attachment and snapshot ID in the POST \/instances request.\n* To restore a data volume from a backup snapshot and attach it, specify the data volume attachment and snapshot ID in the POST \/instances request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_14996-2951-4749","score":18.4693971919,"text":"\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_14984-3011-4697","score":18.261098194,"text":"\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_15034-3931-5816","score":18.2542239095,"text":"\nWhen you restore a volume from a snapshot, and the tags that are applied to the new volume match the tags in a backup policy, the new volume is backed up. But you can't directly back up a snapshot that has tags in a backup policy.\n\n\n\n\n\n How long are backups retained? \n\nYou can specify that backups be kept 1 - 30 days (default). The retention period can't be shorter than the backup frequency or it returns an error.\n\nYou can also specify the number of backups to retain, up to 750 per volume, after which the oldest backups are deleted.\n\n\n\n\n\n Are there limitations on how many backups I can take? \n\nYes. You can create 10 backup policies per account and up to 750 backups of a volume. For other limitations of this release, see [Limitations in this release](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-limitations).\n\n\n\n\n\n How do I create a new volume from a backup? \n\nRestoring from a backup snapshot creates a volume with data from the snapshot. You can restore data from a backup by using the UI, the CLI, or the API. You can restore boot and data volumes during instance creation, when you modify an existing instance, or when you provision a stand-alone volume. When you restore data from a backup snapshot, the data is pulled from an Object Storage bucket. For best performance, you can enable backup snapshots for fast restore. By using the fast restore feature, you can restore a volume that is fully provisioned when the volume is created. When you use fast restore, the data is pulled from a cached backup snapshot in another zone of your VPC. For more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Am I charged for usage? \n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-vpc-faq"},{"document_id":"ibmcld_15007-13930-15825","score":18.1914421713,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15020-13969-15864","score":18.1914421713,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_14996-1525-3435","score":18.1855257992,"text":"\nAfter the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. For more information, see [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\nTo restore a volume, the backup snapshot must be in a stable state.\n\nYou can't simultaneously restore a boot and a data volume.\n\n\n\n Restoring from a bootable backup \n\nWhen you restore from a bootable backup snapshot, you create a boot volume that you use to provision another instance. The boot volume uses a general-purpose profile and is limited to 250 GB. Because the bootable backup snapshot is not fully provisioned, in the beginning the performance is slower than when you use a regular boot volume. For more information, see [Performance impact](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-boot-perf).\n\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1175161048}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03068-34858-36104","score":29.9538716273,"text":"\nTo check whether the updated cacerts file is present in the configmap, run the oc get configmap watson-assistant-skill-cacerts --output yaml command.\n5. Override the cacerts file in the search skill pods. In this step, you configure the Watson Assistant operator to override the cacerts file in the search skill pods with the updated cacerts file. In the following example file, the Watson Assistant instance is called watson-assistant---wa. Replace this value with the name of your instance:\ncat <<EOF | oc apply -f -\nkind: TemporaryPatch\napiVersion: com.ibm.oppy\/v1\nmetadata:\nname: watson-assistant---wa-skill-cert\nspec:\napiVersion: com.ibm.watson.watson-assistant\/v1\nkind: WatsonAssistantSkillSearch\nname: \"watson-assistant---wa\" Replace this with the name of your Watson Assistance instance\npatchType: patchStrategicMerge\npatch:\n\"skill-search\":\ndeployment:\nspec:\ntemplate:\nspec:\nvolumes:\n- name: updated-cacerts\nconfigMap:\nname: watson-assistant-skill-cacerts\ndefaultMode: 420\ncontainers:\n- name: skill-search\nvolumeMounts:\n- name: updated-cacerts\nmountPath: \/opt\/ibm\/java\/jre\/lib\/security\/cacerts\nsubPath: cacerts\nEOF\nShow more\n6. Wait until new search skill pods are created. It might take up to 10 minutes before the updates take affect.7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-troubleshoot"},{"document_id":"ibmcld_03121-4-1692","score":29.6506891264,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Working with your assistant \n\nLearn how to find and open assistants and skills that you created or can access.\n\nAssistants and skills are created within a Watson Assistant service instance. To continue working with a skill or assistant, open the service instance that contains the skill or assistant. If you can't remember the service instance name, you can switch between instances from within the Watson Assistant user interface.\n\n\n\n1. Go to the [IBM Cloud Resource list](https:\/\/cloud.ibm.com).\n2. Log in.\n\nA list of the service instances that you own or were given access to is displayed.\n3. Click a service instance to open it.\n4. Click Launch Watson Assistant from the service instance details page to open the product in a new browser tab or window.\n5. Click the appropriate icon from the navigation pane to see a list of your assistants or skills.\n\n\n\n* ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-ass-icon.png) Assistants\n* ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-skills-icon.png) Skills\n\n\n\n\n\nIf you do not see the skill or assistant you are looking for, you can look for it in a different service instance.\n\n\n\n Switching the service instance \n\nTo switch to a different Watson Assistant service instance, complete the following steps:\n\n\n\n1. From the header of any page in the current instance, click the User icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settings"},{"document_id":"ibmcld_07018-7974-8883","score":29.4423429216,"text":"\nTo deploy a Conversational Search project, connect this project to an assistant that is built with Watson Assistant. The general steps to follow include:\n\n\n\n1. Create an assistant.\n\nYou can use a Watson Assistant Trial plan for testing purposes.\n2. Add a search skill to your assistant, and then connect it to this project.\n3. Deploy your assistant.\n\nFor more information about building a Watson Assistant search skill, see the appropriate documentation for your deployment:\n\n\n\nIBM Cloud\n\nFrom the new experience, see [Adding a search integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add).\nIBM Cloud\n\nFrom the classic experience, see [Embedding existing help content](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\nIBM Cloud Pak for Data\n\n[Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy"},{"document_id":"ibmcld_03118-1768-3298","score":29.1480388802,"text":"\n(Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes. If you use the v1 \/message method, you must implement your own state management, and you cannot take advantage of versioning or any of the other features of an assistant.\n\n\n\n\n\n Authoring applications \n\nThe v1 API provides methods that enable an application to create or modify dialog skills, as an alternative to building a skill graphically using the Watson Assistant user interface. An authoring application uses the API to create and modify skills, intents, entities, dialog nodes, and other artifacts that make up a dialog skill. For more information, see the [v1 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1).\n\nNote: The v1 authoring methods create and modify workspaces rather than skills. A workspace is a container for the dialog and training data (such as intents and entities) within a dialog skill. If you create a new workspace using the API, it will appear as a new dialog skill in the Watson Assistant user interface.\n\nFor a list of the available API methods, see [API methods summary](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-methods).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_03329-4-1522","score":29.086673175,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Getting started with a dialog skill \n\nIn this short tutorial, we help you use a dialog skill to build your first conversation.\n\nA dialog skill uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n\n\n\n Step 1: Create an assistant \n\nAn assistant is a cognitive bot to which you add skills that enable it to interact with your customers in useful ways.\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-ass-icon.png), and then click Create assistant.\n\n![Create assistant button on the Assistants page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant.png)\n2. Name the assistant My first assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_03381-4-1869","score":28.9667037415,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_16245-1169-2070","score":28.8670100215,"text":"\nFor more information, see [Calling actions from a dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-call-action).\n\n\n\n\n\n Migrating existing skills \n\nOnce the dialog feature is activated, you can start a new dialog conversation from scratch if you want. But, you probably have an existing dialog skill that you want to migrate into the new Watson Assistant.\n\nTo migrate an existing dialog skill:\n\n\n\n1. Use the classic experience to [download your dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) in JSON format.\n2. In the new Watson Assistant, open the Dialog page.\n3. In Options, choose Upload \/ Download.\n\n![Upload dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/dialog-upload.png)\n4. On the Upload tab, upload the JSON file for your dialog skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-activate-dialog"},{"document_id":"ibmcld_03139-4-1679","score":28.6995658433,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Backing up and restoring data \n\nBack up and restore your data by downloading, and then uploading the data.\n\nYou can download the following data from a Watson Assistant service instance:\n\n\n\n* Dialog skill training data (intents and entities)\n* Dialog skill dialog\n* Actions skill\n\n\n\nYou cannot download the following data:\n\n\n\n* Search skill\n* Assistant, including any configured integrations\n\n\n\n\n\n Retaining logs \n\nIf you want to store logs of conversations that users have had with your assistant, you can use the \/logs API to export your log data. See [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs) for details.\n\nTo get the workspace ID for a skill, from the skill tile, click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose View API Details.\n\nLogs are stored for a different amount of time depending on your service plan. For example, Lite plans provide logs from the past 7 days only. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for more information.\n\nYou cannot import logs from one skill into another skill.\n\n\n\n\n\n Downloading a skill \n\nTo back up actions or dialog skill data, download the skill as a JSON file, and store the JSON file.\n\n\n\n1. Find the actions or dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_03353-4-2000","score":28.6502056316,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03411-4-2097","score":28.6449779044,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing workflow with versions \n\nVersions help you manage the workflow of a dialog skill development project.\n\nCreate a skill version to capture a snapshot of the training data (intents and entities) and dialog in the skill at key points during the development process. Being able to save an in-progress skill at a specific point in time is especially useful as you start to fine tune your assistant. You often need to make a change and see the impact of the change in real time before you can determine whether or not the change improves or lessens the effectiveness of the assistant. Based on your findings from a test environment deployment, you can make an informed decision about whether to deploy a given change to an assistant that is deployed in a production environment.\n\nIf you have a free (Lite) plan, you cannot create skill versions.\n\nTo learn more about how versions can improve the workflow you use to build an assistant, [read this blog post](https:\/\/medium.com\/ibm-watson\/watson-assistant-versions-announcement-d60869b1f5f).\n\n\n\n Creating a version \n\nYou can edit only one version of the dialog skill at a time. The in-progress version is called the development version.\n\nWhen you save a version, any skill settings that you applied to the development version are saved also.\n\nTo create a dialog skill version, follow these steps:\n\n\n\n1. From the header of the skill, click Save new version, and then describe the current state of the skill.\n\nAdding a good description will help you to distinguish multiple versions from one another later.\n\nAdd the date you deploy the version to its description to make it easier to filter logs by version from the Analytics page later. For more information, see [Picking a data source](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-pick-data-source).\n2. Click Save.\n\n\n\nA snapshot is taken of the current skill and saved as a new version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05525-70102-71582","score":23.5653145028,"text":"\nKubernetes v1.13.5 v1.14.1 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.14.1) and [Kubernetes 1.14 blog](https:\/\/kubernetes.io\/blog\/2019\/03\/25\/kubernetes-1-14-release-announcement\/). <br>The Kubernetes default role-based access control (RBAC) policies no longer grant access to [discovery and permission-checking APIs to unauthenticated users](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/rbac\/discovery-roles). This change applies only to new version 1.14 clusters. If you update a cluster from a prior version, unauthenticated users still have access to the discovery and permission-checking APIs. \n Kubernetes admission controllers configuration N\/A N\/A <br><br> * Added NodeRestriction to the --enable-admission-plugins option for the cluster's Kubernetes API server and configured the related cluster resources to support this security enhancement.<br> * Removed Initializers from the --enable-admission-plugins option and admissionregistration.k8s.io\/v1alpha1=true from the --runtime-config option for the cluster's Kubernetes API server because these APIs are no longer supported. Instead, you can use [Kubernetes admission webhooks](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/).<br><br><br> \n Kubernetes DNS autoscaler 1.3.0 1.4.0 See the [Kubernetes DNS autoscaler release notes](https:\/\/github.com\/kubernetes-sigs\/cluster-proportional-autoscaler\/releases\/tag\/1.4.0).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-114_changelog"},{"document_id":"ibmcld_14497-2717-4672","score":19.2083727454,"text":"\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.\n* Bootstrap node - As each node in the cluster requires information about the cluster when it is provisioned, a temporary bootstrap node is used. The bootstrap node creates the control plane nodes that make up the control plane. The control plane nodes then create the worker nodes. After the cluster initializes, the bootstrap node can be destroyed.\n* Control-plane nodes - These nodes run services that are required to control the Kubernetes cluster. They contain more than just the Kubernetes services for managing the cluster. The terms \"primary\" and \"control-plane\" are used interchangeably.\n* Compute nodes - In a Kubernetes cluster, the compute nodes are where the workloads are run. The compute nodes advertise their capacity to the control-plane nodes.\n* DNS - A correct DNS setup is imperative for a functioning Red Hat OpenShift cluster. The vCenter Server instance AD DNS server to host the required DNS records.\n* Load-balancer - An NSX ESG load-balancer service is used to front end the Red Hat OpenShift APIs, both internal and external, and the Red Hat OpenShift router. The load balancer is configured so that Port 6443 and 22623 point to the bootstrap and control plane nodes, while ports 80 and 443 are configured to point to the worker nodes.\n* Webserver - A web server is needed to hold the ignition configurations and installation images for the installation of RHEL CoreOS. NGINX is installed on the bastion node to provide this function.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_06004-39237-41150","score":19.0442977677,"text":"\nKubernetes network policies can also help you enforce workload isolation between namespaces by controlling how pods and services in different namespaces can communicate. For clusters that run Kubernetes 1.21 and later, the service account tokens that pods use to communicate with the Kubernetes API server are time-limited, automatically refreshed, scoped to a particular audience of users (the pod), and invalidated after the pod is deleted. To continue communicating with the API server, you must design your apps to read the refreshed token value on a regular basis, such as every minute. For more information, see [Bound Service Account Tokens](https:\/\/github.com\/kubernetes\/enhancements\/blob\/master\/keps\/sig-auth\/1205-bound-service-account-tokens\/README.md).\n\n\n\n\n\n Managing access and monitoring app health \n\nAfter you deploy your app, you can control who can access the app, and monitor the health and performance of the app.\n\n\n\n How can I control who has access to my app deployments? \n\nThe account and cluster administrators can control access on many different levels: the cluster, Kubernetes namespace, pod, and container.\n\nWith IBM Cloud IAM, you can assign permissions to individual users, groups, or service accounts at the cluster-instance level. You can scope cluster access down further by restricting users to particular namespaces within the cluster. For more information, see [Assigning cluster access](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-usersusers).\n\nTo control access at the pod level, you can configure [pod security policies (PSPs)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-psp).\n\nWithin the app deployment YAML, you can set the security context for a pod or container. For more information, review the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/security-context\/).\n\nWant to control access at the application level?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_10510-63266-65518","score":18.8470463107,"text":"\nYou can also configure a single-tenant cluster to allow privileged pods without putting other tenants at risk of being compromised. Keep in mind that managing a cluster requires in-depth Kubernetes, Red Hat OpenShift, and infrastructure knowledge to ensure cluster capacity and security for your deployments.\n\nMulti-tenant clusters use Red Hat OpenShift projects to isolate tenants and are usually managed by a separate team that does not belong to one of the tenants. A multi-tenant cluster might be your option if you have multiple teams that must run small workloads in a cluster, and where creating a single-tenant cluster that is highly available across multiple zones does not bring the cost benefits that you want. While multi-tenant clusters usually require fewer people to manage and administer the cluster, they might not provide the level of isolation that you need and add more complexity in the following areas:\n\n\n\n* Access: When you set up multiple projects, you must configure proper RBAC policies for each project to ensure resource isolation. RBAC policies are complex and require in-depth Kubernetes knowledge.\n* Privileged pods: If one tenant in a multi-tenant cluster requires to run privileged pods, this pod can access other projects in the cluster or damage the shared compute host. Controlling privileged pods is a complex task that requires effort and deep technical expertise. Use [security context constraints (SCCs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_sccoc_sccs) to control what resources your tenants can deploy in the cluster.\n* Network policies: Because your worker nodes are connected to the same private network, you must make sure that you have strict network policies in place to prevent pods from accessing pods in other namespaces.\n* Compute resource limitation: To ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) for every namespace. Resource quotas determine the deployment constraints for a project, such as the number of Kubernetes resources that you can deploy, and the amount of CPU and memory that can be consumed by those resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06063-62476-64570","score":18.7345932045,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_single_multitenant.png)\n\nFigure 1. Single tenant versus multi-tenant cluster\n\nDeciding between single-tenant and multi-tenant clusters depends on the number of teams that must run workloads in a cluster, their service requirements, the size of the service, and the level of isolation that you want to achieve for your workloads.\n\nA single-tenant cluster might be your option if you have many teams with complex services that each must have control over the lifecycle of the cluster. This includes having the freedom to decide when a cluster is updated or what resources can be deployed to the cluster. You can also configure a single-tenant cluster to allow privileged pods without putting other tenants at risk of being compromised. Keep in mind that managing a cluster requires in-depth Kubernetes and infrastructure knowledge to ensure cluster capacity and security for your deployments.\n\nMulti-tenant clusters use Kubernetes namespaces to isolate tenants and are usually managed by a separate team that does not belong to one of the tenants. A multi-tenant cluster might be your option if you have multiple teams that must run small workloads in a cluster, and where creating a single-tenant cluster that is highly available across multiple zones does not bring the cost benefits that you want. While multi-tenant clusters usually require fewer people to manage and administer the cluster, they might not provide the level of isolation that you need and add more complexity in the following areas:\n\n\n\n* Access: When you set up multiple namespaces, you must configure proper RBAC policies for each namespace to ensure resource isolation. RBAC policies are complex and require in-depth Kubernetes knowledge.\n* Privileged pods: If one tenant in a multi-tenant cluster requires to run privileged pods, this pod can access other namespaces in the cluster or damage the shared compute host. Controlling privileged pods is a complex task that requires effort and deep technical expertise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_10439-42889-44657","score":18.669387205,"text":"\nFor clusters that run Kubernetes 1.21 and later, the service account tokens that pods use to communicate with the Kubernetes API server are time-limited, automatically refreshed, scoped to a particular audience of users (the pod), and invalidated after the pod is deleted. To continue communicating with the API server, you must design your apps to read the refreshed token value on a regular basis, such as every minute. For more information, see [Bound Service Account Tokens](https:\/\/github.com\/kubernetes\/enhancements\/blob\/master\/keps\/sig-auth\/1205-bound-service-account-tokens\/README.md).\n\n\n\n\n\n Managing access and monitoring app health \n\nAfter you deploy your app, you can control who can access the app, and monitor the health and performance of the app.\n\n\n\n How can I control who has access to my app deployments? \n\nThe account and cluster administrators can control access on many different levels: the cluster, Red Hat OpenShift project, pod, and container.\n\nWith IBM Cloud IAM, you can assign permissions to individual users, groups, or service accounts at the cluster-instance level. You can scope cluster access down further by restricting users to particular namespaces within the cluster. For more information, see [Assigning cluster access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersusers).\n\nTo control access at the pod level, you can configure [security context constraints (SCCs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_sccoc_sccs).\n\nWithin the app deployment YAML, you can set the security context for a pod or container. For more information, review the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/security-context\/).\n\nWant to control access at the application level?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_05557-7-1853","score":18.6514731306,"text":"\nAccessing the cluster master with admission controllers and webhooks \n\nAdmission controllers intercept authorized API requests from various Kubernetes resources before the requests reach the API server that runs in your IBM Cloud Kubernetes Service cluster master. Mutating admission webhooks might modify the request, and validating admission webhooks check the request. If either webhook rejects a request, the entire request fails. Advanced features, whether built-in or added on, often require admission controllers as a security precaution and to control what requests are sent to the API server. For more information, see [Using Admission Controllers](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/) and [Dynamic Admission Control](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/) in the Kubernetes documentation.\n\n\n\n What are the default admission controllers in my cluster? \n\nReview the order of default admission controllers by cluster version in the [kube-apiserver component reference information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-settingskube-apiserver).\n\n\n\n\n\n Can I create my own admission controllers? \n\nYes, see the [Kubernetes](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/) documentation for more information.\n\nAs noted in the Kubernetes documentation, you can use admission controllers for operations that are otherwise handled by the control plane. As such, take great caution when you configure a custom admission controller. You are responsible for any changes that happen in your cluster because of a custom admission controller.\n\n\n\n\n\n What are the best practices for using webhooks? \n\nKeep in mind the following best practices and considerations when you configure a webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooks"},{"document_id":"ibmcld_12666-2025-3606","score":18.2937406982,"text":"\nAdditionally, the workstation must have a directory with write permissions and sufficient storage to store the backup. 125GB of storage space is sufficient for all deployments.\n\nTo take a backup, follow these steps:\n\n\n\n1. Access the cluster where Data Security Broker Manager is deployed by logging into a Kubernetes or Red Hat OpenShift workstation.\n2. To back up the MongoDB collections and Data Security Broker Manager configuration files, create the script provided below and execute it. The location that is specified after the -b option is where the backup file is kept by the script. Check whether the script is being used to back up a Data Security Broker Manager deployment on a Red Hat OpenShift cluster or a Kubernetes cluster, and uncomment the relevant command alias for the specified type of cluster where Data Security Broker Manager is installed.\n\n\n\n!\/bin\/bash\nif [ $ -eq 0 ]\nthen\necho \"No arguments supplied\"\necho \"Usage: $0 -b <backup location> -n <k8s namespace>\"\nfi\n\nwhile getopts b:n: flag\ndo\ncase \"${flag}\" in\nb) backup=${OPTARG};;\nn) namespace=${OPTARG};;\nesac\ndone\n\nif [ -z \"${backup}\" ];\nthen\necho \"Please provide backup location with -b option\"\nexit\nfi\n\nif [! -d \"$backup\" ];\nthen\necho \"Please provide a valid backup location with -b option\"\nexit\nfi\n\nif [ -z \"${namespace}\" ];\nthen\necho \"Please provide a valid namespace with -n option\"\nexit\nfi\n\n NOTE: SET THE kb ALIAS TO THE CORRECT ONE FOR THE CLUSTER TYPE\n\n For Kubernetes\nkb='kubectl --namespace $namespace'\n For OpenShift\nkb='kubectl --namespace '$namespace\n\n Retrieving container details\n\n\necho $kb","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_dr"},{"document_id":"ibmcld_06033-7-2044","score":18.2168206863,"text":"\nConfiguring pod security policies \n\nWith [pod security policies (PSPs)](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-policy\/), you can configure policies to authorize who can create and update pods in IBM Cloud\u00ae Kubernetes Service.\n\nPod security policies are not available in clusters that run version 1.25 or later. In clusters that run version 1.25 or later, use [Pod Security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission) instead. To upgrade a cluster with pod security policies from version 1.24 to version 1.25, follow the steps in [Migrating from PSPs to Pod Security Admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission-migration).\n\n\n\n FAQs \n\nLearn about some common FAQs for configuring your pod security policies.\n\n\n\n Why do I set pod security policies? \n\nAs a cluster admin, you want to control what happens in your cluster, especially actions that affect the cluster's security or readiness. Pod security policies can help you control usage of privileged containers, root privileges, host networking and ports, volume types, host file systems, Linux capabilities, and more.\n\nWith the PodSecurityPolicy admission controller, pod creation is controlled by pod security policies and related role-based access control (RBAC). By default, IBM Cloud Kubernetes Service clusters don't restrict pod creation for any authenticated users or service accounts. To secure your cluster, customize the pod security policies. This customization can have unintended side-effects, so make sure to thoroughly test your customizations. To deploy apps, the user and service accounts must all be authorized by the pod security policies that are required to deploy pods.\n\nTrying to control which users have access to the IBM Cloud Kubernetes Service? See [Assigning cluster access](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-usersusers) to set IBM Cloud IAM and infrastructure permissions.\n\n\n\n\n\n Are any policies set by default? What can I add?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-psp"},{"document_id":"ibmcld_05616-19122-20754","score":18.1819141015,"text":"\nScored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/eventratelimit) admission controller since it is a Kubernetes alpha feature. \n 1.2.12 IBM Cloud Kubernetes Service does not enable the [AlwaysPullImages](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/alwayspullimages) admission controller since it overrides a container's imagePullPolicy and may impact performance. \n 1.2.13 IBM Cloud Kubernetes Service can optionally configure [Pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission), which is similar to the unsupported [Kubernetes pod security policies](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-policy\/). \n 1.2.16 IBM Cloud Kubernetes Service can optionally configure [Pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission), which is similar to the unsupported [Kubernetes pod security policies](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-policy\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08474-1435-3113","score":27.3644067109,"text":"\nOperational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n 22 internal keystores $3795 (5x0+15x225+2x210) \n 15 external keystores $980 (1x0+14x70) \n Unified Key Orchestrator connection $3600 (30x24x5.00) \n Total charge $11442.2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing"},{"document_id":"ibmcld_07578-1183252-1185036","score":27.1331487354,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1185885-1187669","score":27.1331487354,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12746-0-1760","score":27.0533176319,"text":"\n\n\n\n\n\n\n  How does Security and Compliance Center calculate pricing? \n\nPricing for IBM Cloud\u00ae Security and Compliance Center is based on the number of evaluations performed. An evaluation is the check of one assessment against one resource.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate from either the [provisioning](https:\/\/cloud.ibm.com\/security-compliance\/catalog) or [plan page](https:\/\/cloud.ibm.com\/security-compliance\/plan).\n\n\n\n  Plan types \n\nThe service offers two pricing plans.\n\nTrial\n:   To try out the service, you can enroll in a Trial period where you have access the full capabilities of the Posture Management component for 30 days at no charge. You can create profiles, set up credentials, and configure your account to evaluate your resources, among other things. Each account can have 1 instance of the trial service for the lifetime of the account.\n\nStandard\n:   With a Standard plan, you are able to access the full capabilities of the service without limitations. However, you are charged per evaluation.\n\n\n\n\n\n  When am I charged? \n\nYou are charged if an evaluation produces a result of pass or fail. You are not charged for the evaluation if the check cannot be performed or is not applicable. Each scan that is run provides you with the number of billable evaluations in the results UI.\n\n\n\n\n\n  How do I stop getting charged for Security and Compliance Center? \n\nYou are charged when an evaluation takes place. If you no longer want to be charged for a specific evaluation, stop the scan or scans that you do not want to be charged for from running by deleting your attachment. This does not remove your historical results, but it does stop future scans from being run.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-scc-pricing"},{"document_id":"ibmcld_02775-4830-5961","score":27.0275327106,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_08474-7-1664","score":23.6723402013,"text":"\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing"},{"document_id":"ibmcld_11408-11687-13539","score":23.6210202408,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_07578-906253-908122","score":23.4533049582,"text":"\nCustomer-managed encrypted resources such as Block Storage for VPC volumes use your root key (CRK) as the root-of-trust key that encrypts a LUKS passphrase that encrypts a master key that's protecting the volume. You can import your CRK to a key management service (KMS) instance or instruct the KMS to generate one for you. Root keys are rotated in your KMS instance.\n\nWhen you rotate a root key, a new version of the key is created by generating or importing new cryptographic key material. The old root key is retired, which means its key material remains available for decrypting existing volumes, but not available for encrypting new ones. New resources are protected by the latest key. For more information, see [How key rotation works](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-key-rotationvpc-key-rotation-function).\n* Am I charged for using customer-managed encryption?\n\n Am I charged for using customer-managed encryption? \n\nYou are not charged extra for creating volumes with customer-managed encryption. However, setting up a Key Protect or Hyper Protect Crypto Services instance to import, create, and manage your root keys is not without cost. Contact your IBM customer service representative for details.\n* What's the difference between using Key Protect as my KMS compared to Hyper Protect Crypto Services? When would I use one over the other?\n\n What's the difference between using Key Protect as my KMS compared to Hyper Protect Crypto Services? When would I use one over the other? \n\nBoth key management systems provide you complete control over your data, managed by your root keys. Key Protect is a multi-tenant KMS where you can import or create your root keys and securely manage them. Hyper Protect Crypto Services is a single-tenant KMS and hardware security module (HSM) that is controlled by you, which offers the highest level of security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-906130-907999","score":23.4533049582,"text":"\nCustomer-managed encrypted resources such as Block Storage for VPC volumes use your root key (CRK) as the root-of-trust key that encrypts a LUKS passphrase that encrypts a master key that's protecting the volume. You can import your CRK to a key management service (KMS) instance or instruct the KMS to generate one for you. Root keys are rotated in your KMS instance.\n\nWhen you rotate a root key, a new version of the key is created by generating or importing new cryptographic key material. The old root key is retired, which means its key material remains available for decrypting existing volumes, but not available for encrypting new ones. New resources are protected by the latest key. For more information, see [How key rotation works](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-key-rotationvpc-key-rotation-function).\n* Am I charged for using customer-managed encryption?\n\n Am I charged for using customer-managed encryption? \n\nYou are not charged extra for creating volumes with customer-managed encryption. However, setting up a Key Protect or Hyper Protect Crypto Services instance to import, create, and manage your root keys is not without cost. Contact your IBM customer service representative for details.\n* What's the difference between using Key Protect as my KMS compared to Hyper Protect Crypto Services? When would I use one over the other?\n\n What's the difference between using Key Protect as my KMS compared to Hyper Protect Crypto Services? When would I use one over the other? \n\nBoth key management systems provide you complete control over your data, managed by your root keys. Key Protect is a multi-tenant KMS where you can import or create your root keys and securely manage them. Hyper Protect Crypto Services is a single-tenant KMS and hardware security module (HSM) that is controlled by you, which offers the highest level of security.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16315-6754-8418","score":23.3051519868,"text":"\n\"card_title\": \"Let\u2019s dispute a charge\",\n\"card_description\": \"Follow along with this guided journey to learn how to find and dispute charges.\",\n\"user_defined_type\": \"IBM_BETA_JOURNEYS_TOUR\",\n\"steps\":\n{\n\"response_type\": \"text\",\n\"text\": \"Charges are listed on the Transactions page. Click your profile photo in the top right corner of your screen, and then click Transactions from the menu.\"\n},\n{\n\"response_type\": \"text\",\n\"text\": \"Here you can view your charges.n Scroll through the Transactions page and review your charges. Each charge contains a merchant name, transaction date, and amount charged.\"\n},\n{\n\"response_type\": \"image\",\n\"source\": \"https:\/\/example.com\/image.png\",\n\"alt_text\": \"Image showing location of Dispute option\",\n\"description\": \"The option to Dispute is marked in red on the right hand side of each row in the Transactions table. Just click here to file a dispute.\"\n},\n{\n\"response_type\": \"video\",\n\"source\": \"https:\/\/vimeo.com\/769580398\",\n\"description\": \"Watch this short video to learn what to expect now that you\u2019ve filed a dispute.\"\n}\n]\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Starting a journey without opening the web chat \n\nAlthough journeys are part of the web chat integration, you can make it possible for your customers to start a journey directly from your website without opening the web chat window at all. For example, you might want to include a Show me button on your website that customers can click to launch an interactive tour of the page.\n\nTo start a journey without opening the web chat:\n\n\n\n1. In the action that sends the journey response, edit the JSON that defines the journey. Include \"skip_card\": true to bypass the introductory card.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-journeys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00579-8462-10444","score":23.6711873997,"text":"\nThese partitioned queries exercise only one shard of the database. This practice makes them faster to execute than global queries. For billing purposes, they are classified as \u201cread\u201d requests instead of the more expensive \u201cquery\u201d requests, which provides you with more usable capacity from the same IBM Cloudant plan.\n\nNot all data designs lend themselves to a partitioned design, but if your data can be molded into a <partition key>:<document key> pattern, then your application can benefit in terms of performance and cost.\n\n\n\n* [Partitioned Databases documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n* [Partitioned Databases - Introduction blog](https:\/\/blog.cloudant.com\/2019\/03\/05\/Partition-Databases-Introduction.html)\n\n\n\n\n\n\n\n Treat the primary index as a free search index \n\nA default IBM Cloudant document _id is a 32-character string, encoding 128 bits of random data. The _id attribute is used to construct the database\u2019s primary index, which is used by IBM Cloudant to retrieve documents by _id or ranges of keys when the user supplies a startkey\/endkey pair. We can leverage this fact to pack our data into the _id field and use it as a \u201cfree\u201d index that can query for ranges of values.\n\nSee some examples in the following list:\n\n\n\n* Use time-sortable document IDs so that your documents are sorted into rough date and time order. This sorting makes it easy to retrieve recent additions to the database. For more information, see [Time-sortable -IDs](https:\/\/blog.cloudant.com\/2018\/08\/24\/Time-sortable-document-ids.html).\n* Pack searchable data into your _id field, for example, <customerid><date><orderid> can be used to retrieve data by customer, customer\/date, or customer\/date\/orderid.\n* In a partitioned database, the judicious choice of partition key allows an entire database to be winnowed down to a handful of documents for a known partition key. Make sure that your partitioning schema solves your most common use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00495-5198-6563","score":23.6074719288,"text":"\nThis data is used in other tutorials, like [Using IBM Cloudant Query to find data](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query).\n\n\n\n1. Create sample data.\n\nsampleData = [\n1, \"one\", \"boiling\", 100],\n2, \"two\", \"hot\", 40],\n3, \"three\", \"hot\", 75],\n4, \"four\", \"hot\", 97],\n5, \"five\", \"warm\", 20],\n6, \"six\", \"cold\", 10],\n7, \"seven\", \"freezing\", 0],\n8, \"eight\", \"freezing\", -5]\n]\n2. Use a for statement to retrieve the fields in each row by going through each row in the array.\n\nfor document in sampleData:\n Retrieve the fields in each row.\nnumber = document[0]\nname = document[1]\ndescription = document[2]\ntemperature = document[3]\n3. Create a JSON document that represents all the data in the row.\n\njsonDocument = {\n\"numberField\": number,\n\"nameField\": name,\n\"descriptionField\": description,\n\"temperatureField\": temperature\n}\n4. Create a document by using the Database API.\n\nnewDocument = myDatabaseDemo.create_document(jsonDocument)\n5. Check that the document exists in the database.\n\nif newDocument.exists():\nprint(\"Document '{0}' successfully created.\".format(number))\n\n\n\n\n\n\n\n Step 4: Retrieving data \n\nTo perform a minimal retrieval, you first request a list of all documents within the database. This list is returned as an array. You can then show the content of an element in the array.\n\n\n\n1. Retrieve a minimal amount of data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"},{"document_id":"ibmcld_12896-5234-6599","score":23.6074719288,"text":"\nThis data is used in other tutorials, like [Using IBM Cloudant Query to find data](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query).\n\n\n\n1. Create sample data.\n\nsampleData = [\n1, \"one\", \"boiling\", 100],\n2, \"two\", \"hot\", 40],\n3, \"three\", \"hot\", 75],\n4, \"four\", \"hot\", 97],\n5, \"five\", \"warm\", 20],\n6, \"six\", \"cold\", 10],\n7, \"seven\", \"freezing\", 0],\n8, \"eight\", \"freezing\", -5]\n]\n2. Use a for statement to retrieve the fields in each row by going through each row in the array.\n\nfor document in sampleData:\n Retrieve the fields in each row.\nnumber = document[0]\nname = document[1]\ndescription = document[2]\ntemperature = document[3]\n3. Create a JSON document that represents all the data in the row.\n\njsonDocument = {\n\"numberField\": number,\n\"nameField\": name,\n\"descriptionField\": description,\n\"temperatureField\": temperature\n}\n4. Create a document by using the Database API.\n\nnewDocument = myDatabaseDemo.create_document(jsonDocument)\n5. Check that the document exists in the database.\n\nif newDocument.exists():\nprint(\"Document '{0}' successfully created.\".format(number))\n\n\n\n\n\n\n\n Step 4: Retrieving data \n\nTo perform a minimal retrieval, you first request a list of all documents within the database. This list is returned as an array. You can then show the content of an element in the array.\n\n\n\n1. Retrieve a minimal amount of data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"},{"document_id":"ibmcld_00580-41116-43256","score":23.5973328324,"text":"\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list. It contains data that is sorted by the fields you specify, for example, books that are sorted by date and title. If you perform a query that asks for data that matches a document's date and title, the indexed data structure can be used to speed up the query process. Instead of scanning through every document in turn, IBM Cloudant can jump to the relevant part of the index (say, the section on 20th century books) and retrieve the data much more quickly.\n\nIBM Cloudant Query indexes include two types of indexes: type=json and type=text. These indexes are backed by two underlying indexing technologies that we meet in subsequent parts of this course.\n\nAn index is defined when you POST some JSON to a database's _index endpoint.\n\nThe index object contains a fields array, which specifies which document attributes to index. Usually, the fields that need indexing are equivalent to the attributes used in the selector of a query you're going to use to retrieve the data. That is, if you need to query by the date field, we need to index the date field.\n\nAlthough the name of an index is optional, it's good practice and we follow this convention. It's good to ask IBM Cloudant a question and specify the name of the index you intend it to use. This practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00459-7365-9041","score":21.997846878,"text":"\n: Number of provisioned throughput capacity blocks, where block is 100 reads\/sec, 50 writes\/sec, and 5 global queries\/sec.\n\nthroughput\n: A breakdown of the specific number of reads\/sec, writes\/sec, and global queries\/sec.\n\nSee the following example JSON response with the target capacity set:\n\n{\n\"current\": {\n\"throughput\": {\n\"read\": 500,\n\"write\": 250,\n\"blocks\": 5,\n\"query\": 25\n}\n},\n\"target\": {\n\"throughput\": {\n\"read\": 1000,\n\"write\": 500,\n\"blocks\": 10,\n\"query\": 50\n}\n}\n}\nShow more\n\n\n\n\n\n View the current consumption of provisioned throughput capacity used \n\nUse a GET method to the \/_api\/v2\/user\/current\/throughput endpoint to see the current consumption of provisioned throughput capacity for an IBM Cloudant instance. The current consumption shows the quantities of reads, writes, and global queries conducted against the instance for a given second. When you use this endpoint, it is a best practice to aggregate this data continuously over time to get a more comprehensive view of a IBM Cloudant instance's throughput consumption patterns.\n\nMethod\n: GET\n\nPath\n: \/_api\/v2\/user\/current\/throughput\n\nResponse\n: The current consumption of provisioned throughput capacity used, broken down by the number of reads, writes, and global queries.\n\nSee the following example request to retrieve the current consumption of capacity by using HTTP:\n\nGET $SERVICE_URL\/_api\/v2\/user\/current\/throughput\n\nSee the following example request to retrieve the current consumption of capacity:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"$SERVICE_URL\/_api\/v2\/user\/current\/throughput\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.CurrentThroughputInformation;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-capacity"},{"document_id":"ibmcld_00579-4284-6271","score":21.7550276116,"text":"\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search. Stored fields are retrieved in the query without doing include_docs=true so the tradeoff is similar to the [Understand the tradeoffs in emitting data or not into a view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-queryingtradeoffs-emit-data-or-not-in-view) section. For more information, see IBM Cloudant Search [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search).\n\n\n\n\n\n Design document management requires some flair \n\nAs your data set grows, and your number of views goes up, sooner or later you want to ponder how you organize your views across design documents. A single design document can be used to form a so-called view group: a set of views that belong together by some metric that makes sense for your use case. If your views are static, that makes your view query URLs semantically similar for related queries. It\u2019s also more performant at index time because the index loads the document once and generates multiple indexes from it.\n\nDesign documents themselves are read and written by using the same read\/write endpoints as any other document. With these endpoints, you can create, inspect, modify, and delete design documents from within your application. However, even small changes to design documents can have significant effects on your database. When you update a design document, all views in it become unavailable until indexing is complete. This lag can be problematic in production.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00474-6472-8322","score":21.5956901235,"text":"\nWhen the front end submits a team selection to the team route (see [index.html](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-servicesindex-html-redis)), the app.route function first checks the cache to see whether it has the data already. If it does, then it returns that. Otherwise, it makes a query to IBM Cloudant to retrieve team data, store it in the cache, and return it to the front end.\n\nThe read operation uses an IBM Cloudant design document and a MapReduce view to select documents. This selection is beyond the scope of this tutorial, but you can read more about [views and design documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce) in the documentation.\n\nThis script also contains some code that uploads test data (contained in the directorydata.json file) to the database the first time it runs.\n\n\n\n\n\n index.html \n\nThe index.html page is the only page of the application that is using the [Vue.js framework](https:\/\/vuejs.org\/). When it loads, it shows you the available teams.\n\nWhen you select a team, it makes an HTTP POST request with your choice to the \/team route of the application (see [redis.js](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-servicesserver-js-redis)). A successful return from the application contains all the data for the team members. We are displaying only their names and town for simplicity.\n\n\n\n\n\n Summary \n\nToday, we combined two IBM Cloud services to optimize cost and user experience: IBM Cloudant as a document store and query engine and Databases for Redis as a content cache. Cached documents can be retrieved more quickly and more cheaply, but the tradeoff is that your application might be showing old data to your users for a time.\n\nIf you followed this tutorial, you must deprovision your resources to stop incurring charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services"},{"document_id":"ibmcld_00518-7-1546","score":21.2074731783,"text":"\nDesign document management \n\nThe scalable JSON data store for IBM Cloudant has several querying mechanisms, all of which generate indices that are created and maintained separately from the core data.\n\nArticle contributed by Glynn Bird, Developer Advocate at IBM Cloudant, [glynn@cloudant.com](mailto:glynn@cloudant.com).\n\nIndexing isn't performed immediately when a document is saved. Instead, indexing is scheduled to happen later, providing a faster, non-blocking write throughput.\n\n\n\n* MapReduce views are indexes into the data set with key value pairs that are stored in a BTree for efficient retrieval by key or range of keys.\n* Search Indexes are constructed by using Apache Lucene to allow free-text search, faceting, and complex ad hoc queries.\n\n\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae's [search indexes](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search) and [MapReduce views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce) are configured by adding design documents to a database. Design documents are JSON documents that include the instructions about how the view or index is to be built. Let's take a simple example. Assume that you have a simple collection of data documents, similar to the following example.\n\nSee an example of a simple data document:\n\n{\n\"_id\": \"23966717-5A6F-E581-AF79-BB55D6BBB613\",\n\"_rev\": \"1-96daf2e7c7c0c277d0a63c49b57919bc\",\n\"doc_name\": \"Markdown Reference\",\n\"body\": \"Lorem Ipsum\",\n\"ts\": 1422358827\n}\n\nEach data document includes a name, a body, and a timestamp.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-document-management"},{"document_id":"ibmcld_00625-7-1766","score":20.7759535464,"text":"\nReading a document \n\nThe steps shown here demonstrate how to read a document:\n\n\n\n1. Send a GET request to retrieve a document.\n2. Run the following command: https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID.\n\n\n\nRecall that for a partitioned database the $DOCUMENT_ID is formed of a partition key part and a document key part.\n\nIf you don't know the _id for a particular document, you can [query the database](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostalldocsqueries) for all documents.\n\nDue to the distributed, eventually consistent nature of IBM Cloudant, reads might return stale data. In particular, data written recently, even by the same client, might not be returned from a read request immediately following the write request. To work around this behavior, a client can cache the state of data locally. Caching also helps to keep request counts down, increase application performance, and decrease load on the database cluster. This behavior also applies to other read requests such as to MapReduce and search indexes.\n\nSee an example of retrieving a document by using HTTP:\n\nGET \/$DATABASE\/$DOCUMENT_ID HTTP\/1.1\n\nYou can customize this section for the programming language that you want to use by selecting the language in the code examples.\n\nSee an example of retrieving a document:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X GET \"$SERVICE_URL\/products\/small-appliances:1000042\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.Document;\nimport com.ibm.cloud.cloudant.v1.model.GetDocumentOptions;\n\nCloudant service = Cloudant.newInstance();\n\nGetDocumentOptions documentOptions =\nnew GetDocumentOptions.Builder()\n.db(\"products\")\n.docId(\"small-appliances:1000042\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-read-a-document"},{"document_id":"ibmcld_00580-57127-59386","score":20.5908467377,"text":"\nThis video is part 15 - Partitioned database.\n\nIBM Cloudant is a distributed database, which is a discussion that is coming up. Many storage nodes make up an IBM Cloudant service and a database's documents are distributed across the nodes in groups called shards. A single database is said to be sharded or divided into multiple pieces.\n\nIn a normal IBM Cloudant database, a document is allocated a shard algorithmically - effectively documents are distributed around the shards randomly.\n\nIn a partitioned database, you define which shard the documents are stored in by supplying a partition key.\n\nPartitioned databases are not created with the same PUT \/<database name> API call but with an extra query string parameter: partitioned=true.\n\nIn the first example, the products database is created as a partitioned database, in the second example, as a standard, unpartitioned database.\n\nWhen you add documents to a partitioned database, you must supply a document _ID - (no auto-generated document _IDs exist). A document _id has two parts, which are separated by a colon character:\n\nPartition key\n: A string that defines on which partition to store the document.\n\nDocument key\n: A string that uniquely identifies a document within the partition.\n\nIn the first example, a book is being added into the book partition of the products database.\n\nThen, another document is being added into the DVD partition and a third into the household partition.\n\nThe effect of this is that documents that share a partition key reside in the same shard of the databases. Documents in the same partition are stored together in document key order.\n\nThe advantage comes when retrieving data. We can direct IBM Cloudant Queries, MapReduce requests, and searches at a single partition. In this example, an IBM Cloudant Query selector is being sent to the book partition. This action means you exercise only a fraction of the IBM Cloudant infrastructure (only the shard that hosts the book partition is used, the rest of the cluster remains idle).\n\nThis scenario makes for faster query performance, cheaper query costs, and better scalability.\n\nThe key to great partitioned query performance is the choice of partition key:\n\nIt needs to be a value that repeats within your data set.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-807740-809746","score":30.0017005638,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-807613-809619","score":30.0017005638,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-806120-808288","score":29.8101815029,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":29.8101815029,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01623-6277-8255","score":29.5759140487,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_03735-7-1918","score":29.030150522,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_05666-10204-11956","score":26.5986344194,"text":"\nIn the [Kubernetes cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscosts-for-clusters).\n\n\n\n\n\n Managing costs \n\nThe following steps present a general process to manage costs for your IBM Cloud Kubernetes Service clusters.\n\n\n\n1. Decide on a cloud platform strategy to manage your resources.\n\n\n\n* See [Best practices for billing and usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-best-practices).\n* Organize your billing with [resource groups](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs).\n* [Add tags to your clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workerscluster_tags) according to your organizational strategy.\n\n\n\n2. Plan the type of cluster that you need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_07578-506456-508701","score":26.5096553904,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-506398-508643","score":26.5096553904,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02665-3418-5653","score":26.4123721228,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2184074368}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03085-4-2046","score":43.4214520747,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_03068-34858-36104","score":29.6363139712,"text":"\nTo check whether the updated cacerts file is present in the configmap, run the oc get configmap watson-assistant-skill-cacerts --output yaml command.\n5. Override the cacerts file in the search skill pods. In this step, you configure the Watson Assistant operator to override the cacerts file in the search skill pods with the updated cacerts file. In the following example file, the Watson Assistant instance is called watson-assistant---wa. Replace this value with the name of your instance:\ncat <<EOF | oc apply -f -\nkind: TemporaryPatch\napiVersion: com.ibm.oppy\/v1\nmetadata:\nname: watson-assistant---wa-skill-cert\nspec:\napiVersion: com.ibm.watson.watson-assistant\/v1\nkind: WatsonAssistantSkillSearch\nname: \"watson-assistant---wa\" Replace this with the name of your Watson Assistance instance\npatchType: patchStrategicMerge\npatch:\n\"skill-search\":\ndeployment:\nspec:\ntemplate:\nspec:\nvolumes:\n- name: updated-cacerts\nconfigMap:\nname: watson-assistant-skill-cacerts\ndefaultMode: 420\ncontainers:\n- name: skill-search\nvolumeMounts:\n- name: updated-cacerts\nmountPath: \/opt\/ibm\/java\/jre\/lib\/security\/cacerts\nsubPath: cacerts\nEOF\nShow more\n6. Wait until new search skill pods are created. It might take up to 10 minutes before the updates take affect.7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-troubleshoot"},{"document_id":"ibmcld_03121-4-1692","score":29.604538776,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Working with your assistant \n\nLearn how to find and open assistants and skills that you created or can access.\n\nAssistants and skills are created within a Watson Assistant service instance. To continue working with a skill or assistant, open the service instance that contains the skill or assistant. If you can't remember the service instance name, you can switch between instances from within the Watson Assistant user interface.\n\n\n\n1. Go to the [IBM Cloud Resource list](https:\/\/cloud.ibm.com).\n2. Log in.\n\nA list of the service instances that you own or were given access to is displayed.\n3. Click a service instance to open it.\n4. Click Launch Watson Assistant from the service instance details page to open the product in a new browser tab or window.\n5. Click the appropriate icon from the navigation pane to see a list of your assistants or skills.\n\n\n\n* ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-ass-icon.png) Assistants\n* ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-skills-icon.png) Skills\n\n\n\n\n\nIf you do not see the skill or assistant you are looking for, you can look for it in a different service instance.\n\n\n\n Switching the service instance \n\nTo switch to a different Watson Assistant service instance, complete the following steps:\n\n\n\n1. From the header of any page in the current instance, click the User icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settings"},{"document_id":"ibmcld_07018-7974-8883","score":29.2363353172,"text":"\nTo deploy a Conversational Search project, connect this project to an assistant that is built with Watson Assistant. The general steps to follow include:\n\n\n\n1. Create an assistant.\n\nYou can use a Watson Assistant Trial plan for testing purposes.\n2. Add a search skill to your assistant, and then connect it to this project.\n3. Deploy your assistant.\n\nFor more information about building a Watson Assistant search skill, see the appropriate documentation for your deployment:\n\n\n\nIBM Cloud\n\nFrom the new experience, see [Adding a search integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add).\nIBM Cloud\n\nFrom the classic experience, see [Embedding existing help content](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\nIBM Cloud Pak for Data\n\n[Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy"},{"document_id":"ibmcld_16245-1169-2070","score":29.1250575166,"text":"\nFor more information, see [Calling actions from a dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-call-action).\n\n\n\n\n\n Migrating existing skills \n\nOnce the dialog feature is activated, you can start a new dialog conversation from scratch if you want. But, you probably have an existing dialog skill that you want to migrate into the new Watson Assistant.\n\nTo migrate an existing dialog skill:\n\n\n\n1. Use the classic experience to [download your dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) in JSON format.\n2. In the new Watson Assistant, open the Dialog page.\n3. In Options, choose Upload \/ Download.\n\n![Upload dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/dialog-upload.png)\n4. On the Upload tab, upload the JSON file for your dialog skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-activate-dialog"},{"document_id":"ibmcld_03139-4-1679","score":28.9943238324,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Backing up and restoring data \n\nBack up and restore your data by downloading, and then uploading the data.\n\nYou can download the following data from a Watson Assistant service instance:\n\n\n\n* Dialog skill training data (intents and entities)\n* Dialog skill dialog\n* Actions skill\n\n\n\nYou cannot download the following data:\n\n\n\n* Search skill\n* Assistant, including any configured integrations\n\n\n\n\n\n Retaining logs \n\nIf you want to store logs of conversations that users have had with your assistant, you can use the \/logs API to export your log data. See [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs) for details.\n\nTo get the workspace ID for a skill, from the skill tile, click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose View API Details.\n\nLogs are stored for a different amount of time depending on your service plan. For example, Lite plans provide logs from the past 7 days only. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for more information.\n\nYou cannot import logs from one skill into another skill.\n\n\n\n\n\n Downloading a skill \n\nTo back up actions or dialog skill data, download the skill as a JSON file, and store the JSON file.\n\n\n\n1. Find the actions or dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_03381-4-1869","score":28.8026561661,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03118-4-2208","score":28.740253069,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_03329-4-1522","score":28.73149486,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Getting started with a dialog skill \n\nIn this short tutorial, we help you use a dialog skill to build your first conversation.\n\nA dialog skill uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n\n\n\n Step 1: Create an assistant \n\nAn assistant is a cognitive bot to which you add skills that enable it to interact with your customers in useful ways.\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-ass-icon.png), and then click Create assistant.\n\n![Create assistant button on the Assistants page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant.png)\n2. Name the assistant My first assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_03385-4-1596","score":28.7078182505,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Working with skills \n\nPerform common tasks, such as renaming or deleting a skill.\n\n\n\n Renaming a skill \n\nYou can change the name of a skill and its associated description after you create the skill.\n\nTo rename a skill, follow these steps:\n\n\n\n1. From the Skills page, find the skill that you want to rename.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Rename.\n3. Edit the name, and then click Save.\n\n\n\n\n\n\n\n Duplicating a skill \n\nYou can duplicate a skill to make a copy of it.\n\nTo duplicate a skill, follow these steps:\n\n\n\n1. From the Skills page, find the skill that you want to duplicate.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Duplicate. The copied skill has the word copy added to the end of its name.\n\n\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03158-17978-19852","score":87.4083640736,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. Click Customer success as the case type.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16288-10521-12298","score":86.9605304772,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-9295-10984","score":83.8331073068,"text":"\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup)\n* [Bring your own SIP trunk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-byost)\n* [Migrate from Voice Agent with Watson](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https:\/\/www.twilio.com\/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard. If you do not see it on the sidebar, go to the Search Bar at the top and search for 'Elastic SIP Trunking', then select Elastic SIP Trunks.\n3. On the Elastic SIP Trunks page, click the Create new SIP Trunk button to create a SIP trunk. Enter a name for your SIP trunk and click Create. If you already have a SIP trunk, go to the next step.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-16828-18419","score":83.7465621743,"text":"\nYou can set up a SIP trunk in the following ways:\n\n\n\n* [Create a Twilio SIP trunk](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-twilio-setup)\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-request-setup)\n* [Bring your own SIP trunk](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-byost)\n* [Migrate from Voice Agent with Watson](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https:\/\/www.twilio.com\/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard.\n3. Select Trunks from the navigation bar and create a SIP trunk. If you already have a SIP trunk, click the plus sign (+). Enter a name for your SIP trunk and click Create.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03312-5487-7760","score":82.5022927874,"text":"\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16250-5445-7809","score":81.2269484436,"text":"\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03158-8929-11062","score":81.180078553,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16288-1733-3996","score":77.5204948083,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03312-3639-6036","score":74.0628023793,"text":"\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region. The remainder of this section focuses on handling a failover between regions.\n\n\n\n\n\n Full service outage \n\nPhone integration failures have two types. The first type is a full outage where the session border controllers in all 3 regional zones become unreachable. This is the easier of the two types to detect and handle because the SIP trunking provider is immediately notified via SIP timeouts that the call fails and can be configured to either automatically fail over or the call routing can be manually reconfigured at the SIP trunking provider to direct traffic away from the failed region towards the passive backup region. If a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_03158-12123-14237","score":74.0411171191,"text":"\nA 180 Ringing response is sent from the assistant back to the SIP trunk provider while your assistant processes the incoming call invitation. The ringing response is sent by default.\n* Don't place callers on hold while transferring to a live agent: Choose whether the phone integration puts the caller on hold.\n\nIf your SIP trunk provider manages holds, disable this feature. For example, some SIP trunk providers prefer to have the assistant send a SIP REFER request, so they can put the call on hold themselves.\n\n\n\nFor more information about the SIP protocol, see [RFC 3261](https:\/\/tools.ietf.org\/html\/rfc3261) and about the RTP protocol, see [RFC 3550](https:\/\/tools.ietf.org\/html\/rfc3550).\n\n\n\n\n\n\n\n Configuring backup call center support \n\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have human backup available. You can design your assistant to be able to transfer a call to a human in case the phone connection fails, or a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. If you use the web chat integration with service desk support, there's no way to transfer the phone call to the existing service desk that is set up for the web chat, for example.\n\nFor whichever call center service you use, you will need to provide the call center SIP URI. You must specify this information in your dialog when you enable a call transfer from a dialog node. For more information, see [Transfer a call to a human agent](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n\n\n\n\n\n Optimize your dialog for voice \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your dialog text responses. To add formatting, use Markdown.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10290-110067-111621","score":25.5994670408,"text":"\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud oc worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud oc worker replace command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10284-1470-3569","score":25.3703626829,"text":"\n* Image and version updates: Worker node updates, such as security patches to the image or Red Hat OpenShift versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary. Worker node lifecycle operations, such as autorecovery, reloading, updating, or replacing a worker node, change any modifications back to the default settings.\n* Persistent modifications: For modifications to persist across worker node lifecycle operations, create a daemon set that uses an init container. For more information, see [Modifying default worker node settings to optimize performance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelworker).\n\n\n\nModifications to the operating system are not supported. If you modify the default settings, you are responsible for debugging and resolving the issues that might occur.\n\n\n\n\n\n Hardware changes \n\nTo change the compute hardware, such as the CPU and memory per worker node, choose among the following options.\n\n\n\n* [Create a worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers). The instructions vary depending on the type of infrastructure for the cluster, such as classic, VPC, Satellite, or gateway clusters.\n* [Update the flavor](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type) in your cluster by creating a worker pool and removing the previous worker pool.\n\n\n\n\n\n\n\n\n\n Modifying worker node settings to optimize performance \n\n\n\n Modifying worker node settings by using the Node Tuning Operator \n\nYou can use the node tuning operator to tune worker node performance by creating custom profiles. For more information, see the Red Hat [Node Tuning Operator](https:\/\/docs.openshift.com\/container-platform\/4.7\/scalability_and_performance\/using-node-tuning-operator.html) docs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernel"},{"document_id":"ibmcld_05891-112012-113705","score":25.2591330743,"text":"\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud ks worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud ks worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-112645-114324","score":25.2591330743,"text":"\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud ks worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud ks worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05598-24740-26499","score":24.807972296,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1562\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N\/A N\/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1562, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1562. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1561\n\n Component Previous Current Description \n\n Containerd v1.4.9 v1.4.11 See the [security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6501867) and the [change logs](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.4.11). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3778) and [CVE-2021-3796](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1561, released 27 September 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1561. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.14_1559\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_06209-11131-12823","score":24.8049039209,"text":"\nIf applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Kubernetes version preparation guide](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions).\n* If you want to apply a patch update, review the [Kubernetes version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud ks worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\nkubectl describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-10731-12253","score":24.6227330636,"text":"\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud oc worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\noc describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>\nLabels: arch=amd64\nbeta.kubernetes.io\/arch=amd64\nbeta.kubernetes.io\/os=linux\nfailure-domain.beta.kubernetes.io\/region=us-south\nfailure-domain.beta.kubernetes.io\/zone=dal12","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-6757-8643","score":24.2290669503,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05599-40319-41968","score":23.9394554851,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.20.11_1555\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N\/A N\/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.20.11_1555, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.20.11_1555. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.20.11_1554\n\n Component Previous Current Description \n\n Containerd v1.4.9 v1.4.11 See the [security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6501867) and the [change logs](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.4.11). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3778) and [CVE-2021-3796](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for master fix pack 1.20.11_1553, released 28 September 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 1.21.1_1553. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.20.10_1550\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_120"},{"document_id":"ibmcld_10642-6354-8294","score":23.8858837457,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05342-35727-36837","score":10.0768393456,"text":"\n_) \/ \/( (_ )( \/ \/ ) _)\n(____)_)__) ___\/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=\/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPWD=\/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap-secret"},{"document_id":"ibmcld_05436-35667-36777","score":10.0768393456,"text":"\n_) \/ \/( (_ )( \/ \/ ) _)\n(____)_)__) ___\/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=\/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPWD=\/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret"},{"document_id":"ibmcld_05557-5511-7293","score":9.4648927198,"text":"\nIn Kubernetes cluster versions 1.21 and later, Konnectivity replaced the OpenVPN solution. If you have cluster version 1.21 and later, and your webhook uses the ClusterIP, you must update your webhook to use a Kubernetes service instead.\n\nYou can configure a webhook by referencing the webhook app as a Kubernetes service, or by referencing the webhook app as an IP address or publicly registered DNS name.\n\nExample configuration for referencing the webhook app as a Kubernetes service\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nservice:\nname: admission-webhook\nnamespace: default\npath: \/validate\nport: 443\n\nExample configuration for referencing the webhook app as an IP address or publicly registered DNS name\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nurl: https:\/\/WEBHOOK_URL:443\/validate\n\nShow more\n\nNote the following limitations for referencing the webhook app as an IP address or DNS name:\n\n\n\n* If the URL is a DNS, then this DNS must be a publicly registered DNS name. Private DNS configurations are not supported.\n* If the URL is an external IP address, which means the webhook service is outside of the cluster, the control plane network is used to connect to the service. The control plane must be able to reach the IP address. If, for example, the IP address is from an on-premises network and the control plane can't reach the IP address, the webhook service does not work.\n* If the URL is a cluster IP address, which means the webhook service is inside of the cluster, the Kubernetes API needs to connect to cluster network. If you have cluster version 1.21 and later, and your webhook uses the cluster IP address, you must update your webhook to use a Kubernetes service instead.\n\n\n\n\n\n\n\n\n\n I need help with a broken webhook. What can I do?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooks"},{"document_id":"ibmcld_11886-2994-4812","score":9.4516431853,"text":"\nFor more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/).\n\nIf you choose a custom access option, some Satellite Config components might not work. For example, if you grant access to view only certain resources, you cannot use subscriptions to create Kubernetes resources in your cluster group. To view an inventory of your Kubernetes resources in a cluster, Satellite Config must have an appropriate role that is bound to the razee-viewer service account. To deploy Kubernetes resources to a cluster by using subscriptions, Satellite Config must have an appropriate role that is bound to the razee-editor service account.\n\n\n\n\n\n Cluster admin access \n\nGrant the Satellite Config service accounts access to the cluster admin role.\n\nkubectl create clusterrolebinding razee-cluster-admin --clusterrole=razee-cluster-admin --serviceaccount=razeedeploy:razee-viewer --serviceaccount=razeedeploy:razee-editor --serviceaccount=razeedeploy:razee-satcon\n\n\n\n\n\n Custom access, cluster-wide \n\nCreate custom RBAC policies to grant Satellite Config access to the actions and Kubernetes resources that you want for the cluster.\n\n\n\n1. Create a cluster role with the actions and resources that you want to grant. For example, the following command creates a viewer role so that Satellite Config can list all the Kubernetes resources in a cluster, but cannot modify them.\n\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_02683-2805-4831","score":9.2953487101,"text":"\nFor your application and SDK to continue operations during the unlikely scenario of an App Configuration service downtime, across your application restarts, you can configure the SDK to work by using a persistent cache. The SDK uses the persistent cache to store the App Configuration data that is available across your application restarts.\n\n\/\/ 1. default (without persistent cache)\nappConfigClient.setContext(collectionId, environmentId);\n\n\/\/ 2. optional (with persistent cache)\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setPersistentCacheDirectory(\"\/var\/lib\/docker\/volumes\/\");\nappConfigClient.setContext(collectionId, environmentId, configOptions);\n\nWhere:\n\n\n\n* persistentCacheDirectory: Absolute path to a directory that has read and write permission for the user. The SDK creates a file - appconfiguration.json in the specified directory, and it is used as the persistent cache to store the App Configuration service information.\n\n\n\nWhen persistent cache is enabled, the SDK keeps the last known good configuration at the persistent cache. If the App Configuration server being unreachable, the latest configurations at the persistent cache are loaded to the application to continue working.\n\nEnsure that the cache file is not lost or deleted in any case. For example, consider the case when a kubernetes pod is restarted and the cache file (appconfiguration.json) was stored in ephemeral volume of the pod. As pod gets restarted, kubernetes destroys the ephermal volume in the pod, as a result the cache file gets deleted. So, make sure that the cache file created by the SDK is always stored in persistent volume by providing the correct absolute path of the persistent directory.\n\n\n\n\n\n Offline options \n\nThe SDK is also designed to serve configurations, and perform feature flag and property evaluations without being connected to App Configuration service.\n\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setBootstrapFile(\"saflights\/flights.json\");","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_06123-1617-3175","score":8.8078384592,"text":"\nRPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Kubernetes clusters are deployed in different regions, such as us-south and us-east. Each cluster has its own Portworx installation and uses a separate Portworx key-value store that is not shared. To replicate data between clusters, you must set up scheduled replication between these clusters. Because of the higher latency and scheduled replication times, the RPO for this scenario might be up to 15 minutes.\n\n\n\nTo include your cluster in a Portworx disaster recovery configuration:\n\n\n\n1. [Choose the disaster recovery configuration that works for your cluster setup](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/).\n2. Review the prerequisites for the [Metro DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/px-metro\/1-install-px\/prerequisites) and [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/async-dr\/pre-requisites) configuration.\n3. Configure disaster recovery for your cluster. Metro DR:\n\n\n\n1. Choose at least two Kubernetes clusters that are located in the same metro location. If you have one cluster only, you can still configure this cluster for metro disaster recovery, but Portworx can't do a proper failover until a second cluster is configured.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_recovery"},{"document_id":"ibmcld_06004-14210-16020","score":8.4979170452,"text":"\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/cron-jobs\/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/) or [Secret](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_10439-18453-20263","score":8.4979170452,"text":"\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/cron-jobs\/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/) or [Secret](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_07578-534510-536520","score":8.4805021457,"text":"\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-534464-536474","score":8.4805021457,"text":"\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00519-12531-14412","score":31.6903960979,"text":"\nIn particular, you must not use functions that generate random numbers or return the current time.\n\n\n\n\n\n\n\n Filter functions \n\nDesign documents with options.partitioned set to true can't contain a filters field.\n\nFilter functions are design documents that filter the [changes feed](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasesget-changes). They work by applying tests to each of the objects included in the changes feed.\n\nIf any of the function tests fail, the object is \"removed\" or \"filtered\" from the feed. If the function returns a true result when applied to a change, the change remains in the feed. In other words, filter functions \"remove\" or \"ignore\" changes that you don't want to monitor.\n\nFilter functions can also be used to modify a [replication task](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationfiltered-replication-adv-repl).\n\nFilter functions require two arguments: doc and [req](https:\/\/docs.couchdb.org\/en\/stable\/json-structure.htmlrequest-object).\n\nThe doc argument represents the document that is tested for filtering.\n\nThe req argument includes more information about the request. With this argument, you can create filter functions that are more dynamic because they're based on multiple factors such as query parameters or the user context.\n\nFor example, you could control aspects of the filter function tests by using dynamic values that are provided as part of the HTTP request. However, in many filter function use cases, only the doc parameter is used.\n\nSee the following example design document that includes a filter function:\n\n{\n\"_id\":\"_design\/example_design_doc\",\n\"filters\": {\n\"example_filter\": \"function (doc, req) { ... }\"\n}\n}\n\nSee the following example of a filter function:\n\nfunction(doc, req){\n\/\/ we need only mail documents\nif (doc.type != 'mail'){\nreturn false;\n}\n\/\/ we're interested only in new ones","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-documents"},{"document_id":"ibmcld_00472-19526-21520","score":28.5929717285,"text":"\nIt differs from using \"fieldname:value\" in the q parameter only in that the values aren't analyzed. [Faceting](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-searchfaceting) must be enabled for this parameter to function. No JSON A JSON array that includes two elements: the field name and the value. Yes \n group_field Field by which to group search matches. Yes String A string that includes the name of a string field. Fields that include other data such as numbers, objects, or arrays can't be used. No \n group_limit Maximum group count. This field can be used only if group_field is specified. Yes Numeric No \n group_sort This field defines the order of the groups in a search that uses group_field. The default sort order is relevance. Yes JSON This field can have the same values as the sort field, so single fields and arrays of fields are supported. No \n highlight_fields Specifies which fields to highlight. If specified, the result object includes a highlights field with an entry for each specified field. Yes Array of strings Yes \n highlight_pre_tag A string that is inserted before the highlighted word in the highlights output. Yes, defaults to <em> String Yes \n highlight_post_tag A string that is inserted after the highlighted word in the highlights output. Yes, defaults to <\/em> String Yes \n highlight_number Number of fragments that are returned in highlights. If the search term exceeds the fragment size, then the entire search term is returned. Yes, defaults to 1 Numeric Yes \n highlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_00580-37889-39953","score":28.5921383901,"text":"\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-4796-6846","score":28.3884685386,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-6386-8382","score":28.1539529303,"text":"\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00546-1171-2777","score":27.7932837348,"text":"\n\"products\",\n)\n\ndatabaseInformation, response, err := service.GetDatabaseInformation(getDatabaseInformationOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(databaseInformation, \"\", \" \")\nfmt.Println(string(b))\n\nconst { CloudantV1 } = require('@ibm-cloud\/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.getDatabaseInformation({db: 'products'}).then(response => {\nconsole.log(response.result);\n});\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nThe elements of the returned structure are shown in the following table:\n\n\n\nTable 1. Database details\n\n Field Description \n\n compact_running Set to true if the database compaction routine is operating on this database. \n db_name The name of the database. \n disk_format_version The version of the physical format that is used for the data that is stored on disk. \n disk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-database-details"},{"document_id":"ibmcld_00579-1483-3406","score":27.5107383472,"text":"\nSince the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.\n\n\n\nThis example also means that a potential race condition exists here. The document might change, or be deleted, between the index and document read (although unlikely in practice).\n\nEmitting data into the index (a so-called \u201cprojection\u201d in relational algebra terms) means that you can fine-tune the exact subset of the document that you need. In other words, you don\u2019t need to emit the whole document. Emit a value that represents only the data you need in the app that is a cut-down object with minimal details, for example:\n\nemit(doc.indexed_field, {name: doc.name, dob: doc.dob});\n\nIf you change your mind on what fields you want to emit, the index needs rebuilding.\n\nIBM Cloudant Query\u2019s JSON indexes use views this way under the hood. IBM Cloudant Query can be a convenient replacement for some types of view queries, but not all. Do take the time to understand when to use one or the other.\n\n\n\n* IBM Cloudant Query [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_07028-8585-10420","score":26.4962641415,"text":"\nTo add an advanced rule model, complete the following steps:\n\n\n\n1. Create the model and export the ZIP file that contains the model resources.\n\nFor more information about how to export the model, see the instructions for your model source:\n\n\n\n* [Knowledge Studio for IBM Cloud Pak\u00ae for Data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-advanced-rules-model)\n* [Knowledge Studio for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-create-advanced-rules-model)\n* [Open source NLP Editor](https:\/\/github.com\/CODAIT\/nlp-editor)\n\n\n\n2. From the Teach domain concepts section of the Improvement tools panel, choose Advanced rules model.\n3. Click Upload.\n4. Specify a name for the model, and then choose the language that was used to define the model.\n5. Specify a name for the result field, which is the field in the index where the output of this enrichment will be stored.\n6. Click Upload to browse for the ZIP file that you exported earlier.\n7. Click Create.\n8. Choose the collection and field where you want to apply the enrichments from the model, and then click Apply.\n\n\n\n\n\n\n\n Output format for advanced rules \n\nKnowledge Studio uses the Annotation Query Language (AQL) to define the rules in an advanced rules model. Each model is defined by one or more views. Each view is a relational data structure that contains multiple data records. Each record is composed of values in columns that are defined by the view\u2019s schema. To facilitate representing these models, which are custom and therefore have various schemas, a uniform JSON output schema is used.\n\n\n\n* Each JSON object represents an Annotation Query Language (AQL) view.\n* The name-and-value pairs in the JSON objects represent the names and values of the attributes in the view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-ml"},{"document_id":"ibmcld_00580-41116-43256","score":26.3520705349,"text":"\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list. It contains data that is sorted by the fields you specify, for example, books that are sorted by date and title. If you perform a query that asks for data that matches a document's date and title, the indexed data structure can be used to speed up the query process. Instead of scanning through every document in turn, IBM Cloudant can jump to the relevant part of the index (say, the section on 20th century books) and retrieve the data much more quickly.\n\nIBM Cloudant Query indexes include two types of indexes: type=json and type=text. These indexes are backed by two underlying indexing technologies that we meet in subsequent parts of this course.\n\nAn index is defined when you POST some JSON to a database's _index endpoint.\n\nThe index object contains a fields array, which specifies which document attributes to index. Usually, the fields that need indexing are equivalent to the attributes used in the selector of a query you're going to use to retrieve the data. That is, if you need to query by the date field, we need to index the date field.\n\nAlthough the name of an index is optional, it's good practice and we follow this convention. It's good to ask IBM Cloudant a question and specify the name of the index you intend it to use. This practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_13493-1220-3010","score":25.976956818,"text":"\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03353-4-2000","score":31.2656666828,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03040-42016-43592","score":30.6764894283,"text":"\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.4 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.4 is compatible with IBM Cloud Pak\u00ae for Data version 2.5.\n\nCzech language not automatically enabled\n: The Czech language is not enabled automatically anymore.\n\nAssistants and Skills navigation menu update\n: The main menu options of Assistants and Skills have moved from being displayed at the top of the page to being shown as icons in a new navigation pane.\n\n\n\n* ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) Assistants\n* ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png) Skills\n\n\n\nSkills secondary navigation menu update\n: The tabbed pages for the tools that you use to develop a dialog skill were moved to a secondary navigation bar that is displayed when you open the skill.\n\n![Skills secondary navigation menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/secondary-nav.png)\n\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_03145-4-1748","score":30.3556908633,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Using built-in intents \n\nContent Catalogs provide an easy way to add common intents to your Watson Assistant dialog skill.\n\nIntents you add from the catalog are meant to provide a starting point. Add to or edit the catalog intents to tailor them for your use case.\n\nThe latest content catalog, named Covid-19, is available in Brazilian Portuguese, English, French, and Spanish only. For more information about language support for the catalogs, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n Adding a content catalog to your dialog skill \n\n\n\n1. Open your dialog skill, open the Content Catalog page.\n\n![Screen capture showing available catalogs](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/catalog-overview.png)\n2. Select a content catalog, such as Banking, to see the intents that are provided with it.\n\n![Screen capture showing Banking category intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/catalog-open.png)\n\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_03043-7-2031","score":30.0978778451,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03381-4-1869","score":29.9831711193,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03027-7-1946","score":29.7774698565,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03369-36856-39124","score":29.7423745874,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03054-18427-20301","score":29.5363773723,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03369-89572-91689","score":29.2694717756,"text":"\n: The technology preview user interface was replaced with the Watson Assistant standard user interface. If you used an Actions page to create actions and steps for your skill previously, you cannot access the Actions page anymore. Instead, use the Intents and Dialog pages to work with your skill.\n\n\n\n\n\n 16 March 2020 \n\nInstructions updated for Slack integrations\n: The steps required to set up a Slack integration have changed to reflect permission assignment changes that were made by Slack. For more information, see [Integrating with Slack](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-slack).\n\nOrder of response types is preserved\n: Previously, if you included a response type of Search skill in a list of response types for a dialog node, the search results were displayed last despite its placement in the list. This behavior was changed to show the search results in the appropriate order, namely in the sequence in which the search skill response type is listed for the dialog node.\n\n\n\n\n\n 10 March 2020 \n\nContextual entity support is generally available\n: You can add contextual entities to English-language dialog skills. For more information about contextual entities, see [Creating entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFrench language support added for autocorrection\n: Autocorrection helps your assistant understand what your customers want. It corrects misspellings in the input that customers submit before the input is evaluated. With more precise input, your assistant can more easily recognize entity mentions and understand the customer's intent. See [Correcting user input](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-spell-check) for more details.\n\nThe new system entities are used by new skills\n: For new English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills, the new system entities are enabled automatically. If you decide to turn on a system entity and add it to your dialog, it's the new and improved version of the system entity that is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_07578-18457-20516","score":29.1539380109,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1212442-1214450","score":16.9442316026,"text":"\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1215075-1217083","score":16.9442316026,"text":"\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08695-7-1852","score":16.4465384523,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_09088-12268-14104","score":15.9510129547,"text":"\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n\n\n\n\n\n What happens when I need to delete or deprovision my Key Protect instance? \n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n\n\n\n\n\n Why does the user interface show unauthorized access? \n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_09061-4-1966","score":15.9488914997,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4-1684","score":15.9437146222,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09088-10880-12721","score":15.9311033612,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_07578-1211120-1213024","score":15.8493769161,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":15.8493769161,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09192-4150-5583","score":15.612554404,"text":"\nIf the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys \n\nWhen you use the Key Protect user interface or REST API, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou're assigned a Manager access policy for the Key Protect instance. You try to delete a key, but the action fails with the following error message.\n\nConflict: Key could not be deleted. Status: 409, Correlation ID: 160cc463-71d1-4b30-a5f2-d3f7e9f2b75e\n\nYou also try to delete the key by using the Key Protect API, but you receive the following error message.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key could not be deleted. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16464-12399-14287","score":65.8656222848,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":65.0519905872,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":65.0519905872,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":64.2487973212,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-7044-9159","score":62.8659173939,"text":"\nYou can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common. For another example, if you create annotation sets with overlapping documents, but add one annotation set per task instead of adding all of the annotation sets to a single task, no overlapping documents will be found and inter-annotator agreement cannot be calculated.\n\n\n\n\n\n Procedure \n\nTo assess annotation agreement between human annotators:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab. Open the task that you want to evaluate.\n3. Click Calculate Inter-Annotator Agreement. The default view shows agreement scores for how consistently pairs of human annotators annotated mentions. The top row shows the overall consistency between each pair of annotators, and the table below shows how consistently a pair of annotators labeled specific mentions in the text.\n4. To explore how consistently pairs of human annotators annotated relations and coreferences, select Relation or Coreference from the first menu.\n5. To explore how consistently a pair of human annotators annotated entities, relations, or coreferences in specific overlapping documents, select Document in the second menu and then select the pair of annotators that you want to evaluate.\n6. After reviewing the scores, you can decide whether you want to approve or reject annotation sets that are in Submitted status. After an annotation set is submitted, a check box is displayed next to its name. Take one of these actions:\n\n\n\n* If the inter-annotator agreement scores are acceptable for an annotation set, select the check box and click Accept.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-7043-9158","score":62.8659173939,"text":"\nYou can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common. For another example, if you create annotation sets with overlapping documents, but add one annotation set per task instead of adding all of the annotation sets to a single task, no overlapping documents will be found and inter-annotator agreement cannot be calculated.\n\n\n\n\n\n Procedure \n\nTo assess annotation agreement between human annotators:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab. Open the task that you want to evaluate.\n3. Click Calculate Inter-Annotator Agreement. The default view shows agreement scores for how consistently pairs of human annotators annotated mentions. The top row shows the overall consistency between each pair of annotators, and the table below shows how consistently a pair of annotators labeled specific mentions in the text.\n4. To explore how consistently pairs of human annotators annotated relations and coreferences, select Relation or Coreference from the first menu.\n5. To explore how consistently a pair of human annotators annotated entities, relations, or coreferences in specific overlapping documents, select Document in the second menu and then select the pair of annotators that you want to evaluate.\n6. After reviewing the scores, you can decide whether you want to approve or reject annotation sets that are in Submitted status. After an annotation set is submitted, a check box is displayed next to its name. Take one of these actions:\n\n\n\n* If the inter-annotator agreement scores are acceptable for an annotation set, select the check box and click Accept.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-10867-12930","score":62.8566861956,"text":"\n[This screen capture shows two mentions connected by the relation type, \"founderOf\".](images\/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\n> Note: In a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16563-12333-14196","score":62.0203090831,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":61.5978231746,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":61.5978231746,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1772392868}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04184-7-1931","score":47.1601163717,"text":"\nUsing mutual TLS \n\nMutual Transport Layer Security (mTLS) authentication ensures that traffic is both secure and trusted in both directions between a client and server. It is only available for customers at the Enterprise or Security plan level.\n\nWhen mTLS is configured, access is granted only to requests with a corresponding client certificate. When a request reaches the application, CIS responds with a request for the client certificate. If the client fails to present the certificate, the request is not allowed to proceed. Otherwise, the key exchange proceeds.\n\nZoom\n\n![Diagram of mTLS handshake](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/mtls-handshake.png)\n\nFigure 1. Diagram of an mTLS handshake\n\n\n\n Configuring mutual TLS \n\nMutual TLS is not enabled by default. It is an additional service that requires prior authorization and enablement.\n\nTo obtain authorization, you must submit an IBM Support case.\n\nAfter mTLS is turned on for your account, take the following steps to enable it.\n\n\n\n1. Navigate to the Security page in the CIS UI.\n2. Select the Mutual TLS tab.\n3. Click Enable to enable the feature.\n\n\n\nAfter mTLS is enabled, it cannot be disabled.\n\nTo set up mTLS authentication in the IBM Cloud Internet Services UI for a particular endpoint:\n\n\n\n1. In the Root certificates table, click Add to define a new root certificate.\n2. Paste the certificate content into the content field, provide a name for the Root CA, and add one or more fully qualified domain names (FQDN) of the endpoints that you want to use this certificate. These FQDNs are the hostnames that are used for the resources being protected by the application policy. You must associate the Root CA with the FQDN that the application being protected uses.\n3. Click Save.\n\nIf your zone is using an intermediate certificate in addition to the root certificate, upload the entire chain.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features"},{"document_id":"ibmcld_08766-9493-11228","score":39.8375510777,"text":"\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_08739-11193-12939","score":39.5294852476,"text":"\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_08766-8126-10005","score":35.9028287171,"text":"\n[IBM Db2 default encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-db2.svg)\n\nFigure 5. IBM Db2 default encryption by using the standard PKCS #11 API\n\n\n\nWith the PKCS #11 library integration, Hyper Protect Crypto Services supports the industry-standard PKCS #11 API. The Hyper Protect Crypto Services PKCS #11 library connects your database to Hyper Protect Crypto Services to perform cryptographic operations. The database system can invoke operations to manage the TDE master encryption keys or the master keys in the Hyper Protect Crypto Services PKCS #11 library. The Hyper Protect Crypto Services PKCS #11 library then interacts with your Hyper Protect Crypto Services instance to provide the highest level of security for storing and managing your TDE master encryption keys or your master keys in the cloud. It, in turn, provides the highest level of security to your data encryption keys and your data.\n\n\n\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_04168-3136-4483","score":32.2221313516,"text":"\n* [Enabling Proxy protocol](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-enable-proxy-protocol)\n\n\n\n* [Using service endpoints to privately connect to CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-service-endpoints)\n* Working with TLS\n\n\n\n* [Setting Transport Layer Security (TLS) options](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options)\n* [Using mutual TLS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features)\n* [Authenticated origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-authenticated-origin-pull)\n\n\n\n* Working with WAFs\n\n\n\n* [WAF actions and rule sets](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-settings)\n* [Using the CIS Security Events capability](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-using-the-cis-security-events-capability)\n\n\n\n* Working with firewall rules\n\n\n\n* [Creating, editing, and deleting firewall rules](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-firewall-rules)\n* [Assigning firewall rule actions](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions)\n* [Using fields, functions, and expressions](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions)\n* [Prioritizing options](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-priority)\n\n\n\n* Working with global load balancers\n\n\n\n* [Configuring a global load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configure-glb)\n* Global load balancer features","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_05440-3062-4677","score":31.9684616689,"text":"\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"},{"document_id":"ibmcld_08666-8778-10361","score":31.3258713553,"text":"\nEP11_endpoint_port_number The port number of the EP11 API endpoint. It is located after the colon in the endpoint URL. \n enable_mtls Valid values are true or false to indicate whether you want to enable mutual TLS to add a second layer of authentication for PKCS #11 API access for Hyper Protect Crypto Services Standard Plan. By default, set it false as EP11 requires server-only authentication. For more information about the mutual TLS connections, see [Enabling the second layer of authentication for EP11 connections](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-enable-authentication-ep11). \n client_certificate If you enable mutual TLS connections, specify the file path of the client certificate that is uploaded to your instance by the certificate administrator. Otherwise, keep this field empty. \n client_certificate_private_key If you enable mutual TLS connections, specify the file path of the client certificate private key that is used to sign the certificate. Otherwise, keep this field empty. \n SO_user_name The name for the Security Officer (SO) user type. The PKCS #11 standard defines two types of users for login: the security officer (SO) and the normal user. For more information about the PKCS #11 user types, see <br><br>[PKCS #11 Cryptographic Token Interface Usage Guide Version 2.40 - Users](http:\/\/docs.oasis-open.org\/pkcs11\/pkcs11-ug\/v2.40\/cn02\/pkcs11-ug-v2.40-cn02.html_Toc406759984). \n normal_user_name The name for the normal user type. The PKCS #11 standard defines two types of users for login: the security officer (SO) and the normal user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-pkcs-api"},{"document_id":"ibmcld_05876-32979-34054","score":29.4677822457,"text":"\n2. Apply the authentication policy to a namespace.\n\nkubectl apply -f default.yaml -n <namespace>\n3. Create a destination rule file that is named destination-mtls.yaml. This policy configures service mesh workloads in a namespace to send traffic by using TLS. Note that the host: .local wildcard applies this destination rule to all services in the mesh.\n\napiVersion: \"networking.istio.io\/v1beta1\"\nkind: \"DestinationRule\"\nmetadata:\nname: \"destination-mtls\"\nspec:\nhost: \".local\"\ntrafficPolicy:\ntls:\nmode: ISTIO_MUTUAL\n4. Apply the destination rule.\n\nkubectl apply -f destination-mtls.yaml -n <namespace>\n5. If you want to achieve mTLS for service mesh workloads in other namespaces, repeat these steps each namespace.\n\n\n\nDestination rules are also used for non-authentication reasons, such as routing traffic to different versions of a service. Any destination rule that you create for a service must also contain the same TLS block that is set to mode: ISTIO_MUTUAL. This block prevents the rule from overriding the mesh-wide mTLS settings that you configured in this section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-mesh"},{"document_id":"ibmcld_05877-8738-10241","score":29.4383110055,"text":"\nCreate an authentication policy file that is named default.yaml. This policy is namespace-scoped and configures workloads in the service mesh to accept only encrypted requests with TLS. Note that no targets specifications are included because the policy applies to all services in the mesh in this namespace.\n\napiVersion: \"security.istio.io\/v1beta1\"\nkind: \"PeerAuthentication\"\nmetadata:\nname: \"default\"\nspec:\nmtls:\nmode: STRICT\n2. Apply the authentication policy to a namespace.\n\nkubectl apply -f default.yaml -n <namespace>\n3. Create a destination rule file that is named destination-mtls.yaml. This policy configures service mesh workloads in a namespace to send traffic by using TLS. Note that the host: .local wildcard applies this destination rule to all services in the mesh.\n\napiVersion: \"networking.istio.io\/v1beta1\"\nkind: \"DestinationRule\"\nmetadata:\nname: \"destination-mtls\"\nspec:\nhost: \".local\"\ntrafficPolicy:\ntls:\nmode: ISTIO_MUTUAL\n4. Apply the destination rule.\n\nkubectl apply -f destination-mtls.yaml -n <namespace>\n5. If you want to achieve mTLS for service mesh workloads in other namespaces, repeat these steps each namespace.\n\n\n\nDestination rules are also used for non-authentication reasons, such as routing traffic to different versions of a service. Any destination rule that you create for a service must also contain the same TLS block that is set to mode: ISTIO_MUTUAL. This block prevents the rule from overriding the mesh-wide mTLS settings that you configured in this section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-qs"},{"document_id":"ibmcld_04111-19172-20546","score":28.9915976186,"text":"\nDelete a mTLS application DELETE \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id} internet-svcs.security.manage internet-svcs.access-apps.delete \n Get mTLS policies GET \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies internet-svcs.security.read internet-svcs.access-policies.read \n Create a mTLS policy POST \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies internet-svcs.security.manage internet-svcs.access-policies.create \n Update a mTLS policy PUT \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id}\/policies\/{policy_id} internet-svcs.security.update internet-svcs.access-policies.update \n Delete a mTLS policy DELETE \/v1\/{crn}\/zones\/{domain_id}\/access\/apps\/{app_id} internet-svcs.security.manage internet-svcs.access-policies.delete \n\n\n\n\n\n\n\n Origin TLS Client Authentication \n\n\n\nTable 20. Edge Functions\n\n Action Method IAM ACTION AT ACTION \n\n List certificates used for origin TLS client authentication at domain level. GET \/v1\/{crn}\/zones\/{domain_id}\/origin_tls_client_auth internet-svcs.security.read internet-svcs.origin-tls-client-auth.read \n Create a certificate used for origin TLS client authentication at domain level. POST \/v1\/{crn}\/zones\/{domain_id}\/origin_tls_client_auth\/{cert_id} internet-svcs.security.manage internet-svcs.origin-tls-client-auth.create \n Delete a certificate used for origin TLS client authentication used at domain level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":64.6748737172,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":57.6889580017,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16313-8575-10638","score":38.8555298962,"text":"\nFor more information on uploading or downloading example phrases, see [Adding more examples](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-adding-more-examples).\n\n\n\n\n\n\n\n Editing the fallback action \n\nThe built-in Fallback action is automatically provided with each assistant and cannot be deleted. However, you can edit the Fallback action to modify the conversation your users have with the assistant when errors occur. For example, you might want to add steps or modify step conditions to provide more control over how specific error conditions are handled.\n\nTo edit the Fallback action, click Set by assistant in the list of actions, and then click Fallback.\n\nZoom\n\n![Fallback built-in action](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/fallback-action.png)\n\nFallback built-in action\n\nWhenever the Fallback action is triggered, the assistant also sets a value for the Fallback reason session variable. This value indicates what kind of situation led to the Fallback action being triggered. By default, this variable can have one of five values:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a live agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16313-10077-11045","score":38.6324382562,"text":"\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_09906-1621-3194","score":38.5264644204,"text":"\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"url\": \"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"url\":\"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_16356-7-2036","score":37.3478315834,"text":"\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16356-1613-3336","score":36.6329929423,"text":"\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input. Use this step to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity.\n\nFor example, you might add darn, dang, and heck as trigger words for the Show warning step:\n\nZoom\n\n![Adding trigger words to the Show warning step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/show-warning-phrases.png)\n\nAdding trigger words to the Show warning step\n\nIn this example, a customer enters darn, dang, or heck, the assistant responds with Please use appropriate language when interacting with the assistant. You can customize this message.\n\nIf the customer triggers the Show warning step again, the Fallback action is triggered. The default setting is if attempts exceed 2 total tries. You can customize this setting.\n\nIn the Fallback action, step 5 has:\n\n\n\n* Profanity detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_13761-7-2364","score":35.8028133931,"text":"\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_07140-17709-19868","score":35.7748600688,"text":"\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations. Optionally, a Knowledge Studio custom model can be specified to extract custom entities.\n\n\n\n* \"sentiment\" : boolean - optional - When true, sentiment analysis is performed on the extracted entity in the context of the surrounding content.\n* \"emotion\" : boolean - optional - When true, emotional tone analysis is performed on the extracted entity in the context of the surrounding content.\n* \"limit\" : INT - optional - The maximum number of entities to extract from the ingested document. The default is 50.\n* \"mentions\": boolean - optional - When true, the number of times that this entity is mentioned is recorded. The default is false.\n* \"mention_types\": boolean - optional - When true, the mention type for each mention of this entity is stored. The default is false.\n* \"sentence_location\": boolean - optional - When true, the sentence location of each entity mention is stored. The default is false.\n* \"model\" : string - optional - When specified, the custom model is used to extract entities instead of the public model. This option requires a Knowledge Studio custom model to be associated with your instance of Discovery. See [Integrating with Watson Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks) for more information.\n\n\n\n\n\n\n\n keywords \n\nThe keywords enrichment extracts instances of significant words within the text. To understand the difference between keywords, concepts, and entities, see [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_16251-6430-8753","score":35.0896867208,"text":"\nPortuguese (Brazilian) (pt-br) GA GA GA \n Spanish (es) GA GA GA \n Universal (xx) GA GA GA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the user interface itself (such as descriptions and labels) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee mandates that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing an assistant language \n\nAfter an assistant is created, its language cannot be modified.\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents with the Watson Assistant service. As such, both accented and nonaccented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the nonaccented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system provides the highest confidence scores in entities with exact matches. For example, barrio isn't detected if barri\u00f3 is in the training set; and barri\u00f3 isn't detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words that use the Spanish letter \u00f1 versus the letter n, such as \"u\u00f1a\" versus \"una\". In this case, the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.9066276098}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":23.4439194498,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":23.2370111195,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_01660-16615-18504","score":23.1844019249,"text":"\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/account\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_13429-166159-168045","score":22.8352192909,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_07642-0-563","score":22.3791160634,"text":"\n\n\n\n\n\n\n  AC-19 (5) - Full Device \/ Container-based Encryption \n\n\n\n  Control requirements \n\nAC-19 (5) - 0\n:   The organization employs [IBM Assignment: file level, full disk\/device, or both] to protect the confidentiality and integrity of information on [Assignment: organization-defined mobile devices].\n\n\n\n\n\n  NIST supplemental guidance \n\nContainer-based encryption provides a more fine-grained approach to the encryption of data\/information on mobile devices, including for example, encrypting selected data structures such as files, records, or fields.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-19.5"},{"document_id":"ibmcld_16727-1086316-1088349","score":22.2891978991,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1083825-1085863","score":22.2463062736,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14390-16273-17983","score":21.5595944301,"text":"\n* At the end of the documented process, your vCenter Server instance is running vSphere 7.0 Update 1c with N-VDS distributed switches. This configuration is different than the currently supported [Software BOM for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_bomvc_bom-software), which is vSphere 7.0 Update 3c with Distributed vSwitch 7.0.0.\n* For more information about the migration of N-VDS to VDS switches for vSphere 7.0 or later and NSX-T Data Center 3.0 and later, see [Migrate host switch to vSphere Distributed Switch](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-1039A36F-F55E-4A0A-B6C6-2C383F4A716D.html). Currently, this procedure is not verified on a VMware Solutions vCenter Server instance.\n* IBM Cloud is undertaking an assessment of the N-VDS to VDS conversion and the required changes to the automation database to allow this in-place upgrade.\n* Currently, Day 2 automation workflows such as add host or add cluster, are not tested against VMware Solutions vCenter Server instances that are upgraded from vSphere 6.7 to 7 and still using N-VDS distributed switches. Customers must assume that this automation might fail and that if this automation is required then the lift and shift migration approach used. If this automation is not needed, you can use the upgrade process that is documented.\n* A workaround for the add nodes and add cluster features is to use the VMware vSphere offering. For more information, see [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview). You must complete a number of manual tasks after the automated deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-v2t-migration"},{"document_id":"ibmcld_10852-44214-45420","score":21.1299445875,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_00959-2830-5215","score":20.8023803099,"text":"\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-5434-7003","score":75.9299940159,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":75.6976897559,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":75.6185400919,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15647-27849-29558","score":72.9114034956,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-27823-29559","score":72.4884693119,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15507-8094-9618","score":69.685677667,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15175-10224-11754","score":69.4943135845,"text":"\necc68c2f-96a1-4862-bc86-14f47e5d9ed8 aa-1-bx-boot-1617035447000\nCreated 2021-05-20T09:43:16+08:00\nVisibility private\nFile size(GB) -\nEncryption none\nResource group f22cf48f-8836-4527-9131-1d7c73ba85e9\n\n\n\n\n\n\n\n Schedule custom image lifecycle status changes by using the CLI \n\nWhen you import a custom image by using the command-line interface (CLI), you can also schedule the lifecycle status changes of the IBM Cloud VPC custom image at the same time by using options of the ibmcloud is image-create command.\n\nSpecify the name of the custom image to be created by using the IMAGE_NAME variable and the source by using the --source-volume option to indicate that the source is an existing boot volume.\n\nTo schedule the deprecate-at or obsolete-at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates and times, the deprecate-at date must be after the obsolete-at date and time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifv"},{"document_id":"ibmcld_15646-26617-28366","score":66.0520998885,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":66.0520998885,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-6657-8493","score":65.2594629918,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2857142857,"recall_5":0.2857142857,"recall_10":0.4285714286,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.3835663674,"ndcg_cut_10":0.3903229029}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07214-62508-64603","score":21.5458199914,"text":"\nAs a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded. : You can delete documents either individually in the API, using the [delete-doc](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-a-document) method, or you can delete whole collections, using the tooling or API, by using the [delete-collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-a-collection) method. : Upgrade your plan to a level that meets your storage needs. : Customers with size 12 or 3 environments will be automatically migrated to the Advanced plan.\n\n\n\n\n\n 17 July 2017 \n\nUpdate to relevancy training, natural language query, and highlighting : Relevancy training announced on 23 June 2017 moved from beta to GA status. : Natural language query announced on 19 June 2017 movedd from beta to GA status. : Highlighting announced on 25 May 2017 moved from beta to GA status.\n\nUpdate to enrichment mechanism : IBM Watson\u2122 Discovery is changing its enrichment mechanism from AlchemyLanguage to Natural Language Understanding as of this release. : AlchemyLanguage is in the process of being deprecated, so it is recommended that you start using Natural Language Understanding as soon as possible. : If you integrate with Watson Knowledge Studio, you must still use the AlchemyLanguage enrichment configuration. For details, see [Integrating with IBM Watson\u2122 Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks).\n\nUpdate to version string : The version string for all API calls changed to 2017-07-19 from 2017-06-25. This version enables an NLU default config on collection creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07214-60873-63067","score":21.0914441871,"text":"\nThese queries can be used as a starting point for writing your own queries. Sample queries are available for both IBM Watson\u2122 Discovery News and private collections.\n\nNew beta visual aggregation builder : Added the beta ability to write aggregations with a visual builder. Click Build in visual mode above the Write an aggregation query using the Discovery Query Language field to try it out. As you build your aggregation visually, the query displays in the Discovery Query Language below it.\n: The visual aggregation builder is currently supported only as a beta capability.\n\n\n\n\n\n 31 July 2017 \n\nNew release of Discovery News : A new version of IBM Watson\u2122 Discovery News was released. The original version is renamed as IBM Watson\u2122 Discovery News Original and is retired, with a removal from service date of 15 January 2018. : If you create a new instance of Discovery, you only have access to the new version of IBM Watson\u2122 Discovery News.\n\nNew pricing structure : A new pricing plan for IBM Watson\u2122 Discovery was released. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details.\n\nUpdate to version string : The version string for all API calls changed to 2017-08-01 from 2017-07-19. This version includes updates for the new pricing plan and the new version of Watson Discovery News. Update the version string to avoid conflicts and possible errors.\n\n\n\n\n\n 19 July 2017 \n\nChange to Pricing plans : Pricing changes will take effect on 1 August 2017. : Users that are currently on the deprecated 30 day free trial plan will be automatically migrated to the Lite plan. As a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_04326-3485-4944","score":20.623351349,"text":"\nExample: \"{\"database\":\"db1\",\"host\":\"databases.example.com\", \"password\":\"adminpassword\", \"port\":\"31365\", \"ssl\":\"true\", \"username\":\"admin\"}\". Required.\n\n--asset-category (string)\n: The asset category. Allowable values: [user,system].\n\n\n\n\n\n Examples \n\nAdd datasource connections\n\nibmcloud watson-query datasource-connection-add --datasource-type MongoDB --name mongo1 --origin-country us --properties \"{\"database\":\"db1\",\"host\":\"databases.example.com\", \"password\":\"adminpassword\", \"port\":\"31365\", \"ssl\":\"true\", \"username\":\"admin\"}\"\n\n\n\n\n\n\n\n ibmcloud watson-query datasource-connection-delete \n\nDeletes a data source connection from the watson query service.\n\nibmcloud watson-query datasource-connection-delete --connection-id CONNECTION-ID --cid CID\n\n\n\n Command options \n\n--connection-id (string)\n: The connection identifier for the platform.. Required.\n\n--cid (string)\n: The identifier of the connection for the watson query.. Required.\n\n\n\n\n\n Examples \n\nDelete datasource connection\n\nibmcloud watson-query datasource-connection-delete --connection-id 3ba0b656-bbb0-4f1c-8228-e6e800d3b2fa\n\n\n\n\n\n\n\n\n\n Users \n\nManage user access to virtualized table.\n\n\n\n ibmcloud watson-query virtualized-table-user-grant \n\nGrant a user access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --user USER\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16567-3486-4945","score":20.623351349,"text":"\nExample: \"{\"database\":\"db1\",\"host\":\"databases.example.com\", \"password\":\"adminpassword\", \"port\":\"31365\", \"ssl\":\"true\", \"username\":\"admin\"}\". Required.\n\n--asset-category (string)\n: The asset category. Allowable values: [user,system].\n\n\n\n\n\n Examples \n\nAdd datasource connections\n\nibmcloud watson-query datasource-connection-add --datasource-type MongoDB --name mongo1 --origin-country us --properties \"{\"database\":\"db1\",\"host\":\"databases.example.com\", \"password\":\"adminpassword\", \"port\":\"31365\", \"ssl\":\"true\", \"username\":\"admin\"}\"\n\n\n\n\n\n\n\n ibmcloud watson-query datasource-connection-delete \n\nDeletes a data source connection from the watson query service.\n\nibmcloud watson-query datasource-connection-delete --connection-id CONNECTION-ID --cid CID\n\n\n\n Command options \n\n--connection-id (string)\n: The connection identifier for the platform.. Required.\n\n--cid (string)\n: The identifier of the connection for the watson query.. Required.\n\n\n\n\n\n Examples \n\nDelete datasource connection\n\nibmcloud watson-query datasource-connection-delete --connection-id 3ba0b656-bbb0-4f1c-8228-e6e800d3b2fa\n\n\n\n\n\n\n\n\n\n Users \n\nManage user access to virtualized table.\n\n\n\n ibmcloud watson-query virtualized-table-user-grant \n\nGrant a user access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --user USER\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_16582-3525-4984","score":20.623351349,"text":"\nExample: \"{\"database\":\"db1\",\"host\":\"databases.example.com\", \"password\":\"adminpassword\", \"port\":\"31365\", \"ssl\":\"true\", \"username\":\"admin\"}\". Required.\n\n--asset-category (string)\n: The asset category. Allowable values: [user,system].\n\n\n\n\n\n Examples \n\nAdd datasource connections\n\nibmcloud watson-query datasource-connection-add --datasource-type MongoDB --name mongo1 --origin-country us --properties \"{\"database\":\"db1\",\"host\":\"databases.example.com\", \"password\":\"adminpassword\", \"port\":\"31365\", \"ssl\":\"true\", \"username\":\"admin\"}\"\n\n\n\n\n\n\n\n ibmcloud watson-query datasource-connection-delete \n\nDeletes a data source connection from the watson query service.\n\nibmcloud watson-query datasource-connection-delete --connection-id CONNECTION-ID --cid CID\n\n\n\n Command options \n\n--connection-id (string)\n: The connection identifier for the platform.. Required.\n\n--cid (string)\n: The identifier of the connection for the watson query.. Required.\n\n\n\n\n\n Examples \n\nDelete datasource connection\n\nibmcloud watson-query datasource-connection-delete --connection-id 3ba0b656-bbb0-4f1c-8228-e6e800d3b2fa\n\n\n\n\n\n\n\n\n\n Users \n\nManage user access to virtualized table.\n\n\n\n ibmcloud watson-query virtualized-table-user-grant \n\nGrant a user access to a specific virtualized table.\n\nibmcloud watson-query virtualized-table-user-grant --table-name TABLE-NAME --table-schema TABLE-SCHEMA --user USER\n\n\n\n Command options \n\n--table-name (string)\n: The name of the virtualized table. Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_16310-7-2016","score":20.5380516221,"text":"\nFilter query reference \n\nThe Watson Assistant service REST API offers powerful log search capabilities through filter queries. You can use the v2 \/logs API filter parameter to search your skill log for events that match a specified query.\n\nThe filter parameter is a cacheable query that limits the results to those matching the specified filter. You can filter on various objects that are part of the JSON response model (for example, the user input text, the detected intents and entities, or the confidence score).\n\nTo see examples of filter queries, see [Examples](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-referencefilter-reference-examples).\n\nFor more information about the \/logs GET method and its response model, refer to the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs).\n\n\n\n Filter query syntax \n\nThe following example shows the general form of a filter query:\n\n\n\n Location Query operator Term \n\n request.input.text :: \"IBM Watson\" \n\n\n\n\n\n* The location identifies the field that you want to filter on (in this example, request.input.text).\n* The query operator, which specifies the type of matching you want to use (fuzzy matching or exact matching).\n* The term specifies the expression or value you want to use to evaluate the field for matching. The term can contain literal text and operators, as described in the [next section](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-referencefilter-reference-operators).\n\n\n\nFiltering by intent or entity requires slightly different syntax from filtering on other fields. For more information, see [Filtering by intent or entity](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-referencefilter-reference-intent-entity).\n\nNote: The filter query syntax uses some characters that are not allowed in HTTP queries. Make sure that all special characters, including spaces and quotation marks, are URL encoded when sent as part of an HTTP query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference"},{"document_id":"ibmcld_13074-7-2122","score":19.8982999603,"text":"\nConfiguring Discovery \n\nConfiguring Discovery makes it possible to gain useful insights by enriching your own data and then delivering it in a query-able form.\n\nBefore you add your own content to Discovery, you must configure the basic parameters of the service ([Preparing the service for your documents](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicepreparing-the-service-for-your-documents)). This includes creating an environment and creating one or more collections within that environment.\n\n\n\n Preparing the service for your documents \n\nIn Discovery, the content that you upload is stored in a collection that is part of your environment. You must create the environment and collection before you can upload your content.\n\n\n\n* Environment \u2014 The environment defines the amount of storage space that you have for content in Discovery. A maximum of one environment can be created for each instance of Discovery.\n\nYou have several plans (Lite, Advanced, Premium) to choose from, see the [Discovery catalog](https:\/\/cloud.ibm.com\/catalog\/services\/discovery) and [Discovery Pricing Plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details. Your source files do not count against your plan size limit, only the size of the converted JSON that is indexed counts towards your size limit.\n* Collection \u2014 A collection is a grouping of your content within the environment. You must create at least one collection to be able to upload your content.\n\nCollections are comprised of your private data, but Discovery also includes Discovery News, a pre-enriched, public dataset.\n\nDiscovery News, a public data set that is pre-enriched with cognitive insights, is also included with Discovery. You can use it to query for insights; for example: news alerts, event detecting, and trending topics in the news; that you can integrate into your applications. See [Watson Discovery News](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-watson-discovery-news) for more information. You cannot adjust the Discovery News configuration or add documents to this collection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_04326-10875-12516","score":19.7821972858,"text":"\nThe json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options \n\n--virtualized-schema (string)\n: The schema of virtualized table to be deleted. Required.\n\n--virtualized-name (string)\n: The name of virtualized table to be deleted. Required.\n\n\n\n\n\n Examples \n\nDelete virtualized table\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema DV_IBMID_270001PD8Q --virtualized-name TABLE1\n\n\n\n\n\n\n\n\n\n Primary catalog \n\nManage the primary WKC catalog information in watson query console.\n\n\n\n ibmcloud watson-query primary-catalog \n\nGet primary catalog ID from the table.\n\nibmcloud watson-query primary-catalog\n\n\n\n Examples \n\nGet primary catalog ID from the table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16567-10878-12519","score":19.7821972858,"text":"\nThe json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options \n\n--virtualized-schema (string)\n: The schema of virtualized table to be deleted. Required.\n\n--virtualized-name (string)\n: The name of virtualized table to be deleted. Required.\n\n\n\n\n\n Examples \n\nDelete virtualized table\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema DV_IBMID_270001PD8Q --virtualized-name TABLE1\n\n\n\n\n\n\n\n\n\n Primary catalog \n\nManage the primary WKC catalog information in watson query console.\n\n\n\n ibmcloud watson-query primary-catalog \n\nGet primary catalog ID from the table.\n\nibmcloud watson-query primary-catalog\n\n\n\n Examples \n\nGet primary catalog ID from the table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_10811-9991-11469","score":19.576489142,"text":"\n[query-relations](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-relations) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, entities, context, sort, filter, count, evidence_count Query a Knowledge Graph relationship. \n [add-training-data](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-training-data) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, natural_language_query, filter, examples, Add a query to training data. \n [create-training-example](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-training-example) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, query_id, document_id, cross_reference, relevance Add an example to training data query. \n [delete-all-training-data](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id Delete all training data. \n [delete-training-data](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-training-data) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, query_id Delete a training data query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discovery"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":34.6206844274,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":34.5732298682,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_06004-36463-38401","score":31.0122652086,"text":"\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_07971-2155-4528","score":30.4041019118,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_10439-40150-42016","score":29.6168384936,"text":"\nAs you plan how many Service objects you need in your cluster, keep in mind that Kubernetes uses iptables to handle networking and port forwarding rules. If you run many services in your cluster, such as 5000, performance might be impacted.\n\n\n\n\n\n\n\n Securing apps \n\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_07578-365833-367834","score":29.2833832553,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":29.2833832553,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-6329-8623","score":28.6738913266,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":28.6738913266,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01447-7-2032","score":28.3196856362,"text":"\nAbout Container Registry \n\nUse IBM Cloud\u00ae Container Registry to store and access private container images in a highly available and scalable architecture.\n\nIBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image\n\nregistrythat is hosted and managed by IBM. You can use Container Registry by setting up your own imagenamespaceand pushing container images to your namespace.\n\nZoom\n\n![Diagram showing how you can interact with IBM Cloud Container Registry.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/images\/about_container_registry_v2.svg)\n\nFigure 1. How Container Registry interacts with your images\n\nA Docker image is the basis for every container that you create. An image is created from a\n\nDockerfile, which is a file that contains instructions to build the image. A Dockerfile might reference build artifacts in its instructions that are stored separately, such as an app, the configuration of the app, and its dependencies. Images are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry). By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03196-46002-48092","score":38.2640315355,"text":"\nYou can trigger a search of the existing material in real time to get the latest and most up-to-date answer for your customers.\n\nTo use the search skill response type, you must create a search skill and add it to the same assistant that uses this dialog skill. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\n\nTo add a Search skill response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Search skill.\n\nIndicates that you want to search an external data source for a relevant response.\n2. To edit the search query to pass to the Discovery service, click Customize, and then fill in the following fields:\n\n\n\n* Query: Optional. You can specify a specific query in natural language to pass to Discovery. If you do not add a query, then the customer's exact input text is passed as the query.\n\nFor example, you can specify What cities do you fly to?. This query value is passed to Discovery as a search query. Discovery uses natural language understanding to understand the query and to find an answer or relevant information about the subject in the data collection that is configured for the search skill.\n\nYou can include specific information provided by the user by referencing entities that were detected in the user's input as part of the query. For example, Tell me about @product. Or you can reference a context variable, such as Do you have flights to $destination?. Just be sure to design your dialog such that the search is not triggered unless any entities or context variables that you reference in the query have been set to valid values.\n\nThis field is equivalent to the Discovery natural_language_query parameter. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n\n\n\n* Filter: Optional. Specify a text string that defines information that must be present in any of the search results that are returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_16364-91253-93195","score":37.5908110332,"text":"\nSOC 2 reports provide details about the nature of internal controls that are implemented to protect customer-owned data. For more information, see [IBM Cloud compliance programs](https:\/\/www.ibm.com\/cloud\/compliance\/global).\n\n\n\n\n\n 25 February 2021 \n\nSearch skill can emphasize the answer\n: You can configure the search skill to highlight text in the search result passage that Discovery determines to be the exact answer to the customer's question. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\n\nIntegration changes\n: The following changes were made to the integrations:\n\n\n\n* The name of Preview link integration changed to Preview.\n* The Web chat and Preview integrations are no longer added automatically to every new assistant.\n\nThe integrations continue to be added to the My first assistant that is generated for you automatically when you first create a new service instance.\n\n\n\nMessage and log webhooks are generally available\n: The premessage, postmessage, and log webhooks are now generally available. For more information about them, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n\n\n\n\n\n 11 February 2021 \n\nThe user_id value is easier to access\n: The user_id property is used for billing purposes. Previously, it was available from the context object as follows:\n\n\n\n* v2: context.global.system.user_id\n* v1: context.metadata.user_id\n\n\n\nThe property is now specified at the root of the \/message request in addition to the context object. The built-in integrations typically set this property for you. If you're using a custom application and don't specify a user_id, the user_id is set to the session_id (v2) or conversation_id(v1) value.\n\nDigression bug fix\n: Fixed a bug where digression setting changes that were made to a node with slots were not being saved.\n\n\n\n\n\n 5 February 2021 \n\nDocumentation update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03043-3079-5106","score":36.1228313315,"text":"\nIn the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/complex-impl.png)\n\nAs you add information, the skill uses this unique data to build a machine learning model that can recognize these and similar user inputs. Each time you add or change the training data, the training process is triggered to ensure that the underlying model stays up-to-date as your customer needs and the topics they want to discuss change.\n\nFor help creating a dialog skill, see [Creating a dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add).\n\n\n\n\n\n Search skill \n\nWhen Watson Assistant doesn't have an explicit solution to a problem, it routes the user question to a search skill to find an answer from across your disparate sources of self-service content. The search skill interacts with the IBM Watson\u00ae Discovery service to extract this information from a configured data collection.\n\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03383-17365-19519","score":34.8331812596,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":34.8331812596,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03369-77396-79625","score":34.8185825236,"text":"\nThe new legacy API format simulates the legacy system entities behavior. In particular, it returns a metadata object and does not stop the service from idenfifying multiple system entities for the same input string. In addition, it returns an interpretation object, which was introduced with the new version of system entities. Review the interpretation object to see the useful information that is returned by the new version.\n\n\n\nUpdate your skills to use the new system entities from the Options>System Entities page.\n\nWeb chat security is generally available\n: Enable the security feature of web chat so that you can verify that messages sent to your assistant come from only your customers and can pass sensitive information to your assistant.\n\nWhen configuring the JWT, you no longer need to specify the Authentication Context Class Reference (acr) claim.\n\n\n\n\n\n 1 July 2020 \n\nSalesforce support is generally available\n: Integrate your web chat with Salesforce so your assistant can transfer customers who asks to speak to a person to a Salesforce agent who can answer their questions. For more information, see [Integrating with Salesforce](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce).\n\n\n\n\n\n 24 June 2020 \n\nGet better answers from search skill\n: The search skill now has a beta feature that limits the search results that are returned to include only those for which Discovery has calculated a 20% or higher confidence score. You can toggle the feature on or off from the Refine results to return more selective answers switch on the configuration page. You cannot change the confidence score threshold from 0.2. This beta feature is enabled by default. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\n\n\n\n\n\n 3 June 2020 \n\nZendesk support is generally available\n: Integrate your web chat with Zendesk so your assistant can transfer customers who asks to speak to a person to a Zendesk agent who can answer their questions. And now you can secure the connection to Zendesk. For more information, see [Adding support for transfers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk).\n\nPricing plan changes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03118-4-2208","score":34.5963492,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_16364-115172-117163","score":34.338492963,"text":"\nWhen configuring the JWT, you no longer need to specify the Authentication Context Class Reference (acr) claim.\n\n\n\n\n\n 1 July 2020 \n\nSalesforce support is generally available\n: Integrate your web chat with Salesforce so your assistant can transfer customers who asks to speak to a person to a Salesforce agent who can answer their questions. For more information, see [Integrating with Salesforce](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce).\n\n\n\n\n\n 24 June 2020 \n\nGet better answers from search skill\n: The search skill now has a beta feature that limits the search results that are returned to include only those for which Discovery has calculated a 20% or higher confidence score. You can toggle the feature on or off from the Refine results to return more selective answers switch on the configuration page. You cannot change the confidence score threshold from 0.2. This beta feature is enabled by default. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\n\n\n\n\n\n 3 June 2020 \n\nZendesk support is generally available\n: Integrate your web chat with Zendesk so your assistant can transfer customers who asks to speak to a person to a Zendesk agent who can answer their questions. And now you can secure the connection to Zendesk. For more information, see [Adding support for transfers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk).\n\nPricing plan changes\n: We continue to revamp the overall service plan structure for Watson Assistant. In April, we announced [a new low cost entry point](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-noteswatson-assistant-apr012020) for the Plus plan. Today, the Standard plan is being retired. Existing Standard plan users are not impacted; they can continue to work in their Standard instances. New users do not see the Standard plan as an option when they create a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03158-13826-15767","score":34.3308801826,"text":"\nFor more information, see [Transfer a call to a human agent](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n\n\n\n\n\n Optimize your dialog for voice \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your dialog text responses. To add formatting, use Markdown. For more information, see [Simple text response](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-simple-text).\n* Use the Connect to human agent response type to initiate a transfer to a human agent. For more information, see [Transferring a call to a human agent](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n* Use the Channel transfer response type to initiate a transfer to the web chat integration. For more information, see [Transferring the caller to the web chat integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n* The pause response type is not supported. If you want to add a pause, use the turn_settings.timeout_count context variable (for more information, see [Context variables that are set by your dialog or actions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-contextphone-context-variables-set-by-dialog)).\n* You can include search skill response types in dialog nodes that the phone integration will read. The introductory message (I searched my knowledge base and so on), and then the body of only the first search result is read.\n\nThe search skill response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03006-4831-6845","score":33.8180636567,"text":"\nDefine one intent for each goal that can be identified in a user's input. For example, you might define an intent that is named store_hours that answers questions about store hours. For each intent, you add sample utterances that reflect the input customers might use to ask for the information they need, such as, What time do you open?\n\nOr use prebuilt content catalogs that are provided by IBM to get started with data that addresses common customer goals.\n* Dialog: Use the dialog tool to build a dialog flow that incorporates your intents. The dialog flow is represented graphically in the tool as a tree. You can add a branch to process each of the intents that you want your assistant to handle.\n* Entities: An entity represents a term or object that provides context for an intent. For example, an entity might be a city name that helps your dialog to distinguish which store the user wants to know store hours for. After you add entities, update your dialog to use them. Add dialog nodes that handle the many possible permutations of a request based on the entities that are found in the user input.\n\n\n\nAs you add training data, a natural language classifier is automatically added to the skill. The classifier model is trained to understand the types of requests that you teach your assistant to listen for and respond to.\n3. Create a search skill. Configure a connection to a Discovery instance. If the dialog is configured to perform a search or is not designed to answer a particular type of question, the assistant searches the configured external data sources to find a response.\n4. Add the skills to your assistant.\n5. Bring the assistant to your customers where they are by adding integrations.\n\nBuild your own client application as the user interface for the assistant. Or add the built-in web chat integration to your company website.\n\n\n\nRead more about these steps by following these links:\n\n\n\n* [Assistant overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":57.7193374424,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":48.2838523563,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":43.5532859926,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":38.069508738,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-7-1743","score":37.9532660261,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":37.7769210059,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":33.0165661705,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":28.3726783703,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-2884-4620","score":23.429710874,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12344-0-1245","score":19.9057697846,"text":"\n\n\n\n\n\n\n  Why generate SDKs? \n\n\n\n  Leverage code generation \n\nThe basic service-level elements of the SDK SHOULD be generated from the API definition.\n\nThe reasons for using SDK generation include:\n\n\n\n*  Faster time to market. Reduce the time it takes to add SDK support for new features in a service.\n*  Improved quality. Avoid \u201ccopy-and-paste\u201d and typo errors that occur in hand-written SDKs.\n*  Enforced compliance. Improve and enforce agreement with the API definition.\n*  Enforced consistency. Establish a common style for a particular language SDK across a family of APIs.\n*  Increased adoption. Generated SDKs have common style, making them easier for developers to learn.\n\n\n\n\n\n\n\n  Core SDK libraries \n\nSDKs produced with generation require a common set of capabilities, such as networking operations or authentication mechanisms. Handwritten SDKs are also welcome to leverage these common operations.\n\nCore libraries:\n\n\n\n*  [IBM go-sdk-core](https:\/\/github.com\/IBM\/go-sdk-core)\n*  [IBM java-sdk-core](https:\/\/github.com\/IBM\/java-sdk-core)\n*  [IBM node-sdk-core](https:\/\/github.com\/IBM\/node-sdk-core)\n*  [IBM python-sdk-core](https:\/\/github.com\/IBM\/python-sdk-core)\n*  [IBM swift-sdk-core](https:\/\/github.com\/IBM\/swift-sdk-core)\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-sdkgen"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06843-4238-6198","score":24.5453039455,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-8087-10171","score":24.1400264663,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06836-18833-20499","score":23.0497570092,"text":"\nPull request pipeline stages setup, test, detect-secrets, and branch-protection. The detect-secrets and branch-protection stages are not custom stages. They are provided by the pipelines by default. \n Continuous integration pipeline stages setup, test, static-scan, containerize, sign-artifact, deploy, acceptance-test, scan-artifact, release, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n continuous deployment pipeline stages setup, deploy, acceptance-test, create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request. The create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request stages are not custom stages. They are provided by the pipelines by default. \n Continuous compliance pipeline stages setup, test, static-scan, scan-artifact, acceptance-test, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n\n\n\n\n\n Example usage \n\n List saved stage results\n$ get_data result\ndetect-secrets\nbranch-protection\n\n Get stage result\n$ get_data result detect-secrets\nsuccess\n\nFor more information about the Stage Results API, see [Using the Stage Results API in custom scripts](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-stage-results).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_07899-3004-4915","score":22.512822843,"text":"\nSI-2 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"},{"document_id":"ibmcld_07844-4589-6711","score":22.3272368387,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07578-1213887-1215935","score":22.0479380329,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":22.0479380329,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07844-3757-5369","score":22.0368295112,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07844-2925-4586","score":22.0312527791,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07899-4108-6235","score":21.8761301726,"text":"\nSI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain collects software bills of materials (SBOM) to provide transparency in build artifacts<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain signs build artifacts to attest their provenance<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13429-127288-129174","score":44.9560742852,"text":"\nIf your application uses the sessions interface, you must migrate to one of the following interfaces by September 7:\n\n\n\n* For stream-based speech recognition (including live-use cases), use the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), which provides access to interim results and the lowest latency.\n* For file-based speech recognition, use one of the following interfaces:\n\n\n\n* For shorter files of up to a few minutes of audio, use either the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http)(POST \/v1\/recognize) or the [asynchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-async) (POST \/v1\/recognitions).\n* For longer files of more than a few minutes of audio, use the asynchronous HTTP interface. The asynchronous HTTP interface accepts as much as 1 GB of audio data with a single request.\n\n\n\n\n\nThe WebSocket and HTTP interfaces provide the same results as the sessions interface (only the WebSocket interface provides interim results). You can also use one of the Watson SDKs, which simplify application development with any of the interfaces. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n\n\n 13 July 2018 \n\nUpdates to Spanish narrowband model for improved speech recognition\n: The Spanish narrowband model, es-ES_NarrowbandModel, was updated for improved speech recognition. By default, the service automatically uses the updated model for all recognition requests. If you have custom language or custom acoustic models that are based on this model, you must upgrade your custom models to take advantage of the updates by using the following methods:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/upgrade_model\n* POST \/v1\/acoustic_customizations\/{customization_id}\/upgrade_model","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13455-7-1568","score":41.9476946273,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13263-7-1922","score":40.8952514621,"text":"\nUsing a custom acoustic model for speech recognition \n\nAcoustic model customization is available only for previous-generation models. It is not available for next-generation models.\n\nOnce you create and train your custom acoustic model, you can use it in speech recognition requests by using the acoustic_customization_id query parameter. By default, no custom acoustic model is used with a request. You can create multiple custom acoustic models for the same or different domains. But you can specify only one custom acoustic model at a time for a speech recognition request. You must issue the request with credentials for the instance of the service that owns the custom model.\n\nA custom model can be used only with the base model for which it is created. If your custom model is based on a model other than the default, you must also specify that base model with the model query parameter. For more information, see [Using the default model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-usemodels-use-default).\n\nYou can also specify a custom language model to be used with the request, which can increase transcription accuracy. For more information, see [Using custom language and custom acoustic models for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-useBothuseBothRecognize).\n\n\n\n Examples of using a custom acoustic model \n\nThe following examples show the use of a custom acoustic model with each speech recognition interface:\n\n\n\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), use the \/v1\/recognize method. The specified custom model is used for all requests that are sent over the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&model=en-US_NarrowbandModel'\n+ '&acoustic_customization_id={customization_id}';","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-acousticUse"},{"document_id":"ibmcld_13361-7-1989","score":40.7674158483,"text":"\nUsing a grammar for speech recognition \n\nOnce you create and train your custom language model with your grammar, you can use the grammar in speech recognition requests:\n\n\n\n* Use the language_customization_id query parameter to specify the customization ID (GUID) of the custom language model for which the grammar is defined. A custom model can be used only with the base model for which it is created. If your custom model is based on a model other than the default, you must also specify that base model with the model query parameter. For more information, see [Using the default model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-usemodels-use-default). You must issue the request with credentials for the instance of the service that owns the model.\n* Use the grammar_name parameter to specify the name of the grammar. You can specify only a single grammar with a request.\n\n\n\nWhen you use a grammar, the service recognizes only words from the specified grammar. The service does not use custom words that were added from corpora, that were added or modified individually, or that are recognized by other grammars.\n\nFor more information about the languages and models that support grammars and their level of support (generally available or beta), see [Language support for customization](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-support).\n\n\n\n Examples of using a grammar with a custom language model \n\nThe following examples show the use of a grammar with a custom language model for each speech recognition interface:\n\n\n\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13429-108147-110176","score":40.4861401714,"text":"\n28 January 2019 \n\nNew support for IBM Cloud IAM by WebSocket interface\n: The WebSocket interface now supports token-based Identity and Access Management (IAM) authentication from browser-based JavaScript code. The limitation to the contrary has been removed. To establish an authenticated connection with the WebSocket \/v1\/recognize method:\n\n\n\n* If you use IAM authentication, include the access_token query parameter.\n* If you use Cloud Foundry service credentials, include the watson-token query parameter.\n\n\n\nFor more information, see [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open).\n\n\n\n\n\n 20 December 2018 \n\nNew beta grammars feature for custom language models now available\n: The service now supports grammars for speech recognition. Grammars are available as beta functionality for all languages that support language model customization. You can add grammars to a custom language model and use them to restrict the set of phrases that the service can recognize from audio. You can define a grammar in Augmented Backus-Naur Form (ABNF) or XML Form.\n\nThe following four methods are available for working with grammars:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} adds a grammar file to a custom language model.\n* GET \/v1\/customizations\/{customization_id}\/grammars lists information about all grammars for a custom model.\n* GET \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} returns information about a specified grammar for a custom model.\n* DELETE \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} removes an existing grammar from a custom model.\n\n\n\nYou can use a grammar for speech recognition with the WebSocket and HTTP interfaces. Use the language_customization_id and grammar_name parameters to identify the custom model and the grammar that you want to use. Currently, you can use only a single grammar with a speech recognition request.\n\nFor more information about grammars, see the following documentation:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13429-118420-120353","score":40.4315879713,"text":"\nWhen you use the curl command to make a speech recognition request with the HTTP interface, you must specify the audio format with the Content-Type header, specify \"Content-Type: application\/octet-stream\", or specify \"Content-Type:\". If you omit the header entirely, curl uses a default value of application\/x-www-form-urlencoded. Most of the examples in this documentation continue to specify the format for speech recognition requests regardless of whether it's required.\n\nThis change applies to the following methods:\n\n\n\n* \/v1\/recognize for WebSocket requests. The content-type field of the text message that you send to initiate a request over an open WebSocket connection is now optional.\n* POST \/v1\/recognize for synchronous HTTP requests. The Content-Type header is now optional. (For multipart requests, the part_content_type field of the JSON metadata is also now optional.)\n* POST \/v1\/recognitions for asynchronous HTTP requests. The Content-Type header is now optional.\n\n\n\nFor more information, see [Audio formats](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-list).\n\nUpdates to Brazilian Portuguese broadband model for improved speech recognition\n: The Brazilian Portuguese broadband model, pt-BR_BroadbandModel, was updated for improved speech recognition. By default, the service automatically uses the updated model for all recognition requests. If you have custom language or custom acoustic models that are based on this model, you must upgrade your existing custom models to take advantage of the updates by using the following methods:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/upgrade_model\n* POST \/v1\/acoustic_customizations\/{customization_id}\/upgrade_model\n\n\n\nFor more information, see [Upgrading custom models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-upgrade).\n\nThe customization_id parameter renamed to language_customization_id","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13384-7-1898","score":40.111963061,"text":"\nUsing a custom language model for speech recognition \n\nOnce you create and train your custom language model, you can use it in speech recognition requests by using the language_customization_id query parameter. By default, no custom language model is used with a request. You can create multiple custom language models for the same or different domains. But you can specify only one custom language model at a time for a speech recognition request. You must issue the request with credentials for the instance of the service that owns the custom model.\n\nA custom model can be used only with the base model for which it is created. If your custom model is based on a model other than the default, you must also specify that base model with the model query parameter. For more information, see [Using the default model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-usemodels-use-default).\n\nFor information about telling the service how much weight to give to words from a custom model, see [Using customization weight](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageUseweight). For examples that use a grammar with a custom language model, see [Using a grammar for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse).\n\n\n\n Examples of using a custom language model \n\nThe following examples show the use of a custom language model with each speech recognition interface. In this case, the custom model that is used is based on the next-generation model en-US_Telephony.\n\n\n\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), use the \/v1\/recognize method. The specified custom model is used for all requests that are sent over the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageUse"},{"document_id":"ibmcld_13429-38145-40029","score":39.2165180647,"text":"\nDifferences exist between the use of the sounds_like field for custom models that are based on next-generation and previous-generation models. For more information about using the sounds_like field with custom models that are based on next-generation models, see [Working with custom words for next-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ngworkingWords-ng).\n\nImportant: Deprecated customization_id parameter removed from the documentation\n: Important: On [9 October 2018](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notesspeech-to-text-9october2018), the customization_id parameter of all speech recognition requests was deprecated and replaced by the language_customization_id parameter. The customization_id parameter has now been removed from the documentation for the speech recognition methods:\n\n\n\n* \/v1\/recognize for WebSocket requests\n* POST \/v1\/recognize for synchronous HTTP requests (including multipart requests)\n* POST \/v1\/recognitions for asynchronous HTTP requests\n\n\n\nNote: If you use the Watson SDKs, make sure that you have updated any application code to use the language_customization_id parameter instead of the customization_id parameter. The customization_id parameter will no longer be available from the equivalent methods of the SDKs as of their next major release. For more information about the speech recognition methods, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text\/speech-to-textservice-endpoint).\n\n\n\n\n\n 17 March 2022 \n\nGrammar support for next-generation models is now generally available\n: Grammar support is now generally available (GA) for next-general models that meet the following conditions:\n\n\n\n* The models are generally available.\n* The models support language model customization.\n\n\n\nFor more information, see the following topics:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13429-109689-111379","score":39.095443196,"text":"\n* DELETE \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} removes an existing grammar from a custom model.\n\n\n\nYou can use a grammar for speech recognition with the WebSocket and HTTP interfaces. Use the language_customization_id and grammar_name parameters to identify the custom model and the grammar that you want to use. Currently, you can use only a single grammar with a speech recognition request.\n\nFor more information about grammars, see the following documentation:\n\n\n\n* [Using grammars with custom language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammars)\n* [Understanding grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUnderstand)\n* [Adding a grammar to a custom language model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarAdd)\n* [Using a grammar for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse)\n* [Managing grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageGrammars)\n* [Example grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarExamples)\n\n\n\nFor information about all methods of the interface, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nNew numeric redaction feature for US English, Japanese, and Korean now available\n: A new numeric redaction feature is now available to mask numbers that have three or more consecutive digits. Redaction is intended to remove sensitive personal information, such as credit card numbers, from transcripts. You enable the feature by setting the redaction parameter to true on a recognition request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13446-7-2012","score":38.9963783877,"text":"\nParameter summary \n\nThe following sections provide a summary of all of the parameters that are available for speech recognition. The information includes availability for previous- and next-generation models, and support and usage for speech recognition interfaces.\n\n\n\n* For more information about previous-generation languages and models, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n* For more information about next-generation languages and models, see [Next-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ng).\n\n\n\n\n\n access_token \n\nA required access token that you use to establish an authenticated connection with the WebSocket interface. For more information, see [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open).\n\n\n\nTable 1. The access_token parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Not supported \n Asynchronous HTTP Not supported \n\n\n\n\n\n\n\n acoustic_customization_id \n\nAn optional customization ID for a custom acoustic model that is adapted for the acoustic characteristics of your environment and speakers. By default, no custom model is used. For more information, see [Using a custom acoustic model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-acousticUse).\n\n\n\nTable 2. The acoustic_customization_id parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available or beta for all models that support acoustic model customization. For more information, see [Customization support for previous-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-supportcustom-language-support-pg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":44.7610729394,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16384-1889-3334","score":40.7821848853,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16384-7-2422","score":38.758810653,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03080-7-1901","score":37.0603647009,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":36.9774536788,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03421-1518-3290","score":36.8506333281,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_02855-5574-7284","score":36.7626094275,"text":"\nFor more information, see the [Using a custom launcher tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03166-8640-10452","score":36.0362125336,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-1529-3357","score":35.8045601201,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16334-27263-29119","score":35.447907684,"text":"\nFor more information about the suggestions feature, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate). For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* onError callback: The new onError callback option in the web chat configuration enables you to specify a callback function that is called if errors occur in the web chat. This makes it possible for you to handle any errors or outages that occur with the web chat. For more information, see [Listening for errors](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail).\n* Session ID available in widget state: The state information returned by the getState() instance method now includes the session ID for the current conversation. For more information, see [instance.getState()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsgetState).\n* IBM watermark: The web chat can now display a Built with IBM Watson watermark to users. This watermark is always enabled for any new web chat integrations on Lite plans. For more information, see [Create a web chat instance to add to your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.530721274}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-593375-595353","score":19.8481827613,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-593333-595311","score":19.8481827613,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11997-5537-6386","score":18.3022879188,"text":"\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.\n* See [understanding blueprint templates and configuration](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-templates) to dig into how to define cloud environments using blueprint templates and inputs of latest version.\n* [Beta code for Schematics Blueprints](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-beta-limitations) to provide your feedback and understand beta limitations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro"},{"document_id":"ibmcld_12581-17606-19704","score":17.0529602052,"text":"\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom"},{"document_id":"ibmcld_08921-1291-2538","score":16.9633944226,"text":"\n\"name\": \"Schematic Dev Workspace\",\n\u00a0 \"type\": [\n\u00a0\u00a0\u00a0 \"terraform_v0.13.7\"\n\u00a0 ],\n\u00a0 \"location\": \"us-south\",\n\u00a0 \"description\": \"Schematic Dev Workspace\",\n\u00a0 \"tags\": [],\n\u00a0 \"template_repo\": {\n\u00a0\u00a0\u00a0 \"url\": \"<GitHub repo URL>\",\n\u00a0\u00a0\u00a0 \"githubtoken\": \"<github-token>\"\n\u00a0 }\n\n\n\n Example Python request for schematics_variables_update.py file \n\nThe following Python example request is for the example file, schematics_variables_update.py.\n\nimport logging, os, json\n\nlogging.basicConfig()\nlogging.root.setLevel(logging.NOTSET)\nlogging.basicConfig(level=logging.NOTSET)\n\nfrom schematics_env_class import HPCCEnvironmentValues\n\nlogging.info(\"Schematic Variable Update Started\")\n\nif __name__ == '__main__':\n\n\u00a0\u00a0\u00a0 json_files = os.path.join(os.path.abspath(\".\"), \"config.json\")\n\n\u00a0\u00a0\u00a0 with open(json_files, \"r\") as file:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 config_data = json.load(file)\n\n\u00a0\u00a0\u00a0 api_key = config_data[\"template_data\"][\"variablestore\"][\"value\"]\n\n\u00a0\u00a0\u00a0 schematic_obj = HPCCEnvironmentValues(api_key)\n\n\u00a0\u00a0\u00a0 workspace_response = schematic_obj.schematics_service.get_workspace(w_id=\"<workspace id>\").get_result()\n\u00a0\u00a0\u00a0 schematic_obj.update_variables(w_id=\"<workspace id>\",\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 t_id=workspace_response[\"template_data\"][\"id\"],\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 variablestore=config_data[\"template_data\"][\"variablestore\"]\n\u00a0\u00a0\u00a0 )","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-update-variables"},{"document_id":"ibmcld_12008-4112-6332","score":16.7119464645,"text":"\nCorrect the Terraform config error at source and push a new release to its Git source repository.\n\nIf explicit version of the blueprint modules is used on specific branches. The blueprint template requires updating in its Git repository to specify the new release tag or branch for the module statement.\n\n\n\n* Update the blueprint module statements to specify the new module version.\n* Push the new release of the blueprint template to its Git source repository. With an updated release tag for the template if needed.\n\n\n\nFor modules, when no Git release is specified on the blueprint module statements and relaxed module version are used. No update to the blueprint template is needed. The current change to the module repository is pulled automatically by Schematics.\n\nRun the ibmcloud schematics blueprint update command to refresh the blueprint configuration that is stored by Schematics with the update to the blueprint template. With latest release, Schematics identifies the updated module Git repository and run the Pull-Latest to update any modules with the modified Terraform configurations.\n\nibmcloud schematics blueprint update -id <blueprint_ID>\u00a0\n\nIf explicit version is used with release tags for each blueprint template release, the blueprint configuration must be updated in Schematics with the new release tag.\n\nibmcloud schematics blueprint update --id <blueprint_ID> --bp-git-release x.y.z\u00a0\u00a0\n\nFinally, run the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and to complete all operations against all modules.\n\nibmcloud schematics blueprint apply -id <blueprint_ID>\u00a0\n\n\n\n\n\n Blueprint apply failure due to Terraform timeouts or transient failures \n\n What\u2019s happening \n\nWhen you run the blueprint apply command, it fails with message that the install of module fails.\n\n Why it\u2019s happening \n\nAnalysis of the logs indicates that the modules Terraform apply operation that is timed out or a transient failure occurs.\n\n How to fix it \n\nNo user action must be necessary to recover and the apply operation can be retried.\n\nRun the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and complete all operations against all modules.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-apply-fails"},{"document_id":"ibmcld_08295-130293-131214","score":16.5843858804,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"},{"document_id":"ibmcld_12258-139533-140454","score":16.5843858804,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference&interface=cli"},{"document_id":"ibmcld_04516-139667-140633","score":16.4944145749,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace. Initial support for files up to 4MB in size.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-schematics-cli-reference"},{"document_id":"ibmcld_08331-131395-132711","score":16.4052360253,"text":"\ntemplate_data[0].variablestore[v].use_default Optional Set the use_default parameter to true to override the default .tfvars parameter. By default, this parameter is set to false. \n github_source_repo_url Optional Enter the link to your GitHub repository. The link can point to the master branch, a different branch, or a subdirectory. \n\n\n\n\n\n\n\n Example for variable store \n\n\"variablestore\": [\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-schematics-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
